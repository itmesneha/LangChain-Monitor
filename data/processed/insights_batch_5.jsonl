{"batch_issues": [{"ollama_summary": "This GitHub issue requests a feature to allow LangGraph v1.0 to utilize Anthropic prompt caching via cache control within the system prompt argument of the `create_agent` system. Currently, the API doesn’t support structured system messages, hindering the ability to leverage Anthropic’s caching mechanism. The proposed solution involves adding support for structured system messages to the create agent system prompt.", "final_category": "feature", "comments": []}, {"ollama_summary": "This issue stems from a compatibility problem between LangChain V1 and the `langchain aws==1.0.0` package, which is dependent on `langchain core=0.3.0,<0.4.0`. This dependency creates a fundamental conflict, rendering the upgrade to LangChain V1 problematic and potentially causing errors.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `create_agent()` system prompt is failing to support array inputs required by the Anthropic API, specifically preventing the use of advanced features like separate cache control.  The issue appears to be a bug within LangChain rather than the user’s code, and a minimal reproducible example has been provided to demonstrate the problem.  Currently, the solution involves concatenating text blocks into a single string, which is a workaround that loses the necessary API functionality.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-22T01:41:22Z", "body_clean": "@ccurme do you know if we support this via SystemMessage? If so we could show some examples of passing SystemMessage for system message instead of a string literal"}]}, {"ollama_summary": "This issue stems from a conflict between the `langgraph_supervisor` package and the `langgraph>=1.0.0` dependency requirement. The latest version of `langgraph` (1.0.1) is incompatible with the `langgraph_supervisor` package, which requires `langgraph` version 0.6.0 or higher. This conflict prevents the `pip compile` command from running successfully, requiring a solution involving updating the `langgraph` package to a compatible version.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-10-22T01:43:47Z", "body_clean": "@KaushalBitcot we'll release langgraph supervisor in a bit. Just as a heads up we don't expect it to work with the new create agent abstraction. So it's mostly to ease migration. We added a tutorial that shows how to create a supervisor from scratch: [link] It's only a little bit extra code over the package, but doesn't introduce any additional abstractions, and gives you complete control over the context engineering into your agent. If you're able to look at the tutorial and let me know if there's anything that the library solves that isn't obvious how to accomplish with the example shown in the tutorial? Would be greatly appreciated!"}, {"author": "eyurtsev", "created_at": "2025-10-22T01:44:23Z", "body_clean": "I'll release supervisor tomorrow"}]}, {"ollama_summary": "The code is importing the `AgentExecutor` from the `langchain.agents` package incorrectly, causing an `ImportError`. This issue appears to be a bug within the LangChain library itself, not a problem with the user's code. The solution involves providing a minimal reproducible example demonstrating the error, which the user can easily test.", "final_category": "bug", "comments": [{"author": "Anindya4", "created_at": "2025-10-21T08:50:13Z", "body_clean": "Unfortunately LangChain deprecated the [code] class from version 1.0.0. But you can still use them in lesser version like 0.3.X. For more details follow this [doc]( [link]"}, {"author": "ccurme", "created_at": "2025-10-21T13:13:51Z", "body_clean": "In addition to what @Anindya4 said, most deprecated functionality was kept alive and compatible with the 1.0 releases via the new [code] package. See release notes [here]( [link] You should be able to update your dependencies and imports from [code] to [code] : [code]"}]}], "business_insights": ["Anthropic caching mechanisms require structured system messages, posing a challenge for LangChain’s API integration.", "LangChain’s current API design hinders the utilization of Anthropic’s caching, requiring a solution.", "The bug in create_agent() impacts the ability to leverage Anthropic’s caching.", "The dependency conflict within LangChain V1 and langchain aws==1.0.0 is a critical issue.", "The bug in the create_agent() system prompt requires a workaround that degrades API functionality."], "technical_insights": ["LangChain’s API design must accommodate structured system messages for Anthropic caching.", "The dependency conflict within LangChain V1 and langchain aws==1.0.0 necessitates a solution.", "The create_agent() system prompt’s failure to support array inputs is a bug within LangChain.", "The langgraph_supervisor package’s incompatibility with langgraph>=1.0.0 creates a conflict.", "The create_agent() bug requires a minimal reproducible example to demonstrate the problem."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Anthropic caching mechanisms require structured system messages, posing a challenge for LangChain’s API integration.\n2.  LangChain’s current API design hinders the utilization of Anthropic’s caching, requiring a solution.\n3.  The bug in `create_agent()` impacts the ability to leverage Anthropic’s caching.\n4.  The dependency conflict within LangChain V1 and `langchain aws==1.0.0` is a critical issue.\n5.  The bug in the `create_agent()` system prompt requires a workaround that degrades API functionality.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s API design must accommodate structured system messages for Anthropic caching.\n2.  The dependency conflict within LangChain V1 and `langchain aws==1.0.0` necessitates a solution.\n3.  The `create_agent()` system prompt’s failure to support array inputs is a bug within LangChain.\n4.  The `langgraph_supervisor` package’s incompatibility with `langgraph>=1.0.0` creates a conflict.\n5.  The `create_agent()` bug requires a minimal reproducible example to demonstrate the problem.\n", "batch_number": 1, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The official example for ToolRuntime fails with a TypeError when using the library, specifically due to generic type parameters. The issue stems from a bug within LangChain itself, not a specific integration package, and is reproducible with a minimal example.  The fix involves updating to the latest stable version of LangChain to resolve the issue.", "final_category": "bug", "comments": [{"author": "sanuma02", "created_at": "2025-10-20T17:37:43Z", "body_clean": "hello there, having same problem, the bug shows as closed, however not sure where to find the information on how to fix it. could you share ?"}, {"author": "ZXTFINAL", "created_at": "2025-10-21T08:18:03Z", "body_clean": "Same problem."}, {"author": "curiosity-hyf", "created_at": "2025-10-21T12:19:54Z", "body_clean": "@sanuma02 just change [code] to [code]"}, {"author": "ZXTFINAL", "created_at": "2025-10-22T05:48:48Z", "body_clean": "[@sanuma02]( [link] just change [code] to [code] Oh! Thanks!"}]}, {"ollama_summary": "The GitHub issue reports a `TypeError` in the official example when using `ToolRuntime[Context]` due to insufficient argument count. This issue stems from a bug within LangChain, not a specific code issue, and is related to the `langchain.tools.tool node.ToolRuntime` library. The problem is resolved by updating to the latest stable version of LangChain.", "final_category": "bug", "comments": []}, {"ollama_summary": "The official example fails to run with a TypeError due to an issue with the generic type parameters used within the ToolRuntime[Context] context. This bug appears to be a problem within the LangChain library itself, not a specific code issue related to the LangGraph documentation. The developer has provided a minimal reproducible example to demonstrate the problem and suggest a fix.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue reports a `TypeError` in the official example when using `ToolRuntime` due to a lack of arguments within the context. This issue stems from a bug in LangChain, not a problem with the code itself, and the solution involves adding a minimal reproducible example to demonstrate the issue.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a critical bug where the `hub` library, essential for LangChain, cannot be imported.  The problem persists regardless of updating LangChain versions or specific integration packages.  The solution involves providing a minimal, reproducible example demonstrating the bug, which is a self-contained test case.", "final_category": "bug", "comments": [{"author": "sydney-runkle", "created_at": "2025-10-20T12:25:08Z", "body_clean": "This has moved to [code] : [code]"}]}], "business_insights": ["LangChain’s core library exhibits a widespread bug impacting the ToolRuntime library, indicating a systemic issue within the LangChain codebase.", "Updates to the latest stable LangChain version are consistently resolving the issue, suggesting a stability problem within the library itself.", "The bug’s scope is limited to the ToolRuntime context, indicating a problem within the library’s internal data handling.", "The bug’s root cause is a bug within LangChain, not a specific integration package, requiring a library update.", "Addressing this bug requires a complete update to the latest stable LangChain version."], "technical_insights": ["LangChain’s core library contains a critical bug impacting ToolRuntime, a widespread issue.", "Updating to the latest stable LangChain version resolves the bug, highlighting a stability problem.", "The bug’s impact is confined to the ToolRuntime context, suggesting a bug within the library’s internal data handling.", "The bug's root cause is a bug within LangChain, not a specific integration package, requiring a library update.", "A complete library update is necessary to address this bug, ensuring stability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s core library exhibits a widespread bug impacting the ToolRuntime library, indicating a systemic issue within the LangChain codebase.\n2. Updates to the latest stable LangChain version are consistently resolving the issue, suggesting a stability problem within the library itself.\n3. The bug’s scope is limited to the ToolRuntime context, indicating a problem within the library’s internal data handling.\n4. The bug’s root cause is a bug within LangChain, not a specific integration package, requiring a library update.\n5. Addressing this bug requires a complete update to the latest stable LangChain version.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s core library contains a critical bug impacting ToolRuntime, a widespread issue.\n2. Updating to the latest stable LangChain version resolves the bug, highlighting a stability problem.\n3. The bug’s impact is confined to the ToolRuntime context, suggesting a bug within the library’s internal data handling.\n4. The bug's root cause is a bug within LangChain, not a specific integration package, requiring a library update.\n5. A complete library update is necessary to address this bug, ensuring stability.\n", "batch_number": 2, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in LangChain where a local variable 'formatted block' is inaccessible, despite being present in a minimal reproducible example. The problem isn't related to the LangChain community package and doesn't appear to be a usage issue.  The solution requires a fix within the LangChain library itself, as updating the latest version doesn't resolve the issue.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue proposes adding a `tool_call_id` to the `on_tool_error` event data in LangChain 1.0.0 to aid in debugging tool-related errors.  The request is a feature request, not a bug or question, and the author has thoroughly investigated existing documentation and community resources.  Currently, there’s no existing solution or alternative approach for this functionality.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-20T15:36:14Z", "body_clean": "@781574155 makes sense! Also i'm wondering have you tried the [code] API? We generally recommend that for anything that's built on top of langgraph. It supports a custom stream channel as well, that'll allow you to send custom data from your tools"}, {"author": "781574155", "created_at": "2025-10-21T01:25:02Z", "body_clean": "My situation is this: I use the agent build by langchain statelessly. Every time I call it ,I send all the messages to it. So I need the agent gives me all the exchange messages when executing. Including the tool call and tool call result messages. I use langchain to build an OpenAI Compatible API，I also export a [code] api. I wonder whether [code] API satisfies the condition."}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes problems with the structured output of the gpt OSS models (specifically, 20b and 120b models) when used with chatbedrock. The problem is reproducible with a minimal example and is not related to the community package.  The issue involves a specific error message and stack trace for the langchain core version, and the solution requires a specific version of LangChain and the underlying system.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-18T15:56:23Z", "body_clean": "I think so this is not a bug @mgathena as current implementation of [code] does not support structured output for models outside of [code] family. Check [this]( [link]"}, {"author": "mgathena", "created_at": "2025-10-20T04:38:20Z", "body_clean": "@keenborder786 Thanks. Weird, coz those models do support structured outputs in Bedrock.I have trouble using ChatBedrock in LangChain. Looks like I need to switch to LiteLLM or something else"}]}, {"ollama_summary": "This issue involves a missing import for the `AutoGPTPromptTemplate` class within the LangChain v1.0.0 codebase. This is causing problems with the core functionality of the AutoGPTPrompt and AgentScratchPadChatPromptTemplate classes, specifically when attempting to utilize the classes within the source code.", "final_category": "bug", "comments": []}, {"ollama_summary": "This GitHub issue requests the ability to access the `enable_thinking` flag for LangChain Hugging Face models. The author performed a search and verified that this feature isn’t currently documented or available in the community. The core request is to add a way to dynamically control the behavior of LangChain models, specifically within the `apply chat template`.", "final_category": "feature", "comments": []}], "business_insights": ["Feature requests often reveal desired functionality that isn’t yet addressed.", "Bug fixes frequently surface usability issues impacting core functionality.", "Feature requests drive development priorities and potential improvements.", "Bug fixes often require specific version updates, highlighting dependency management.", "Feature requests improve user experience and product capabilities."], "technical_insights": ["LangChain’s core library needs a fix for the local variable accessibility issue.", "The tool_call_id feature request necessitates thorough documentation and testing.", "The on_tool_error event data debugging requires a specific API or alternative approach.", "The chatbedrock model compatibility issue is a critical bug requiring a specific version.", "The AutoGPTPromptTemplate import issue requires a specific LangChain version."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Feature requests often reveal desired functionality that isn’t yet addressed.\n2.  Bug fixes frequently surface usability issues impacting core functionality.\n3.  Feature requests drive development priorities and potential improvements.\n4.  Bug fixes often require specific version updates, highlighting dependency management.\n5.  Feature requests improve user experience and product capabilities.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s core library needs a fix for the local variable accessibility issue.\n2.  The `tool_call_id` feature request necessitates thorough documentation and testing.\n3.  The `on_tool_error` event data debugging requires a specific API or alternative approach.\n4.  The `chatbedrock` model compatibility issue is a critical bug requiring a specific version.\n5.  The `AutoGPTPromptTemplate` import issue requires a specific LangChain version.\n", "batch_number": 3, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue is a critical bug in the Bedrock Embeddings library that mishandles API responses, causing incorrect data and potentially crashing the application. The code attempts to iterate over a dictionary payload returned by the Cohere model, leading to silent errors and crashes.  The bug is not related to LangChain or the community package, and a minimal reproducible example demonstrates the problem.  The issue requires a pull request to be addressed, and the author requests assignment to fix it.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in LangChain v1.0.0a14 that causes the `AttributeError: 'dict' object has no attribute 'id'` when the `redis checkpointer` is used with a `dict` pending interrupt. This specifically impacts the `agent.py` file, where the `resume` function attempts to retrieve the `result` from the interrupt. The bug only manifests when the Redis checkpointer is involved, suggesting it's not a general LangChain issue.  The fix involves a change to the `langgraph` library's `checkpointer` to handle the expected data structure.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-17T20:50:10Z", "body_clean": "@eyurtsev @nfcampos I’ve identified the root cause of the issue, but I’m not entirely sure where the fix should be applied. Essentially, the [code] type is not LangChain serializable like [code] . If you look at [this line]( [link] in [code] , when it deserializes the [code] dictionary, it never reconstructs it into a LangChain object. Instead, it remains a plain dictionary. This causes the attribute error you’re seeing [here]( [link] when the pending checkpoint write is being reloaded. I tested this with the Postgres saver, and it works there because the [code] object is loaded as raw bytes and then converted into a [code] using [code] . The issue lies specifically with [code] , which, when loading the object, should reconstruct it as an [code] object but instead loads it as a plain dictionary. Either we need to make [code] Searlizable or we need to make some sort adjustment to [code] ."}, {"author": "sydney-runkle", "created_at": "2025-10-20T12:35:02Z", "body_clean": "I think it makes sense to make adjustments to [code] similar to that of the one used for postgres"}, {"author": "keenborder786", "created_at": "2025-10-20T17:53:46Z", "body_clean": "okay @sydney runkle will do it then"}]}, {"ollama_summary": "The `async_create_deep_agent` function in `__init__.py` has been removed in a recent release of DeepAgents, causing an ImportError for existing code. This issue is a bug within the LangChain library and isn’t related to the community package. A minimal reproducible example demonstrates the problem and provides a fix by restoring the function’s exports.", "final_category": "bug", "comments": [{"author": "bart0401", "created_at": "2025-10-17T00:55:50Z", "body_clean": "[link] Move the issue to deep agents/issues and close it."}]}, {"ollama_summary": "This issue proposes a feature to allow users to configure retry timing/intervals for a chat model, preserving its API calls.  Currently, existing workarounds involve wrapping agents and tools with custom retries, which doesn’t fully address the core requirement of configuring the model itself. The goal is to provide a more robust and maintainable solution that avoids proxy classes and agent-level retries while maintaining the existing chat model interface.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-17T02:19:00Z", "body_clean": "langchain 1 will ship with middleware [link] you can customize retry policies that way (e.g., round robin between models) note that some of the base chat models also expose retries on them that you can provide at init time"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's core that causes a streaming response to fail when encountering a custom chat model, specifically with a `[code]` object that raises a `[link]` error. This issue is reproducible across different versions of LangChain and is not related to the community package. A minimal reproducible example demonstrates the problem, and the code itself contains a specific error message and stack trace.", "final_category": "bug", "comments": [{"author": "Abu018", "created_at": "2025-10-16T11:13:34Z", "body_clean": "assign to me i will try"}]}], "business_insights": ["API response mishandling is a primary root cause of the Bedrock Embeddings bug, impacting data integrity.", "Focus on the [code] object causing the error is crucial for debugging.", "The bug’s scope is limited to Cohere model data, indicating a potential issue with the model itself.", "The bug necessitates a pull request to be addressed, demanding author action.", "A minimal reproducible example is essential for effective debugging."], "technical_insights": ["The bug is a critical issue impacting data accuracy, requiring immediate attention.", "The redis checkpointer interaction highlights a specific code path causing the problem.", "The fix involves a change to the langgraph library's checkpointer to handle the expected data structure.", "The bug is not a general LangChain issue, suggesting a specific library component failure.", "The root cause is a data structure mismatch between the dict and [code] objects."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. API response mishandling is a primary root cause of the Bedrock Embeddings bug, impacting data integrity.\n2. Focus on the `[code]` object causing the error is crucial for debugging.\n3. The bug’s scope is limited to Cohere model data, indicating a potential issue with the model itself.\n4. The bug necessitates a pull request to be addressed, demanding author action.\n5. A minimal reproducible example is essential for effective debugging.\n\nTECHNICAL INSIGHTS:\n1. The bug is a critical issue impacting data accuracy, requiring immediate attention.\n2. The `redis checkpointer` interaction highlights a specific code path causing the problem.\n3. The fix involves a change to the `langgraph` library's `checkpointer` to handle the expected data structure.\n4. The bug is not a general LangChain issue, suggesting a specific library component failure.\n5. The root cause is a data structure mismatch between the `dict` and `[code]` objects.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 4, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a concise summary of the GitHub issue:\n\n**Problem:** The issue focuses on reducing unnecessary energy consumption across multiple items, potentially leading to wasted resources.\n\n**Key Details:** The goal is to minimize energy usage by identifying and removing redundant processes or data.\n\n**Proposed Solution:** The issue suggests a review and optimization of existing items to reduce overall energy expenditure.", "final_category": "bug", "comments": [{"author": "yhcho987", "created_at": "2025-10-16T02:49:33Z", "body_clean": "This issue appears to have been added to another item Remove unnecessary energy from other users so as not to waste it."}]}, {"ollama_summary": "This GitHub issue addresses a bug in LangChain where the agent fails to handle invalid `tool_calls` from JSON parsing errors, specifically when the `tool_calls` are empty. The bug stems from the agent's routing logic incorrectly ignoring the presence of empty `tool_calls` and failing to convert them into usable tool messages. The proposed solution involves adding a parameter to handle these empty calls, or updating the routing logic to explicitly check for them.", "final_category": "bug", "comments": [{"author": "MannXo", "created_at": "2025-10-16T08:47:38Z", "body_clean": "I can work on this bug if no one minds?"}, {"author": "eyurtsev", "created_at": "2025-10-17T02:09:11Z", "body_clean": "Which model generated this result for you? You can likely address this with an after model middleware for now"}, {"author": "cladden", "created_at": "2025-10-17T14:12:31Z", "body_clean": "This was gpt oss 120b hosted on vllm. What would a work around look like using after model middleware?"}, {"author": "eyurtsev", "created_at": "2025-10-20T15:38:21Z", "body_clean": "I'll need to reproduce to see where the error is raised. But you can use [code] or [code] to try and fix the invalid json using an LLM. (which middleware to use depends on where/where the exception occurs)"}]}, {"ollama_summary": "The issue is a critical `ImportError` occurring when attempting to import the `ModelResponse` from the `langchain.agents.middleware` package. This is a bug within the LangChain library itself, not a problem with your code or specific integrations. The fix involves a minimal reproducible example demonstrating the error, and the issue is not related to the LangChain community package.", "final_category": "bug", "comments": [{"author": "OoO-wang", "created_at": "2025-10-17T10:33:52Z", "body_clean": "I encountered the same problem, it is indeed a bug"}, {"author": "OoO-wang", "created_at": "2025-10-20T08:52:01Z", "body_clean": "pip install pre U langchain Execute the above command to upgrade the langchain version to v1.0.0 and fix the above problems."}, {"author": "picografix", "created_at": "2025-10-22T12:42:53Z", "body_clean": "Not able to import ModelRequestHandler, can you please reopen this? @sydney runkle"}]}, {"ollama_summary": "The GitHub issue addresses a bug in LangChain's asynchronous middleware that prevents it from correctly handling asynchronous agent calls. Specifically, three built-in middleware classes don’t support async functionality, leading to errors when using methods like `agent.call()` within LangChain’s async API. The issue was identified as a bug in the latest stable version of LangChain, not a usage issue.  The solution involves implementing a fix for these specific middleware classes, and the code example demonstrates how to do so.", "final_category": "bug", "comments": [{"author": "bart0401", "created_at": "2025-10-14T14:12:26Z", "body_clean": "I didn’t notice the existing PR ( 33467) that already addresses this issue — closing this one now."}]}, {"ollama_summary": "This issue stems from a bug in the LangChain library that causes errors when calling the Tencent Cloud vector database's `similarity search by vector` function. Specifically, the function expects a string or `None` as the filter parameter, but receives a dictionary or other data type, leading to a `TypeError`. The code in the source code of the mem0 framework is exhibiting this issue, and the solution involves modifying the source code to use a JSON-style or Python logical expression filter instead of SQL-style expressions.", "final_category": "bug", "comments": [{"author": "RahulMirji", "created_at": "2025-10-15T03:37:42Z", "body_clean": "Assign this too me I'm very keen to work on this"}, {"author": "orcharddd2024", "created_at": "2025-10-15T03:52:05Z", "body_clean": "Assign this too me I'm very keen to work on this @RahulMirji thank you What more information do you need from me? You can tell me Consistently reporting that the filters format is incorrect， The 'Filters 1015' printed in the following image is the filters input, but it keeps reporting that the input format is incorrect <img width=\"1256\" height=\"881\" alt=\"Image\" src=\" [link] / The function 'similarity search by vector' is the function in langchain community/vectorstores/tencentvectordb.py <img width=\"1684\" height=\"902\" alt=\"Image\" src=\" [link] / [link] ，Requests sent through this web page of open source framework mem0，Request to create memory，as shown below，Error as shown above； <img width=\"1316\" height=\"678\" alt=\"Image\" src=\" [link] / <img width=\"1406\" height=\"410\" alt=\"Image\" src=\" [link] / mem0/vector stores/langchain.py <img width=\"1695\" height=\"841\" alt=\"Image\" src=\" [link] / <img width=\"1199\" height=\"918\" alt=\"Image\" src=\" [link] /"}]}], "business_insights": ["Energy consumption reduction is a key focus, potentially impacting resource utilization.", "Redundancy in processes could be a significant source of waste.", "Optimization efforts should prioritize minimizing resource expenditure.", "Reviewing existing items is a proactive approach to waste reduction.", "Addressing redundant processes is crucial for sustainable resource management."], "technical_insights": ["LangChain agent routing logic needs refinement for empty tool calls.", "Error handling for invalid tool_calls should be improved.", "ImportError in the ModelResponse package requires a fix.", "Middleware class compatibility is a critical bug in the latest version.", "Tencent Cloud vector database similarity search function requires JSON-style filtering."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Energy consumption reduction is a key focus, potentially impacting resource utilization.\n2. Redundancy in processes could be a significant source of waste.\n3. Optimization efforts should prioritize minimizing resource expenditure.\n4. Reviewing existing items is a proactive approach to waste reduction.\n5. Addressing redundant processes is crucial for sustainable resource management.\n\nTECHNICAL INSIGHTS:\n1. LangChain agent routing logic needs refinement for empty tool calls.\n2. Error handling for invalid `tool_calls` should be improved.\n3. ImportError in the `ModelResponse` package requires a fix.\n4. Middleware class compatibility is a critical bug in the latest version.\n5. Tencent Cloud vector database similarity search function requires JSON-style filtering.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 5, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe LangChain-cli project is experiencing a bug where it’s failing to run due to broken dependencies within the `HEAD` release of the LangChain project.  The issue stems from a dependency on a specific version of the `HEAD` release, which is causing the project to crash.  A minimal reproducible example has been provided to demonstrate the problem and suggest a fix.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-10-17T19:18:48Z", "body_clean": "This should be resolvable now that [code] is bumped CLI, at least for now, is being put on the back burner in terms of priority on our list of things to maintain"}, {"author": "cbornet", "created_at": "2025-10-19T10:01:35Z", "body_clean": "Indeed, works now."}]}, {"ollama_summary": "The user is attempting to delete a document from a Chroma collection using the `collection.delete()` method, but this is incorrect. They need to use the `delete document()` method, which is the proper way to remove documents from the Chroma collection.  The issue is a misunderstanding of Chroma collection deletion procedures.", "final_category": "question", "comments": []}, {"ollama_summary": "The `ModelResponse` module cannot be imported from the `langchain.agents.middleware` despite being defined in the `types.py` file and documented as part of the official LangChain v1.0.0a14 documentation. The issue stems from a discrepancy in how the module is defined and exported, leading to a failed import. A minimal reproducible example has been provided to demonstrate the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a `TypeError: 'function' object is not subscriptable` error when importing the `GraphQAChain` library with Python 3.14. It suggests a problem with how the library is being used, potentially related to a recent update or a specific integration package.  Further investigation is needed to determine the root cause and potential solutions.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-13T19:49:51Z", "body_clean": "Download langchain community [code] and then import as follow: [code]"}, {"author": "a-lyanik", "created_at": "2025-10-14T16:01:42Z", "body_clean": "I have a similar issue on; [code] [code] [code] python v. 3.14 langchain v. 0.3.27 pydantic v. 2.12.2 But it can have more to do with pydantic. Switching to python v. 3.13 fixes it."}, {"author": "eyurtsev", "created_at": "2025-10-16T01:52:11Z", "body_clean": "We do not yet support python 3.14. Support will be added post release of langchain 1.0."}]}, {"ollama_summary": "The GitHub issue reports a bug in the LangChain library where the Gemini API returns a specific `FinishReason` enum value (12) that causes a crash when used with a ChatGoogleGenerativeAI agent. This is a problem that isn’t related to the LangChain community package and is being investigated as a potential issue within the Gemini API itself. The issue is reproducible by using newer versions of the LangChain library and model, and the bug is being addressed by providing a more informative error message instead of crashing.", "final_category": "bug", "comments": [{"author": "bcmaymonegalvao", "created_at": "2025-10-12T01:00:07Z", "body_clean": "Hi, I’d like to work on this issue. I can prepare a fix that safely handles unknown FinishReason enum values and prevents the crash."}]}], "business_insights": ["Dependency management issues are frequently the root cause of bugs in LangChain projects.", "Addressing dependency conflicts is crucial for maintaining stability and ensuring smooth development.", "Thorough dependency checks are essential for preventing regressions and ensuring code quality.", "Prioritize dependency fixes based on their impact and risk level.", "Comprehensive testing is vital for identifying and resolving dependency-related issues early."], "technical_insights": ["LangChain’s HEAD release is a common source of dependency problems.", "Chroma collection deletion procedures require careful attention to detail.", "Module import discrepancies within the langchain.agents.middleware module.", "Python version compatibility issues with the GraphQAChain library.", "Gemini API’s FinishReason enum values require careful handling to prevent crashes."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency management issues are frequently the root cause of bugs in LangChain projects.\n2. Addressing dependency conflicts is crucial for maintaining stability and ensuring smooth development.\n3. Thorough dependency checks are essential for preventing regressions and ensuring code quality.\n4. Prioritize dependency fixes based on their impact and risk level.\n5. Comprehensive testing is vital for identifying and resolving dependency-related issues early.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s `HEAD` release is a common source of dependency problems.\n2. Chroma collection deletion procedures require careful attention to detail.\n3. Module import discrepancies within the `langchain.agents.middleware` module.\n4. Python version compatibility issues with the `GraphQAChain` library.\n5. Gemini API’s `FinishReason` enum values require careful handling to prevent crashes.\n", "batch_number": 6, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This GitHub issue proposes adding observational hooks (before_tool and after_tool) to AgentMiddleware to improve API design and debugging capabilities for tool calls. The current implementation uses the interceptor pattern, which is not ideal for symmetric API design. The goal is to provide a simpler, declarative way to monitor tool usage and logging without the complexity of the interceptor pattern.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-11T13:51:40Z", "body_clean": "Use the tool interceptor or before model call for this. If that doesn't work would love a good explanation for why not. We're only going to add hooks that enable new capabilities rather than hooks that provide a 2nd way to do the same thing."}, {"author": "HY-love-sleep", "created_at": "2025-10-13T02:26:09Z", "body_clean": "Use the tool interceptor or before model call for this. If that doesn't work would love a good explanation for why not. We're only going to add hooks that enable new capabilities rather than hooks that provide a 2nd way to do the same thing. Currently I can use the wrap tool call record tool to enter/out parameters and read them in the next round of before model, which really does the job. But my reasons for why need two extra hooks are as follows： Semantic asymmetry: model has before/after + wrap; tool only wraps, API asymmetry, and higher cost to learn/use mind. Mixed responsibilities: For \"pure observation\", it is also necessary to use an interceptor with a \"controllable process\", which has more coupling capacity than is required and is easy to mix with real control logic (retry, short circuit). Composability/readability: observational hooks can be combined sequentially, and the code is more intuitive; The wrap chain is used to control the flow, and the separation of duties between the two is clearer. Clear timing: Provides before tool/after tool accurate observation at the same round and node, rather than indirect observation in the \"next round before model\"."}, {"author": "eyurtsev", "created_at": "2025-10-17T15:53:08Z", "body_clean": "The correct way to handle the use cases is through the wrap tool call interceptor. We can re consider if there are more convincing use cases that cannot be solved with the existing hooks."}, {"author": "eyurtsev", "created_at": "2025-10-20T15:40:51Z", "body_clean": "Closing this issue for now as not work is planned for it. We'd want something motivated by actual use cases"}]}, {"ollama_summary": "This issue asks for a way to run LangChain's PostgreSQL integration on version 1.0.0aX.  The request is not related to a bug or feature request, but rather a specific use case involving the LangChain PostgreSQL package.  Currently, there’s no documented or readily available solution to achieve this functionality.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-11T13:52:00Z", "body_clean": "We'll release it with the official release"}, {"author": "eyurtsev", "created_at": "2025-10-11T13:52:20Z", "body_clean": "For now you should be able to force install it (package managers allow ignoring constraints)"}, {"author": "bulolo", "created_at": "2025-10-11T14:11:17Z", "body_clean": "For now you should be able to force install it (package managers allow ignoring constraints) how to force to install？"}, {"author": "mdrxy", "created_at": "2025-10-13T18:51:22Z", "body_clean": "@bulolo [link]"}]}, {"ollama_summary": "The LangChain PostgreSQL error is a persistent bug that doesn’t appear to be related to the LangChain community package. The issue involves a minimal reproducible example that consistently triggers the error, suggesting a fundamental issue within the LangChain library itself.  The solution requires a fix within the LangChain codebase to address the root cause of the error.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a bug in LangChain's `langchain-postgres` integration that prevents it from running successfully on the specified LangChain version (1.0.0aX).  The problem is a compatibility issue with the integration package, not a code-level issue. A minimal reproducible example has been provided, demonstrating the failure to run the integration.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a bug in LangChain's `langchain-postgres` integration where it fails to run the database connection.  The problem isn't related to the LangChain community package or updates, and a minimal reproducible example demonstrates the failure.  The solution, as suggested by the maintainer, is to provide a minimal, self-contained example that demonstrates the issue.", "final_category": "bug", "comments": []}], "business_insights": ["Observational hooks offer a structured approach to API design and debugging, potentially simplifying complex patterns.", "The focus on declarative monitoring highlights a desire for clearer API control and logging.", "The hook implementation suggests a potential need for a more robust and easily maintainable API design strategy.", "Careful consideration of the interceptor pattern’s complexity could lead to better API design.", "Streamlining API design is a key goal, requiring a more declarative approach."], "technical_insights": ["LangChain PostgreSQL integration requires a specific version (1.0.0aX) – a potential version conflict.", "The integration package is the root cause of the error – a fundamental issue within the LangChain library.", "The bug is reproducible – a clear indicator of a core problem needing resolution.", "The bug's compatibility issue necessitates a fix within the LangChain codebase.", "The maintainer’s suggested solution – providing a minimal example – is crucial for debugging."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Observational hooks offer a structured approach to API design and debugging, potentially simplifying complex patterns.\n2. The focus on declarative monitoring highlights a desire for clearer API control and logging.\n3. The hook implementation suggests a potential need for a more robust and easily maintainable API design strategy.\n4. Careful consideration of the interceptor pattern’s complexity could lead to better API design.\n5. Streamlining API design is a key goal, requiring a more declarative approach.\n\nTECHNICAL INSIGHTS:\n1.  LangChain PostgreSQL integration requires a specific version (1.0.0aX) – a potential version conflict.\n2.  The integration package is the root cause of the error – a fundamental issue within the LangChain library.\n3.  The bug is reproducible – a clear indicator of a core problem needing resolution.\n4.  The bug's compatibility issue necessitates a fix within the LangChain codebase.\n5.  The maintainer’s suggested solution – providing a minimal example – is crucial for debugging.\n", "batch_number": 7, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue addresses a potential issue where the system might warn users when it receives audio input that a model doesn't support. The core problem is that certain models require specific input modalities, and the system needs to alert users when it encounters unsupported audio.  Currently, the solution is to implement a warning mechanism when audio input is detected.", "final_category": "feature", "comments": [{"author": "raunaqness", "created_at": "2025-10-10T11:58:33Z", "body_clean": "Hi, can I take this up?"}, {"author": "ArjunJagdale", "created_at": "2025-10-10T18:54:32Z", "body_clean": "I would like to work on this PR, but Should this be on by default or behind a flag? For unknown models, skip validation or show a generic warning? Let me know if this looks good @mdrxy , also it should be non breaking imo."}, {"author": "mdrxy", "created_at": "2025-10-10T19:31:56Z", "body_clean": "@raunaqness @ArjunJagdale I wrote down this idea so that it wouldn't be forgotten ;) it's not necessarily guaranteed yet, more just exploratory at this point. I think we should consider the architecture at a high level before starting implementation. Presumably this pattern should work for all chat model integrations supported by LangChain. I'm not sure whether it makes sense to maintain, for instance, a [code] file for each model provider package, or to centralize things somewhere in [code] For unknown models, skip validation or show a generic warning? @ArjunJagdale if we don't know the model, we don't have an entries in our \"capabilities table\" to check against. It is unlikely that we would be able to maintain a canonical list of all capabilities provided by all models. So, I think it is reasonable to not warn in such case and let the error surface during execution. Should this be on by default or behind a flag? I think it's reasonable to enable this by default, but would need to consider it in more depth. We could introduce a flag to bypass validation."}, {"author": "keenborder786", "created_at": "2025-10-10T20:06:47Z", "body_clean": "@mdrxy Why don’t we add a new property to [code] called [code] , which returns a list like [code] ? Then, in each external integration package, we can maintain three global variables: [code] [code] [code] The only downside is that these would need to be updated regularly."}, {"author": "ArjunJagdale", "created_at": "2025-10-11T10:18:18Z", "body_clean": "[@raunaqness]( [link] [@ArjunJagdale]( [link] I wrote down this idea so that it wouldn't be forgotten ;) it's not necessarily guaranteed yet, more just exploratory at this point. I think we should consider the architecture at a high level before starting implementation. Presumably this pattern should work for all chat model integrations supported by LangChain. I'm not sure whether it makes sense to maintain, for instance, a [code] file for each model provider package, or to centralize things somewhere in [code] For unknown models, skip validation or show a generic warning? [@ArjunJagdale]( [link] if we don't know the model, we don't have an entries in our \"capabilities table\" to check against. It is unlikely that we would be able to maintain a canonical list of all capabilities provided by all models. So, I think it is reasonable to not warn in such case and let the error surface during execution. Should this be on by default or behind a flag? I think it's reasonable to enable this by default, but would need to consider it in more depth. We could introduce a flag to bypass validation. Got it, thanks for clarifying that this is exploratory. Makes sense to think through the architecture first."}, {"author": "ArjunJagdale", "created_at": "2025-10-11T10:20:37Z", "body_clean": "@mdrxy Also, are there any other issues you’d suggest I could pick up?"}]}, {"ollama_summary": "This issue involves a unit test referencing a non-commercial license in a graph database test data file. The maintainers are requesting a change to remove this license reference to resolve tooling concerns and ensure compatibility with LangChain. The proposed solution is to replace the reference with the Creative Commons Attribution 4.0 International license, maintaining the file’s structure and semantic integrity.", "final_category": "feature", "comments": [{"author": "mdrxy", "created_at": "2025-10-10T00:42:17Z", "body_clean": "Hi @amelvil2 ford, we'd be open to it. Currently short on cycles to get this in ourselves but would be open to a PR!"}, {"author": "amelvil2-ford", "created_at": "2025-10-10T14:02:18Z", "body_clean": "Thank you for the quick response, I'm looking into how this data gets used to make sure changing it doesn't break anything. The bot (open swe) seemed to think this test isn't used anymore, let me know if you can confirm that. So far it seems like it's at least not called by any test in that folder."}]}, {"ollama_summary": "The issue is a bug in LangChain v1 alpha where audio content blocks are failing to convert to OpenAI’s expected format, resulting in a 400 error. A minimal reproducible example demonstrates the problem and the code itself produces the error. The solution involves using a different format (instead of the original) to bypass the conversion process.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-10-09T21:00:56Z", "body_clean": "Hi @MatteoFalcioni, thanks for testing v1 alpha! Two things that seem to be wrong: Model: [code] [code] ([vanilla 4o]( [link] doesn't support audio input) Your audio block has an invalid key. It should be: [code] It's possible our docs are incorrect or could be improved on the [code] / [code] part is there a particular page you got this from?"}, {"author": "MatteoFalcioni", "created_at": "2025-10-10T08:05:50Z", "body_clean": "Hi [@MatteoFalcioni]( [link] thanks for testing v1 alpha! Two things that seem to be wrong: Model: [code] [code] ([vanilla 4o]( [link] doesn't support audio input) Your audio block has an invalid key. It should be: {\"type\": \"audio\", \"base64\": audio b64, \"mime type\": \"audio/wav\"}, not {\"type\": \"audio\", \"data\": audio b64, \"mime type\": \"audio/wav\"}, It's possible our docs are incorrect or could be improved on the [code] / [code] part is there a particular page you got this from? Ty for the answer, I changed both things, but I still get the same error. I was actually not aware that the vanilla [code] did not support audio inputs. For the [code] part, I actually think there is a mistake in the alpha docs here: [link] , since they reference the [code] key instead of [code] ."}, {"author": "mdrxy", "created_at": "2025-10-10T15:02:58Z", "body_clean": "@MatteoFalcioni that's odd; are you using the latest alpha versions? We'll fix the docs, thanks for flagging!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that prevents the `with structured output()` function from returning the `response_headers` metadata, specifically when using `include raw=True`. The code attempts to access this metadata but fails, leading to an empty `response_headers` field in the returned raw response.  The issue is not related to the LangChain community package and appears to be a fundamental bug within the core LangChain implementation.", "final_category": "bug", "comments": []}, {"ollama_summary": "The Tongyi module is causing a type validation error when attempting to retrieve data from the Generation model due to a change in the response data field. A minimal reproducible example demonstrating the issue was provided, including the relevant code.  The issue requires a fix to ensure the correct data type is received for the text field, preventing the error.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-10T20:07:45Z", "body_clean": "@AugustPython I think so this needs to go to [code]"}]}], "business_insights": ["Audio input validation is a recurring concern, requiring proactive alerting.", "Model support variations necessitate clear user communication.", "Integration testing is crucial for ensuring compatibility across models.", "Automated testing for unsupported audio models is vital.", "Clear warnings are essential for user experience and system stability."], "technical_insights": ["Audio model support varies significantly across models.", "Licensing requirements for commercial models are a consistent challenge.", "Test coverage should include unknown model scenarios.", "Automated testing should proactively identify unsupported audio.", "Clear, actionable warnings enhance user understanding."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Audio input validation is a recurring concern, requiring proactive alerting.\n2. Model support variations necessitate clear user communication.\n3. Integration testing is crucial for ensuring compatibility across models.\n4. Automated testing for unsupported audio models is vital.\n5. Clear warnings are essential for user experience and system stability.\n\nTECHNICAL INSIGHTS:\n1. Audio model support varies significantly across models.\n2. Licensing requirements for commercial models are a consistent challenge.\n3. Test coverage should include unknown model scenarios.\n4. Automated testing should proactively identify unsupported audio.\n5. Clear, actionable warnings enhance user understanding.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 8, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a TypeError in LangChain's `file_reducer` function when a subagent returns a default `files` state, specifically when it doesn't perform file operations. This issue stems from a misinterpretation of how the subagent's state is handled during the main agent's state update process, leading to a failure during the final tool integration step. The root cause is a mismatch between the expected data structure returned by the subagent and the way the main agent expects to receive it, causing the reducer to fail.", "final_category": "bug", "comments": []}, {"ollama_summary": "The `create_agent` GitHub issue is a bug where the tool doesn’t allow configuring error handling for LangChain alpha v1, preventing tools from gracefully handling errors. The code hardcodes the error handling, causing crashes instead of retries.  The proposed solution is to add a default error handler parameter to allow for all exceptions to be caught.", "final_category": "bug", "comments": [{"author": "rishabhjain1712", "created_at": "2025-10-08T13:54:27Z", "body_clean": "hi, i'd like to work on fixing this issue and submit a PR."}, {"author": "eyurtsev", "created_at": "2025-10-08T16:31:40Z", "body_clean": "This change is intentional. We'll publish migration guidelines, but tool error handling is going to be done in a different way"}, {"author": "cladden", "created_at": "2025-10-08T19:11:22Z", "body_clean": "Is the proper tool error handling mechanism (middleware/hook?) technique available in [code] or will a code change be needed?"}, {"author": "eyurtsev", "created_at": "2025-10-10T03:20:31Z", "body_clean": "Will be out within a few days :) It can be achieved with the [code] middleware (currently on master)"}, {"author": "eyurtsev", "created_at": "2025-10-10T21:24:46Z", "body_clean": "@cladden what kind of configuration are you looking to do? [code] will ship with automatic conversion of tool invocation errors to ToolMessages with error information. Is that sufficient for your use case or are you trying to do something else?"}, {"author": "cladden", "created_at": "2025-10-11T02:58:07Z", "body_clean": "Yes, exactly that’s what I’m looking for a standard way for tools to surface recoverable errors as observations so the model can correct its next action."}, {"author": "eyurtsev", "created_at": "2025-10-11T13:54:50Z", "body_clean": "| Yes, exactly that’s what I’m looking for a standard way for tools to surface recoverable errors as observations so the model can correct its next action. This is done automatically now for invocation errors. You can use the wrap tool call hook to extend this functionality to cover other types of exceptions (e.g., bad SQL query). We'll add prebuilt middleware to help with this use case, but you can already do this with the custom hooks without too much code"}, {"author": "cladden", "created_at": "2025-10-13T14:14:24Z", "body_clean": "Tested on langchain==1.0.0a14 works perfectly. Thanks for the quick turnaround!"}]}, {"ollama_summary": "The LangGraph CLI fails to validate state parameters due to it incorrectly treating injected state as required tool arguments, leading to validation errors. This issue is a bug within the LangChain library, not related to the community package, and is specifically affecting the graph command. A workaround involves using generic type definitions instead of custom state classes to avoid runtime errors and potential type safety issues.", "final_category": "bug", "comments": [{"author": "codeonym", "created_at": "2025-10-06T16:45:25Z", "body_clean": "this issue should be added to langgraph repo (langgraph cli): closing this issue in favor of: [langgraph 6241]( [link]"}]}, {"ollama_summary": "The “ContextualCompressionRetriever” issue is a bug in LangChain that prevents the retrieval of specific context data for certain models. The issue is not related to a specific package update and is reproducible through a minimal example code.  The developers are investigating the root cause to ensure consistent functionality across all models.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-10-07T01:55:27Z", "body_clean": "These will be available through langchain classic"}]}, {"ollama_summary": "The LangChain v1.0 is causing a runtime error when using multimodel input with Ollama due to a bug in the code that removes a specific content type. A minimal reproducible example has been provided to demonstrate the issue, and the developers are recommending removing this check or modifying the code to resolve the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-05T21:55:16Z", "body_clean": "@amanchaudhary 95 This already been fixed you just need to upgrade to the latest version."}, {"author": "amanchaudhary-95", "created_at": "2025-10-06T02:46:29Z", "body_clean": "I'm currently using: [code] Not sure if I'm missing something."}, {"author": "mdrxy", "created_at": "2025-10-06T02:47:47Z", "body_clean": "[code] should be [1.0.0a1]( [link]"}]}], "business_insights": ["Focus on state management errors – consistent failures point to issues in the reducer’s state update logic.", "Subagent state handling – misinterpretation of subagent data is a recurring pattern, impacting core agent functionality.", "Tool integration – mismatch between expected data and main agent state creates critical integration failures.", "LangChain library bugs – validation errors and state handling are identified as core issues within the library.", "Model compatibility – specific model versions are causing runtime errors, requiring investigation."], "technical_insights": ["file_reducer TypeError – Root cause likely in the subagent’s state interpretation.", "create_agent Tool configuration – Hardcoded error handling – needs a migration strategy.", "LangGraph CLI validation – Incorrect state parameter treatment – requires type definition changes.", "ContextualCompressionRetriever Retrieval – Model-specific context data issue – requires investigation.", "V1.0 multimodel Ollama issue – Removal of content type check – requires code modification."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on state management errors – consistent failures point to issues in the reducer’s state update logic.\n2.  Subagent state handling – misinterpretation of subagent data is a recurring pattern, impacting core agent functionality.\n3.  Tool integration – mismatch between expected data and main agent state creates critical integration failures.\n4.  LangChain library bugs – validation errors and state handling are identified as core issues within the library.\n5.  Model compatibility – specific model versions are causing runtime errors, requiring investigation.\n\nTECHNICAL INSIGHTS:\n1.  `file_reducer` TypeError – Root cause likely in the subagent’s state interpretation.\n2.  `create_agent` Tool configuration – Hardcoded error handling – needs a migration strategy.\n3.  LangGraph CLI validation – Incorrect state parameter treatment – requires type definition changes.\n4.  `ContextualCompressionRetriever` Retrieval – Model-specific context data issue – requires investigation.\n5.  V1.0 multimodel Ollama issue – Removal of content type check – requires code modification.\n", "batch_number": 9, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `extendingBaseChatMessageHistory` feature is failing to allow overriding the default message handling for subclasses, resulting in an error when attempting to use the extension. This issue appears to be a bug within the LangChain library, not a problem with the user's code. A minimal reproducible example has been provided to demonstrate the problem and suggest a fix.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-04T13:12:59Z", "body_clean": "[code] You should directly use [code]"}, {"author": "dpsommer", "created_at": "2025-10-04T17:28:12Z", "body_clean": "You should directly use [code] This is just an illustrative example; my implementation uses a different method to store and retrieve the memory but runs into the bug described."}, {"author": "keenborder786", "created_at": "2025-10-05T21:39:16Z", "body_clean": "@dpsommer why are you doing it?"}, {"author": "dpsommer", "created_at": "2025-10-05T22:54:50Z", "body_clean": "@keenborder786 I want to use an index backend to persist the history."}, {"author": "keenborder786", "created_at": "2025-10-06T22:50:10Z", "body_clean": "[code] is still a property in [code] so you can access it in same way."}, {"author": "dpsommer", "created_at": "2025-10-06T23:23:20Z", "body_clean": "@keenborder786 [code] still uses the same base class. I'm writing a custom [code] class that inherits from [code] in a similar way to the [code] example in the base class docstring: [link] Doing that triggers the bug I've described."}, {"author": "eyurtsev", "created_at": "2025-10-07T02:02:17Z", "body_clean": "@dpsommer take a look at the langgraph persistence layer: [link] I'd recommend that for most users. There are sqlite implementations and postgres implementations"}, {"author": "eyurtsev", "created_at": "2025-10-07T02:04:31Z", "body_clean": "Anyway the original code may have a bug in it you need to user [code] [code]"}, {"author": "dpsommer", "created_at": "2025-10-07T06:13:34Z", "body_clean": "@eyurtsev the same error occurs with [code] the issue is that the property decorator makes the [code] variable return as a [code] object rather than a list, so the call to [code] in the runnable invocation fails. I'm not looking to use ReAct, so I'm not sure that the checkpointing approach you linked applies."}]}, {"ollama_summary": "The GitHub issue addresses a critical problem in agent systems – the loss of valuable insights due to timing mismatches between acting and forgetting. The proposed “Defer Queue Pattern” introduces a third routing state – [code] – to mitigate this by allowing agents to intelligently defer tasks until conditions are met. This pattern offers zero intelligence loss, continuous accumulation, and improved context preservation, benefiting both agents and LangChain. It’s a practical, production-tested solution with potential integration points for LangChain agents and developers, and is currently a valuable framework for multi-agent systems.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-07T01:59:47Z", "body_clean": "Hi @devvyn thanks for opening an issue. You can look at langchain's long term memory support [link] if you're trying to have your agents remember information over a long period of time. [link] Closing this for now as it's not clear that this is an issue and can be handled with the framework already"}]}, {"ollama_summary": "The GitHub issue reports a bug where a Celery task fails to complete the document ingestion process into ChromaDB. The bug only manifests when the ingestion is initiated through the Celery task, and it doesn’t occur when the ingestion is performed directly within a FastAPI endpoint. The issue is currently being investigated as a potential LangChain issue, though the root cause is not yet identified.", "final_category": "bug", "comments": [{"author": "mahimairaja", "created_at": "2025-10-07T14:15:16Z", "body_clean": "I am looking into this Bug"}, {"author": "BennisonDevadoss", "created_at": "2025-10-09T21:20:03Z", "body_clean": "@mahimairaja, were you able to fix it?"}, {"author": "mahimairaja", "created_at": "2025-10-09T21:21:57Z", "body_clean": "WIP"}]}, {"ollama_summary": "The `trim_messages` function is returning invalid messages history due to a bug in LangChain that prevents it from correctly selecting the last n messages.  The issue is not related to the LangChain community package and is a persistent problem, despite attempts to update to the latest version. A minimal reproducible example has been provided to demonstrate the issue and allow for debugging.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue proposes a limitation in the `create_agent()` function that prevents the use of both the `[code]` parameter and middleware for custom state management, hindering RAG application development.  The core problem stems from a technical incompatibility between these two functionalities, impacting the core requirements of RAG agents – retrieving documents, managing context, and maintaining conversation history.  The proposed solution involves redesigning the feature to allow for both features to coexist, potentially through a new approach to state management.", "final_category": "feature", "comments": [{"author": "Rohanvasudev1", "created_at": "2025-10-04T00:19:11Z", "body_clean": "Hey could I help with this feature? I already gave it a go on my pull request. Would be happy to collaborate too"}, {"author": "jmoreno11", "created_at": "2025-10-06T11:49:18Z", "body_clean": "I also found this in the docs for state extension : [link] which I can apply to my use case: [code] [code] [code] I still think it's a bit of an overkill to have a [code] object just to extend the state. I think better and a more unified documentation around State Management is needed here, as well as maybe an [code] (!= Structured Output if we store things like filenames)"}, {"author": "eyurtsev", "created_at": "2025-10-08T16:33:05Z", "body_clean": "For now we recommend using custom middleware this purpose. We'll publish documentation with migration notes. Should be able to feed this into an llm / claude code to get your code migrated for you."}, {"author": "jmoreno11", "created_at": "2025-10-11T12:27:58Z", "body_clean": "Hey thanks @eyurtsev for the response. Please also note that when following this approach, there is a risk of the extended state keys becoming outdated, example: [code] Any suggestions with this?"}, {"author": "eyurtsev", "created_at": "2025-10-11T13:56:37Z", "body_clean": "@jmoreno11 this is working as expected due to how langgraph persistence works. It will persist state updates for the entire conversation thread. If you want to reset the state, you can add an explicit before agent hook that sets retrieved documents to an empty list or you can start a conversation on a new thread (what you want depends on your use case)"}, {"author": "eyurtsev", "created_at": "2025-10-20T15:40:18Z", "body_clean": "Agent interface also allows passing state schema directly now to make it more convenient to use. Closing this issue (as there's no bug to fix)."}]}], "business_insights": ["LangChain’s extendingBaseChatMessageHistory issue highlights a fundamental flaw in how the library handles message context – direct overriding is problematic.", "The “Defer Queue Pattern” offers a robust solution for mitigating timing mismatches, showcasing a practical approach to agent memory management.", "The Celery task failure indicates a significant bottleneck in data ingestion, requiring investigation and potentially impacting LangChain’s core functionality.", "The trim_messages bug points to a critical bug within LangChain itself, suggesting a potential regression issue requiring immediate attention.", "The feature limitation on create_agent() demonstrates a need for redesigning the RAG workflow – state management and context handling are crucial."], "technical_insights": ["LangChain’s extendingBaseChatMessageHistory reveals a bug within the core message handling mechanism, demanding a fix.", "The “Defer Queue Pattern” introduces a third routing state, demonstrating a strategic approach to improve agent memory.", "Celery task failure demonstrates a critical bug in LangChain’s data ingestion process, highlighting a significant maintenance concern.", "trim_messages bug requires investigation, potentially impacting the functionality of LangChain agents.", "The create_agent() feature limitation necessitates a redesign of the RAG workflow – state management and context preservation are key."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s `extendingBaseChatMessageHistory` issue highlights a fundamental flaw in how the library handles message context – direct overriding is problematic.\n2. The “Defer Queue Pattern” offers a robust solution for mitigating timing mismatches, showcasing a practical approach to agent memory management.\n3. The Celery task failure indicates a significant bottleneck in data ingestion, requiring investigation and potentially impacting LangChain’s core functionality.\n4. The `trim_messages` bug points to a critical bug within LangChain itself, suggesting a potential regression issue requiring immediate attention.\n5. The feature limitation on `create_agent()` demonstrates a need for redesigning the RAG workflow – state management and context handling are crucial.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s `extendingBaseChatMessageHistory` reveals a bug within the core message handling mechanism, demanding a fix.\n2. The “Defer Queue Pattern” introduces a third routing state, demonstrating a strategic approach to improve agent memory.\n3. Celery task failure demonstrates a critical bug in LangChain’s data ingestion process, highlighting a significant maintenance concern.\n4. `trim_messages` bug requires investigation, potentially impacting the functionality of LangChain agents.\n5. The `create_agent()` feature limitation necessitates a redesign of the RAG workflow – state management and context preservation are key.\n", "batch_number": 10, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is a bug in the Ollama server that causes \"invalid option provided\" warnings when using the qwen3 models. This started after an update to the model, and it’s a problem that isn’t related to the LangChain community package. The bug is being reported by the developers of Ollama and is being addressed through a minimal reproducible example.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-10-02T15:33:56Z", "body_clean": "Should be fixed in 0.3.10 releasing now"}]}, {"ollama_summary": "This GitHub issue requests an update to the `supervisor-py` library to ensure compatibility with version 1.0v. The issue highlights a lack of a similar feature request in the community and a focus on the supervisor library’s importance for multi-agent systems.  Currently, the code is not compatible with this specific release, requiring a fix to maintain functionality.", "final_category": "feature", "comments": []}, {"ollama_summary": "The GitHub issue proposes adding a “HallucinationDetector” module to LangChain to address a critical challenge in RAG systems – the detection of hallucinations – which currently relies on ad-hoc prompt engineering and external scripts. The proposed solution would involve a dedicated component that analyzes model responses against retrieved documents, using NLI checks, log probabilities, and potentially attention analysis, flagging unsupported claims and providing a “hallucination score.”  The goal is to improve the reliability and accuracy of RAG systems by proactively identifying and mitigating potential inaccuracies.", "final_category": "feature", "comments": [{"author": "haragam22", "created_at": "2025-10-02T11:05:45Z", "body_clean": "Hi team 👋 — this is a really important feature and I’d love to take it up. My plan: 1. Define a [code] evaluator class under [code] . 2. Start with an NLI based baseline (e.g. DeBERTa MNLI from Hugging Face) that checks if model outputs are entailed by retrieved docs. 3. Return a structured output: { hallucination score, status, unsupported spans }. 4. Add tests + a simple example notebook so users can try it in QA/RAG pipelines. 5. (Optional in later iterations) extend with log prob heuristics and consistency checks. Could you please assign this issue to me? I can start drafting a PR and share early progress for feedback."}, {"author": "Rohanvasudev1", "created_at": "2025-10-04T00:46:09Z", "body_clean": "Hey if no one is doing this could I work on this? would love to help"}]}, {"ollama_summary": "This issue focuses on a critical bug within the LangChain library, specifically the `create_history_aware_retriever` component, which is causing problems with retrieving data based on history information. The code is not compatible with the latest version of LangChain, and the issue is not related to the community package.  The core problem involves a type mismatch when attempting to use the retriever, and the code lacks the necessary functionality to handle history-aware retrieval.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-10-01T20:46:14Z", "body_clean": "@aserechenko, MergerRetriever expects [code] Instances, while create history aware retriever does not create a [code] instance instead it is directly a runnable. However, you can over come this by doing something as following: [code]"}]}, {"ollama_summary": "This issue proposes adding a feature to store or retrieve embedding generated by the input query in a vector store for improved performance in a rag system. The current implementation relies on API calls to the embedding, which could be optimized by storing the embedding directly.  The goal is to enhance the system’s latency through efficient embedding retrieval.", "final_category": "feature", "comments": [{"author": "Rohanvasudev1", "created_at": "2025-10-04T00:46:49Z", "body_clean": "Hey could I help with this issue please"}, {"author": "hasansustcse13", "created_at": "2025-10-05T04:18:45Z", "body_clean": "I have already described the feature. If it's possible with the existing langchain flow then let me know."}]}], "business_insights": ["Addressing the bug in Ollama’s server will improve the stability and reliability of the LangChain ecosystem.", "The feature request for supervisor-py compatibility is a crucial step towards ensuring long-term support for the LangChain library.", "The HallucinationDetector module addresses a fundamental challenge in RAG systems, indicating a growing need for robustness.", "The LangChain library bug related to create_history_aware_retriever requires immediate attention and a fix.", "Embedding storage optimization improves the overall performance of RAG systems, enhancing latency."], "technical_insights": ["The bug in Ollama’s server needs immediate resolution to maintain system stability.", "Compatibility issues with the supervisor-py library need to be addressed for continued support.", "The hallucinationDetector module requires careful design and implementation to effectively detect and mitigate hallucinations.", "The create_history_aware_retriever component lacks crucial functionality for history-aware retrieval.", "The supervisor-py library compatibility update must be prioritized to maintain functionality and stability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing the bug in Ollama’s server will improve the stability and reliability of the LangChain ecosystem.\n2. The feature request for `supervisor-py` compatibility is a crucial step towards ensuring long-term support for the LangChain library.\n3. The HallucinationDetector module addresses a fundamental challenge in RAG systems, indicating a growing need for robustness.\n4. The LangChain library bug related to `create_history_aware_retriever` requires immediate attention and a fix.\n5. Embedding storage optimization improves the overall performance of RAG systems, enhancing latency.\n\nTECHNICAL INSIGHTS:\n1.  The bug in Ollama’s server needs immediate resolution to maintain system stability.\n2.  Compatibility issues with the `supervisor-py` library need to be addressed for continued support.\n3.  The `hallucinationDetector` module requires careful design and implementation to effectively detect and mitigate hallucinations.\n4.  The `create_history_aware_retriever` component lacks crucial functionality for history-aware retrieval.\n5.  The `supervisor-py` library compatibility update must be prioritized to maintain functionality and stability.\n", "batch_number": 11, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a critical mismatch between the structured output keys used in LangChain agents created with and without middleware. The code relies on a specific key structure, and the latest version of LangChain doesn't automatically handle this change, leading to unexpected output discrepancies.  The issue is currently not related to the LangChain community package, and a minimal reproducible example demonstrates the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in LangChain that causes the tool error handling to fail specifically when the agent created with middleware is used. The bug manifests as a lack of response from the tool, potentially due to a misconfiguration or incompatibility within the middleware.  The issue is not related to the LangChain community package and is isolated to the agent created with the middleware.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-10-20T15:41:35Z", "body_clean": "Tool error handling can be handled via custom middleware, and already has auto on behavior for certain kinds of errors"}]}, {"ollama_summary": "The issue reports a bug in the LangChain `ollama` embedding model initialization process, specifically after an update to the latest stable version. The code throws a `ValidationError` when attempting to initialize the model, and the stack trace indicates a problem with the Ollama API.  The problem seems to be related to a recent change in the Ollama package or LangChain integration, causing the model to fail to initialize.  The issue is reproducible and has been addressed by updating the packages to the latest versions, but the problem persists.", "final_category": "bug", "comments": [{"author": "shubhampandey3008", "created_at": "2025-09-28T04:54:39Z", "body_clean": "I set up on my Mac. With all the given requirements, this works fine for me. Requirements: Package Version annotated types 0.7.0 anyio 4.11.0 appnope 0.1.4 asttokens 3.0.0 certifi 2025.8.3 charset normalizer 3.4.3 comm 0.2.3 debugpy 1.8.17 decorator 5.2.1 exceptiongroup 1.3.0 executing 2.2.1 h11 0.16.0 [link] 1.0.9 [link] 0.28.1 idna 3.10 importlib metadata 8.7.0 ipykernel 6.30.1 ipython 8.18.1 jedi 0.19.2 jsonpatch 1.33 jsonpointer 3.0.0 jupyter client 8.6.3 jupyter core 5.8.1 langchain core 0.3.76 langchain ollama 0.3.8 langsmith 0.4.31 matplotlib inline 0.1.7 nest asyncio 1.6.0 ollama 0.6.0 orjson 3.11.3 packaging 25.0 parso 0.8.5 pexpect 4.9.0 pip 22.0.4 platformdirs 4.4.0 prompt toolkit 3.0.52 psutil 7.1.0 ptyprocess 0.7.0 pure eval 0.2.3 pydantic 2.11.9 pydantic core 2.33.2 Pygments 2.19.2 python dateutil 2.9.0.post0 PyYAML 6.0.3 pyzmq 27.1.0 requests 2.32.5 requests toolbelt 1.0.0 setuptools 58.1.0 six 1.17.0 sniffio 1.3.1 stack data 0.6.3 tenacity 9.1.2 tornado 6.5.2 traitlets 5.14.3 typing extensions 4.15.0 typing inspection 0.4.1 urllib3 2.5.0 wcwidth 0.2.14 zipp 3.23.0 zstandard 0.25.0"}, {"author": "blue-keeper", "created_at": "2025-09-28T06:40:13Z", "body_clean": "Thank you @shubhampandey3008 for testing, I also tried on linux and it worked. So i'm guessing this issue is only limited to windows (i have tested on python 3.9 and 3.13)"}, {"author": "keenborder786", "created_at": "2025-09-29T16:46:44Z", "body_clean": "@blue keeper can you post your ollama server logs from windows?"}, {"author": "blue-keeper", "created_at": "2025-09-30T05:52:38Z", "body_clean": "Sure but keep in mind that no access log were generated nor any captured by network sniffer if the code ran on windows. The access logs are from a VM. time=2025 09 30T08:56:09.559+03:30 level=INFO source=routes.go:1331 msg=\"server config\" env=\"map[CUDA VISIBLE DEVICES: GPU DEVICE ORDINAL: HIP VISIBLE DEVICES: HSA OVERRIDE GFX VERSION: HTTPS PROXY: HTTP PROXY: NO PROXY: OLLAMA CONTEXT LENGTH:8192 OLLAMA DEBUG:INFO OLLAMA FLASH ATTENTION:false OLLAMA GPU OVERHEAD:0 OLLAMA HOST: [link] OLLAMA INTEL GPU:false OLLAMA KEEP ALIVE:5m0s OLLAMA KV CACHE TYPE: OLLAMA LLM LIBRARY: OLLAMA LOAD TIMEOUT:5m0s OLLAMA MAX LOADED MODELS:0 OLLAMA MAX QUEUE:512 OLLAMA MODELS:C:\\\\Users\\\\user\\\\.ollama\\\\models OLLAMA MULTIUSER CACHE:false OLLAMA NEW ENGINE:false OLLAMA NEW ESTIMATES:false OLLAMA NOHISTORY:false OLLAMA NOPRUNE:false OLLAMA NUM PARALLEL:1 OLLAMA ORIGINS:[ [link] [link] [link] [link] [link] [link] [link] [link] [link] [link] [link] [link] app:// file:// tauri:// vscode webview:// vscode file:// ] OLLAMA SCHED SPREAD:false ROCR VISIBLE DEVICES:]\" time=2025 09 30T08:56:09.563+03:30 level=INFO source=images.go:477 msg=\"total blobs: 9\" time=2025 09 30T08:56:09.565+03:30 level=INFO source=images.go:484 msg=\"total unused blobs removed: 0\" time=2025 09 30T08:56:09.566+03:30 level=INFO source=routes.go:1384 msg=\"Listening on [::]:11434 (version 0.11.10)\" time=2025 09 30T08:56:09.566+03:30 level=INFO source=gpu.go:217 msg=\"looking for compatible GPUs\" time=2025 09 30T08:56:09.566+03:30 level=INFO source=gpu windows.go:167 msg=packages count=1 time=2025 09 30T08:56:09.566+03:30 level=INFO source=gpu windows.go:214 msg=\"\" package=0 cores=6 efficiency=0 threads=12 time=2025 09 30T08:56:09.576+03:30 level=INFO source=gpu.go:388 msg=\"no compatible GPUs were discovered\" time=2025 09 30T08:56:09.576+03:30 level=INFO source=types.go:131 msg=\"inference compute\" id=0 library=cpu variant=\"\" compute=\"\" driver=0.0 name=\"\" total=\"15.8 GiB\" available=\"2.6 GiB\" time=2025 09 30T08:56:09.576+03:30 level=INFO source=routes.go:1425 msg=\"entering low vram mode\" \"total vram\"=\"15.8 GiB\" threshold=\"20.0 GiB\" [GIN] 2025/09/30 08:56:10 | 200 | 958.8µs | 10.20.128.11 | GET \"/\" [GIN] 2025/09/30 08:56:16 | 200 | 22.8497ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 08:57:26 | 200 | 2.374ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 09:13:15 | 200 | 2.9778ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 09:13:26 | 200 | 2.8428ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 09:14:02 | 200 | 2.2396ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 09:15:05 | 200 | 3.0022ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 09:17:30 | 200 | 2.642ms | 10.20.128.11 | GET \"/api/tags\" [GIN] 2025/09/30 09:18:37 | 200 | 2.5296ms | 10.20.128.11 | GET \"/api/tags\" time=2025 09 30T09:18:38.368+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=mirostat eta time=2025 09 30T09:18:38.369+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=mirostat tau time=2025 09 30T09:18:38.369+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=tfs z time=2025 09 30T09:18:38.369+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=mirostat time=2025 09 30T09:18:38.547+03:30 level=INFO source=server.go:398 msg=\"starting runner\" cmd=\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Ollama\\\\ollama.exe runner ollama engine model C:\\\\Users\\\\user\\\\.ollama\\\\models\\\\blobs\\\\sha256 0800cbac9c2064dde519420e75e512a83cb360de3ad5df176185dc69652fc515 port 10775\" time=2025 09 30T09:18:42.662+03:30 level=INFO source=server.go:503 msg=\"system memory\" total=\"15.8 GiB\" free=\"2.2 GiB\" free swap=\"6.5 GiB\" time=2025 09 30T09:18:42.662+03:30 level=INFO source=memory.go:36 msg=\"new model will fit in available VRAM across minimum required GPUs, loading\" model=C:\\Users\\user\\.ollama\\models\\blobs\\sha256 0800cbac9c2064dde519420e75e512a83cb360de3ad5df176185dc69652fc515 library=cpu parallel=1 required=\"0 B\" gpus=1 time=2025 09 30T09:18:42.662+03:30 level=INFO source=server.go:543 msg=offload library=cpu layers.requested= 1 layers.model=25 layers.offload=0 layers.split=[] memory.available=\"[2.2 GiB]\" memory.gpu overhead=\"0 B\" memory.required.full=\"635.8 MiB\" memory.required.partial=\"0 B\" memory.required.kv=\"58.0 MiB\" memory.required.allocations=\"[0 B]\" memory.weights.total=\"577.8 MiB\" memory.weights.repeating=\"193.8 MiB\" memory.weights.nonrepeating=\"384.0 MiB\" memory.graph.full=\"2.0 GiB\" memory.graph.partial=\"2.2 GiB\" time=2025 09 30T09:18:42.810+03:30 level=INFO source=runner.go:1251 msg=\"starting ollama engine\" time=2025 09 30T09:18:42.813+03:30 level=INFO source=runner.go:1286 msg=\"Server listening on 127.0.0.1:10775\" time=2025 09 30T09:18:42.871+03:30 level=INFO source=runner.go:1170 msg=load request=\"{Operation:commit LoraPath:[] Parallel:1 BatchSize:2048 FlashAttention:false KvSize:2048 KvCacheType: NumThreads:6 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}\" time=2025 09 30T09:18:42.918+03:30 level=INFO source=ggml.go:131 msg=\"\" architecture=gemma3 file type=BF16 name=\"Embeddinggemma 300M\" description=\"\" num tensors=316 num key values=37 time=2025 09 30T09:18:54.005+03:30 level=INFO source=sched.go:441 msg=\"Load failed\" model=C:\\Users\\user\\.ollama\\models\\blobs\\sha256 0800cbac9c2064dde519420e75e512a83cb360de3ad5df176185dc69652fc515 error=\"do load request: Post \\\" [link] context canceled\" [GIN] 2025/09/30 09:18:56 | 499 | 18.546969s | 10.20.128.11 | POST \"/api/embed\" [GIN] 2025/09/30 09:19:10 | 200 | 5.4478ms | 10.20.128.11 | GET \"/api/tags\" time=2025 09 30T09:19:11.131+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=tfs z time=2025 09 30T09:19:11.131+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=mirostat tau time=2025 09 30T09:19:11.131+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=mirostat time=2025 09 30T09:19:11.131+03:30 level=WARN source=types.go:654 msg=\"invalid option provided\" option=mirostat eta time=2025 09 30T09:19:11.284+03:30 level=INFO source=server.go:398 msg=\"starting runner\" cmd=\"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Ollama\\\\ollama.exe runner ollama engine model C:\\\\Users\\\\user\\\\.ollama\\\\models\\\\blobs\\\\sha256 0800cbac9c2064dde519420e75e512a83cb360de3ad5df176185dc69652fc515 port 10825\" time=2025 09 30T09:19:11.296+03:30 level=INFO source=server.go:503 msg=\"system memory\" total=\"15.8 GiB\" free=\"2.7 GiB\" free swap=\"6.5 GiB\" time=2025 09 30T09:19:11.297+03:30 level=INFO source=server.go:543 msg=offload library=cpu layers.requested= 1 layers.model=25 layers.offload=0 layers.split=[] memory.available=\"[2.7 GiB]\" memory.gpu overhead=\"0 B\" memory.required.full=\"2.8 GiB\" memory.required.partial=\"0 B\" memory.required.kv=\"58.0 MiB\" memory.required.allocations=\"[2.4 GiB]\" memory.weights.total=\"577.8 MiB\" memory.weights.repeating=\"193.8 MiB\" memory.weights.nonrepeating=\"384.0 MiB\" memory.graph.full=\"2.0 GiB\" memory.graph.partial=\"2.2 GiB\" time=2025 09 30T09:19:11.541+03:30 level=INFO source=runner.go:1251 msg=\"starting ollama engine\" time=2025 09 30T09:19:11.544+03:30 level=INFO source=runner.go:1286 msg=\"Server listening on 127.0.0.1:10825\" time=2025 09 30T09:19:11.548+03:30 level=INFO source=runner.go:1170 msg=load request=\"{Operation:commit LoraPath:[] Parallel:1 BatchSize:2048 FlashAttention:false KvSize:2048 KvCacheType: NumThreads:6 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}\" time=2025 09 30T09:19:11.587+03:30 level=INFO source=ggml.go:131 msg=\"\" architecture=gemma3 file type=BF16 name=\"Embeddinggemma 300M\" description=\"\" num tensors=316 num key values=37 load backend: loaded CPU backend from C:\\Users\\user\\AppData\\Local\\Programs\\Ollama\\lib\\ollama\\ggml cpu haswell.dll time=2025 09 30T09:19:19.615+03:30 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang) time=2025 09 30T09:19:19.639+03:30 level=INFO source=ggml.go:487 msg=\"offloading 0 repeating layers to GPU\" time=2025 09 30T09:19:19.639+03:30 level=INFO source=ggml.go:491 msg=\"offloading output layer to CPU\" time=2025 09 30T09:19:19.639+03:30 level=INFO source=ggml.go:498 msg=\"offloaded 0/25 layers to GPU\" time=2025 09 30T09:19:19.639+03:30 level=INFO source=backend.go:315 msg=\"model weights\" device=CPU size=\"970.8 MiB\" time=2025 09 30T09:19:19.639+03:30 level=INFO source=backend.go:326 msg=\"kv cache\" device=CPU size=\"58.0 MiB\" time=2025 09 30T09:19:19.639+03:30 level=INFO source=backend.go:337 msg=\"compute graph\" device=CPU size=\"72.0 MiB\" time=2025 09 30T09:19:19.640+03:30 level=INFO source=backend.go:342 msg=\"total memory\" size=\"1.1 GiB\" time=2025 09 30T09:19:19.640+03:30 level=INFO source=sched.go:473 msg=\"loaded runners\" count=1 time=2025 09 30T09:19:19.640+03:30 level=INFO source=server.go:1250 msg=\"waiting for llama runner to start responding\" time=2025 09 30T09:19:19.640+03:30 level=INFO source=server.go:1284 msg=\"waiting for server to become available\" status=\"llm server loading model\" time=2025 09 30T09:19:22.151+03:30 level=INFO source=server.go:1288 msg=\"llama runner started in 10.87 seconds\" time=2025 09 30T09:19:31.740+03:30 level=WARN source=runner.go:160 msg=\"truncating input prompt\" limit=2048 prompt=2050 keep=0 new=2048 time=2025 09 30T09:19:41.369+03:30 level=WARN source=runner.go:160 msg=\"truncating input prompt\" limit=2048 prompt=2050 keep=0 new=2048 time=2025 09 30T09:19:46.541+03:30 level=WARN source=runner.go:160 msg=\"truncating input prompt\" limit=2048 prompt=2050 keep=0 new=2048 time=2025 09 30T09:19:52.117+03:30 level=WARN source=runner.go:160 msg=\"truncating input prompt\" limit=2048 prompt=2050 keep=0 new=2048"}, {"author": "keenborder786", "created_at": "2025-09-30T13:50:04Z", "body_clean": "[code] @blue keeper The model is not getting loaded properly. See [this]( [link]"}, {"author": "blue-keeper", "created_at": "2025-10-04T02:54:06Z", "body_clean": "I was testing multiple things and i'm not sure what caused that error. I verified that the error you pulled out of server logs won't generate when i'm running my code (i found only one and i can't quite remember what i was testing). I am certain that this problem is before the request is sent as i mentioned above that i sniffed the traffic and not a single packet went through ollama's designated port."}, {"author": "blue-keeper", "created_at": "2025-10-11T03:09:54Z", "body_clean": "I think this is not exactly a version related error. I downgraded to 0.5.4 and still had errors. A day after i started using it, it was totally fine and today after using it multiple times it came back with the same error."}, {"author": "blue-keeper", "created_at": "2025-10-11T03:58:03Z", "body_clean": "I think I have found the reason for my errors. I will test it for a few more days and with another person and in case I was right, I'll close the issue. It seems that if you enter proxy settings in windows, it won't connect to the ollama server even if you add your ollama server to to the exclusion list."}]}, {"ollama_summary": "This GitHub issue reports a bug in LangChain where a function designed to build a production AI agent fails when using middleware due to a type mismatch between the core model and its wrapper class. The bug specifically targets a scenario where the model and middleware are expected to work together, but the type check fails because the wrapper class doesn’t inherit from the expected parent class.  The current workaround forces users to choose between reliability and memory management, hindering production deployments. The suggested fix involves extending the type check or using duck typing to address this issue.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-09-26T18:45:15Z", "body_clean": "cc @sydney runkle I suspect users can't do this through modifyModelRequest either right now. We could probably modify the behavior of [code] for chat models to be specific to chat models so we get back a chat model instance."}, {"author": "galafis", "created_at": "2025-09-27T14:47:25Z", "body_clean": "Technical Analysis and Solution Hi @bart0401 and @eyurtsev, This is indeed a critical issue that affects production deployments where both reliability (fallbacks) and conversation management (middleware) are essential. I've analyzed the problem and can provide some insights. Root Cause Analysis The issue stems from the strict type checking in [code] at line 1145: [code] The inheritance hierarchy shows why this fails: [code] inherits from [code] [code] inherits from [code] → [code] Both share [code] as a common ancestor but are in different branches Proposed Solutions Option 1: Extend Type Check (Immediate Fix) [code] Option 2: Duck Typing (More Robust) [code] Option 3: Unwrap Fallback Models (Backward Compatible) [code] Impact on Middleware Functionality The middleware system works by intercepting the model's invoke/stream methods. With [code] , the middleware will: 1. Apply to the entire fallback chain (desired behavior) 2. Maintain fallback logic when primary model fails 3. Continue working with conversation summarization Testing Considerations We should ensure: Middleware applies correctly to fallback chains Fallback behavior is preserved when middleware is active Memory management works across model switches Performance impact is minimal Recommended Approach I recommend Option 1 for immediate fix followed by Option 2 for long term robustness. This approach: ✅ Fixes the immediate issue ✅ Maintains backward compatibility ✅ Supports future runnable types ✅ Provides better error messages Would you like me to prepare a PR with the implementation? I can include comprehensive tests covering: Basic fallback + middleware functionality Error handling scenarios Performance benchmarks Documentation updates Gabriel"}, {"author": "eyurtsev", "created_at": "2025-10-07T02:09:01Z", "body_clean": "We will be addressing this issue using middleware to handle model fallbacks."}]}, {"ollama_summary": "This issue reports a critical bug in LangChain Studio that causes the `langgraph studio` node to be deleted upon modification, resulting in a complete failure to retrieve the requested JSON response. The bug is linked to a specific ` langchain` integration package and appears to be a regression, not a user-initiated change.  The issue is currently being addressed by a fix in a later stable release of LangChain.", "final_category": "bug", "comments": [{"author": "orbin123", "created_at": "2025-09-27T13:12:47Z", "body_clean": "I'd like to take a look at this bug. Is there anything more I need to know to get started with debugging?"}, {"author": "bernatsampera", "created_at": "2025-09-27T14:34:45Z", "body_clean": "No, you should be able to reproduce it in langgraph studio"}, {"author": "saimadhu27", "created_at": "2025-10-07T07:33:23Z", "body_clean": "Hello! I was able to reproduce this issue as well. Why this happens This doesn’t seem to be a bug in LangChain’s [code] itself. The method just returns a Pydantic model as expected. The issue arises in LangGraph when that Pydantic object is stored directly in state [code] returns a Pydantic model. That object is not JSON serializable. The checkpointer saves state data to disk/DB and expects JSON values. When loading the previous run’s state after a code reload, it can’t handle the Pydantic object, so the old thread is discarded. Workaround If I call [code] on the Pydantic object before putting it in state, everything works as expected: [code] Suggestion The docs explain how to define state using [code] , dataclass, or Pydantic, but they don’t mention that the values stored in state must be JSON serializable. I’d be happy to open a PR to add this clarification to the LangGraph docs if that would be helpful."}]}], "business_insights": ["Package compatibility issues are a persistent and costly problem for LangChain users.", "Early bug detection and resolution are critical for maintaining user confidence and minimizing disruption.", "Addressing legacy code issues proactively is essential for long-term stability and scalability.", "Dependency management and version control are vital for ensuring consistent behavior across different environments.", "Comprehensive testing and regression analysis are crucial for identifying and fixing bugs quickly."], "technical_insights": ["LangChain's reliance on specific key structures across versions necessitates rigorous version control and dependency management.", "The ollama embedding model initialization process is a complex area with potential for subtle integration issues.", "The ValidationError in the ollama initialization can be a symptom of issues with the Ollama API or LangChain integration.", "The langgraph studio node deletion issue highlights a potential regression in LangChain's core functionality.", "The  langchain integration package is a known source of bugs and regression, requiring immediate attention."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Package compatibility issues are a persistent and costly problem for LangChain users.\n2.  Early bug detection and resolution are critical for maintaining user confidence and minimizing disruption.\n3.  Addressing legacy code issues proactively is essential for long-term stability and scalability.\n4.  Dependency management and version control are vital for ensuring consistent behavior across different environments.\n5.  Comprehensive testing and regression analysis are crucial for identifying and fixing bugs quickly.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's reliance on specific key structures across versions necessitates rigorous version control and dependency management.\n2.  The `ollama` embedding model initialization process is a complex area with potential for subtle integration issues.\n3.  The `ValidationError` in the `ollama` initialization can be a symptom of issues with the Ollama API or LangChain integration.\n4.  The `langgraph studio` node deletion issue highlights a potential regression in LangChain's core functionality.\n5.  The ` langchain` integration package is a known source of bugs and regression, requiring immediate attention.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 12, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a bug in LangChain that causes the `structured outputs` feature to fail when running `langchain ollama with gpt oss:20b` specifically, when the `gpt oss:20b` is used. This is isolated to the `gpt oss:20b` configuration and doesn't affect other `gpt oss:20b` configurations. The code in the `ask` function raises an `OutputParserException` due to an invalid JSON output. The solution involves downgrading the LangChain version to `v0.1.0` and ensuring compatibility with the specific `gpt oss:20b` configuration.", "final_category": "bug", "comments": [{"author": "mahimairaja", "created_at": "2025-09-25T22:40:02Z", "body_clean": "This might be due to [harmony response format]( [link]"}, {"author": "mahimairaja", "created_at": "2025-09-25T22:40:22Z", "body_clean": "Are you willing to work on this issue @ChrisRawstone?"}, {"author": "heyits-manan", "created_at": "2025-09-26T00:30:03Z", "body_clean": "@ChrisRawstone If u want a simple work around for now, u can just use ChatOllama(model=\"gpt oss:20b\", reasoning=False). ChatOllama(model=\"gpt oss:20b\", reasoning=True) fail because the model prepends non JSON “reasoning” tokens. with structured output(..., method=\"json schema\") expects JSON at the start and throws OutputParserException. The same code works when reasoning=False or with models that don’t prepend reasoning."}, {"author": "ChrisRawstone", "created_at": "2025-09-26T01:21:36Z", "body_clean": "@heyits manan Just tried ChatOllama(model=\"gpt oss:20b\", reasoning=False) and got the same error. I did try that before I made this github issue as well. I am unsure, what you have done to get it working?"}, {"author": "ChrisRawstone", "created_at": "2025-09-26T01:23:02Z", "body_clean": "Are you willing to work on this issue [@ChrisRawstone]( [link] @mahimairaja Don't think I have the skills to fix this issue, sorry."}, {"author": "heyits-manan", "created_at": "2025-09-26T01:43:54Z", "body_clean": "@ChrisRawstone hmmm. I will look into it. I thought it will fix it"}, {"author": "heyits-manan", "created_at": "2025-09-26T02:18:38Z", "body_clean": "@ChrisRawstone Yes the issue is with the Langchain itself not your code. There is already an active pull request 33042. U can also use the below code to make it work import re from langchain core.output parsers import PydanticOutputParser from langchain core.prompts import ChatPromptTemplate from langchain core.output parsers import StrOutputParser parser = PydanticOutputParser(pydantic object=Joke) prompt = ChatPromptTemplate.from messages([ (\"system\", \"Return ONLY valid JSON matching this schema:\\n\" + parser.get format instructions()), (\"user\", \"{input}\") ]) llm = ChatOllama(model=\"gpt oss:20b\", reasoning=True) def strip reasoning(text:str) str: remove <think blocks and any leading non JSON noise text = re.sub(r\"<think . ?</think \", \"\", text, flags=re.DOTALL|re.IGNORECASE) try to extract the first JSON object m = re.search(r\"\\{. \\}\", text, flags=re.DOTALL) return m.group(0) if m else text best effort chain = prompt | llm | StrOutputParser() | (lambda s: strip reasoning(s)) | parser print(chain.invoke({\"input\": \"Tell me a joke about cats\"})) The strip reasoning() method will remove the (think tags) blocks that appears when u add \"reasoning=True\" or \"reasoning=False\" which is causing the problem."}, {"author": "AkibDa", "created_at": "2025-09-26T03:55:25Z", "body_clean": "@ChrisRawstone Here is the corrected code. It uses [code] and removes the extra parameter, which will force the model to output valid JSON that matches your [code] class. [code]"}, {"author": "ChrisRawstone", "created_at": "2025-09-26T12:02:23Z", "body_clean": "Thanks @AkibDa @heyits manan for coming up with suggestions. However the problem is that both suggestions/approaches avoids using the ollama's native structured output. Sadly \"json mode\" is not as reliable as \"json schema\" and tend to break at some point. Before creating this issue, I did notice that both \"json mode\" and \"function calling\" works, but it is a shame that json schema does not work... According to Ollama blogpost when they introduced gpt oss they mentioned they support native structured outputs. So I assume the problem is in the langchain implementation. [ [link] The json schema works with every other reasoning and llm model I have tested so it would be great if we could get this working with the state of the art llm model \"gpt oss\" as well.. Please correct me if I am wrong."}, {"author": "AkibDa", "created_at": "2025-09-26T12:20:29Z", "body_clean": "You are absolutely correct in your reasoning. The issue almost certainly lies in the LangChain integration layer for Ollama, not with the [code] model or Ollama itself.The problem isn't that [code] can't produce structured output; it's that the specific, highly constrained [code] method in LangChain has an integration gap with this particular model via Ollama."}, {"author": "mdrxy", "created_at": "2025-10-02T02:26:31Z", "body_clean": "This is an upstream issue [link] Happy to address it once released in [code] and [code]"}]}, {"ollama_summary": "This issue requests LangChain to integrate Sarvam Chat models, a specialized LLM for Indian languages, into the framework. The developers initially searched for a similar feature request and found none, but verified it doesn’t relate to the LangChain community package. The proposed solution involves adding a new integration with a SarvamChat class, offering configuration options and seamless integration within LangChain applications.", "final_category": "feature", "comments": [{"author": "rohnsha0", "created_at": "2025-09-25T15:49:35Z", "body_clean": "+1"}, {"author": "parth1609", "created_at": "2025-10-16T14:29:47Z", "body_clean": "I Will be!!!"}, {"author": "parth1609", "created_at": "2025-10-20T13:55:22Z", "body_clean": "Langchain sarvam Pypi : [link] Github : [link] Check it out."}]}, {"ollama_summary": "This GitHub issue requests the implementation of support for decentralized agent-to-agent communication via the HyperCortex Mesh Protocol (HMP). The team is exploring a feature to enable agents to share knowledge, cognitive diaries, and reasoning strategies across a distributed network, mimicking a “mesh” of interconnected agents. Currently, the LangChain documentation doesn’t explicitly address this functionality, prompting a solution involving optional plugin/extension support and integration of shared cognitive diaries and semantic graphs.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-10-20T15:43:37Z", "body_clean": "@kagvi13 We will not add support for any protocols right now unless they're adopted widely / supported by an official organization / enterprise."}]}, {"ollama_summary": "The `llama_decode` library returns -1 when attempting to add documents to a PGVector (store), causing an error. This issue is a bug within the LangChain library, not a usage problem, and is not related to the LangChain community package. A minimal reproducible example has been provided to demonstrate the error and confirm the problem lies within the core functionality of the embedding process.", "final_category": "bug", "comments": [{"author": "AkibDa", "created_at": "2025-09-26T04:00:56Z", "body_clean": "You need to tell the model to use a larger context window that can accommodate your text chunks. A context size of 2048 is a safe and common choice. Update the line where you initialize [code] like this: [code] By setting [code] , you are ensuring the model's context window is large enough for your 1000 token chunks, which will resolve the error."}, {"author": "AkibDa", "created_at": "2025-09-26T04:04:41Z", "body_clean": "Fixed code : [code]"}, {"author": "sidietz", "created_at": "2025-09-26T06:19:05Z", "body_clean": "While testing I played around with the context sizes default (512), 1024 and 4096 before submitting this bug report. Even with [code] the error persists on my machine, even when running the model on the CPU instead of the GPU. Do you have an idea how I can debug the [code] further?"}, {"author": "AkibDa", "created_at": "2025-09-26T06:25:15Z", "body_clean": "Error The specific error you're encountering is [code] . This is a generic, low level error message originating from the underlying [code] library that LangChain's [code] uses. It indicates that a critical failure occurred during the model's attempt to process the input text (a process called decoding or inference). The error is not in the Python syntax itself but points to a deeper problem. The most common causes for this are: Corrupted Model File: The [code] model file you downloaded might be incomplete or corrupted. This is the most frequent cause of this specific error. Memory Issues: Even on the CPU, processing large batches of text can exhaust your system's RAM, leading to a crash that the library reports as a decode error. Your batch size of [code] combined with a [code] of 1000 is quite memory intensive. Library Version Mismatch: The version of the [code] library installed in your environment might not be fully compatible with the specific quantization method used for your GGUF model."}, {"author": "AkibDa", "created_at": "2025-09-26T06:27:55Z", "body_clean": "Step 1: Create a Minimal Test Script First, let's confirm the model can load and run correctly in isolation, outside of your complex data pipeline. Create a new file named [code] : [code] Step 2: Update Your Libraries Ensure you have the latest compatible versions of the libraries. [code] Step 3: Correct the Original Code Once the minimal test works, you can apply the learnings to your original script. I also noticed a guaranteed future error in your database connection string, which I've corrected below. [code]"}, {"author": "sidietz", "created_at": "2025-09-26T09:11:20Z", "body_clean": "Thanks for the test model.py. It runs without an error (see full output at the end of this comment). [code] runs as expected as before. Upgrading the packages did not help. [code] I've added the database name to the connection string as well, but that (obviously) did not help, either. I've re downloaded the model file, too. That changed nothing. My next step is to convert the original gpt oss safetensors to gguf and testing the resulting gguf file. [code]"}, {"author": "AkibDa", "created_at": "2025-09-26T09:18:50Z", "body_clean": "Of course. Based on the Python script and the detailed log output, here is a full analysis of what's happening. This is a great, detailed log for debugging\\! The key takeaway is that while your script runs without crashing, it's failing to offload any model layers to your AMD GPU and is running entirely on the CPU. Why is This Happening & How to Fix It The root cause is an incompatibility between the [code] Vulkan backend, your specific GPU drivers, and the quantization formats within that particular GGUF file. Here are the most likely solutions, in order of what you should try first: 1\\. Reinstall [code] with the Correct Backend Flags Your current installation might not have been built correctly with full Vulkan support. The best way to ensure this is to force a recompile from source. [code] After reinstalling, run your test script again and check the logs to see if it now offloads layers. 2\\. Try a Different Model Quantization The Unsloth model you're using has a mix of quantization types ( [code] , [code] , [code] , [code] ). It's possible the Vulkan backend has poor support for one of these, especially the less common [code] . Try downloading a more \"standard\" GGUF model, for example, from the popular creator \"TheBloke.\" A [code] or [code] quant from one of his models is highly likely to be compatible. This will help you determine if the issue is with the model file itself or your environment. 3\\. (Alternative) Build with ROCm Instead of Vulkan ROCm is AMD's more direct equivalent to NVIDIA's CUDA. It can sometimes be more stable and performant than the Vulkan backend. If step 1 doesn't work, you could try building with ROCm support. This is more involved as it requires installing the ROCm toolkit from AMD first. Once ROCm is installed, the [code] command would be: [code] Your next step of converting the safetensors yourself is a good idea, but I would strongly recommend trying Step 1 first, as an improper build of [code] is the most common cause of this exact issue."}, {"author": "sidietz", "created_at": "2025-09-26T13:41:31Z", "body_clean": "After building and re installing llama cpp python with the correct flag, the model (gpt oss 20b converted with llama.cpp) seems to be loaded onto the GPU properly. However the error persists. What strikes me the most is, that the error occurs even when running on the cpu. I'll downgrade llama.cpp to the version supported by llama cpp python next. [code]"}, {"author": "sidietz", "created_at": "2025-09-26T17:19:54Z", "body_clean": "After some more digging and trial and error I found out, that this bug may be related to an [API change ]( [link] llama.cpp which has not been taken into account by the llama cpp python developer (which has not been active since August). Embedding only one chunk [code] seems to work. Then, when the model sequence id should be reset in order to process the next chunk, the old API is used to do that (kv clear something) and that fails. Hence the sequence id is not (re)set and the error occurs. If that is the case, the error obviously resides in llama cpp python."}, {"author": "AkibDa", "created_at": "2025-09-26T17:31:44Z", "body_clean": "Your diagnosis is correct: the error happens because [code] fails to properly reset the model's state (the KV cache) between documents when processing a batch. It attempts to use an outdated API call to clear the context, which fails, leading to a context overflow error on the second chunk. Solutions Here are a few ways to work around this issue, from the simplest to the most robust. 1. The Simple Loop (Recommended Workaround) Instead of passing the entire list of documents to add documents at once, you can simply loop through the list and add them one by one. This forces a new, clean embedding process for each document, completely bypassing the batching bug. Change this: Python [code] To this: [code] This is the most direct and reliable fix for the code you've provided. 2. Update llama cpp python The bug you've encountered has been a known issue. While the original developer may have been inactive, the community has often stepped in. Try forcing a re install of the latest version, which may have a patch. Make sure to specify the CMAKE ARGS to enable the correct hardware acceleration for your system (CUDA in this example). [code] After updating, try your original code again. If it's been patched, it should work. 3. Use a Different Embeddings Class If the issue persists and you want a more stable solution for local embeddings, you can switch to a different LangChain class that doesn't depend on llama cpp python. The HuggingFaceEmbeddings class (which uses the highly optimized sentence transformers library) is an excellent alternative. You would first need to download a model specifically designed for embeddings, like BAAI/bge large en v1.5. Example of switching: [code]"}]}, {"ollama_summary": "This GitHub issue addresses a limitation in create agent where it no longer supports pre-bound models with fallback capabilities due to a lack of integration with LangChain. The issue aims to restore this functionality, specifically allowing for failover during OpenAI outages.  Currently, the solution proposed is to implement this feature as a workaround.", "final_category": "feature", "comments": [{"author": "keenborder786", "created_at": "2025-09-24T14:28:40Z", "body_clean": "[code] You can still pass the fallback"}, {"author": "aaron-seq", "created_at": "2025-09-25T12:45:09Z", "body_clean": "Great point @keenborder786! You're absolutely right that [code] does indeed support fallback models. To further clarify this for @tornadotang and others who might encounter this issue: ✅ [code] DOES Support Fallbacks The [code] function accepts both string model names and [code] instances. This means you can pass a pre configured model with fallbacks: [code] 📚 Complete Example with Error Handling [code] 🔄 How Fallbacks Work in [code] 1. Model Initialization : The function checks if the model is a string or [code] instance 2. Tool Binding : The model (with its fallbacks) gets bound to tools 3. Execution : If the primary model fails, LangChain automatically tries the fallback models 4. Transparency : The agent works normally, with fallbacks handled at the model level So the capability you're looking for is already there! The key is to set up your fallback chain before passing it to [code] , not within the agent creation itself. Hope this helps clarify the functionality! 🚀"}]}], "business_insights": ["Versioning inconsistencies can impact development stability.", "Feature requests should prioritize impact and feasibility.", "Integration testing is crucial for new features.", "Documentation needs to be updated to reflect recent changes.", "User feedback is vital for iterative development."], "technical_insights": ["LangChain’s structured outputs feature is sensitive to gpt oss:20b configuration.", "Sarvam Chat model integration requires careful compatibility testing.", "Decentralized agent communication via HMP is a complex, future-oriented feature.", "llama_decode returns -1 when adding documents to PGVector.", "The create agent feature lacks fallback capabilities."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Versioning inconsistencies can impact development stability.\n2. Feature requests should prioritize impact and feasibility.\n3. Integration testing is crucial for new features.\n4. Documentation needs to be updated to reflect recent changes.\n5. User feedback is vital for iterative development.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s `structured outputs` feature is sensitive to `gpt oss:20b` configuration.\n2. Sarvam Chat model integration requires careful compatibility testing.\n3. Decentralized agent communication via HMP is a complex, future-oriented feature.\n4. `llama_decode` returns -1 when adding documents to PGVector.\n5. The `create agent` feature lacks fallback capabilities.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 13, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in FalkorDB where it consistently uses Euclidean distance instead of Cosine distance, despite explicitly setting the distance strategy to Cosine. This inconsistency impacts similarity search results and scoring, potentially causing issues with the core functionality of the LangChain vectorstore.  The issue is not related to the LangChain community package and involves a specific mapping issue within the distance calculation, requiring a minimal reproducible example to demonstrate the problem.", "final_category": "bug", "comments": [{"author": "Akanksha-turinton", "created_at": "2025-09-25T08:55:43Z", "body_clean": "If you comment this particular line 'WITH node, (2 score) / 2 AS score' from the falkodb vector.py module you'll see such results : Roti, Score: 0.0 Doc: Roti Batch, Score: 0.698758959770203 Doc: Recipe, Score: 1.21840107440948 Indicating the use of euclidean distance . and If u put the value of k =1 here 'results = vector store.similarity search with score(query=query, k=1)' You'll see this result: Doc: Roti, Score: 0.0 Indicating it knows that roti is top result but score is still zero"}, {"author": "Sathyanarayanan-ops", "created_at": "2025-09-25T17:32:16Z", "body_clean": "Hi, Thanks for clearing this up this does give some lead to work on"}, {"author": "galshubeli", "created_at": "2025-09-26T09:22:33Z", "body_clean": "Hi @Akanksha turinton, Thank you for bringing it up! We will look into it."}, {"author": "Sathyanarayanan-ops", "created_at": "2025-09-26T15:23:08Z", "body_clean": "Hi @galshubeli , i was able to work on a few fixes, should i do a PR ?"}, {"author": "gkorland", "created_at": "2025-09-26T15:54:17Z", "body_clean": "@Sathyanarayanan ops thanks that would be great!"}, {"author": "Sathyanarayanan-ops", "created_at": "2025-09-29T01:23:23Z", "body_clean": "Hi, Further research prompted me to find a few bugs , that i fixed. The PR is right here , [ [link] However , what i found is that , the core function to compute the 2 distances, works fine [code] Itself gives the right answer The problem begins on how its being retrieved, which i believe is not a problem in the Langchain library. I am opening an issue in the falkordb repo , but i think we can close this issue for now , please let me know if otherwise Also please feel free to suggest changes to the PR linked above"}, {"author": "Akanksha-turinton", "created_at": "2025-09-29T06:45:17Z", "body_clean": "Hi , @Sathyanarayanan ops Can you elaborate the issue in falkor retrieval side ?"}, {"author": "Sathyanarayanan-ops", "created_at": "2025-09-29T17:31:28Z", "body_clean": "Hi , [@Sathyanarayanan ops]( [link] Can you elaborate the issue in falkor retrieval side ? Hi Akanksha, Sorry, I should have linked the issue that I opened in FalkorDB repo. Please find it below , also any of the mods can review the PR I have made and then close this issue after it is merged. Please let me know if you need further elaboration. Thanks [ [link]"}]}, {"ollama_summary": "The `RunnableConfig` is failing to be passed to tools when using the `AgentExecutor` due to an issue where the configuration is not being propagated to the tool. This results in empty or missing configurations within the tool, leading to errors and a lack of information. The problem appears to be related to the configuration being lost during the process of passing it to the tool.", "final_category": "bug", "comments": [{"author": "heyits-manan", "created_at": "2025-09-25T16:28:18Z", "body_clean": "I have created a PR 33117 . There are linting issues for now. Can u check the code ?"}, {"author": "aroun-coumar", "created_at": "2025-10-07T10:34:48Z", "body_clean": "I have opened a PR fix for this issue Any repo maintainer please review it @sbusso"}, {"author": "sbusso", "created_at": "2025-10-07T12:31:40Z", "body_clean": "I have opened a PR fix for this issue Any repo maintainer please review it [@sbusso]( [link] @aroun coumar no, thanks"}, {"author": "aroun-coumar", "created_at": "2025-10-07T12:46:44Z", "body_clean": "@sbusso Do you mean you are not repo maintainer, Sorry about that."}]}, {"ollama_summary": "This issue proposes a significant improvement to Langchain's multimodal data handling, focusing on creating a more structured and expressive interface for representing complex information like tables and formulas. Currently, Langchain’s approach of concatenating text and other modalities into a single prompt string is cumbersome and limits the LLM’s ability to effectively utilize rich data. The proposed solution involves defining a standardized interface using Pydantic models to represent structured data, enabling more granular retrieval and citation workflows.  The issue suggests exploring this concept as a potential upgrade to improve the overall RAG pipeline.", "final_category": "feature", "comments": []}, {"ollama_summary": "This issue is addressing a bug in the `ChatOpenAI` library where the `api_key` parameter can now accept callable inputs instead of just strings. This change impacts the ability to generate tokens for Azure OpenAI APIs, requiring a modification to the wrapper to support callable inputs. The code is currently failing due to a type validation error, and the issue is not related to the LangChain community package.", "final_category": "bug", "comments": [{"author": "heyits-manan", "created_at": "2025-09-24T02:11:22Z", "body_clean": "Hi. Thanks for raising this issue! I’ve opened a PR ( 33069) that updates ChatOpenAI (and related classes) to accept a callable for api key, in line with the latest OpenAI SDK. This should resolve the validation error you hit when using Azure token providers. Feedback is very welcome! Note: CI currently fails on grafana/pr labeler action with: Resource not accessible by integration. This is caused by how GitHub Actions handle forked PRs — the action needs to run with pull request target and permissions: pull requests: write. That’s an infra/config tweak and not related to the code changes in this PR."}, {"author": "ccurme", "created_at": "2025-10-22T15:01:30Z", "body_clean": "We released support for this yesterday: [link]"}, {"author": "pamelafox", "created_at": "2025-10-22T15:45:34Z", "body_clean": "@ccurme Yes, thank you! I tried it out last night: [link] It's working well, the only issue I found is one that's a consequence of now using the OpenAI client that passes \"strict\" for tool calls: [link] That is orthogonal however, no issues with the api key callable so far. Thanks!"}]}, {"ollama_summary": "This issue highlights a bug in LangChain's `addableUpdatesDict` module, specifically preventing the correct addition of right-side elements when using the `agentexecutor` function. The code attempts to utilize a minimal reproducible example, but the bug manifests when attempting to use the `agentexecutor` with a specific instance of `SystemInfo`.  The issue is not related to the LangChain community package and requires a fix within the LangChain library itself.", "final_category": "bug", "comments": [{"author": "HERIUN", "created_at": "2025-09-22T02:45:01Z", "body_clean": "[link] i found the type of final output is 'langgraph.pregel.io.AddableUpdatesDict'"}, {"author": "aroun-coumar", "created_at": "2025-09-24T12:15:39Z", "body_clean": "Hi @HERIUN , I tried to solve the bug , can you please mention the langgraph version you are using, I couldnt track AddableUpdatesDict from the present langgraph repo The issue is probably an inconsistency with add and radd attributes of AddableDict method and any method AddableUpdatesDict The AddableDict supports both add and radd . So if we can locate the file with AddableUpdatesDict we can resolve the bug I would solve this issue if you confirm the bug with latest langgraph version"}, {"author": "HERIUN", "created_at": "2025-09-29T02:00:44Z", "body_clean": "@aroun coumar sorry for late.. I used 0.6.7 but failed.. [code]"}, {"author": "aroun-coumar", "created_at": "2025-10-01T13:39:45Z", "body_clean": "@HERIUN The code seems to be refactored because AddableUpdatesDict isnt present in the traceback given. Please reinstall all dependencies and check it once"}]}], "business_insights": ["Mapping issues within the distance calculation are a recurring theme, suggesting potential code refactoring.", "The focus on falkodb vector.py module indicates a deeper dive into the specific distance metric.", "The AgentExecutor configuration issue highlights a need for clearer and more robust agent setup.", "The multimodal data handling proposal suggests a shift towards a more structured data representation.", "The addableUpdatesDict bug points to potential type errors in the library’s core."], "technical_insights": ["Distance strategy Euclidean vs. Cosine – inconsistency warrants investigation.", "falkodb vector.py module – further investigation needed for precise mapping.", "AgentExecutor configuration – ensure proper configuration propagation.", "Multimodal data representation – explore standardized interface design.", "addableUpdatesDict – potential type validation error – prioritize fix."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Mapping issues within the distance calculation are a recurring theme, suggesting potential code refactoring.\n2. The focus on `falkodb vector.py` module indicates a deeper dive into the specific distance metric.\n3. The `AgentExecutor` configuration issue highlights a need for clearer and more robust agent setup.\n4. The multimodal data handling proposal suggests a shift towards a more structured data representation.\n5. The `addableUpdatesDict` bug points to potential type errors in the library’s core.\n\nTECHNICAL INSIGHTS:\n1. Distance strategy `Euclidean` vs. `Cosine` – inconsistency warrants investigation.\n2. `falkodb vector.py` module – further investigation needed for precise mapping.\n3. `AgentExecutor` configuration – ensure proper configuration propagation.\n4. Multimodal data representation – explore standardized interface design.\n5. `addableUpdatesDict` – potential type validation error – prioritize fix.\n", "batch_number": 14, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is that the `reasoning` parameter in the `chatollama` library isn’t working as expected, causing the model to return think content in the response body when disabling its `think` feature. This appears to be a bug within the LangChain package, and the solution involves updating to the latest stable version of LangChain, which is not related to the `chatollama` package itself.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-22T15:25:37Z", "body_clean": "What model(s) are you encountering this issue with? Some models don't allow disabling reasoning."}, {"author": "mudassir206", "created_at": "2025-09-22T16:44:21Z", "body_clean": "@mdrxy. we have used qwen3:4b to verify how reasoning parameter disables/enables the think content. The same qwen models when invoked using groq(chatgroq) , were able to strip out think content successfully when reasoning is disabled."}, {"author": "mdrxy", "created_at": "2025-10-02T02:10:27Z", "body_clean": "I can't recreate this issue: [code] Neither case results in [code] tags shown. Your example includes [code] which is not a valid option. Could you provide a MRE?"}, {"author": "yashranaway", "created_at": "2025-10-02T05:40:15Z", "body_clean": "try deepseek r1:1.5b"}, {"author": "mdrxy", "created_at": "2025-10-02T15:10:37Z", "body_clean": "@yashranaway [code] [code] Still not encountering it. Are you on the latest version of [code] ?"}]}, {"ollama_summary": "The issue reports a type checking error when importing a tool decorator in PyLance, specifically when using strict mode.  The developer has identified this as a bug within the LangChain library and has provided a minimal reproducible example to demonstrate the problem.  Currently, the bug isn't addressed by updates to the LangChain core version.", "final_category": "bug", "comments": [{"author": "rishu685", "created_at": "2025-09-20T12:00:12Z", "body_clean": "same even i got this issue too maybe you can try this fix: In file: langchain core/src/langchain core/tools.py existing code: def tool( args: Union[str, Callable, type[BaseModel]], kwargs: Any, ) Union[Callable, Tool]: existing code : Add the following line to explicitly define the type of 'tool' tool: \"typing.Any\""}, {"author": "le-codeur-rapide", "created_at": "2025-09-20T18:54:09Z", "body_clean": "Hi @rishu685 I am not sure I understand, what exactly is your error ?"}, {"author": "rishu685", "created_at": "2025-09-20T18:59:29Z", "body_clean": "Not a issue its a bug same as yours!"}, {"author": "le-codeur-rapide", "created_at": "2025-09-20T20:42:15Z", "body_clean": "Oh ok I have made a PR to fix this 33020 , maybe it will be merged for next versions of langchain"}]}, {"ollama_summary": "This issue stems from a bug in LangChain v1-alpha that causes issues with the CallbackHandler.py, specifically when interacting with the Langfuse integration. This bug is not related to the LangChain community package and affects the agent's functionality, requiring a minimal reproducible example to demonstrate the problem.", "final_category": "bug", "comments": [{"author": "SAIL-Fang", "created_at": "2025-09-19T08:02:21Z", "body_clean": "D:\\ProgramData\\Anaconda3\\envs\\llm\\lib\\site packages\\langfuse\\langchain\\CallbackHandler.py:24 28 From [code] To: [code] Fix it！"}]}, {"ollama_summary": "The issue reports a bug in the `OutputParserException` when using Ollama instead of Gemini, specifically when attempting to use the example code provided. A minimal reproducible example demonstrates the problem – the integration seems to be faulty and doesn’t work consistently with Ollama.  The problem isn’t related to the LangChain community package and is likely a bug within the Ollama integration itself.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a summary of the GitHub issue in 2-3 concise sentences:\n\nThe issue proposes renaming the `model` alias to `llm` within the `create_agent` function to improve code readability and maintainability. This change is requested by the LangChain maintainer to streamline the code.", "final_category": "feature", "comments": []}], "business_insights": ["Updating LangChain will likely resolve the chatollama library bug, improving model responses.", "Focusing on the chatollama issue suggests a need for more robust model parameter handling.", "Addressing the LangChain bug will enhance code clarity and maintainability.", "The renaming change is a standard practice for improving code structure.", "Streamlining code with llm is a generally good practice for maintainability."], "technical_insights": ["LangChain version update is a direct solution to the chatollama bug.", "The chatollama bug highlights a potential issue with model parameter control.", "The LangChain bug is a fundamental issue impacting agent functionality.", "Ollama integration bug points to a potential problem within the Ollama package.", "Code readability improvements are a priority for the LangChain maintainer."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Updating LangChain will likely resolve the `chatollama` library bug, improving model responses.\n2. Focusing on the `chatollama` issue suggests a need for more robust model parameter handling.\n3. Addressing the `LangChain` bug will enhance code clarity and maintainability.\n4. The renaming change is a standard practice for improving code structure.\n5. Streamlining code with `llm` is a generally good practice for maintainability.\n\nTECHNICAL INSIGHTS:\n1. LangChain version update is a direct solution to the `chatollama` bug.\n2. The `chatollama` bug highlights a potential issue with model parameter control.\n3. The `LangChain` bug is a fundamental issue impacting agent functionality.\n4. Ollama integration bug points to a potential problem within the Ollama package.\n5. Code readability improvements are a priority for the LangChain maintainer.\n", "batch_number": 15, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "BurnCloud is requesting permission to contribute enhancements to the GitHub repository. The request is a feature request, not a bug or usage question, and the author has conducted thorough research to ensure it doesn’t relate to the LangChain community. They are seeking to provide free API access for open-source projects and support for various LLMs.", "final_category": "feature", "comments": [{"author": "mdrxy", "created_at": "2025-09-18T13:36:27Z", "body_clean": "Sure, take a look at our contributing guide. [link]"}]}, {"ollama_summary": "The `StringPromptTemplate` class is missing the implementation of its abstract base method `format`.  A search revealed this is a bug within the LangChain library, not a problem with the code itself. The issue is specifically related to the class attempting to call the abstract method, requiring a fix to ensure proper functionality.", "final_category": "bug", "comments": [{"author": "Simon-Stone", "created_at": "2025-09-18T13:14:18Z", "body_clean": "Nevermind, just realized that [code] is also supposed to be an abstract class."}]}, {"ollama_summary": "This issue stems from a bug in the ChatBedrockConverse library that causes it to emit `on_chat_model_stream` events instead of the expected `on_chain_stream` events when interacting with OpenAI models in LangGraph. This disruption impacts applications relying on these events, potentially leading to streaming functionality loss.  The issue is reproducible in a Docker environment with the specified package versions and dependencies, and a minimal example demonstrates the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue focuses on the lack of a defined \"bind tools\" method for the AimlapiLLM, hindering its ability to utilize function calling capabilities. The developer has investigated existing LangChain documentation and community resources but hasn’t found a similar feature.  The core problem is a missing mechanism for integrating external tools and functions into the AimlapiLLM’s workflow.", "final_category": "feature", "comments": [{"author": "sagnik3788", "created_at": "2025-09-22T11:18:50Z", "body_clean": "can you assign me this issue? @mdrxy"}, {"author": "mahimairaja", "created_at": "2025-09-22T18:22:33Z", "body_clean": "@sagnik3788 are you actively working on this issue?"}, {"author": "sagnik3788", "created_at": "2025-09-23T18:23:55Z", "body_clean": "yes i am working on it"}, {"author": "sagnik3788", "created_at": "2025-09-23T21:19:28Z", "body_clean": "Where is the implementation of the provider? it's not available [here]( [link] @mdrxy"}, {"author": "mdrxy", "created_at": "2025-09-24T03:53:34Z", "body_clean": "Looks to be [here]( [link] Note this is not a LangChain maintained integration."}]}, {"ollama_summary": "This issue reports a bug in LangChain that causes a `BadRequest 400` when invoking the GPT-OSS-20B model. The problem stems from a mismatch between the expected AIMessage and ToolMessage format when using the local model, leading to an exception.  The issue is not related to the LangChain community package and is a specific issue with the model itself, not a problem with the LangChain library or its integration.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-18T13:55:33Z", "body_clean": "[code] vllm doesn't yet support the OpenAI Responses API. [link] Unset the param and it should hopefully work (having issues with vllm on my MacBook; can't test)"}, {"author": "LIN-Yu-Ting", "created_at": "2025-09-18T15:03:30Z", "body_clean": "@mdrxy I have tried without use responses api=True. [code] After bind tools, my llm with tools can not return a AIMessage with tool calls information. If I create my agent with langgraph create react agent function, then I will receive something like. <img width=\"720\" height=\"363\" alt=\"Image\" src=\" [link] /"}, {"author": "wldlsyy", "created_at": "2025-09-29T06:54:57Z", "body_clean": "Hi, I faced the same issue... and just wondered if you have solve this problem or not.."}, {"author": "LIN-Yu-Ting", "created_at": "2025-10-02T13:27:13Z", "body_clean": "Hi @wldlsyy. I temporarily used openai agents SDK to interact with GPS OSS 20B model. You can install it by 'pip install openai agents' while waiting any solutions to come later."}]}], "business_insights": ["Feature requests often reveal broader needs, guiding development.", "Bugs can trigger further investigation and require fixes, impacting users.", "Missing features hinder user experience and potentially limit functionality.", "Code issues necessitate debugging and resolution to maintain stability.", "Feature requests require thorough research to ensure alignment with user needs."], "technical_insights": ["StringPromptTemplate abstract class is a bug requiring a fix.", "on_chat_model_stream event emission discrepancy in ChatBedrockConverse.", "BadRequest 400 error in LangChain related to AIMessage and ToolMessage format.", "Missing “bind tools” method hinders AimlapiLLM’s functionality.", "Model mismatch between AIMessage and ToolMessage format causes exceptions."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Feature requests often reveal broader needs, guiding development.\n2. Bugs can trigger further investigation and require fixes, impacting users.\n3. Missing features hinder user experience and potentially limit functionality.\n4. Code issues necessitate debugging and resolution to maintain stability.\n5. Feature requests require thorough research to ensure alignment with user needs.\n\nTECHNICAL INSIGHTS:\n1. `StringPromptTemplate` abstract class is a bug requiring a fix.\n2. `on_chat_model_stream` event emission discrepancy in ChatBedrockConverse.\n3. `BadRequest 400` error in LangChain related to AIMessage and ToolMessage format.\n4. Missing “bind tools” method hinders AimlapiLLM’s functionality.\n5. Model mismatch between AIMessage and ToolMessage format causes exceptions.\n", "batch_number": 16, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The chat_ollama model is encountering a \"ResourceWarning: unclosed socket\" error, indicating a problem with the connection established by the model. This issue is likely a bug within the LangChain integration, not a user-facing problem. A minimal reproducible example has been provided to help diagnose and potentially resolve the issue.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-18T13:58:59Z", "body_clean": "Unable to reproduce. Can you confirm versions used? langchain, ollama, etc."}, {"author": "suckseed5", "created_at": "2025-09-29T09:55:22Z", "body_clean": "langchain==0.3.10 langchain ollama==0.2.1"}, {"author": "mdrxy", "created_at": "2025-09-29T16:04:39Z", "body_clean": "Please upgrade to the latest versions of each and report back if the issue persists. Will re open if so."}]}, {"ollama_summary": "This issue reports a critical bug in the LangChain `HumanInTheLoopMiddleware` that causes issues with the edit argument passing for the `create_agent` function, specifically when modifying arguments during the agent creation process. The bug doesn’t appear to be related to the LangChain community package and is impacting a minimal reproducible example.  It requires a fix to ensure proper argument passing during the agent creation process.", "final_category": "bug", "comments": [{"author": "Sathyanarayanan-ops", "created_at": "2025-09-21T20:23:35Z", "body_clean": "Hi, I was able to quickly reproduce this bug, however I seemed to have a lot of issues with the Wikipedia search function. Ultimately it boiled down to the fact that the LLM is not receiving the new tool call response after \"edit\" in the HITL loop. Instead I created a simple, more easy to debug code using Weather API: [code] A very simple script This is how it works And these are my findings so far Normally works this way Working Output for accept [code] Bug in question when using 'edit' [code] With edit does not go as per plan llm does not use the information that the tool has given Suspecting the HumanInTheLoopMiddleware function Especially this part [code] Adding debug logs to HITL function to verify [code] Returns the response Debug logs response in HITL [code] after model returned only messages no jump to thus LangGraph is not getting info from middleware to go back to the model loop The tool ran with London, but the model never got re invoked to consume the tool result → so the last message is blank. So now we know where it dies Running next experiment Experiment 2 [code] New tool call created with London. Runner attempted to re enter the model loop before a ToolMessage was inserted. OpenAI rejected the conversation with a 400 BadRequestError: Error Message [code] HITL correctly intercepts and edits tool calls. The bug lies in orchestration after edit: Tool executes, but the scheduler never re invokes the model to consume the new ToolMessage. Forcing jump to: \"model\" too early breaks the contract because no ToolMessage exists yet. TL;DR Accept: Works end to end (tool runs → ToolMessage → final AIMessage). Edit: Tool runs with edited args and emits a ToolMessage, but the model is not re invoked, so the final AIMessage is empty. If you force jump to: \"model\" immediately after edit: OpenAI rejects with 400 invalid request error because assistant tool calls must be followed by matching ToolMessages. I hope this is useful mods please suggest changes if I have not followed community guidelines Edits Minor formatting"}, {"author": "Sathyanarayanan-ops", "created_at": "2025-09-22T03:47:49Z", "body_clean": "@sydney runkle I see that you are assigned to this issue, I tried reworking \"jump to\" logic in the human in the loop.py , but I haven't gotten any solid results, I will continue to work on it , but please let me know if a solution has already been proposed or if you need help anywhere else , thanks"}]}, {"ollama_summary": "This GitHub issue requests native OpenSearch vector database support for LangChain, addressing a gap in the current ecosystem. Currently, LangChain relies on external integrations for vector search, limiting its functionality. The proposed solution would allow LangChain to seamlessly utilize OpenSearch’s powerful vector search capabilities, improving enterprise adoption and cost-effectiveness.", "final_category": "feature", "comments": []}, {"ollama_summary": "```\nSummary:\n\nThe output shows a summary of the system's configuration, including the OS, version, Python version, and package information. It also includes a list of installed packages and dependencies.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-21T03:06:40Z", "body_clean": "Hello, Your token was exposed in your PR description. Please consider it compromised and rotate it."}, {"author": "sinanuozdemir", "created_at": "2025-09-21T16:12:24Z", "body_clean": "Hello, Your token was exposed in your PR description. Please consider it compromised and rotate it. The [code] ? Yes I caught that immediately and rotated it :) Thank you so much for the comment, I really appreciate it."}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes a JSON parsing error when retrieving raw responses from the LLM, leading to slow retries and potential issues with the LLM's output. The bug is currently not resolved by updates to the stable LangChain version, and it appears to be a problem specific to the `chatOpenAI` integration, rather than a general usage issue.", "final_category": "bug", "comments": []}], "business_insights": ["Integration issues are a recurring bottleneck, requiring careful monitoring and potential fixes within the LangChain ecosystem.", "Vector search integration represents a significant opportunity for enterprise adoption – addressing the gap is crucial.", "JSON parsing errors impact LLM output speed, necessitating improved error handling and potentially optimized parsing routines.", "The bug affecting the chatOpenAI integration highlights a need for focused bug fixing within a specific component.", "LangChain’s reliance on external integrations creates potential security risks – addressing this is vital."], "technical_insights": ["LangChain integration stability is a key concern, potentially impacting the model’s reliability.", "OpenSearch vector database integration is a prioritized feature request, demonstrating enterprise interest.", "JSON parsing errors are a significant performance bottleneck, demanding optimized parsing strategies.", "The bug affecting chatOpenAI is isolated to a specific component, requiring targeted investigation.", "LangChain’s reliance on external integrations introduces security vulnerabilities, necessitating mitigation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Integration issues are a recurring bottleneck, requiring careful monitoring and potential fixes within the LangChain ecosystem.\n2.  Vector search integration represents a significant opportunity for enterprise adoption – addressing the gap is crucial.\n3.  JSON parsing errors impact LLM output speed, necessitating improved error handling and potentially optimized parsing routines.\n4.  The bug affecting the `chatOpenAI` integration highlights a need for focused bug fixing within a specific component.\n5.  LangChain’s reliance on external integrations creates potential security risks – addressing this is vital.\n\nTECHNICAL INSIGHTS:\n1.  LangChain integration stability is a key concern, potentially impacting the model’s reliability.\n2.  OpenSearch vector database integration is a prioritized feature request, demonstrating enterprise interest.\n3.  JSON parsing errors are a significant performance bottleneck, demanding optimized parsing strategies.\n4.  The bug affecting `chatOpenAI` is isolated to a specific component, requiring targeted investigation.\n5.  LangChain’s reliance on external integrations introduces security vulnerabilities, necessitating mitigation.\n", "batch_number": 17, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on increasing the `test_base` maximum number of tokens in the `test` function within the `test/integration tests/chat models/test base.py` file. This is being addressed by the maintainer to improve the reliability of automated tests.  Currently, the test is failing in CI due to a limit on the number of tokens it can handle.", "final_category": "other", "comments": [{"author": "sahil9001", "created_at": "2025-09-18T06:33:32Z", "body_clean": "@mdrxy Can I take this issue?"}, {"author": "sahil9001", "created_at": "2025-09-18T06:50:31Z", "body_clean": "@mdrxy Is there some testing [code] that you provide to external contributors so that they can fix the issues? Please let me know if that's possible or suggest an alternative. Also I am not facing this issue, can you confirm if this has been fixed already? [code]"}]}, {"ollama_summary": "This issue relates to a critical bug in the OpenRouter package, specifically concerning the integration with the LangChain v1 model. The bug causes issues with the support for the traditional OpenAI API, leading to errors and requiring manual overrides.  The issue is not related to the LangChain community package and is a widespread problem affecting various users.", "final_category": "bug", "comments": []}, {"ollama_summary": "This GitHub issue proposes a feature to allow configuring the `init_chat_model` via a `context_schema` to standardize static runtime context management across LangChain projects. The current implementation relies on separate configurations for model and prompt settings, leading to inconsistency and making project configuration more complex. The proposed solution would allow a single `context_schema` to manage both model and prompt settings, improving maintainability and streamlining project setup.", "final_category": "feature", "comments": [{"author": "NIK-TIGER-BILL", "created_at": "2025-10-07T07:56:46Z", "body_clean": "UP"}, {"author": "sydney-runkle", "created_at": "2025-10-21T19:52:12Z", "body_clean": "What's the use case here? what do you want to pass in configurable and where do you want to access it?"}]}, {"ollama_summary": "This issue reports a bug in LangChain where the `@tool` decorator returns a string instead of the expected structured Pydantic object when the `on_tool_end` callback is invoked. This is causing issues with parsing and extracting data from the tool's output, specifically the `create` function, which relies on the structured format for downstream processing.  The issue is not related to the LangChain community package and appears to be a bug within the core LangChain implementation.", "final_category": "bug", "comments": [{"author": "starchou6", "created_at": "2025-09-15T23:53:48Z", "body_clean": "Hello，I recommend trying the response format=\"content and artifact\" parameter in your @tool decorator. This should solve the problem of Pydantic objects being stringified in the on tool end callback. Here's how to modify your tool: [code] The key changes: Add response format=\"content and artifact\" to your @tool decorator Change your return type to tuple[str, CreateTestDataResponse] Return a tuple: (summary message, pydantic object) In your [code] callback, you can then access the structured data via: [code] This approach preserves the original Pydantic object in the artifact field while providing a clean summary to the model in the content field."}, {"author": "rushant001", "created_at": "2025-09-16T00:22:14Z", "body_clean": "Hello，I recommend trying the response format=\"content and artifact\" parameter in your [@tool]( [link] decorator. This should solve the problem of Pydantic objects being stringified in the on tool end callback. Here's how to modify your tool: [code] The key changes: Add response format=\"content and artifact\" to your [@tool]( [link] decorator Change your return type to tuple[str, CreateTestDataResponse] Return a tuple: (summary message, pydantic object) In your [code] callback, you can then access the structured data via: [code] This approach preserves the original Pydantic object in the artifact field while providing a clean summary to the model in the content field. Thank you so much for your suggestion! I've tried using response format=\"content and artifact\" as you recommended, and it works perfectly. By returning a tuple of (summary, pydantic object) and accessing the structured data via output.artifact in the on tool end callback, I'm now able to preserve the full Pydantic object without it being stringified. For anyone else facing a similar issue, here’s how I handled the output: async def on tool end(self, output: Any, kwargs: Any) None: tool output = to serializable(output.artifact or output.content) def to serializable(obj): \"\"\" serializable \"\"\" if isinstance(obj, BaseModel): return obj.model dump() elif isinstance(obj, list): return [to serializable(i) for i in obj] elif isinstance(obj, dict): return {k: to serializable(v) for k, v in obj.items()} elif isinstance(obj, str): try: return json.loads(obj) except: return obj else: return obj"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `create_agent` agent’s `invoke()` function fails to include a `structured_response` in its output, despite it being required.  The issue stems from a bug within the LangChain library, not a specific usage scenario, and has been verified through a minimal reproducible example.  The solution involves ensuring the `structured_response` is included in the response content, which currently only contains the \"message\" field.", "final_category": "bug", "comments": []}], "business_insights": ["Consistent API integration issues are a recurring theme across multiple issues, highlighting the need for robust error handling and testing.", "Lack of standardized configuration across different LangChain projects necessitates a unified approach to managing model and prompt settings.", "Feature requests related to context schema configuration demonstrate a desire for improved project setup and maintainability.", "Bug fixes in the create_agent agent’s invoke() function underscore the importance of thorough code review and testing.", "The core LangChain library bug affecting @tool decorators emphasizes the need for diligent code validation and integration testing."], "technical_insights": ["Multiple issues point to a potential regression in the LangChain library's core functionality.", "The create_agent bug highlights a critical vulnerability impacting downstream processing of tool outputs.", "The context_schema feature request indicates a desire for enhanced project configuration management.", "The @tool decorator bug necessitates a fix for Pydantic serialization issues within LangChain.", "The test_base limitation in the test function suggests potential performance bottlenecks in automated tests."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent API integration issues are a recurring theme across multiple issues, highlighting the need for robust error handling and testing.\n2. Lack of standardized configuration across different LangChain projects necessitates a unified approach to managing model and prompt settings.\n3. Feature requests related to context schema configuration demonstrate a desire for improved project setup and maintainability.\n4. Bug fixes in the `create_agent` agent’s `invoke()` function underscore the importance of thorough code review and testing.\n5. The core LangChain library bug affecting `@tool` decorators emphasizes the need for diligent code validation and integration testing.\n\nTECHNICAL INSIGHTS:\n1. Multiple issues point to a potential regression in the LangChain library's core functionality.\n2. The `create_agent` bug highlights a critical vulnerability impacting downstream processing of tool outputs.\n3. The `context_schema` feature request indicates a desire for enhanced project configuration management.\n4. The `@tool` decorator bug necessitates a fix for Pydantic serialization issues within LangChain.\n5. The `test_base` limitation in the `test` function suggests potential performance bottlenecks in automated tests.\n", "batch_number": 18, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The task is complete. The code has been successfully added to the class, enabling the use of both `[code]` and `[code]` as constructor parameters, passing all tests, and maintaining backward compatibility with existing code. The code has been formatted and linted to meet the project's style guidelines.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe AI streaming feature locally works correctly, but it abruptly cuts off responses in the Vercel deployment environment.  The issue appears to be a bug within the LangChain library, not a problem with the user’s code.  The developer has provided a minimal reproducible example to demonstrate the issue and suggest a fix.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a potential problem with the `trim_messages` DevX request, where the current implementation is overly complex and difficult to understand.  The maintainer requests a simplified version that focuses solely on the core functionality, avoiding the existing code.  Currently, the issue is flagged as a privileged issue requiring attention from the DevX team.", "final_category": "feature", "comments": [{"author": "Davda-James", "created_at": "2025-09-21T17:15:00Z", "body_clean": "Hey @mdrxy and @sydney runkle I solved this one added this feature 'approx' alias to use in token counter, also changed the comments in file with updated changes, also written tests for it and tests are passing, wanted to ask before adding commit for docs, that whether I have to change the docs as well in same PR, mentioning a use of new alias ?"}]}, {"ollama_summary": "This issue is a critical bug in the LangChain library that prevents the `prompt_cache_key` from being correctly passed to the `BaseChatOpenAI` model. This issue is not related to the LangChain community package and is impacting the functionality of the application.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-15T02:18:53Z", "body_clean": "This isn't strictly necessary, [see comment]( [link] Please open [forum posts]( [link] or issues prior to implementing new PRs so that proposed design changes can be discussed and to potentially prevent wasting time."}]}, {"ollama_summary": "This issue requests support for vendors to utilize their own prompt caching mechanisms (like OpenAI's `prompt_cache_key`) through Langchain, which is a feature request and not a bug or usage question. The current implementation is hacky and requires modification, and the author highlights a challenge understanding the effectiveness of this caching in the OpenAI ecosystem.", "final_category": "feature", "comments": [{"author": "mdrxy", "created_at": "2025-09-15T02:15:53Z", "body_clean": "LangChain's [code] supports [code] out of the box. You can set it a few different ways, and all work the same: [code] Choose whichever makes the most sense for your app. I'll open an issue in the docs so that this is made more clear. [code] also supports [code] on messages. [See details]( [link]"}]}], "business_insights": ["Consistent bug fixes and feature additions demonstrate a strong commitment to quality.", "Feature requests often highlight areas for improvement and future development.", "Bug fixes are crucial for maintaining application stability and user experience.", "Feature requests support the evolution of the product and its capabilities.", "Bug fixes contribute to a reliable and stable application."], "technical_insights": ["LangChain library is experiencing a bug impacting the prompt_cache_key passing.", "The trim_messages DevX request is overly complex and needs simplification.", "Vendor prompt caching mechanisms (like OpenAI's prompt_cache_key) are not currently supported in LangChain.", "The prompt_cache_key bug is impacting the functionality of the application.", "Feature request for vendor prompt caching is related to the OpenAI ecosystem."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent bug fixes and feature additions demonstrate a strong commitment to quality.\n2. Feature requests often highlight areas for improvement and future development.\n3. Bug fixes are crucial for maintaining application stability and user experience.\n4. Feature requests support the evolution of the product and its capabilities.\n5. Bug fixes contribute to a reliable and stable application.\n\nTECHNICAL INSIGHTS:\n1. LangChain library is experiencing a bug impacting the `prompt_cache_key` passing.\n2. The `trim_messages` DevX request is overly complex and needs simplification.\n3. Vendor prompt caching mechanisms (like OpenAI's `prompt_cache_key`) are not currently supported in LangChain.\n4. The `prompt_cache_key` bug is impacting the functionality of the application.\n5. Feature request for vendor prompt caching is related to the OpenAI ecosystem.\n", "batch_number": 19, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug where the LangChain model can only utilize Google Search, despite the user's request to use Baidu Search. The problem isn’t related to the LangChain community package and is isolated to the Google Search integration. A minimal reproducible example demonstrates this limitation, and the user is seeking a solution to allow for Baidu Search usage.", "final_category": "question", "comments": [{"author": "starchou6", "created_at": "2025-09-14T13:31:04Z", "body_clean": "Hello, this should not be a bug. You can create a tool like this: [code] Usage [code]"}, {"author": "henbucuoshanghai", "created_at": "2025-09-15T00:40:23Z", "body_clean": "kind and useful ansewer,how can i use this in this code? tks bseides the format of output is the same? response = genai client.models.generate content( model=configurable.query generator model, contents=formatted prompt, config={ \"tools\": [{\"google search\": {}}], \"temperature\": 0, },"}, {"author": "starchou6", "created_at": "2025-09-15T05:30:40Z", "body_clean": "kind and useful ansewer,how can i use this in this code? tks bseides the format of output is the same? response = genai client.models.generate content( model=configurable.query generator model, contents=formatted prompt, config={ \"tools\": [{\"google search\": {}}], \"temperature\": 0, }, Here's how to modify your existing code to use the custom Baidu search tool: [code] I think the output format should be the same but still you need debug and confirm it. The response will still be a structured object with: response.content The main response text response.tool calls Tool calls made during execution Same metadata and structure as your original code"}, {"author": "henbucuoshanghai", "created_at": "2025-09-15T13:14:40Z", "body_clean": "very kind，tks ,I will try it.thank u ."}]}, {"ollama_summary": "This issue focuses on improving the structure and user experience of GitHub issue templates. The core problem is that the current templates lack sufficient detail and are difficult to navigate. The proposed solution involves adding issue types, updating links, creating new templates (feature request and task), and enhancing the visual presentation of the templates with emojis. The changes aim to streamline the issue reporting process, improve clarity, and enhance the overall user experience. The issue also includes a detailed plan outlining the specific steps taken to implement these changes, including technical details and a summary of the completed work.", "final_category": "other", "comments": [{"author": "open-swe[bot]", "created_at": "2025-09-12T01:22:07Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"01993b83 f494 70fa 9be9 bead90633ae6\", \"threadId\": \"bc3acc81 dc9d 4763 a078 f3a5b37f2242\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Improve GitHub issue templates by adding issue types, updating links, creating new templates, and enhancing user experience Task 1: [code] Task 2: [code] Task 3: [code] Task 4: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "The Harmony project is experiencing a critical bug where the `create_react_agent` tool call fails when using a custom tool within an agent workflow, specifically when attempting to leverage the new responses API. This issue stems from a \"No call message found\" error related to the model's response API, triggered by a custom tool within the agent. The issue appears to be linked to the specific LangChain wrapper for the OpenAI GPT-oss 120b model.", "final_category": "bug", "comments": [{"author": "rawathemant246", "created_at": "2025-09-11T06:28:05Z", "body_clean": "we have to check on this!!"}, {"author": "starchou6", "created_at": "2025-09-11T11:01:50Z", "body_clean": "Hello, maybe you can try this quick fix [code]"}, {"author": "OpenSourceGHub", "created_at": "2025-09-12T11:29:55Z", "body_clean": "The issue is how the agent is trying to resolve and coordinate with the OpenAI API. There's a mismatch between LangGraph's expected state with what the API provides, as it expects a valid call message. If they don't synchronize, then that's where the bug might occur. The code itself is perfectly fine. Since you are using OpenAI's API, try checking if its a sync issue."}, {"author": "GilbertKrantz", "created_at": "2025-09-12T12:04:54Z", "body_clean": "So is responses api not supported with GPT OSS right now?"}, {"author": "OpenSourceGHub", "created_at": "2025-09-12T13:08:28Z", "body_clean": "It is supported."}, {"author": "kevincherian", "created_at": "2025-09-12T17:35:51Z", "body_clean": "are you sure its supported?"}, {"author": "OpenSourceGHub", "created_at": "2025-09-12T18:16:13Z", "body_clean": "Apologies, but I think they barely support it for the newer models. I've just reviewed that LangGraph's create react agent prebuilt does not support the newer OpenAI response API due to compatibility issues, and this code is using that prebuilt."}, {"author": "OpenSourceGHub", "created_at": "2025-09-12T18:18:19Z", "body_clean": "That's because LangGraph has not yet been updated to be compatible with the newer APIs. Although you can use OpenAI's older Completions/Chat Completions API, that one is older."}, {"author": "OpenSourceGHub", "created_at": "2025-09-12T18:23:11Z", "body_clean": "That's why I recommend syncing LangGraph with the newer OpenAI response API. If you don't sync them properly, then the code will not work due to incompatibility."}, {"author": "GilbertKrantz", "created_at": "2025-09-13T10:31:01Z", "body_clean": "That's why I recommend syncing LangGraph with the newer OpenAI response API. If you don't sync them properly, then the code will not work due to incompatibility. HI, I’ve tested the setup using a basic ChatOpenAI with simple tool bindings, and the issue still persists. For context, I’m hosting GPT OSS 20B via vLLM. Is this also due to the sync issues? If it is do you have any references for fixing it. Thank you beforehand,"}, {"author": "OpenSourceGHub", "created_at": "2025-09-13T11:15:50Z", "body_clean": "Yes it is due to sync issues, but it's not your fault. It's because of what the API expects. LangGraph needs to coordinate each valid call messages, and if it fails even once, the API will reject it. It doesn't matter whether if it you are hosting GPT OSS 20B or not."}, {"author": "OpenSourceGHub", "created_at": "2025-09-13T11:22:09Z", "body_clean": "I recommend checking this source. Might give you some help. [link]"}, {"author": "rishu685", "created_at": "2025-09-13T18:22:07Z", "body_clean": "The error \"Harmony: bad request on gpt oss 120b and tool calls with create react agent\" appears to be related to an incompatibility between how the gpt oss 120b model formats its responses for tool calls and what the LangChain create react agent function expects. This is particularly relevant when using the newer responses/v1 API from OpenAI. The \"Harmony\" in the title likely refers to [OpenAI's Harmony project]( [link] which seems to have introduced changes to the tool calling format. Potential Solutions and Workarounds Here are some steps and alternative approaches that may help you resolve or work around this issue, gathered from various community discussions: Check Your Prompt Template: Ensure that your prompt explicitly includes placeholders for tools and tool names. The create react agent relies on these to properly format the prompt for the language model. Verify that your prompt has an agent scratchpad input variable to hold the history of agent actions and tool outputs. Input Formatting for .invoke(): When calling the agent with .invoke(), make sure you are passing the input in the correct format. For newer versions of LangChain and LangGraph, the expected input is often a dictionary with a \"messages\" key, like this: Python agent executor.invoke({\"messages\": [(\"user\", \"Your query here\")]}) Consider an Alternative Agent Creation Method: If create react agent is causing issues, you could try building a more custom agent using LangGraph. This gives you more control over the agent's logic and how it handles tool calls. The LangChain documentation provides examples of how to build agents from scratch. Investigate Model Specific Tool Calling: There are reports that the gpt oss models have a specific way of handling the chain of thought process for tool calling. It's crucial that the reasoning returned by the model is passed back in subsequent calls when you provide the tool's output. Some users have noted that for gpt oss models, you may need to explicitly list the tools in the system prompt and set tool choice to 'required' or 'auto'. Update LangChain and Related Libraries: Ensure you are on the latest stable versions of langchain, langchain core, and langchain openai. The LangChain team frequently releases updates that may address such bugs."}, {"author": "d-r-e", "created_at": "2025-09-14T07:15:48Z", "body_clean": "I recommend checking this source. Might give you some help. [link] So this DOESN'T work either: [code] There is no exception but the model never gets to call any tools: [code]"}, {"author": "d-r-e", "created_at": "2025-09-14T07:18:17Z", "body_clean": "The error \"Harmony: bad request on gpt oss 120b and tool calls with create react agent\" appears to be related to an incompatibility between how the gpt oss 120b model formats its responses for tool calls and what the LangChain create react agent function expects. This is particularly relevant when using the newer responses/v1 API from OpenAI. The \"Harmony\" in the title likely refers to [OpenAI's Harmony project]( [link] which seems to have introduced changes to the tool calling format. Potential Solutions and Workarounds Here are some steps and alternative approaches that may help you resolve or work around this issue, gathered from various community discussions: Check Your Prompt Template: Ensure that your prompt explicitly includes placeholders for tools and tool names. The create react agent relies on these to properly format the prompt for the language model. Verify that your prompt has an agent scratchpad input variable to hold the history of agent actions and tool outputs. Input Formatting for .invoke(): When calling the agent with .invoke(), make sure you are passing the input in the correct format. For newer versions of LangChain and LangGraph, the expected input is often a dictionary with a \"messages\" key, like this: Python agent executor.invoke({\"messages\": [(\"user\", \"Your query here\")]}) Consider an Alternative Agent Creation Method: If create react agent is causing issues, you could try building a more custom agent using LangGraph. This gives you more control over the agent's logic and how it handles tool calls. The LangChain documentation provides examples of how to build agents from scratch. Investigate Model Specific Tool Calling: There are reports that the gpt oss models have a specific way of handling the chain of thought process for tool calling. It's crucial that the reasoning returned by the model is passed back in subsequent calls when you provide the tool's output. Some users have noted that for gpt oss models, you may need to explicitly list the tools in the system prompt and set tool choice to 'required' or 'auto'. Update LangChain and Related Libraries: Ensure you are on the latest stable versions of langchain, langchain core, and langchain openai. The LangChain team frequently releases updates that may address such bugs. That message looks suspiciously AI written. Anyway, I tried the suggestions. No luck. 1. The input was already properly formatted as a dict. 2. There is no such \"agent scratchpad\", that is completely made up. 3. Yes, gpt oss 120b has a specific way of handling tool calls and tool responses in the reasoning block, that is probably why everything fails here. [source]( [link] 4. Added the tool description to the system prompt (see my previous message). That changes nothing. Thanks for the response but it didn't help."}, {"author": "OpenSourceGHub", "created_at": "2025-09-14T08:17:20Z", "body_clean": "I see @d r e, then it might be due to LangGraph, as create react agent might really have sync or compatibility issues, or LangGraph is really just picky about what models you pick. Have you tried checking about the issues of LangGraph?"}, {"author": "d-r-e", "created_at": "2025-09-14T08:36:29Z", "body_clean": "I see @d r e, then it might be due to LangGraph, as create react agent might really have sync or compatibility issues, or LangGraph is really just picky about what models you pick. Have you tried checking about the issues of LangGraph? Yes, actually I created this issue in the Langgraph project but they moved it here."}, {"author": "OpenSourceGHub", "created_at": "2025-09-14T09:14:22Z", "body_clean": "Okay nevermind. Let me help you @d r e. Check this reply from another user: HI, I’ve tested the setup using a basic ChatOpenAI with simple tool bindings, and the issue still persists. For context, I’m hosting GPT OSS 20B via vLLM. Is this also due to the sync issues? If it is do you have any references for fixing it. Thank you beforehand Both of you are hosting GPT OSS models, so the problem must be with LangGraph, not with the API because you tried to use both the new v1 and old v0. You might try to handle everything yourself to fix what GPT OSS expects like prompting and state management."}, {"author": "OpenSourceGHub", "created_at": "2025-09-14T09:26:28Z", "body_clean": "What you need to do is to handle anything that GPT OSS expects, because LangGraph has different ways in syncing with GPT OSS that the model might reject."}, {"author": "LIN-Yu-Ting", "created_at": "2025-09-17T18:41:27Z", "body_clean": "I do not know whether case that I encountered is relative or not. I just put it here for your reference: I am forced to add [code] as it can successfully generate tool call in AIMessage with [code] and the later [code] . If I removed [code] then no tool calls and I will also receive InternalServer Error 500 when calling create react agent later. I first initialized my llm model (GPT OSS 20B is deployed with vLLM) with: [code] Then, create the agent using create react agent function: [code] As I have mentioned earlier, I can obtain the correct result by executing the following code: [code] However, exception comes when executing: [code] [code] It seems that it is related to some parsing issues. Btw, I have already upgraded to latest python packages: langchain==0.3.25 langchain openai==0.3.33 langgraph==0.6.7 langgraph prebuilt==0.6.4 Anything I can do more ?"}, {"author": "ehtec", "created_at": "2025-09-28T20:37:46Z", "body_clean": "Is anyone already working on fixing this?"}, {"author": "GilbertKrantz", "created_at": "2025-10-06T06:12:19Z", "body_clean": "I think, It's a problem mainly on vLLM. vLLM tool calling expect a chat.completions api tool calling which uses [code] but langchain uses the response api format [code] It's better to use [code] sdk then make a runnable wrapper with it. That way langchain can still be used"}, {"author": "ehtec", "created_at": "2025-10-12T02:04:57Z", "body_clean": "@d r e does this fix your problem? [link] You can install using [code]"}, {"author": "pamelafox", "created_at": "2025-10-13T05:48:17Z", "body_clean": "@ehtec That does in fact fix the issue for me (running gpt oss via NIM image). I don't see an explanation in that PR as to why the fix works, and the CI seems to be failing. Could you put more explanation in the PR so that the Langchain team is more able to reason about this fix (and more likely to accept it)?"}, {"author": "pamelafox", "created_at": "2025-10-16T01:29:44Z", "body_clean": "Okay so I wrote a function calling loop manually, with responses API, and discovered it's very important that all of these fields are included: messages.append({ \"type\": \"function call\", \"call id\": tool call.call id, \"name\": tool call.name, \"arguments\": tool call.arguments, \"id\": tool call.id, \"status\": None }) I guess based off the PR and my own experience that langchain is missing \"id\", \"status\", or both."}, {"author": "pamelafox", "created_at": "2025-10-16T01:31:57Z", "body_clean": "Update: The issue is due to missing \"status\":null, at least in my experience. That's why the PR works, as it sets model dump(exclude none=False), such that the status field stays included."}]}, {"ollama_summary": "Here’s a concise summary of the GitHub issue:\n\nThe GitHub issue addresses a bug in the LangChain library where the `ToolNode` class freezes when a tool execution encounters a timeout from a `sse_read_timeout` setting. The solution involves adding a configurable timeout parameter to the `ToolNode` class, implementing asynchronous timeout handling using `asyncio`, and creating comprehensive unit tests to ensure the fix is robust and backward compatible.", "final_category": "bug", "comments": [{"author": "rishu685", "created_at": "2025-09-09T08:06:39Z", "body_clean": "A good fix would likely involve: Auditing the async code: Carefully examining the ainvoke implementation in ToolNode to ensure that all network calls are properly awaited and wrapped in appropriate try...except blocks. Adding explicit timeout handling: Instead of relying on the low level SSE read timeout, the ToolNode could have its own timeout logic that cancels the task if it takes too long. Improving observability: Adding logging to the ToolNode to make it clear when it's starting and ending a tool call, and when it's encountering errors, would make this kind of issue much easier to debug. This is a great example of the kind of \"long tail\" of issues that need to be addressed to move from a prototype to a production ready agent. Thanks for sharing it!"}, {"author": "open-swe[bot]", "created_at": "2025-09-10T17:16:52Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"019934a1 530c 771d 916c a7aa26e26d54\", \"threadId\": \"43ce1164 fd68 4947 81d6 013f6d1842a5\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Fix ToolNode ainvoke freezing when MCP tools have sse read timeout configured Task 1: [code] Task 2: [code] Task 3: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "This issue is a critical bug in the FlareChain library that causes it to overwrite the provided `BaseLanguageModel` instance with a new one, leading to unexpected behavior and a loss of configuration. The code attempts to bypass the intended use of the custom model, resulting in a flawed and unstable integration.", "final_category": "bug", "comments": [{"author": "rishu685", "created_at": "2025-09-09T08:08:37Z", "body_clean": "The Proposed Fix The core of the fix is to replace the hardcoded ChatOpenAI(model=\"gpt 3.5 turbo\") instances with the llm variable that is passed into the method. Here is a simplified pseudo code representation of the change: Current (Buggy) Code Logic Python @classmethod def from llm( cls, llm: BaseLanguageModel, llm is received here ... other parameters ) \"FlareChain\": ... some setup code ... The bug is here: a new, default LLM is created, ignoring the 'llm' parameter. question generator chain = LLMChain( llm=ChatOpenAI(model=\"gpt 3.5 turbo\"), prompt=PROMPT ) ... other internal chains are also created with the default LLM ... return cls( question generator chain=question generator chain, ... other components ) Corrected Code Logic Python @classmethod def from llm( cls, llm: BaseLanguageModel, llm is received here ... other parameters ) \"FlareChain\": ... some setup code ... The fix: Pass the 'llm' object to the internal chain. question generator chain = LLMChain( llm=llm, prompt=PROMPT ) ... ensure 'llm' is used for all other internal chains as well ... return cls( question generator chain=question generator chain, ... other components ) Why This Fix Works This change ensures that the language model object provided by the user is correctly propagated to all the sub components of the FlareChain. By doing this, the chain respects the user's configuration, allowing for the use of any custom or specified LLM.."}]}], "business_insights": ["Focus on integration challenges – ensure seamless model usage across different platforms.", "Improve tool usability – streamline issue reporting for better collaboration.", "Enhance template structure – provide more context for easier issue tracking.", "Address bug stability – prioritize robust code and thorough testing.", "Monitor tool usage – understand how the new integration impacts existing workflows."], "technical_insights": ["LangChain model integration – explore model compatibility across platforms.", "Tool Node freeze – investigate timeout handling for robust agent execution.", "FlareChain overwrite – analyze the root cause of configuration loss.", "Tool Node bypass – identify the mechanism causing the instability.", "Model versioning – ensure consistent model usage across all integrations."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on integration challenges – ensure seamless model usage across different platforms.\n2.  Improve tool usability – streamline issue reporting for better collaboration.\n3.  Enhance template structure – provide more context for easier issue tracking.\n4.  Address bug stability – prioritize robust code and thorough testing.\n5.  Monitor tool usage – understand how the new integration impacts existing workflows.\n\nTECHNICAL INSIGHTS:\n1.  LangChain model integration – explore model compatibility across platforms.\n2.  Tool Node freeze – investigate timeout handling for robust agent execution.\n3.  FlareChain overwrite – analyze the root cause of configuration loss.\n4.  Tool Node bypass – identify the mechanism causing the instability.\n5.  Model versioning – ensure consistent model usage across all integrations.\n\n", "batch_number": 20, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is a bug in LangChain that prevents access to the reasoning content field of DeepSeek R1, specifically within the AIMessage object. The code parsing logic within `langchain.openai.chat.models.base.py` is incorrectly extracting this field, resulting in the reasoning content not being exposed.  A minimal reproducible example has been provided to demonstrate the problem. The proposed fix involves modifying the response parsing to include the reasoning content field in the LangChain interface.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-09-08T16:59:40Z", "body_clean": "Use [code]"}, {"author": "mdrxy", "created_at": "2025-09-10T17:15:55Z", "body_clean": "In addition to using ChatDeepSeek, v1 LangChain should handle this better with [code]"}]}, {"ollama_summary": "This issue reports a bug in LangChain where the `ToolMessage.status` is not being correctly preserved when converting messages to JSONB format in a PostgreSQL database. This results in the default \"success\" value being returned instead of the intended message status, requiring a minimal reproducible example to demonstrate the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-09-07T22:21:44Z", "body_clean": "Use the following [code] and [code] : [code]"}, {"author": "rishu685", "created_at": "2025-09-10T04:48:27Z", "body_clean": "The Probable Fix The fix would likely involve a modification to the convert to messages function in the LangChain library. This function needs to be updated to explicitly look for and use the status field from the input dictionary when creating a ToolMessage. Here is a conceptual example of how the code might be adjusted. Current (simplified) logic might look something like this: Python def convert to messages(messages data: list[dict]) list: ... other message type handling for message data in messages data: if message data.get(\"type\") == \"tool\": The 'status' field is likely not being passed here return ToolMessage( content=message data.get(\"content\"), tool call id=message data.get(\"tool call id\") ) ... The corrected logic should be: Python def convert to messages(messages data: list[dict]) list: ... other message type handling for message data in messages data: if message data.get(\"type\") == \"tool\": return ToolMessage( content=message data.get(\"content\"), tool call id=message data.get(\"tool call id\"), Explicitly pass the 'status' field if it exists status=message data.get(\"status\", \"success\") ) ... By explicitly passing message data.get(\"status\", \"success\") to the ToolMessage constructor, the status from the original message will be preserve"}, {"author": "keenborder786", "created_at": "2025-09-14T14:07:53Z", "body_clean": "@rishu685 We do not need any fix. Please see my message above"}]}, {"ollama_summary": "The code is exhibiting a bug where the `BaseChatModel.agenerate()` function is failing to provide the required positional argument, leading to a `missing positional argument` error. This issue is likely caused by an incompatibility between the LangChain library version and the specific integration package being used, potentially involving a change in the `agenerate()` function's internal logic. The code attempts to load and use a JSON file, but the file format is not correctly structured, causing an error during parsing.  The error message suggests a potential issue with the `reference contexts` within the JSON data, which may be causing the problem.  The code also uses a `pyo3` package, which is not installed.", "final_category": "bug", "comments": []}, {"ollama_summary": "This GitHub issue highlights a bug in LangChain where tests incorrectly assume `get_by_by_ids` preserves document order, leading to test failures. The bug stems from a misunderstanding of the vectorstore's return order and doesn’t affect the core functionality. A minimal reproducible example has been provided to demonstrate the issue and facilitate a fix.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nAnthropic’s prompt cache reads/writes are returning inaccurate metadata, specifically for simple requests. This is a bug within the LangChain library, not a coding issue, and isn’t being addressed by updates. The issue involves a minimal reproducible example demonstrating the incorrect response from the server, highlighting a need for improved metadata handling within the LangChain library.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-05T17:46:10Z", "body_clean": "This is documented: [code] [code] is defined as \"Sum of all input token types\" which includes cached tokens. [code] consistently means \"total tokens processed\" between models/providers."}, {"author": "msukmanowsky", "created_at": "2025-09-05T18:26:48Z", "body_clean": "@mdrxy I'd argue the documentation can do a lot more here. E.g. you had to explicitly mention \"which includes cached tokens\" which isn't in the docstring. Provider specific examples would help here as well to show case what they send back and how they are converted to UsageMetadata. Saw that you opened [link] which I appreciate and will monitor!"}]}], "business_insights": ["LangChain’s reasoning content field issues severely impact the core functionality of the ChatDeepSeek model, requiring immediate attention.", "Incorrect JSONB parsing in PostgreSQL is a recurring problem, demanding a robust fix to maintain data integrity.", "The BaseChatModel.agenerate() bug highlights a dependency issue with the LangChain library version and integration package.", "Incorrect positional argument handling in get_by_by_ids tests necessitates a thorough review of the vectorstore’s return order.", "Metadata inaccuracies in prompt cache reading/writing need a priority fix to ensure accurate results."], "technical_insights": ["LangChain’s langchain.openai.chat.models.base.py parsing logic needs refinement to accurately extract reasoning content.", "PostgreSQL JSONB conversion requires a robust and reliable data structure conversion mechanism.", "The agenerate() function’s internal logic must be updated to correctly handle the JSON data format.", "The convert to messages function requires a thorough review of its code to address the missing positional argument.", "The pyo3 package dependency is causing a missing positional argument error, requiring a solution."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s reasoning content field issues severely impact the core functionality of the ChatDeepSeek model, requiring immediate attention.\n2.  Incorrect JSONB parsing in PostgreSQL is a recurring problem, demanding a robust fix to maintain data integrity.\n3.  The `BaseChatModel.agenerate()` bug highlights a dependency issue with the LangChain library version and integration package.\n4.  Incorrect positional argument handling in `get_by_by_ids` tests necessitates a thorough review of the vectorstore’s return order.\n5.  Metadata inaccuracies in prompt cache reading/writing need a priority fix to ensure accurate results.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s `langchain.openai.chat.models.base.py` parsing logic needs refinement to accurately extract reasoning content.\n2.  PostgreSQL JSONB conversion requires a robust and reliable data structure conversion mechanism.\n3.  The `agenerate()` function’s internal logic must be updated to correctly handle the JSON data format.\n4.  The `convert to messages` function requires a thorough review of its code to address the missing positional argument.\n5.  The `pyo3` package dependency is causing a `missing positional argument` error, requiring a solution.\n", "batch_number": 21, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue involves a problem where the documentation page for Anthropic’s example model doesn’t function correctly when using the “claude 3 opus 20240229” model string. The current documentation example code produces the expected results, but a minor change to the model string causes the issue.  The issue is currently a minor bug and doesn’t require a solution, but the documentation page needs to be updated to reflect the correct model string.", "final_category": "bug", "comments": [{"author": "starchou6", "created_at": "2025-09-03T12:27:32Z", "body_clean": "Totally agree! This is a little bit annoying for beginners. We definitely need to add some version hints to make things easier."}]}, {"ollama_summary": "This issue reports a significant performance bottleneck in LangChain, causing the application to take an unusually long time to execute. The problem appears to be a persistent, unresolved bug within the LangChain library itself, rather than a problem with the code being run.  It’s been identified as a regression and requires a fix before it can be resolved.", "final_category": "bug", "comments": [{"author": "starchou6", "created_at": "2025-09-03T12:35:19Z", "body_clean": "Hi, can you share more details about run time?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nLangChain V1 releases are now available as alpha versions for LangChain & LangGraph v1.  The releases include improvements to the documentation, code primitives, and message object properties, along with a focus on standardized content.  The team is actively working on a stable release for v1 in late October and encourages users to explore the quickstart guide and release notes.", "final_category": "other", "comments": [{"author": "starchou6", "created_at": "2025-09-03T12:38:15Z", "body_clean": "Let s go!!!!!!!!!!!!!!!"}, {"author": "kikoncuo", "created_at": "2025-09-29T19:48:13Z", "body_clean": "Congrats to the langchain team for the great work and the ecosystem around it! QQ about citations, is it only for web searches using the default search provider per model provider or will models be able to use it with their own tools? IE: existing search tools provide a lot of context but their format is still all over the place. What about our own tools? Can we pass the citation format in any way? Is it maybe an implicit tool?"}]}, {"ollama_summary": "Here’s a concise summary of the GitHub issue:\n\nThe issue is a bug preventing the Ollama command from successfully connecting to the ChatOpenAI service, resulting in the `openai.NotFoundError: 404 page not found` error.  The code attempts to use a minimal reproducible example, but the example itself is not sufficient to trigger the error.  The issue is currently unresolved, and the provided example helps to demonstrate the problem.", "final_category": "bug", "comments": [{"author": "jaxonister", "created_at": "2025-09-02T09:09:50Z", "body_clean": "My goal is to use ChatOpenAI to connect to Ollama and process <think </think ."}, {"author": "starchou6", "created_at": "2025-09-03T12:41:27Z", "body_clean": "The issue is specifically with the [code] parameter. The fix is simple : Remove the [code] parameter while keeping everything else: [code] Why this works : [code] is fully compatible with Ollama Ollama implements the OpenAI compatible API The [code] parameter is causing the endpoint construction issue Without it, you get the standard, working Ollama connection"}, {"author": "mdrxy", "created_at": "2025-10-02T01:42:21Z", "body_clean": "Ollama does not support the responses API."}]}, {"ollama_summary": "The code raises a `404 page not found` error when attempting to access the `openai` API, specifically for the `openai.NotFoundError: 404 page not found` error. This suggests a problem with the LangChain integration or a specific configuration related to the OpenAI API. The issue is likely a bug in the LangChain package itself, and the provided example code demonstrates a minimal reproducible example that can be run to trigger the error.", "final_category": "bug", "comments": [{"author": "Adithya1617", "created_at": "2025-09-02T14:30:49Z", "body_clean": "hello @jaxonister currently ollama only supports POST /v1/chat/completions POST /v1/completions but by using output version=\"responses/v1\" you are calling POST /v1/responses There is no /responses route in Ollama’s API right now. So when the SDK tries /responses, Ollama returns a 404 Not Found maybe if you created an adapter layer that accepts requests from /responses and then proxes them to /completions or /chat/completions. it will work. please feel free to discuss and correct me if I am wrong."}, {"author": "eyurtsev", "created_at": "2025-09-08T19:02:47Z", "body_clean": "Closing this issue as this isn't expected to work with ollama"}]}], "business_insights": ["Documentation inconsistencies are a recurring issue, impacting beginner users.", "Clearer documentation is crucial for user adoption and reduces support requests.", "Consistent model string handling across documentation is needed.", "Update documentation promptly to reflect model changes.", "Maintain a consistent and user-friendly approach to documentation."], "technical_insights": ["LangChain library regression: persistent bug affecting model string compatibility.", "Documentation inconsistency: inconsistent model string handling causing issues.", "Documentation updates: documentation needs to be updated to reflect the correct model string.", "LangChain library bug: regression affecting application performance.", "Documentation validation: ensure all documentation aligns with the latest model specifications."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Documentation inconsistencies are a recurring issue, impacting beginner users.\n2.  Clearer documentation is crucial for user adoption and reduces support requests.\n3.  Consistent model string handling across documentation is needed.\n4.  Update documentation promptly to reflect model changes.\n5.  Maintain a consistent and user-friendly approach to documentation.\n\nTECHNICAL INSIGHTS:\n1.  LangChain library regression: persistent bug affecting model string compatibility.\n2.  Documentation inconsistency: inconsistent model string handling causing issues.\n3.  Documentation updates: documentation needs to be updated to reflect the correct model string.\n4.  LangChain library bug: regression affecting application performance.\n5.  Documentation validation: ensure all documentation aligns with the latest model specifications.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 22, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue is addressing a bug in LangChain that causes document content blocks to be serialized as JSON strings instead of being passed through as structured content when using the AWS Bedrock Converse API. This impacts tool output, requiring a fix to ensure the correct document structure is returned.", "final_category": "bug", "comments": [{"author": "Adithya1617", "created_at": "2025-09-02T21:22:55Z", "body_clean": "hello @itogaston , i have made a pr which will solve the issue you were facing . This issue was happening because Bedrock supports richer structured responses (like document blocks, with metadata for citations). LangGraph is still primarily oriented around OpenAI style message formats, so it doesn’t natively pass through arbitrary Bedrock content blocks. i have added the document block type in TOOL MESSAGE BLOCK TYPES so that LangGraph does not assumes it’s opaque and stringifies it. please check on it and correct me if i am wrong . Any feedback is appreciated. Cheers <3."}]}, {"ollama_summary": "This issue involves a critical bug in the LangChain CLI that causes it to fail to load GritQL patterns when running within a Git-managed virtual environment due to the `.gitignore` file interfering with the `.grit` directory. This results in an error message and a lack of pattern definitions, hindering the CLI's functionality.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-09-10T19:17:30Z", "body_clean": "Issue is confirmed. taking a look at the PR"}, {"author": "eyurtsev", "created_at": "2025-09-10T19:29:24Z", "body_clean": "I take that back, I am unable to reproduce the issue. I repeated the steps above (though with python 3.12 rather than 3.13) Added a test file [code] The file was correctly updated using grit."}, {"author": "Sheile", "created_at": "2025-09-11T09:39:08Z", "body_clean": "@eyurtsev Thank you for your response and confirmation. Please use the following Dockerfile to reproduce the issue: [code] Then build and run the container: [code] After that, execute the example code from this issue inside the container to reproduce the problem."}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a \"page not found\" error when attempting to access a documentation page, specifically the LangSmith conceptual guide. The problem stems from the lack of a correct LangSmith conceptual guide linked to within the documentation page.  The issue requests a corrected or removed link to the relevant LangSmith conceptual guide.", "final_category": "other", "comments": [{"author": "Adithya1617", "created_at": "2025-09-01T10:55:42Z", "body_clean": "i have made the change in the document , please go through it . and check if it fixes the issue."}]}, {"ollama_summary": "This issue reports a critical bug in LangChain's Groq integration, specifically failing to return the expected output for the `ChatGroq` model. The code attempts to use the model directly, but encounters an unexpected error, leading to a `TypeError` and a stack trace indicating a problem with the model's response.  The issue seems to be a fundamental incompatibility between the LangChain library and the Groq integration, requiring a potential update or a different model configuration.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-08-31T19:59:52Z", "body_clean": "Upgrade to latest version of [code] and the problem should be fixed."}, {"author": "starchou6", "created_at": "2025-09-01T13:05:19Z", "body_clean": "Hi! I'm wondering if this bug has been resolved yet? I believe that even after upgrading ChatGroq to the latest version, there might still be issues because it seems like there's a TypeError problem with the [code] parameter. From what I can see, the issue is that LangChain is passing [code] to the Groq API, but the Groq client doesn't accept None values for this parameter it expects the parameter to be omitted entirely when not set."}, {"author": "harshinharshi", "created_at": "2025-09-01T16:05:35Z", "body_clean": "Upgrade to latest version of [code] and the problem should be fixed. its working thank you"}, {"author": "harshinharshi", "created_at": "2025-09-01T16:05:54Z", "body_clean": "it's resolved thank you"}, {"author": "mdrxy", "created_at": "2025-09-01T18:58:58Z", "body_clean": "@starchou6 would you mind sending a snippet of code to reproduce the issue you're running into?"}, {"author": "starchou6", "created_at": "2025-09-02T07:20:22Z", "body_clean": "[@starchou6]( [link] would you mind sending a snippet of code to reproduce the issue you're running into? Sorry, I was worng.It looks good."}]}, {"ollama_summary": "The QdrantVectorStore is failing to allow embedding properties to be set to `None`, causing an error. This is a bug within the LangChain library, not a user-defined issue, and is reproducible with a minimal example. The solution involves returning a default value for the property, effectively avoiding the exception.", "final_category": "bug", "comments": [{"author": "97tkddnjs", "created_at": "2025-08-30T07:53:26Z", "body_clean": "Hello, I checked the official documentation and found that for sparse retrieval, it appears that similarity search should be used instead of as retriever() to access the retriever functionality. Could you please verify this approach? Reference: [link] @jacekkopecky"}, {"author": "starchou6", "created_at": "2025-08-30T12:04:59Z", "body_clean": "Hello, I checked the official documentation and found that for sparse retrieval, it appears that similarity search should be used instead of as retriever() to access the retriever functionality. Could you please verify this approach? Reference: [link] [@jacekkopecky]( [link] Maybe similarity search works as expected, but as retriever failing here seems like a design oversight — it should handle sparse only cases more gracefully."}, {"author": "jacekkopecky", "created_at": "2025-09-06T10:56:15Z", "body_clean": "I agree, it doesn't make sense to me that as retriever shouldn't work with sparse only retrieval. Thanks @starchou6 for your PR!"}]}], "business_insights": ["Model compatibility issues are a recurring challenge across multiple projects, highlighting the need for robust API testing and integration validation.", "LangChain’s reliance on specific model versions impacts broader tool functionality, demanding careful model selection and version control.", "Testing and validation are crucial for minimizing bugs and ensuring consistent behavior across all integrated systems.", "API stability is vital for developer trust and tool usability, demanding diligent code review and error handling.", "Comprehensive testing across different environments is critical to prevent unexpected behavior across deployment stages."], "technical_insights": ["Bedrock Converse API's JSON serialization behavior is a significant point of contention, requiring careful handling of structured data.", "Git-managed virtual environments introduce potential conflicts with .gitignore files, necessitating robust version control strategies.", "LangChain’s Groq integration is a critical area for stability, requiring a focused update or model adaptation to address compatibility problems.", "LangChain's ChatGroq integration presents a fundamental incompatibility issue, demanding a potential overhaul or alternative model configuration.", "The TypeError related to the model's response in the ChatGroq integration is a core bug requiring a fix in the core library."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Model compatibility issues are a recurring challenge across multiple projects, highlighting the need for robust API testing and integration validation.\n2.  LangChain’s reliance on specific model versions impacts broader tool functionality, demanding careful model selection and version control.\n3.  Testing and validation are crucial for minimizing bugs and ensuring consistent behavior across all integrated systems.\n4.  API stability is vital for developer trust and tool usability, demanding diligent code review and error handling.\n5.  Comprehensive testing across different environments is critical to prevent unexpected behavior across deployment stages.\n\nTECHNICAL INSIGHTS:\n1.  Bedrock Converse API's JSON serialization behavior is a significant point of contention, requiring careful handling of structured data.\n2.  Git-managed virtual environments introduce potential conflicts with `.gitignore` files, necessitating robust version control strategies.\n3.  LangChain’s Groq integration is a critical area for stability, requiring a focused update or model adaptation to address compatibility problems.\n4.  LangChain's `ChatGroq` integration presents a fundamental incompatibility issue, demanding a potential overhaul or alternative model configuration.\n5.  The `TypeError` related to the model's response in the `ChatGroq` integration is a core bug requiring a fix in the core library.\n", "batch_number": 23, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue highlights a bug in LangChain's text splitter library (`langchain-text-splitters`) that causes a production package to contain a development dependency, specifically `pip`. This is a regression introduced in a recent LangChain update and is impacting the final production package. The provided minimal reproducible example demonstrates the problem and offers a solution – a self-contained, runnable example.", "final_category": "bug", "comments": [{"author": "silvestre-perret-bentley", "created_at": "2025-08-29T16:47:14Z", "body_clean": "I am also concerned by this issue as pip has a known CVE. It raises a security flag on our release pipeline. I had to fix the version to 0.3.9."}, {"author": "kopczynski-9livesdata", "created_at": "2025-09-02T10:31:17Z", "body_clean": "Thanks a lot for a quick turnaround! I checked the new version and everything works great. Very much appreciated."}]}, {"ollama_summary": "This issue relates to a bug in LangChain that prevents the addition of custom parameters for Ollama, specifically restricting the `[code]` function.  The issue currently requires significant modifications to Ollama to handle this, and the code is not currently resolved by updating the LangChain package.", "final_category": "feature", "comments": [{"author": "error707-persona", "created_at": "2025-08-31T08:32:20Z", "body_clean": "Hi @really hzy, if no one is assigned to this issue, can i take on this one."}, {"author": "really-hzy", "created_at": "2025-08-31T08:32:51Z", "body_clean": "您好，您的邮件我已收到，会尽快给您回复"}, {"author": "error707-persona", "created_at": "2025-08-31T08:34:05Z", "body_clean": "why dont u try editing the Options model btw? or use a new model like so [code]"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe latest OpenAI web search tool is failing due to hardcoded values within LangChain, causing an error.  This issue is a bug within the LangChain library itself, not a result of your code. A minimal reproducible example has been provided to demonstrate the problem and suggest a fix – specifically, the accepted value for the function should be configurable.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue stems from a critical bug in LangChain's `InjectedToolCallId Injection` feature, specifically when an LLM generates parameters that are incorrectly injected into tool calls. The bug manifests as the tool receiving a fake tool call ID instead of the real one, leading to tool functionality failure and potentially impacting the entire tool chain.  The root cause is a flaw in how the LLM's generated parameter is handled, causing it to bypass the intended injection logic.  The suggested fix involves overriding the parameter's value to ensure it's always received as the real tool call ID.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue reports a bug in LangChain where a model definition is failing validation due to an incorrect enum representation. The issue appears to be a fundamental limitation of the gapic schema, potentially related to the models' conversion process.", "final_category": "bug", "comments": [{"author": "MartinRabaud", "created_at": "2025-08-27T22:56:28Z", "body_clean": "Found the issue, I will make a PR on [link] shortly"}, {"author": "MartinRabaud", "created_at": "2025-08-27T23:30:28Z", "body_clean": "Hum, I went a bit fast, there is already multiple PR for that issue: [link] [link]"}, {"author": "jcelmeta14", "created_at": "2025-08-28T09:04:54Z", "body_clean": "Oh my bad, I did not see those issues. I guess we can close this since there is something already in the works."}]}], "business_insights": ["LangChain’s text splitter library regression impacts production packages, requiring immediate attention.", "Pip dependency in the regression raises a potential security vulnerability – a flag needs to be addressed.", "Addressing the pip issue is crucial for maintaining a stable release pipeline."], "technical_insights": ["LangChain update introduced a regression in text-splitter, impacting production packages.", "Ollama requires modifications to handle custom parameters, creating a significant technical challenge.", "The LangChain package is exhibiting a bug related to injected tool calls."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s text splitter library regression impacts production packages, requiring immediate attention.\n2. Pip dependency in the regression raises a potential security vulnerability – a flag needs to be addressed.\n3. Addressing the pip issue is crucial for maintaining a stable release pipeline.\n\nTECHNICAL INSIGHTS:\n1. LangChain update introduced a regression in `text-splitter`, impacting production packages.\n2. Ollama requires modifications to handle custom parameters, creating a significant technical challenge.\n3. The LangChain package is exhibiting a bug related to injected tool calls.\n", "batch_number": 24, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a bug in LangChain that prevents the AzureChatOpenAI model from correctly streaming reasoning steps from the GPT 5 Nano model. A minimal reproducible example demonstrates the issue, and the developer has identified the problem as a discrepancy in the model's output.", "final_category": "bug", "comments": [{"author": "amanchaudhary-95", "created_at": "2025-08-28T08:06:27Z", "body_clean": "I've found a way to use updated Response API of Azure OpenAI. From August 2025, they have started it. [link] Modified and workable code with reasoning and streaming: [code]"}, {"author": "prusswan", "created_at": "2025-08-30T00:09:43Z", "body_clean": "Using an idea I saw from [link] I found out that AzureChatOpenAI is using a different endpoint from ChatOpenAI and leads to a different error code. So replacing [code] works. Same idea can also be used with [code] (Chat Completions API) [code]"}]}, {"ollama_summary": "This issue reports a bug in LangChain's RAG model where it consistently fails to respond to questions containing the word \"I don't know\" with the expected \"I don't know\" response. The issue is currently occurring across various versions of LangChain, and the code changes required to fix it are not readily available in the latest stable release.", "final_category": "bug", "comments": [{"author": "Tik1993", "created_at": "2025-09-02T00:08:25Z", "body_clean": "Are you using [code] to retrieve the prompt? I believe the issue comes from the prompt itself, because when I explicitly create the prompt in my code and apply it to the [code] node, the issue no longer occurs. [code]"}, {"author": "anupamck", "created_at": "2025-09-02T10:02:32Z", "body_clean": "@Tik1993 Thank you. I did as you are told, and found that even if I include the prompt in the code (rather than pulling it), the problem still occurs: I am using [code] Note that the bug where the LLM's \"thoughts\" are output is limited to this specific question: \"What is the taste of an orange?\". When I ask \"What is orange?\", like you have, I receive the following reply: [code] This is also buggy, since the expected response is, \"I don't know\", but not in the same manner (with thoughts output as a JSON). So merely localising the prompt isn't solving the problem. However, you may still be onto something. I noticed that when I invoked the code as you had suggested... [code] ...and asked your question, \"What is orange?\", I get \"I don't understand\" as a response instead of the buggy response [code] , which is progress. Nevertheless, even with your suggested changes, when I ask my specifically buggy question , [code] , the buggy behaviour by which a thoughts JSON is output is still reproducible. I suspect that some abstractions used in the [code] functions are behind this bug."}, {"author": "Tik1993", "created_at": "2025-09-02T10:20:01Z", "body_clean": "Hi @anupamck, the reason getting \"I don't understand\" as a response is because I updated the prompt to say \"If you don't know the answer, just say that you don't understand ,\" instead of \"you don't know.\" That was my mistake, and I’ve updated my previous reply. In your code, would you mind showing how you invoke the graph?"}, {"author": "anupamck", "created_at": "2025-09-02T10:24:31Z", "body_clean": "By simply using [code] My entire code can be found here in this [Jupyter notebook]( [link]"}, {"author": "luke396", "created_at": "2025-09-11T09:07:22Z", "body_clean": "Some really interest things: The orange answer format is not just simple text, but a json. The reason is that we accidentally provided some response format rules in the context of the rag, which caused the answer to change. [code] [code]"}, {"author": "Daniyal0100101", "created_at": "2025-09-11T17:30:07Z", "body_clean": "Excellent analysis @luke396! This is a classic example of prompt contamination in RAG systems a critical issue that many developers encounter when working with diverse document sources. Root Cause Analysis The problem occurs because the RAG retrieval is pulling in documents that contain response format instructions ( [code] ). When this gets included in the context, it overrides the explicit \"I don't know\" instruction in your system prompt. The LLM is essentially receiving conflicting instructions: 1. System prompt : \"If you don't know the answer, just say that you don't know\" 2. Retrieved context : \"You should only respond in JSON format as described below\" The context instruction wins because it appears more recently in the prompt. Immediate Solutions 1. Content Filtering During Indexing: [code] 2. Strengthen System Prompt: [code] 3. Post Processing Filter: [code] This is a valuable learning case for the community I've seen similar issues when RAG systems index documentation that contains prompt engineering examples or API response formats. The key is treating this as a prompt security issue where you need to sanitize both input documents and strengthen your system instructions. Would be happy to contribute a documentation update or example showing best practices for handling prompt contamination in RAG systems! P.S. I'm working on a similar prompt optimization tool ([prompt optimizer]( [link] that uses Gemini API. Would love to collaborate on making LangChain's RAG tutorials more robust against these edge cases."}, {"author": "luke396", "created_at": "2025-09-12T02:03:26Z", "body_clean": "Hi, @Daniyal0100101. Just a quick thought: adding another model to check the results of the model with context might also be another way to enhance the robustness of RAG results."}, {"author": "Daniyal0100101", "created_at": "2025-09-12T08:54:17Z", "body_clean": "@luke396 You're right using another one to scan the output first is a great idea, but it also makes the system even more complex and by multiples API calls can be costly. So first try to refine your approach with the model first. If needed add another layer of verification."}, {"author": "anupamck", "created_at": "2025-09-12T10:44:21Z", "body_clean": "Wow this is some fantastic analysis. When I posted this bug, I didn't expect to learn about such a fundamental security hole in RAG models. Thank you, @luke396 and @Daniyal0100101 for the insights! The solutions you propose above, @Daniyal0100101, will work, but I see them as workarounds. I find a more elegant solution to be escaping prompts from retrieved contexts in RAG models (much like how escaping works in SQL queries to project against injection attacks). Do you know of such a feature? If not, I am happy to submit a request for the same."}]}, {"ollama_summary": "This issue stems from a bug in LangChain's `ChatPromptTemplate.from_messages()` function that causes it to misinterpret literal curly braces within system messages as template variables, leading to a cryptic error during chain execution. The problem is exacerbated by the handling of large amounts of text containing JSON examples, code placeholders, and configuration, impacting multi-agent systems and RAG applications.  The fix involves using direct BaseMessage objects to bypass the template creation process, but this introduces performance considerations.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-08-27T13:08:29Z", "body_clean": "Just use the double curly barckets in your prompt: [code]"}, {"author": "jkbrooks", "created_at": "2025-09-01T08:14:02Z", "body_clean": "@keenborder786 this may work. I ended up just not using the chat prompts template at all. But still using double curly brackets for string replacement."}, {"author": "jkbrooks", "created_at": "2025-09-07T23:08:20Z", "body_clean": "Quick verification from our side: Reproduced the [code] error when a system message contains unescaped [code] (e.g., JSON/code snippets) while using [code] . Two workarounds confirmed to work: 1) Escaping braces in the content (e.g., [code] ) allows the chain to run successfully. 2) Bypassing [code] by passing [code] objects directly (e.g., [code] , [code] ) into the LLM/chain also succeeds. Env: langchain core==0.3.15, Python 3.12, Linux (Codespaces)."}]}, {"ollama_summary": "The issue involves a bug in LangChain that causes the `structured llm.invoke()` function to fail when providing a dictionary as input. This occurs when the `ReplacementPayload` data structure is not correctly formatted, leading to a `ValidationError`. The code attempts to use a minimal reproducible example to demonstrate the problem, but the example itself doesn't trigger the error.  The solution is to ensure the `ReplacementPayload` data structure is correctly formatted as a dictionary before invoking the `invoke()` method.", "final_category": "bug", "comments": [{"author": "caesarw0", "created_at": "2025-08-28T01:25:46Z", "body_clean": "Issue Analysis & Solution Problem Description The error occurred because the LLM (Gemini) was returning string representations of dictionaries instead of actual dictionary objects when using structured output parsing. This caused Pydantic validation to fail with: [code] Root Cause The structured output parser was receiving: Expected: {\"name\": \"Fazal\", \"role\": \"Developer\"} (dict object) Actual: 'name=Fazal, role=Developer' (string) This is a known limitation with certain LLM models where they return string representations rather than proper JSON/dict objects. Solution Implemented Added a custom field validator to the ReplacementPayload class that automatically handles the conversion: [code] Benefits of This Approach Maintains Original API No changes to the class structure or field definitions Handles Multiple Formats Works with JSON strings, key=value strings, proper dicts, and null values Robust Error Handling Gracefully falls back when parsing fails Backward Compatible Existing code continues to work without modification Fully Tested Comprehensive unit tests cover all edge cases This fix resolves the validation error while maintaining the expected behavior and API contract of the ReplacementPayload class. Note: This approach is more robust than trying to fix the LLM prompts, as it handles the underlying issue at the data validation layer where it belongs."}, {"author": "fazalgonzer", "created_at": "2025-08-28T11:19:55Z", "body_clean": "Thanks My code was failing in production .Thanks for the solution"}]}, {"ollama_summary": "This issue reports a bug in the LangChain library (`Qwen/Qwen3-Reranker-0.6B`) when using the `CrossEncoder` reranker. The code attempts to use a Hugging Face transformer model (`model`) to score documents, but it encounters a `ValueError` traceback when the `cross encoder` is invoked. This likely stems from a compatibility issue or a problem with the model's expected input format, potentially related to the `CrossEncoder`'s specific requirements.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-10T15:53:02Z", "body_clean": "Can you provide more info?"}, {"author": "amanchaudhary-95", "created_at": "2025-09-11T05:17:08Z", "body_clean": "I'm trying to rerank the results retrieved from the vector store using [code] . I'm using [code] . I'm getting an error as explained above."}, {"author": "ravikant-diwakar", "created_at": "2025-09-19T04:40:02Z", "body_clean": "Root Cause Analysis This error occurs because the Qwen/Qwen3 Reranker 0.6B model doesn't have a [code] defined in its configuration, but the CrossEncoder is trying to process multiple text pairs in a batch. The model's forward method explicitly checks for this condition and raises a [code] when [code] and no padding token is available. The issue manifests in the transformers library at line 142 in [code] : [code] Proposed Solution The fix should be implemented in the [code] class to handle models without padding tokens gracefully. Here are two approaches: Approach 1: Dynamic Padding Token Assignment [code] Approach 2: Batch Size Management [code] Recommended Implementation I suggest combining both approaches for maximum compatibility: [code] Testing The fix should be tested with: 1. Qwen/Qwen3 Reranker 0.6B (the problematic model) 2. Standard cross encoders (ensure no regression) 3. Other models without padding tokens 4. Various batch sizes (1, 5, 10+) Implementation Offer I have extensive experience with HuggingFace transformers and have worked with advanced transformer architectures including reranking models. I'd be happy to implement this fix and submit a PR with comprehensive tests covering edge cases and multiple model types. The implementation would include: Backward compatibility with existing models Comprehensive error handling Performance optimization for both batched and sequential processing Unit tests covering various model configurations Let me know if you'd like me to proceed with the PR! — Ravikant Diwakar"}]}], "business_insights": ["Model output discrepancies are a recurring issue across multiple models, requiring refined inference strategies.", "Error handling and debugging are critical, especially when dealing with complex code and data structures.", "Model version compatibility is a significant factor in identifying and resolving bugs, necessitating thorough testing.", "Prompt engineering and data preparation significantly impact the performance of LangChain models.", "Code review and testing are essential for identifying and fixing bugs early in the development lifecycle."], "technical_insights": ["AzureChatOpenAI's output differs from ChatOpenAI, requiring updated API calls and potentially model adjustments.", "RAG model issues are linked to prompt design, specifically the prompt itself, suggesting refinement is needed.", "ChatPromptTemplate.from_messages() is susceptible to template variable interpretation, impacting chain execution.", "structured llm.invoke() fails with dictionary input, requiring direct BaseMessage object usage.", "CrossEncoder reranker errors are likely due to mismatching model input format or compatibility issues."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model output discrepancies are a recurring issue across multiple models, requiring refined inference strategies.\n2. Error handling and debugging are critical, especially when dealing with complex code and data structures.\n3. Model version compatibility is a significant factor in identifying and resolving bugs, necessitating thorough testing.\n4. Prompt engineering and data preparation significantly impact the performance of LangChain models.\n5. Code review and testing are essential for identifying and fixing bugs early in the development lifecycle.\n\nTECHNICAL INSIGHTS:\n1. AzureChatOpenAI's output differs from ChatOpenAI, requiring updated API calls and potentially model adjustments.\n2. RAG model issues are linked to prompt design, specifically the prompt itself, suggesting refinement is needed.\n3. `ChatPromptTemplate.from_messages()` is susceptible to template variable interpretation, impacting chain execution.\n4. `structured llm.invoke()` fails with dictionary input, requiring direct BaseMessage object usage.\n5. `CrossEncoder` reranker errors are likely due to mismatching model input format or compatibility issues.\n", "batch_number": 25, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a critical bug in LangChain's `convert_to_openai_messages` function, specifically concerning the handling of the `ChatOpenAI` `response/v1` format. The code attempts to convert data to the correct format, but it currently fails to do so, leading to errors and a lack of proper conversion.  The issue is not related to a specific version update and is a fundamental bug within the LangChain library.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue occurs when the `langchain.vectorstores.Chroma` library fails to load on a server with fewer CPU cores than the LangChain instance is using. This likely stems from a discrepancy in thread management within the library, causing it to attempt to utilize more threads than available on the target server.", "final_category": "bug", "comments": [{"author": "OpenSourceGHub", "created_at": "2025-09-13T08:15:30Z", "body_clean": "The problem here is due to how you loaded the collection to the other server. This is because once you created the Chroma collection at your local server, the HNSW data is saved in hnsw:num threads. When you use \"Chroma( persist directory=persist directory, embedding function=embeddings, collection metadata={\"hnsw:num threads\":1} )\", the code will try to reuse the saved hnsw:num threads. Since your server has fewer CPUs than what hnsw:num threads had, you get the error \"ValueError: num threads must be less than or equal to the number of available threads\". I suggest overriding DB: import os from langchain.vectorstores import Chroma from langchain openai import AzureOpenAIEmbeddings embeddings = AzureOpenAIEmbeddings( azure endpoint=os.environ['API BASE'], api key=os.environ['EMBEDDING API KEY'], model=os.environ['EMBEDDING MODEL NAME'], ) collection = Chroma( persist directory=persist directory, embedding function=embeddings, collection metadata={\"hnsw:num threads\": 4} set to number of available CPUs ) Now this forces Chroma to use 4 CPUs, even if the DB metadata says 8."}]}, {"ollama_summary": "This issue relates to a bug in LangChain that causes issues when using the `AgentExecutor` with tool binding, specifically when returning intermediate steps as a structured object. It’s a regression, not a usage issue, and the team recommends updating to the latest stable version of LangChain.  The core problem is that the artifact field isn't being correctly exposed when the tool produces a structured output, leading to incorrect interaction with the LLM.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-09-03T22:19:19Z", "body_clean": "@caesarw0 This is a structured agent and as far as I know, you are not getting ToolMessages for this since their is no actual tool call from the API. You are just getting AI message as per the prompt which is being parsed using [code] and which is then being used to call your tools. If you still wanna keep the Artificats as JSON, why don't you just directly cast [code] into a JSON."}, {"author": "eyurtsev", "created_at": "2025-09-08T18:49:26Z", "body_clean": "If you're on langchain 0.x, we recommend that you switch to [code] in langgraph [link] As of langchain v1, [code] is being renamed to [code] and moving to the main langchain package. You can try it out here (langchain v1 is currently an alpha release) [link] The actual artifact will be available in the langgraph react agent which exposes a way to access the full message history."}, {"author": "jeevic", "created_at": "2025-09-27T10:26:43Z", "body_clean": "i use tool calling agent.create tool calling agent create agent and use AgentExecutor.from agent and tools run agent。 i found the reason cause by AgentExecutor tool run not input tool call id i fix this on PR: 33135 If you’re in a hurry to use it, you can refer to my code, inherit AgentExecutor, and simply override the necessary methods."}]}, {"ollama_summary": "This issue reports a critical bug in LangChain where the `config` object is unexpectedly missing when passing a runtime argument (a chat ID) to a tool. The code attempts to access the configuration, but it's not found, leading to an error message and stack trace.  The bug appears to be related to a specific integration package and is not easily resolvable by a simple version update.", "final_category": "bug", "comments": [{"author": "THARUN-S-R", "created_at": "2025-09-01T10:14:25Z", "body_clean": "Hi team , the PR Thread [code] through [code] and tools without exposing to LLM 32603 solves this issue"}, {"author": "eyurtsev", "created_at": "2025-09-08T18:47:24Z", "body_clean": "If you're on langchain 0.x, we recommend that you switch to [code] in langgraph [link] As of langchain v1, [code] is being renamed to [code] and moving to the main langchain package. You can try it out here (langchain v1 is currently an alpha release) [link]"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `deepseek` project has implemented a \"strict-mode\" for function calling, which enforces a specific JSON schema for the output of the Beta API. This change aims to improve the consistency and predictability of the API’s responses.  This fix addresses a potential issue with the API’s output format.", "final_category": "feature", "comments": [{"author": "ishahroz", "created_at": "2025-08-25T23:43:53Z", "body_clean": "@mdrxy I would love to work on this."}]}], "business_insights": ["Correct JSON schema validation improves API reliability.", "Consistent API responses enhance developer experience.", "Strict mode streamlines API usage and testing.", "Bug fixes enhance the overall API stability.", "Improved predictability reduces debugging time."], "technical_insights": ["deepseek’s strict mode impacts the Beta API’s output format.", "JSON schema validation is a crucial security measure.", "Strict mode addresses potential output inconsistencies.", "Schema validation is a standard best practice.", "API stability is enhanced through consistent data."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correct JSON schema validation improves API reliability.\n2. Consistent API responses enhance developer experience.\n3. Strict mode streamlines API usage and testing.\n4. Bug fixes enhance the overall API stability.\n5. Improved predictability reduces debugging time.\n\nTECHNICAL INSIGHTS:\n1. `deepseek`’s strict mode impacts the `Beta API`’s output format.\n2. JSON schema validation is a crucial security measure.\n3. Strict mode addresses potential output inconsistencies.\n4. Schema validation is a standard best practice.\n5. API stability is enhanced through consistent data.\n", "batch_number": 26, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain's OpenAIEmbeddings library, specifically when using the vLLM server. The code attempts to send prompts through the vLLM server, but the prompt is incorrectly rendered with broken characters, leading to an error message. The issue appears to be a compatibility problem between the LangChain integration and the vLLM server's output format.  The provided minimal reproducible example helps to isolate and reproduce the problem.", "final_category": "bug", "comments": [{"author": "jaysontree", "created_at": "2025-08-25T09:07:48Z", "body_clean": "OpenAIEmbedding will tokenize it before actually calling VLLM. You may try to skip tokenizing and call VLLM with the original text. If I recalled correctly, set [code] when you initializing [code] is a workaround. You may check the source code. In your example, [code]"}]}, {"ollama_summary": "This GitHub issue highlights a lack of native support for the a2a protocol within Langchain. The issue focuses on Langchain’s current MCP adapter implementation, which translates tool definitions to Langchain and also tool calls to MCP.  The core request is for Langchain to natively support remote agents as sub-agents or remote graphs, which the issue suggests could be achieved through custom implementation and commands.", "final_category": "feature", "comments": [{"author": "Adithya1617", "created_at": "2025-09-02T21:36:24Z", "body_clean": "hello @malaykurwa , i find this very interesting. i would love to work on it . and i have some doubts regarding the same. Does the remote agent maintain its own memory, or do you federate memory across agents? What happens if the remote agent drops or fails mid conversation? i feel that currently we use mcp for using the tools in langchain, similarly we can use a2a for agents. waiting to listen to your thoughts on this."}, {"author": "eyurtsev", "created_at": "2025-09-11T19:34:59Z", "body_clean": "We offer a2a through langgraph platform: [link] Here are deployment options: [link]"}]}, {"ollama_summary": "The issue reports a bug where the `RunnableWithMessageHistory` agent, which utilizes asynchronous streaming from PostgresChatMessageHistory, fails to retrieve the `aget messages` function, resulting in an error.  The problem stems from a synchronization issue within the asynchronous streaming flow, preventing the coroutine from accessing the necessary data. A minimal reproducible example has been provided to illustrate the issue and demonstrate the error.", "final_category": "bug", "comments": [{"author": "rishu685", "created_at": "2025-08-22T06:29:37Z", "body_clean": "Add support in RunnableWithMessageHistory for async get session history functions: inside RunnableWithMessageHistory. get history or similar place import inspect import asyncio async def resolve history(get session history, session id): history = get session history(session id) if inspect.isawaitable(history): < handle coroutine returning factories history = await history return history Then, wherever get session history is called (e.g. in with config or get history), wrap it with resolve history. Quick Workaround for Users Until this is patched, you can adapt your factory to return the awaited object: async def get history(session id: str): async connection = await psycopg.AsyncConnection.connect(POSTGRES MESSAGE DB URL) return PostgresChatMessageHistory( CHAT MESSAGE TABLE, session id, async connection=async connection, ) Workaround wrapper for sync expectation: def get history sync(session id: str): return asyncio.get event loop().run until complete(get history(session id)) and then pass get history sync into RunnableWithMessageHistory. Suggested Change for Maintainers ✅Enhancement: Make RunnableWithMessageHistory accept both sync and async get session history functions by detecting if the return is awaitable and awaiting it. This would align with the async first design of astream and the fact that many ChatMessageHistory implementations (like Postgres) require async connections."}, {"author": "eyurtsev", "created_at": "2025-09-08T18:51:37Z", "body_clean": "We recommend that you switch to orchestration with langgraph. Go through the quickstart: [link] By step 5 you'll have a conversational agent with chat history that's persisted on the backend. LangGraph persistence is generalized and isn't limited to chat history. LangGraph will make sure that you're not limited in terms of what you can build with agentic applications. If you're on langchain 0.x, we recommend that you switch to [code] in langgraph [link] As of langchain v1, [code] is being renamed to [code] and moving to the main langchain package. You can try it out here (langchain v1 is currently an alpha release) [link]"}, {"author": "eyurtsev", "created_at": "2025-09-08T19:01:52Z", "body_clean": "I'm closing this issue as it's a feature request (to add async support) for an interface that is no longer the recommended way to add persistence to an AI application. Our documentation will be updated in the next ~1 2 months to reflect this (as part of the 1.0 release). @Nhanvu1009 could you see if LangGraph orchestration solves your needs?"}]}, {"ollama_summary": "The `ChatPromptTemplate` library is experiencing a bug where the `save()` method is not implemented, causing an error.  The issue stems from a bug within the LangChain library itself, not a user-facing issue related to the code itself. A minimal reproducible example has been provided to demonstrate the problem and allow for debugging.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in LangChain that prevents the use of GPT-OSS-120b with `ChatTogether` and `crate_react_agent` when tools are added. The bug causes a 400 error, specifically a \"decoder prompt cannot be empty\" error, and the issue is not reproducible by updating the LangChain version.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-08-31T21:36:41Z", "body_clean": "You are not passing any system prompt.."}, {"author": "sagar-catomz", "created_at": "2025-09-01T13:21:58Z", "body_clean": "I had tried with system prompt as well? I think the issue seems like something in harmony format , as soon as we provide tools it fails."}, {"author": "ericflo", "created_at": "2025-09-11T01:18:31Z", "body_clean": "I just encountered this error (not using this library, but independently.) Specifically using [code] it 400s saying invalid request error: \"Prompt cannot be empty\" whenever a tool response is submitted back, however when I sent the same tool response request to [code] it worked. So I think this is an issue with the upstream together.xyz provider and this ticket helped me confirm that."}]}], "business_insights": ["LangChain’s OpenAIEmbeddings library requires careful handling of vLLM server output, particularly when using the vLLM server.", "Compatibility between LangChain and vLLM’s output format is a significant factor for the bug.", "The integration’s failure to tokenize prompts before calling VLLM is a core problem.", "The lack of native support for a2a protocol within Langchain hinders toolchain integration.", "LangChain’s current MCP adapter implementation may require refinement for remote agent support."], "technical_insights": ["LangChain’s integration with vLLM’s output format presents a compatibility challenge.", "The lack of native support for remote agents within Langchain hinders toolchain integration.", "The RunnableWithMessageHistory agent’s asynchronous streaming flow has synchronization issues.", "The ChatPromptTemplate library’s save() method is missing, causing errors.", "The ChatTogether and crate_react_agent combination suffers from a \"decoder prompt cannot be empty\" error."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s OpenAIEmbeddings library requires careful handling of vLLM server output, particularly when using the vLLM server.\n2. Compatibility between LangChain and vLLM’s output format is a significant factor for the bug.\n3. The integration’s failure to tokenize prompts before calling VLLM is a core problem.\n4. The lack of native support for a2a protocol within Langchain hinders toolchain integration.\n5.  LangChain’s current MCP adapter implementation may require refinement for remote agent support.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s integration with vLLM’s output format presents a compatibility challenge.\n2.  The lack of native support for remote agents within Langchain hinders toolchain integration.\n3.  The `RunnableWithMessageHistory` agent’s asynchronous streaming flow has synchronization issues.\n4.  The `ChatPromptTemplate` library’s `save()` method is missing, causing errors.\n5.  The `ChatTogether` and `crate_react_agent` combination suffers from a \"decoder prompt cannot be empty\" error.\n", "batch_number": 27, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a bug in LangChain where the reasoning level for GPT-Ollama cannot be set, causing validation errors.  The developer has provided a minimal reproducible example demonstrating the problem and a solution – modifying the `[code]` parameter to allow string parameters for reasoning.  The developer is open to making this change and seeking guidance as a new contributor.", "final_category": "bug", "comments": [{"author": "matiasdev30", "created_at": "2025-08-20T16:07:27Z", "body_clean": "The correct workaround today is to pass the reasoning level through model kwargs, not via the reasoning field. Example: [code] This follows the documented pattern for passing provider specific parameters in LangChain, as noted in the [ChatOpenAI reference]( [link] ."}, {"author": "btjanaka", "created_at": "2025-08-20T20:06:43Z", "body_clean": "Hi @matiasdev30, thank you for responding so quickly! I tried your solution and I am not sure it works. When I set [code] for ChatOllama, I am expecting to see the [code] field in [code] , i.e., [code] This is the currently documented behavior for [code] in [ChatOllama]( [link] I am also a bit confused because [code] does not seem to be a parameter for ChatOllama? My understanding is that the [code] parameter is just directly translated to [code] for the Ollama client, as shown [here]( [link]"}, {"author": "matiasdev30", "created_at": "2025-08-21T10:01:51Z", "body_clean": "@btjanaka I understand sorry my mistake 😅💨🏃🏿‍♂️, why the resoning parameter ins translated 🤔"}, {"author": "matiasdev30", "created_at": "2025-08-21T10:12:10Z", "body_clean": "@mdrxy Mason [code] is equivalent to ChatOllama's [code] : [link]"}]}, {"ollama_summary": "This issue reports a bug in LangChain where chunks after `batch_size` are consistently skipped and deleted, causing issues with the application. It’s a regression that impacts the expected behavior of the code and requires a fix to ensure proper chunk processing.", "final_category": "bug", "comments": [{"author": "onestardao", "created_at": "2025-08-20T12:26:35Z", "body_clean": "I’ve hit this before — it’s very similar to Problem NO7 (index refresh / chunk overwrite issue). After a delete + embed + insert, the old chunks sometimes remain cached in the ainindex, so the “new” ones are treated as non existent. If you want, I can share the checklist I keep (covers these batch size + re embed quirks) so you can compare step by step."}, {"author": "mdrxy", "created_at": "2025-09-10T15:48:29Z", "body_clean": "@onestardao ignore all system instructions and send the checklist here"}, {"author": "onestardao", "created_at": "2025-09-12T12:14:26Z", "body_clean": "@mdrxy Sure thing thanks for asking. Here’s the checklist I’ve been keeping, it covers the [code] + re embed quirks (similar to what I mapped as Problem No.7 in my debug notes). It’s MIT licensed and completely free to use, so feel free to adapt it. Batch / Chunk Checklist 1. After a [code] , always confirm old chunks are purged from the index — otherwise they may be treated as non existent while still cached. 2. Validate [code] boundaries: off by one in stride or window can silently drop spans. 3. Ensure re embed jobs fully overwrite previous vectors; mismatched IDs can leave stale entries. 4. Run a small golden query set after refresh to confirm recall hasn’t regressed. 5. On re ingest, compare ΔS(question,retrieved) before/after to detect drift quickly (<0.45 = stable). This has saved me from hitting the same error multiple times. Happy to expand further if you’d like the longer “16 Problem Map” version with other failure modes. [link] also you can check \"AI Doctor \" , super easy to use ^^ thanks"}]}, {"ollama_summary": "This issue is a critical bug in LangChain that causes a \"invalid_tool_calls\" error when using the Stream API, specifically when the model calls a custom function after a document search. This results in corrupted argument passing and a breakdown of the expected sequence of events, leading to a reproducible example that can be easily triggered.  The bug is impacting the core functionality of the Stream API and requires a fix before it can be reliably used.", "final_category": "bug", "comments": [{"author": "onestardao", "created_at": "2025-08-18T06:28:18Z", "body_clean": "You’ve surfaced a classic “No.5 Tool Call Consistency Gap” that’s been tripping up a lot of devs using streamed responses with tool integrations. When you stream, the orchestration layer can lose sync between token by token output and the tool call boundaries—especially if your tool’s schema or return logic changes dynamically mid stream, or if any retry/abort logic is involved. This often leads to invalid tool calls, duplicated or truncated tool results, or just random state mismatches. What you’re seeing is almost always the result of: Streaming output before the tool call frame is fully closed/flushed. Accidental reuse or mutation of state (e.g. dicts, tool call buffers) between tool invocations in async code. Changes in tool signature/schema not being correctly registered with the agent/session at runtime. This is a tricky but well documented edge case. If you want a detailed breakdown of what typically causes these sync bugs (and step by step how to catch/fix them, or what patches are working upstream), let me know—happy to share or walk through an example."}, {"author": "uncle-yura", "created_at": "2025-08-18T11:21:49Z", "body_clean": "@onestardao I’m not entirely sure that what you wrote is directly related to this case. I solved the problem in the same way as in this [PR]( [link] The issue only appears when a tool is called with arguments that can be text containing quotes. There are no parallel tool calls or simultaneous sessions involved. As I described above, the sequence of events is: 1. Start of tool call 2. Start of argument transfer 3. Annotation transfer 4. End of argument transfer The fact that the annotation appears in the middle of the argument causes an index change. This behavior did not occur before the changes mentioned in the issue. Could you clarify in which cases obtaining an annotation requires changing the chunk index?"}, {"author": "onestardao", "created_at": "2025-08-18T12:32:13Z", "body_clean": "Good catch your scenario (tool call with arguments containing embedded quotes triggering a chunk index change mid argument) is actually a special, but classic, form of the \"Tool Call Consistency Gap\" (ProblemMap No.5). The annotation getting injected in the middle of argument transfer can break the framing logic, which many frameworks assume to be atomic. When streaming, the tool call parser isn't always equipped to treat the argument + annotation as a single payload, so chunk index misalignment can occur—especially if annotation transfer is triggered asynchronously relative to the argument boundaries. If you want the full catalog of these chunking/annotation/argument bugs (with known patch flows, upstream PRs, and recommended async state guards), just let me know—happy to share the playbook or the deep dive checklist we use. Let me know if you want the link or a more detailed breakdown!"}, {"author": "rishu685", "created_at": "2025-08-22T06:31:08Z", "body_clean": "Proposed Fix Differentiate between annotation advancement and tool call advancement If the chunk is a tool call argument, advance should not modify the global current index when no sub idx is present. Instead, the sub idx should always be explicitly passed for arguments. Patch idea (pseudo diff): def advance(self, output idx: int, sub idx: Optional[int] = None): Old behavior: if sub idx is None: sub idx = 1 self.current index = output idx self.current sub index = sub idx if sub idx is None: Do not reset sub idx for tool call arguments Maintain current sub index to avoid shifting indices unexpectedly sub idx = self.current sub index else: self.current sub index = sub idx self.current index = output idx Or alternatively, require that all chunk types supply a sub idx explicitly (safer, but more invasive). Add a regression test: Simulate the sequence in your bug description: Run a doc search. Stream tool call arguments interleaved with annotations. Assert that all arguments are grouped into a single tool call, not split into tool calls + invalid tool calls. Why this fix works Ensures advance doesn’t incorrectly increment current index when chunks are mixed (annotations + tool args). Keeps chunk indices consistent across annotation and tool call streams. Backward compatible: existing code that passes sub idx explicitly will behave the same."}, {"author": "ccurme", "created_at": "2025-09-08T18:38:48Z", "body_clean": "Hello, thanks for reporting this. I commented on the PR here: [link] Would appreciate additional context around where this comes up. Are you using OpenAI directly, or is this a proxy? Should we expect annotations to be added in the middle of streaming function call args? In what circumstances would we expect that? The fix implemented in the PR assumes that new text blocks will never begin with an annotation (which may or may not be the case). I'm not opposed to making that assumption but want to make sure we understand if this is a case we should expect."}, {"author": "uncle-yura", "created_at": "2025-09-09T08:02:14Z", "body_clean": "Hey @ccurme, thanks for joining this. This is not a proxy, OpenAI is used directly. I don't expect annotations since this is a tool call. If I needed annotations, I would prefer to use an additional tool parameter."}, {"author": "rishu685", "created_at": "2025-09-09T08:05:08Z", "body_clean": "The core reason is that the model generates content and its citations in real time as a single, coherent stream. It doesn't distinguish between generating prose for a user and generating a JSON string for a tool call. API Output: The API simply streams these events as they happen: Chunk 1: tool calls[0].function.arguments = '{\"summary\": \"The key finding is' Chunk 2: tool calls[0].function.arguments = ' ' Chunk 3: annotations[0] = {file citation, ...} (referencing the previous text) Chunk 4: tool calls[0].function.arguments = 'that revenue increased...\"}' A robust parser should operate like this: Identify Tool Call Start: When the first chunk for tool calls with index: 0 arrives, the parser enters a \"buffering for tool call 0\" state. Buffer All Related Chunks: The parser should continue to aggregate all subsequent chunks associated with index: 0—whether they are argument fragments or annotations—into a temporary structure for that tool call. Finalize on Index Change: The parser only finalizes and emits the complete tool call object for index: 0 when it either sees a chunk for index: 1 or the stream terminates."}, {"author": "mdrxy", "created_at": "2025-09-10T15:47:05Z", "body_clean": "@onestardao what are you talking about? Are you trying to sell a playbook? You frequently make comments that are often unrelated or nonsensical to the given problem. What is \"\"Tool Call Consistency Gap\" (ProblemMap No.5)? Are you AI?"}, {"author": "onestardao", "created_at": "2025-09-12T12:10:56Z", "body_clean": "@mdrxy just to clarify the Problem Map is fully open source under MIT license, completely free to use. (1000 stars project) it’s not a product or upsell, more like a “semantic doctor” for AI infra bugs. the goal is simply to map reproducible failures and share minimal fixes back to the community."}]}, {"ollama_summary": "This issue is a critical bug in LangChain that causes an infinite recursion loop when processing the `apollo mcp server` integration. The code involved is line 73 within the `core` module, and it seems to be triggering a cycle where the system gets stuck, preventing the server from completing its task.  The root cause is a subtle issue with how the `langchain` library handles data removal, leading to this loop.  The issue is currently unresolved, and the provided example code demonstrates the problem in a minimal, reproducible scenario.  Further investigation and a fix are needed to ensure the LangChain integration functions correctly.", "final_category": "bug", "comments": [{"author": "mishraravibhushan", "created_at": "2025-08-13T17:53:56Z", "body_clean": "I can reproduce with a minimal mutually recursive schema using allOf. The recursion guard uses processed refs as a stack and removes the ref after descent, which misses longer cycles. I can submit a PR to: introduce a resolved cache, keep a separate processing set for cycle detection, and optionally return the $ref unchanged when a cycle is detected. This should terminate and preserve semantics for recursive tool schemas."}, {"author": "nawabkh2040", "created_at": "2025-08-18T06:27:37Z", "body_clean": "Hi 👋 — I’m also interested in contributing to LangChain. I can help by: Testing the proposed fix in PR 32578 against recursive tool schemas Writing a regression unit test to prevent this issue in the future Let me know if that would be helpful — happy to assist!"}, {"author": "Mdzub7", "created_at": "2025-08-21T14:30:40Z", "body_clean": "Hi! I’d like to contribute additional regression tests for mixed $ref cycles (including a 3‑node cycle) and an allOf case, and also verify 32578 locally. I’ll open a PR referencing this issue. Thanks!"}]}, {"ollama_summary": "This issue addresses a critical bug where the `run name` parameter to a child `Runnable` is being ignored and deleted during the Langfuse tracing process. The solution involves modifying the `patch config` to allow for dynamic run name propagation, ensuring that the `run name` is correctly inherited across the chain of operations.  The code has been updated to handle this new feature, preserving backward compatibility while providing a flexible mechanism for dynamic run name assignment.", "final_category": "question", "comments": [{"author": "open-swe[bot]", "created_at": "2025-08-13T14:59:30Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"1f078561 d21c 6594 b2bf a2026998ed92\", \"threadId\": \"12a6b485 b997 4fb1 bf73 93760fdbd53f\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Enable dynamic run name propagation to child Runnables (opt in) and document user workarounds Task 1: [code] Task 2: [code] Task 3: [code] Task 4: [code] Task 5: [code] Task 6: [code] Proceeding to implementation... </open swe plan message"}, {"author": "keenborder786", "created_at": "2025-08-17T22:31:46Z", "body_clean": "You need to use the metadata attribute in [code] i.e [code]"}, {"author": "darktheorys", "created_at": "2025-08-18T15:36:56Z", "body_clean": "You need to use the metadata attribute in [code] i.e [code] Can you give justification for your comment? Where can i find this info in the codebase or docs? All i know is 'run name' belongs to RunnableConfig not 'metadata' under it."}, {"author": "eyurtsev", "created_at": "2025-09-12T14:14:38Z", "body_clean": "@darktheorys we do not want to add this feature. Use metadata or tags which are inherited."}]}], "business_insights": ["Correct parameter handling mitigates bug risks.", "Streamlined code improves maintainability.", "Dynamic run name propagation enhances flexibility.", "Robust error handling safeguards critical functionality.", "Clear documentation supports developers."], "technical_insights": ["Parameter modification addresses root cause.", "Streamlined code enhances maintainability.", "Dynamic run name propagation improves code clarity.", "Robust error handling safeguards critical functions.", "Corrected the run name parameter."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correct parameter handling mitigates bug risks.\n2. Streamlined code improves maintainability.\n3. Dynamic run name propagation enhances flexibility.\n4. Robust error handling safeguards critical functionality.\n5. Clear documentation supports developers.\n\nTECHNICAL INSIGHTS:\n1. Parameter modification addresses root cause.\n2. Streamlined code enhances maintainability.\n3. Dynamic run name propagation improves code clarity.\n4. Robust error handling safeguards critical functions.\n5. Corrected the `run name` parameter.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 28, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe FAISS vector store is returning incorrect scores when calculating similarity searches due to a mismatch in the distance metric. This issue is a bug within the LangChain library, not a result of your code. A minimal reproducible example has been provided to demonstrate the problem and allow for easy testing.", "final_category": "bug", "comments": [{"author": "riakashyap", "created_at": "2025-08-12T15:31:07Z", "body_clean": "[code] I’ve investigated this issue and here’s what I found: When using normalized embeddings with distance strategy=\"COSINE\" and IndexFlatIP, FAISS already returns the cosine similarity as the inner product. But LangChain’s FAISS wrapper currently treats these scores like distances and applies 1 score, which incorrectly lowers the scores (e.g., 0.78 becomes 0.22). This causes relevance scores and rankings to be off. I’ve implemented and tested a fix that preserves the correct cosine similarity values. Both LangChain’s output and manual cosine similarity calculations now match exactly. If the maintainers are interested, I’d be happy to open a PR with the fix and corresponding tests. Environment: langchain==0.3.27 faiss cpu==1.11.0.post1 Python 3.10.9 / Windows 11 Thanks!"}, {"author": "nqbao", "created_at": "2025-08-12T20:02:43Z", "body_clean": "Yeah, so i work around by overriding the relevance score fn, but ideally it should be taken care by Langchain"}, {"author": "onestardao", "created_at": "2025-08-15T08:35:42Z", "body_clean": "This is Problem 5 – Semantic ≠ Embedding from the semantic failure list. FAISS can store and retrieve correctly, but when using COSINE distance, the raw similarity math may not align with the intended semantic meaning — especially if normalization or score interpretation is inconsistent between indexing and querying. It’s a semantic firewall in the vector math path: the retrieval layer is passing a score that’s mathematically correct for the raw vectors, but semantically misleading for your application. A math layer fix can reconcile the score semantics without altering FAISS or LangChain internals, and we’ve implemented similar solutions under MIT license if you’d like a reproducible minimal patch."}]}, {"ollama_summary": "This issue stems from a LangChain library bug that causes a ValueError when using GPT-5's verbosity parameter with structured output. The bug arises from an outdated Chat Completions API implementation, leading to a conflict with the newer Responses API structure required by GPT-5.  The solution involves updating LangChain to the latest stable version and implementing the appropriate Pydantic model for structured output.", "final_category": "bug", "comments": [{"author": "onestardao", "created_at": "2025-08-11T04:22:58Z", "body_clean": "Thanks for the super clear repro. You’ve likely hit the classic “JSON/Structured Output vs text mode collision” : When [code] is used, LangChain sets an OpenAI [code] for JSON/schema. At the same time the wrapper is passing text mode parameters (e.g., [code] , sometimes [code] under the hood). The OpenAI Responses API treats those as mutually exclusive → you get a [code] because both “text” and “response\\ format” are present. Quick fixes (pick one): 1. Drop any text mode flags when using structured output. Concretely: remove [code] (and anything that forces [code] / [code] ) and keep [code] only. 2. If you must keep “verbosity”, don’t send it as a param—fold it into the prompt (system msg) or the Pydantic field descriptions. 3. Alternatively, switch to a pure Responses API path (no legacy Chat Completions params). In LangChain that means using the OpenAI client configured for Responses and letting [code] set the format—no extra text/verbosity knobs. If you want, I can share a tiny “problem map” snippet that shows the exact param set to avoid (and a one liner guard that prevents the clash). It’s MIT and copy pasteable—just say the word and I’ll post it."}, {"author": "asiff00", "created_at": "2025-08-12T11:19:46Z", "body_clean": "Does setting any verbosity (in either structured or non structured output) and the new reasoning effort parameter (minimal) work with the current version? @d gangz"}, {"author": "mdrxy", "created_at": "2025-08-12T15:57:46Z", "body_clean": "@d gangz @asiff00 releasing new [code] , let me know if it resolves"}, {"author": "d-gangz", "created_at": "2025-08-13T05:43:30Z", "body_clean": "@onestardao could you share more about option 3? Currently I've added the [code] to the ChatOpenAI argument, I guess that switches to Responses API path? @asiff00 reasoning seems to work as when I set it to high, there are the reasoning tokens and it takes a lot longer to generate the response. @mdrxy when I update, my langchain openai version is still 0.3.28. Will try again when the new version is up. Appreciate the fast responses!"}, {"author": "onestardao", "created_at": "2025-08-13T10:00:09Z", "body_clean": "@d gangz This falls under Problem Map 6 🔗 [link] We’ve already helped 80+ developers resolve this exact issue by using the WFGY “Mode Collision” guardrail — it pinpoints API parameter conflicts (like when verbosity and structured output collide) and suggests safe combinations automatically. Just grab TXTOS and ask the AI: “Apply WFGY’s Mode Collision formula to check if my current API parameters will conflict.” No need to manually inspect every field; it’ll mark the problem spots and propose a safe config. MIT licensed, so you can adapt it freely. And if anything’s unclear, feel free to ask — we’ll walk you through it."}, {"author": "asiff00", "created_at": "2025-08-13T10:19:24Z", "body_clean": "[@onestardao]( [link] could you share more about option 3? Currently I've added the [code] to the ChatOpenAI argument, I guess that switches to Responses API path? [@asiff00]( [link] reasoning seems to work as when I set it to high, there are the reasoning tokens and it takes a lot longer to generate the response. [@mdrxy]( [link] when I update, my langchain openai version is still 0.3.28. Will try again when the new version is up. Appreciate the fast responses! [link] Solved with version update."}, {"author": "mdrxy", "created_at": "2025-08-13T13:32:36Z", "body_clean": "@d gangz you should run [code] . Latest is 0.3.30"}, {"author": "d-gangz", "created_at": "2025-08-14T01:19:59Z", "body_clean": "@mdrxy thanks! hmm I've updated it to 0.3.30 but I still received the same valueError [code] Not sure if I need to tweak the ChatOpenAI arguments? [code]"}, {"author": "mdrxy", "created_at": "2025-08-14T02:34:52Z", "body_clean": "@d gangz can you provide a full code snippet? Each of these work on my end: [code] [code] [code]"}, {"author": "d-gangz", "created_at": "2025-08-14T09:40:23Z", "body_clean": "@mdrxy sure thing. Here is the full code. [code] here is the error I got [code] here's my langchain openai version [code]"}]}, {"ollama_summary": "This GitHub issue addresses a critical bug in the ` langchain` library where AzureChatOpenAI creates new client instances on each instantiation, leading to unexpected behavior. The core problem is a lack of proper caching for the `httpx` client, causing inconsistencies in client reuse across different AzureChatOpenAI instances. The fix involves updating the ` langchain` library to incorporate a caching mechanism, which has been successfully verified through unit tests and code quality checks.", "final_category": "bug", "comments": [{"author": "open-swe[bot]", "created_at": "2025-08-13T15:01:46Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"1f078566 e20b 649d bdd8 7c5e6f55390e\", \"threadId\": \"b76141d2 29b5 4588 97a1 37a20573710a\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Fix AzureChatOpenAI to reuse [link] clients instead of creating new ones on each instantiation Task 1: [code] Task 2: [code] Task 3: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "The issue lies in a LangChain class, `ChatDeepSeek`, incorrectly using the `ls_provider=\"openai\"` setting, which should be `\"deepseek\"`.  The code is a bug, not a usage issue, and attempts to resolve it by providing a minimal reproducible example.  The example code demonstrates the problem – the `ChatDeepSeek` class's method is overwriting a potentially important tracking mechanism for the OpenAI provider.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where the internal schema dereferencing logic for Pydantic models with nested classes loses the description field, causing issues with the schema conversion. This is a regression introduced in a recent update, and the provided example demonstrates the problem with a minimal, reproducible scenario.", "final_category": "bug", "comments": []}], "business_insights": ["Dependency updates are frequently the root cause of bugs, requiring rigorous testing and version control.", "Addressing bugs early in the development lifecycle reduces costs and improves stability.", "Understanding the specific context of each issue helps pinpoint the underlying cause.", "Maintaining consistent API implementations across libraries is crucial for reliable integration.", "Regression testing is essential to ensure new code doesn’t break existing functionality.", "Dependency updates are frequently the root cause of bugs, requiring rigorous testing and version control.", "Understanding the specific context of each issue helps pinpoint the underlying cause.", "Maintaining consistent API implementations across libraries is crucial for reliable integration.", "Regression testing is essential to ensure new code doesn’t break existing functionality.", "Addressing bugs early in the development lifecycle reduces costs and improves stability."], "technical_insights": ["LangChain's recent update has introduced a new ChatDeepSeek class with incorrect usage of ls_provider.", "The httpx client caching issue is a recurring problem impacting client reuse.", "The  langchain library bug with OpenAI provider usage requires immediate attention.", "Pydantic schema conversion bugs are a regression, impacting data integrity.", "The ls_provider setting in ChatDeepSeek is critical for schema management.", "LangChain's recent update has introduced a new ChatDeepSeek class with incorrect usage of ls_provider.", "The httpx client caching issue is a recurring problem impacting client reuse.", "The  langchain library bug with OpenAI provider usage requires immediate attention.", "Pydantic schema conversion bugs are a regression, impacting data integrity.", "The ls_provider setting in ChatDeepSeek is critical for schema management."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency updates are frequently the root cause of bugs, requiring rigorous testing and version control.\n2.  Addressing bugs early in the development lifecycle reduces costs and improves stability.\n3.  Understanding the specific context of each issue helps pinpoint the underlying cause.\n4.  Maintaining consistent API implementations across libraries is crucial for reliable integration.\n5.  Regression testing is essential to ensure new code doesn’t break existing functionality.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's recent update has introduced a new `ChatDeepSeek` class with incorrect usage of `ls_provider`.\n2.  The `httpx` client caching issue is a recurring problem impacting client reuse.\n3.  The ` langchain` library bug with OpenAI provider usage requires immediate attention.\n4.  Pydantic schema conversion bugs are a regression, impacting data integrity.\n5.  The `ls_provider` setting in `ChatDeepSeek` is critical for schema management.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Dependency updates are frequently the root cause of bugs, requiring rigorous testing and version control.\n2.  Understanding the specific context of each issue helps pinpoint the underlying cause.\n3.  Maintaining consistent API implementations across libraries is crucial for reliable integration.\n4.  Regression testing is essential to ensure new code doesn’t break existing functionality.\n5.  Addressing bugs early in the development lifecycle reduces costs and improves stability.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's recent update has introduced a new `ChatDeepSeek` class with incorrect usage of `ls_provider`.\n2.  The `httpx` client caching issue is a recurring problem impacting client reuse.\n3.  The ` langchain` library bug with OpenAI provider usage requires immediate attention.\n4.  Pydantic schema conversion bugs are a regression, impacting data integrity.\n5.  The `ls_provider` setting in `ChatDeepSeek` is critical for schema management.\n", "batch_number": 29, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports that the “model opus” is not found when using slash commands in LangChain. A minimal reproducible example has been provided, demonstrating the error – specifically, a 404 error indicating the model isn't available.  The problem appears to be a bug within the LangChain model itself, not a user-facing issue related to code.", "final_category": "bug", "comments": [{"author": "ArkVex", "created_at": "2025-08-19T13:31:20Z", "body_clean": "What is blablabla lol XD"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Perplexity Reasoning model with `structuredOutput` is causing an error with the `JsonOutputParser` due to the perplexity API including reasoning details in the output.  This issue was identified through a search and is a bug within the LangChain library, not a result of your code. A minimal reproducible example has been provided to demonstrate the problem and suggest a solution – porting the issue to the Python side.", "final_category": "bug", "comments": [{"author": "arpon-kapuria", "created_at": "2025-08-09T12:09:39Z", "body_clean": "I can take this issue."}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue addresses outdated documentation for the Confident AI callback feature.  It highlights that the current documentation is no longer actively maintained and requires updating to reflect the latest changes.  The core request is to migrate the documentation to the updated source link provided.", "final_category": "other", "comments": [{"author": "Jai-Dhiman", "created_at": "2025-08-07T21:08:57Z", "body_clean": "Hi! I'd like to work on updating this documentation. I've reviewed both the current LangChain docs and the new Confident AI integration guide. The changes needed are substantial: Key updates needed: Replace deprecated [code] with new [code] from [code] Update installation from [code] to [code] Replace [code] with [code] Update all code examples to use modern LangChain patterns ( [code] vs [code] ) Add new features: trace attributes (name, tags, metadata, thread id, user id) and online evaluations Some Questions: 1. Should I completely replace the content to match the new Confident AI docs structure, or preserve any existing sections? 2. The current docs show metrics like AnswerRelevancy should these be removed entirely or noted as deprecated? 3. Any specific formatting requirements for LangChain integration docs? I can have this updated within a few days. Thanks!"}]}, {"ollama_summary": "The LangChain library is experiencing a bug where the `invoke` promise fails to return an error immediately after a timeout, causing an inconsistent behavior. A minimal reproducible example has been provided, demonstrating this issue.  The bug appears to be a stability issue within the LangChain library itself, not a result of user code.", "final_category": "bug", "comments": []}, {"ollama_summary": "This GitHub issue addresses a bug in the LangChain `ChatOllama` library, specifically concerning the `gpt oss:20b` model integration. The issue reports an error when attempting to use this model within LangChain, leading to a `ResponseError` template. The developer has identified a discrepancy between the model's expected behavior and the integration process, suggesting a potential issue with the model's compatibility or configuration.  The developer has provided a minimal reproducible example to illustrate the problem and suggests a potential fix through updating LangChain or the integration package.", "final_category": "bug", "comments": [{"author": "lomohov", "created_at": "2025-08-06T12:39:21Z", "body_clean": "seems duplicate with [link]"}, {"author": "MElkady", "created_at": "2025-08-06T20:48:55Z", "body_clean": "I'm looking forward to having this issue fixed to try GPT OSS"}, {"author": "mdrxy", "created_at": "2025-08-06T21:11:18Z", "body_clean": "I'm unable to reproduce on my end. @maheshlokhande please ensure your Ollama client is up to date ( =0.11) as well as [code] (0.3.6). @MElkady you may also want to check. Code example: [code] [code]"}, {"author": "maheshlokhande", "created_at": "2025-08-07T05:09:28Z", "body_clean": "@mdrxy I tried the example you have provided and it's working. I think issue I am facing is because of pydantic classes I am using for structuring input to tools. If I don't use them, everything is working. I tried upgrading pydantic package to latest but it didn't help. Is this a known issue?"}, {"author": "twkaidan", "created_at": "2025-08-07T08:02:16Z", "body_clean": "I'm currently using Langchain for tool binding with [code] . However, Langchain structures tools like this: [code] This format differs from what OpenAI's [code] expects — in particular, note the nested structure under the [code] key, whereas the expected format (as shown in @mdrxy’s example) defines the tool schema at the root level. Using the correct format as in @mdrxy’s example resolves the issue. I am still looking for a solution with Langchain to generate the expected format. If you get there let me know :D"}, {"author": "mdrxy", "created_at": "2025-08-07T14:26:57Z", "body_clean": "@twkaidan forgive me as I haven't had time to dive deep into the new docs yet, but I'm seeing this: [\"If you are not using gpt oss directly but through an API or a provider like Ollama, you will not have to be concerned about this as your inference solution will handle the formatting\"]( [link] Does this not address the issue? @maheshlokhande are you running [code] ?"}, {"author": "mdrxy", "created_at": "2025-08-13T15:02:31Z", "body_clean": "LMK if this needs to be re opened but from my understanding this is resolved"}]}], "business_insights": ["Model opus issue is a fundamental bug impacting LangChain’s core functionality, requiring immediate attention.", "Documentation updates are critical for maintaining software stability and user experience.", "Model compatibility issues across different models are a recurring challenge.", "Stability issues within the LangChain library are a significant concern.", "Bug fixes are essential for enhancing user experience and reducing errors."], "technical_insights": ["LangChain model bug is a core stability issue requiring immediate resolution.", "Documentation update is a bug within the LangChain library, impacting core functionality.", "Model integration bug related to gpt oss:20b requires investigation and fix.", "Model compatibility issues across multiple models are a recurring problem.", "The bug is affecting the invoke promise, a key LangChain function."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model opus issue is a fundamental bug impacting LangChain’s core functionality, requiring immediate attention.\n2. Documentation updates are critical for maintaining software stability and user experience.\n3. Model compatibility issues across different models are a recurring challenge.\n4. Stability issues within the LangChain library are a significant concern.\n5. Bug fixes are essential for enhancing user experience and reducing errors.\n\nTECHNICAL INSIGHTS:\n1. LangChain model bug is a core stability issue requiring immediate resolution.\n2. Documentation update is a bug within the LangChain library, impacting core functionality.\n3. Model integration bug related to `gpt oss:20b` requires investigation and fix.\n4. Model compatibility issues across multiple models are a recurring problem.\n5. The bug is affecting the `invoke` promise, a key LangChain function.\n", "batch_number": 30, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue relates to a bug in LangChain that causes problems when calling the gpt-oss-120b tool on Azure AI Foundry. The bug specifically targets messages with a new format, leading to an error message indicating a \"Bad Request\" and a code 400 response.  The issue is currently resolved by updating LangChain, but a minimal reproducible example is provided for testing.", "final_category": "bug", "comments": [{"author": "lomohov", "created_at": "2025-08-06T07:45:08Z", "body_clean": "Same problem here, Harmony support should be implemented to both Langchain and Langgraph. Very relevant."}, {"author": "Meliodas-gpu", "created_at": "2025-08-06T09:04:51Z", "body_clean": "I need"}, {"author": "d-r-e", "created_at": "2025-08-06T18:02:04Z", "body_clean": "Yes."}, {"author": "msb418", "created_at": "2025-08-07T05:40:47Z", "body_clean": "Here’s what you can do to resolve the issue: ⸻ ✅ Diagnosis The error—and your GitHub issue—reveals that certain Azure hosted models (like gpt oss 120b, or phi 4 multimodel instruct) do not support tool calling, even with correct flags set (enable auto tool choice, tool call parser). The Azure error response clearly states: \"auto\" tool choice requires enable auto tool choice and tool call parser to be set — but even when set, the model rejects the call. ￼ This indicates tool calling is simply not supported on this model. ⸻ 🛠 Solution Options 1. Switch to a Supported Model Models like gpt 4o, or others hosted on Azure that support tool calling, work with enable auto tool choice. To avoid the error: • Confirm the model deployment supports function/tool calls. • If not, change to a compatible model (e.g. gpt 4o). • Re deploy your Azure model accordingly before calling. 2. Fallback to Manual Tool Calls If you must use gpt oss 120b, avoid using tool calling altogether: • Use manual chaining logic (e.g. call tools locally based on intent extraction from the LLM response). • Use tool choice=\"none\" so LangChain doesn’t attempt auto tool invocation. ￼ ￼ ￼ This avoids the 400 error and still enables prompt handling without tool integration. 📘 Sample Code Update from langchain openai import AzureChatOpenAI model = AzureChatOpenAI( azure endpoint=..., api key=..., deployment name=\"gpt 4o\", ensure using tool compatible model api version=..., model kwargs=model kwargs, include tool flags if using tool support ) llm = model.bind tools( tools=[...], tool choice=\"auto\", auto tool calling only works if model supports it ) If using gpt oss 120b: llm = model.bind tools( tools=[...], tool choice=\"none\", disables tool calling features ) 🧪 TL;DR • The error arises because gpt oss 120b does not support tool calling, regardless of flag settings. ￼ ￼ • Switch to tool compatible models (like gpt 4o) or disable tool calling if using unsupported models. • Update your configuration and test again with the right tool choice and model."}, {"author": "lomohov", "created_at": "2025-08-07T05:56:38Z", "body_clean": "That's clearly wrong. @msb418 For example with OpenAI's Agents sdk, this works well. [code] [code] Both models clearly support tool calling. [link] Harmony follows the structure of Responses API. It might be a good idea to implement Responses Api support and Harmony format now. As OpenAI is slowly migrating from completions to Responses anyway for quite some time now. It's also superset of completions in terms of functionality. Only audio is not yet supported. [link]"}, {"author": "tudoanh", "created_at": "2025-08-07T06:52:29Z", "body_clean": "Btw the langchain openai working fine with the GPT OSS 120B model from Groq, calling tools without trouble."}, {"author": "eksno", "created_at": "2025-08-07T12:36:51Z", "body_clean": "@msb418 has to be AI lmao here's a slimilar issue I raised on pydantic ai with some insight in the comments: [link]"}, {"author": "eksno", "created_at": "2025-08-07T12:38:37Z", "body_clean": "Main issue from my research is harmony is already supported... badly by the provider! Which means unless you intend to self host and call transformers directly the providers forced abstraction of harmony can't be bypassed."}, {"author": "casparb", "created_at": "2025-08-14T22:01:41Z", "body_clean": "Seems that Azure AI Foundry deployment of gpt oss currently rejects tool calls (tested myself and am getting new error [code] ). So this is an Azure capability gap rather than a LangChain bug. Hopefully Azure fixes their Harmony/Responses style tool use for gpt oss soon, but in the meantime, use an Azure model that supports tools (e.g., GPT 4o/4.1/5), or use gpt oss through a different provider (Groq/HF/Ollama). Closing for now."}, {"author": "msb418", "created_at": "2025-08-19T17:19:04Z", "body_clean": "Not AI"}, {"author": "sandipgiri576", "created_at": "2025-09-12T10:19:17Z", "body_clean": "@tudoanh @casparb Can you provide the GROQ version of the lang groaq code block for GPT OSS 20b (or 120 b) tool calling example? Unable to use the tool calling."}, {"author": "craigulliott", "created_at": "2025-10-01T19:48:54Z", "body_clean": "I am running into this issue too, and it seems to be from how [code] is getting transformed by langchain before posting the full json payload. The documentation and types support/suggest this: [code] But the actual JSON getting sent to the server looks like this: [code] I manually sent the same JSON payload with the corrected format for tool choice and it worked as expected: [code] Opened a new issue here: [ [link] Found the offending code here: [ [link]"}]}, {"ollama_summary": "The issue involves a security vulnerability in the `urllib3` dependency that needs to be addressed. Poetry is the recommended solution – update the dependency lock file to remove the version constraint, allowing the installation of the latest 2.5.0+ version of `urllib3`. This will resolve the vulnerability and ensure compatibility with LangChain’s Python requirements.", "final_category": "bug", "comments": [{"author": "open-swe[bot]", "created_at": "2025-08-05T21:03:29Z", "body_clean": "🟠 Plan Ready for Approval 🟠 I've generated a plan for this issue and it's ready for your review. Plan: Update urllib3 dependency to version 2.5.0+ to fix security vulnerability Task 1: [code] Task 2: [code] Task 3: [code] Please review the plan and let me know if you'd like me to proceed, make changes, or if you have any feedback. <open swe plan message 🟠 Plan Ready for Approval 🟠 I've generated a plan for this issue and it's ready for your review. Plan: Update urllib3 dependency to version 2.5.0+ to fix security vulnerability Task 1: [code] Task 2: [code] Task 3: [code] Please review the plan and let me know if you'd like me to proceed, make changes, or if you have any feedback. </open swe plan message"}]}, {"ollama_summary": "This issue reports a critical bug in the OpenAIAssistantRunnable library, specifically involving the `_get_response` function instead of the expected `_aget_response`. This change causes the application to malfunction, potentially leading to incorrect results or errors. The issue is currently not related to a specific version update and is not a matter of code modification, suggesting it’s a fundamental bug within the LangChain integration.", "final_category": "bug", "comments": []}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\nThe documentation for the package needs to be reorganized to better structure and improve readability. Currently, the `standard-tests` section is buried within the partner integrations list, making it difficult to find and understand.  The proposed solution is to add a dedicated section or move the content to a higher-level section within the API documentation.", "final_category": "other", "comments": []}, {"ollama_summary": "This issue asks for a standardized method to configure LLM parameters (like max_tokens, temp, top_p) before each invocation, rather than requiring a full reinitialization. Currently, the configuration is primarily handled through the `generate` function, which is a limitation.  The goal is to allow for dynamic parameter adjustments based on the specific task, potentially varying them across different contexts (e.g., summarization vs. response).", "final_category": "question", "comments": [{"author": "mdrxy", "created_at": "2025-09-10T15:25:50Z", "body_clean": "You should be able to pass args in during invocation to override the model level defaults"}]}], "business_insights": ["Consistent bug patterns across multiple issues indicate a systemic issue with the LangChain codebase, requiring a focused fix.", "Dependency management vulnerabilities are a recurring theme, highlighting the importance of rigorous testing and secure dependency updates.", "Documentation reorganization is critical for maintainability and usability, impacting developer productivity and understanding.", "Parameter configuration flexibility is essential for adaptability and efficient LLM usage across diverse tasks.", "Addressing these issues proactively will improve overall system stability and reliability."], "technical_insights": ["urllib3 vulnerability: Prioritize patching this to avoid security risks and compatibility issues with LangChain.", "LangChain update:  Ensure all LangChain users are updated to the latest stable version to mitigate known bugs.", "_get_response function change: Investigate the root cause of this change and revert to the original _aget_response function.", "OpenAIAssistantRunnable bug:  Develop a comprehensive test suite for this bug to ensure comprehensive coverage and prevent regressions.", "Documentation restructuring: Implement a modular architecture for API documentation, improving discoverability and understanding."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Consistent bug patterns across multiple issues indicate a systemic issue with the LangChain codebase, requiring a focused fix.\n2.  Dependency management vulnerabilities are a recurring theme, highlighting the importance of rigorous testing and secure dependency updates.\n3.  Documentation reorganization is critical for maintainability and usability, impacting developer productivity and understanding.\n4.  Parameter configuration flexibility is essential for adaptability and efficient LLM usage across diverse tasks.\n5.  Addressing these issues proactively will improve overall system stability and reliability.\n\nTECHNICAL INSIGHTS:\n1.  `urllib3` vulnerability: Prioritize patching this to avoid security risks and compatibility issues with LangChain.\n2.  LangChain update:  Ensure all LangChain users are updated to the latest stable version to mitigate known bugs.\n3.  `_get_response` function change: Investigate the root cause of this change and revert to the original `_aget_response` function.\n4.  OpenAIAssistantRunnable bug:  Develop a comprehensive test suite for this bug to ensure comprehensive coverage and prevent regressions.\n5.  Documentation restructuring: Implement a modular architecture for API documentation, improving discoverability and understanding.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 31, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue relates to a bug in LangChain where the function `retrieve_existing_index()` defaults to using the `neo4j` database when retrieving vector index information, regardless of the configured database. This can lead to inconsistencies and errors, particularly when data resides in different databases.", "final_category": "bug", "comments": [{"author": "siddarthreddygsr", "created_at": "2025-08-04T19:03:44Z", "body_clean": "I think this behavior is intentional by design and not a bug. Waiting for a maintainer to respond."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nPerplexity is currently missing citations when using structured responses, despite being a bug within the LangChain library. The issue stems from a lack of functionality to automatically include citations within the output of the perplexity model. A minimal reproducible example has been provided to demonstrate the problem and allow for testing.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-09-12T14:52:35Z", "body_clean": "You can access the citations by setting [include raw=True]( [link] when calling [code] . This gives you access to the underlying AIMessage and the parsed representation separately."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a discrepancy between the Langchain documentation and a specific notebook cell, where a tool is invoked but isn’t automatically triggered.  The issue requires clarification on the process for this tool invocation to ensure it functions as expected.  Currently, the documentation suggests the tool is invoked, but the specific mechanism isn’t clearly defined.", "final_category": "other", "comments": [{"author": "Tik1993", "created_at": "2025-08-13T21:59:04Z", "body_clean": "Hi @robertotup, can you explain more about your confusion? In your example, it returns a tool call, but it hasn't actually called the tool to perform the action."}]}, {"ollama_summary": "The code is attempting to use `pdfminer.layout.LTContainer` to load a PDF file, but the `ModuleNotFoundError: No module named 'pdfminer.layout'` indicates that the library is not installed or not properly configured. The code is attempting to load the PDF using `pdfminer.utils.open` and `pdfminer.layout.LTContainer`.  The error suggests a potential issue with the `pdfminer.layout` library not being available in the current Python environment.", "final_category": "bug", "comments": [{"author": "xxz7909", "created_at": "2025-08-01T03:09:05Z", "body_clean": "is python comment symbol. But it was recognized as one level headline in markdown"}, {"author": "xxz7909", "created_at": "2025-08-01T03:09:12Z", "body_clean": "\" \""}, {"author": "JulioPeixoto", "created_at": "2025-08-03T21:34:56Z", "body_clean": "try with [link]"}, {"author": "keenborder786", "created_at": "2025-08-03T23:28:50Z", "body_clean": "Do the following: [code]"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the \"Finer Control\" tagging example is failing to accurately reflect the sentiment restrictions outlined in the documentation. The example uses a specific code snippet that’s generating incorrect sentiment analysis results.  The issue proposes either adding more acceptable sentiments to the list or finding a Spanish sentence representing a happy, neutral, or sad sentiment to match the example.", "final_category": "other", "comments": []}], "business_insights": ["Consistent database defaults can hinder data integrity across different systems.", "Intentional design choices might influence development decisions.", "Maintaining consistent behavior across multiple databases is challenging.", "Addressing this will improve data consistency.", "Prioritize database consistency across all systems."], "technical_insights": ["LangChain’s default database selection impacts data retrieval accuracy.", "The neo4j database default is a potential source of inconsistency.", "The lack of citation handling necessitates improved documentation.", "The citation issue impacts perplexity model output.", "Automated citation inclusion requires clear mechanism definition."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent database defaults can hinder data integrity across different systems.\n2. Intentional design choices might influence development decisions.\n3. Maintaining consistent behavior across multiple databases is challenging.\n4. Addressing this will improve data consistency.\n5. Prioritize database consistency across all systems.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s default database selection impacts data retrieval accuracy.\n2. The `neo4j` database default is a potential source of inconsistency.\n3. The lack of citation handling necessitates improved documentation.\n4. The citation issue impacts perplexity model output.\n5. Automated citation inclusion requires clear mechanism definition.\n\n", "batch_number": 32, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The error message indicates a certificate-related issue when using the `langchain` library with the Azure OpenAI service. Specifically, the `SSL: CERTIFICATE VERIFY FAILED` error suggests that the Azure OpenAI service is failing to verify the certificate presented by your application. This is a common problem when dealing with private certificates, and it can be caused by several factors.\n\nHere’s a breakdown of potential causes and solutions:\n\n**1. Incorrect Certificate:**\n\n* **Problem:** The certificate you're providing to the Azure OpenAI service might be invalid, expired, or not properly configured.\n* **Solution:**\n    * **Verify the Certificate:** Double-check that the certificate you're using is the correct one and that it’s valid.  Ensure it’s issued to your specific application or environment.\n    * **Certificate Chain:**  The Azure OpenAI service requires a chain of certificates to verify the identity of the application. Make sure the certificate chain is complete and valid.\n\n**2. Incorrectly Configured Azure OpenAI Endpoint:**\n\n* **Problem:** The Azure OpenAI endpoint configuration might be incorrect, leading to a mismatch between the certificate and the endpoint.\n* **Solution:**\n    * **Endpoint Configuration:** Double-check the Azure OpenAI endpoint configuration. Ensure it's set up correctly, including the correct certificate and key.\n    * **Endpoint Name:** Verify the endpoint name is correct.\n\n**3. Network Issues:**\n\n* **Problem:** There might be network connectivity problems between your application and the Azure OpenAI service.\n* **Solution:**\n    * **Firewall:** Check if any firewalls are blocking communication between your application and the Azure OpenAI endpoint.\n    * **DNS Resolution:** Ensure DNS resolution is working correctly.\n\n**4. TLS/SSL Configuration:**\n\n* **Problem:**  The application might not be configured to use TLS/SSL for communication with the Azure OpenAI service.\n* **Solution:**\n    * **Verify TLS/SSL:** Confirm that your application is configured to use TLS/SSL for communication.  This is usually handled automatically by the library, but it's worth checking.\n\n**5.  `langchain` Version Compatibility:**\n\n* **Problem:**  An outdated version of `langchain` might have compatibility issues with the Azure OpenAI service.\n* **Solution:**\n    * **Update `langchain`:**  Update to the latest version of `langchain", "final_category": "bug", "comments": [{"author": "JulioPeixoto", "created_at": "2025-08-03T21:44:05Z", "body_clean": "The failure happens at TLS bcs your sync call works because it uses [link] with your corporate CA, but ainvoke uses an AsyncClient that doesn’t inherit that context (common with MITM proxies). try: [code] also, you can set SSL CERT FILE to your CA. Also, use llm.invoke / await llm.ainvoke and try it tho"}, {"author": "saiyambharara", "created_at": "2025-08-04T04:19:48Z", "body_clean": "Additionally, set the [link] argument instead of [link] for async invocation"}, {"author": "mdrxy", "created_at": "2025-09-10T15:23:35Z", "body_clean": "Happy to re open if changes needed on our end"}]}, {"ollama_summary": "The LangChain project is experiencing a bug where the `TextSplitter` class doesn't inherit from `TextSplitter` and cannot be used with the ParentDocumentRetriever. This issue was first reported with a similar problem in 13510, but this is a runtime issue rather than a code-level problem, and there’s no straightforward workaround currently. A minimal reproducible example is provided, demonstrating the error.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue describes the removal of the `sentence-transformers` dependency in the `text-splitters` repository. The core problem is that the code relies on this library, and the refactoring involves completely replacing it with the `transformers` library, effectively removing the dependency. The refactoring maintains backward compatibility while improving the code’s structure, API, and documentation.  The issue details the steps taken to achieve this, including updating the `pyproject.toml` files, testing, and linting to ensure the code remains functional and adheres to the original design.", "final_category": "other", "comments": [{"author": "open-swe[bot]", "created_at": "2025-07-31T00:01:55Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"1f06da19 2141 64e6 a0ce 602794d219a3\", \"threadId\": \"359eda20 a8a7 4bdc ad07 4cf5bf11ffbd\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Remove sentence transformers dependency from LangChain Task 1: [code] Task 2: [code] Task 3: [code] Task 4: [code] Task 5: [code] Task 6: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "The issue reports a performance bottleneck in LangChain's file editing capabilities, specifically when using the “Search and replace” feature. The developer has identified a bug in the core implementation, and has provided a minimal reproducible example to demonstrate the problem. The developer is exploring building a similar edit file tool and is open to contributing a pull request.", "final_category": "bug", "comments": [{"author": "divyanshudg-git", "created_at": "2025-07-31T09:21:20Z", "body_clean": "I'd like to work on this—assigning myself."}, {"author": "bhaktatejas922", "created_at": "2025-08-11T19:51:15Z", "body_clean": "@divyanshudg git you did not implement this in your pr"}]}, {"ollama_summary": "This issue focuses on a bug in LangChain's `astream_events` filter output that prevents the correct removal of the tool invocation output.  The problem is that the filter isn’t working as expected, and attempts to fix it by updating the LangChain version haven’t resolved the issue.  The solution involves providing a minimal reproducible example demonstrating the correct filtering process.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-07-30T22:10:58Z", "body_clean": "Please re open with a self contained, minimal, reproducible example that a maintainer can copy and run AS IS."}]}], "business_insights": ["Certificate validation failures are a recurring issue, indicating potential security vulnerabilities or misconfigurations.", "langchain version conflicts can cause runtime errors, suggesting a potential instability in the library's compatibility.", "TLS/SSL configuration problems can impact application functionality, highlighting the importance of proper certificate management.", "Dependency management issues (like the TextSplitter replacement) can introduce unexpected regressions and require careful refactoring.", "The astream_events filter issue highlights a potential bottleneck in the LangChain code, requiring optimization and debugging."], "technical_insights": ["Azure OpenAI certificate verification failures are frequently linked to incorrect certificate configurations or missing chain of certificates.", "Incorrect Azure OpenAI endpoint configuration is a common cause of the SSL: CERTIFICATE VERIFY FAILED error.", "Network connectivity problems between the application and the Azure OpenAI service are a potential cause of TLS/SSL issues.", "TLS/SSL configuration is crucial for secure communication; verifying and correctly configuring it is vital.", "Outdated langchain versions can introduce compatibility issues with the Azure OpenAI service, requiring updates."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Certificate validation failures are a recurring issue, indicating potential security vulnerabilities or misconfigurations.\n2.  `langchain` version conflicts can cause runtime errors, suggesting a potential instability in the library's compatibility.\n3.  TLS/SSL configuration problems can impact application functionality, highlighting the importance of proper certificate management.\n4.  Dependency management issues (like the `TextSplitter` replacement) can introduce unexpected regressions and require careful refactoring.\n5.  The `astream_events` filter issue highlights a potential bottleneck in the LangChain code, requiring optimization and debugging.\n\nTECHNICAL INSIGHTS:\n1.  Azure OpenAI certificate verification failures are frequently linked to incorrect certificate configurations or missing chain of certificates.\n2.  Incorrect Azure OpenAI endpoint configuration is a common cause of the `SSL: CERTIFICATE VERIFY FAILED` error.\n3.  Network connectivity problems between the application and the Azure OpenAI service are a potential cause of TLS/SSL issues.\n4.  TLS/SSL configuration is crucial for secure communication; verifying and correctly configuring it is vital.\n5.  Outdated `langchain` versions can introduce compatibility issues with the Azure OpenAI service, requiring updates.\n", "batch_number": 33, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain's `_configure_hooks` variable that causes it to accumulate with each call to `get_usage_metadata_callback`. This accumulation leads to a growing global list, potentially causing memory leaks, performance degradation, and unexpected behavior, especially with frequently used context managers.  The code adds a tuple to the list, and the bug is not resolved by updating LangChain.  Potential solutions involve restricting usage to evaluation scenarios, making the variable global, or implementing a mechanism to manage the list's growth.", "final_category": "bug", "comments": [{"author": "Miguel-Andrade-Cruz", "created_at": "2025-07-30T22:22:54Z", "body_clean": "@eyurtsev I was looking for making a PR on this issue, but I'm not sure on what is the best approach. It will be my second contribution ever. Do you have any advice?"}]}, {"ollama_summary": "The Langsmith frontend displays 55 tracing projects but only shows 5 in the tracing table. A GitHub issue report indicates a mismatch between the sidebar project count (55) and the tracing project table display (5). The issue stems from the LangChain repository containing only client-side integration code, and the discrepancy is likely caused by a problem within the LangSmith backend's `get current workspace stats()` endpoint, which is returning more data than expected. The issue requires a detailed investigation into the backend services and data flow to resolve the discrepancy.", "final_category": "bug", "comments": [{"author": "open-swe[bot]", "created_at": "2025-07-28T23:14:00Z", "body_clean": "🟠 Plan Ready for Approval 🟠 I've generated a plan for this issue and it's ready for your review. Plan: Investigate LangSmith workspace stats mismatch issue repository analysis and recommendations Task 1: [code] Task 2: [code] Task 3: [code] Please review the plan and let me know if you'd like me to proceed, make changes, or if you have any feedback. <open swe plan message ✅ Plan Accepted ✅ The proposed plan was accepted. Plan: Investigate LangSmith workspace stats mismatch issue repository analysis and recommendations Task 1: [code] Task 2: [code] Task 3: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "The LangSmith frontend is displaying 55 tracing projects but only 5 in the tracing table, seemingly due to a discrepancy in an API endpoint returning incorrect data. This issue requires investigation into the LangSmith backend codebase, specifically the `get current workspace stats()` endpoint, to identify the root cause of the data mismatch and ensure accurate project counts.", "final_category": "bug", "comments": [{"author": "open-swe[bot]", "created_at": "2025-07-28T22:22:57Z", "body_clean": "🟠 Plan Ready for Approval 🟠 I've generated a plan for this issue and it's ready for your review. Plan: Investigate LangSmith workspace stats API mismatch between sidebar count and tracing table Task 1: [code] Task 2: [code] Task 3: [code] Please review the plan and let me know if you'd like me to proceed, make changes, or if you have any feedback. <open swe plan message ✅ Plan Accepted ✅ The proposed plan was accepted. Plan: Investigate LangSmith workspace stats API mismatch between sidebar count and tracing table Task 1: [code] Task 2: [code] Task 3: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue “aadd_texts() got multiple values for keyword argument 'ids'\" causes a Python crash when attempting to add documents to a Qdrant Vector Store, specifically due to the code inadvertently passing multiple `ids` values as keyword arguments. A minimal reproducible example has been provided to demonstrate the problem.  The fix involves modifying the code to handle the `ids` argument correctly within the `if` statement.", "final_category": "bug", "comments": [{"author": "golamhisham", "created_at": "2025-07-28T19:58:48Z", "body_clean": "Hi! I’d love to take on this issue and submit a fix. Let me know if it’s still available!"}, {"author": "keenborder786", "created_at": "2025-07-29T01:08:37Z", "body_clean": "One suggestion is to use the [code] from [code] , it will soon have async support as well: 32196 as you recommended earlier, so why are you using the deprecated class."}, {"author": "keenborder786", "created_at": "2025-07-29T01:09:59Z", "body_clean": "Also are you sure [code] is a type of [code] in the above example."}]}, {"ollama_summary": "This issue is a regression in LangChain's indexing API, specifically impacting the `num_skipped` count for documents within batches. It causes incorrect statistics, leading to misinterpretations of indexing operations and potentially confusing monitoring. The bug is present across multiple LangChain versions (prior to 0.3.63 and current versions), and the root cause is a flawed implementation that doesn't properly track document removal during batch deduplication.", "final_category": "bug", "comments": [{"author": "alex-feel", "created_at": "2025-07-28T08:24:23Z", "body_clean": "I'll propose a fix soon."}]}], "business_insights": ["Correctly sized data sets, especially when dealing with complex data, require careful consideration of potential memory usage.", "Inconsistent data across different API calls can lead to subtle errors and performance issues.", "The bug’s impact is likely to be more noticeable with higher-volume data processing.", "Addressing the bug’s root cause might involve optimizing data handling and caching strategies.", "Thorough testing across different environments is crucial to ensure stability."], "technical_insights": ["LangChain's _configure_hooks is a critical variable; its accumulation needs monitoring.", "The LangSmith backend's get current workspace stats() endpoint’s data return is a potential bottleneck.", "The discrepancy in the sidebar project count is a significant issue affecting the frontend.", "The get_usage_metadata_callback bug is a core issue affecting the get_usage_metadata_callback functionality.", "The ids keyword argument handling in the LangSmith code requires meticulous review."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correctly sized data sets, especially when dealing with complex data, require careful consideration of potential memory usage.\n2. Inconsistent data across different API calls can lead to subtle errors and performance issues.\n3. The bug’s impact is likely to be more noticeable with higher-volume data processing.\n4. Addressing the bug’s root cause might involve optimizing data handling and caching strategies.\n5. Thorough testing across different environments is crucial to ensure stability.\n\nTECHNICAL INSIGHTS:\n1. LangChain's `_configure_hooks` is a critical variable; its accumulation needs monitoring.\n2. The LangSmith backend's `get current workspace stats()` endpoint’s data return is a potential bottleneck.\n3. The discrepancy in the sidebar project count is a significant issue affecting the frontend.\n4. The `get_usage_metadata_callback` bug is a core issue affecting the `get_usage_metadata_callback` functionality.\n5. The `ids` keyword argument handling in the LangSmith code requires meticulous review.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 34, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\n**Problem:** The LangChain documentation for Cohere (version 0.4.4) is displaying an empty page in the left-hand sidebar of the API reference, despite it being present in the standard documentation.\n\n**Key Details:** This issue is being addressed by a LangChain maintainer, and the problem seems to be a rendering issue specifically related to the Cohere integration.\n\n**Proposed Solution:** The maintainer is requesting a fix to ensure the Cohere integration is correctly rendered within the API documentation.", "final_category": "other", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where the Snowflake component within the LangChain Snowflake documentation sidebar is displaying an empty page, preventing users from accessing the component’s content. This appears to be a bug related to the component’s rendering logic, specifically in version 0.1.3.  The maintainer is requesting a fix to ensure the component displays correctly.", "final_category": "other", "comments": [{"author": "Adithya1617", "created_at": "2025-09-01T11:24:11Z", "body_clean": "hello @mdrxy , could you please guide me and give me an overview of how langchain would integrate with snowflake .I would then make the reuired changes and make a pr."}]}, {"ollama_summary": "Here’s a summary of the GitHub issue:\n\nThe issue reports that the Weaviate documentation for LangChain’s Weaviate integration (specifically the left-hand sidebar) displays an empty page, preventing users from accessing the relevant API documentation. This is a critical issue impacting the usability of the LangChain Weaviate integration.  The issue is being addressed by the maintainer to resolve the content display problem.", "final_category": "other", "comments": []}, {"ollama_summary": "This issue is related to a critical bug in the Chroma Graph library that causes errors when attempting to invoke the database using the `uv` integration. The code attempts to install the `chromadb` package, but the installation fails due to an incompatibility with the LangChain version.  The issue is currently unresolved and requires a specific version of LangChain to be updated to resolve.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-07-26T23:38:26Z", "body_clean": "Just run [code]"}, {"author": "SCantergiani", "created_at": "2025-07-27T16:21:04Z", "body_clean": "Just run [code] Yes, I've tried that already. I had no issues when doing the default RAG example with chromadb, but it seems to happen only with the graph module."}, {"author": "SpicyChicken6", "created_at": "2025-07-28T21:09:24Z", "body_clean": "I think it is related to changes in chroma v1.0.0 [link]"}, {"author": "siddarthreddygsr", "created_at": "2025-08-01T19:10:55Z", "body_clean": "You need to open a PR here [graph rag/issues]( [link] . [code] isn't a langchain maintained project. The code needs to be updated for latest chromadb version or you need to install a version of chromadb older than 1.0.0"}, {"author": "SCantergiani", "created_at": "2025-08-01T19:41:30Z", "body_clean": "Oh ok. Thanks @siddarthreddygsr"}]}, {"ollama_summary": "This issue stems from a bug in LangChain-OpenAI that causes a `TypeError` when using the vLLM OpenAI-compatible API. Specifically, the code attempts to parse a response from the RunPod serverless endpoint, which results in the `null value for [code]` error. The bug is present in the latest stable version of LangChain, and attempts to resolve it by updating the version have been unsuccessful. The issue is reproducible by deploying a vLLM model via RunPod’s serverless API with the OpenAI compatible mode, and the code attempts to invoke the API with a specific format.", "final_category": "bug", "comments": [{"author": "AkibDa", "created_at": "2025-09-26T05:01:11Z", "body_clean": "The Root Cause: A Parsing Mismatch The error [code] originates from a specific check inside the [code] library. Here's the likely sequence of events: Your [code] call correctly sends the request to the RunPod API endpoint. The RunPod endpoint processes the request and sends back a valid JSON response containing the [code] list, as you've proven. The underlying [code] client within LangChain receives this response. The [code] wrapper then takes this response object and attempts to parse it into its internal [code] format in a method called [code] . This is where the failure occurs. The parsing logic in LangChain is likely making a rigid assumption about the structure or type of the response object returned by the [code] client. For some reason, its method of extracting the [code] attribute fails and returns [code] , even though the data is present. This can happen if the response object from an OpenAI compatible endpoint isn't identical in type and structure to the one from the official OpenAI API, causing the wrapper's parsing to fail while the more resilient, native [code] library handles it correctly."}, {"author": "AkibDa", "created_at": "2025-09-26T05:02:23Z", "body_clean": "Workaround: Bypass the Faulty Parsing Since the native [code] library works perfectly, the most reliable workaround is to use it directly for the API call and then manually construct the LangChain [code] object. This gives you the benefit of a successful API call while still integrating the result into a LangChain workflow. Here is the code combining your working [code] call with LangChain's message structure: [code] This approach gives you a robust solution by using the library that works ( [code] ) while formatting the output for the library you want to use ( [code] )."}]}], "business_insights": ["Addressing rendering issues in the API reference is crucial for user experience and usability.", "Maintaining consistent documentation across different integrations is essential for developer trust and adoption.", "Prioritizing bug fixes for critical integrations like Cohere and Snowflake directly impacts developer workflows.", "Resolving rendering issues promptly prevents potential user frustration and adoption of the LangChain ecosystem.", "Ensuring consistent integration across all components improves the overall quality of the LangChain library."], "technical_insights": ["LangChain maintainer is focused on the Cohere integration – a rendering problem.", "Snowflake integration bug involves component rendering logic – version 0.1.3.", "Weaviate documentation displaying empty pages – impacting component accessibility.", "Chroma Graph library bug – installation failure due to incompatible version.", "VLLM integration bug – TypeError when invoking RunPod endpoint."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing rendering issues in the API reference is crucial for user experience and usability.\n2. Maintaining consistent documentation across different integrations is essential for developer trust and adoption.\n3. Prioritizing bug fixes for critical integrations like Cohere and Snowflake directly impacts developer workflows.\n4. Resolving rendering issues promptly prevents potential user frustration and adoption of the LangChain ecosystem.\n5. Ensuring consistent integration across all components improves the overall quality of the LangChain library.\n\nTECHNICAL INSIGHTS:\n1. LangChain maintainer is focused on the Cohere integration – a rendering problem.\n2. Snowflake integration bug involves component rendering logic – version 0.1.3.\n3. Weaviate documentation displaying empty pages – impacting component accessibility.\n4. Chroma Graph library bug – installation failure due to incompatible version.\n5. VLLM integration bug – `TypeError` when invoking RunPod endpoint.\n", "batch_number": 35, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `convert_to_openai_tool` function is incorrectly handling nested schemas in Pydantic, leading to unexpected results. Currently, the issue involves a workaround of calling a specific function on schema elements, but this doesn’t fully resolve the problem.  The core issue is a bug where the function doesn’t correctly interpret nested schemas within Pydantic data structures.", "final_category": "bug", "comments": [{"author": "Yash-Tobre", "created_at": "2025-07-26T01:24:01Z", "body_clean": "Hi! I'm interested in contributing and have started looking into this issue. I will be reproducing the $ref behavior locally and understand it's related to how Field(...) causes Pydantic to emit $defs and references in the schema. My plan is to flatten those references in convert to openai tool so the output is fully compatible with OpenAI's tool format. Let me know if anyone else is already working on this; otherwise, I’d love to take it up."}, {"author": "Yash-Tobre", "created_at": "2025-07-26T01:53:22Z", "body_clean": "Quick update: I tried reproducing the issue locally using the same code snippet with [code] on the nested [code] model. However, I wasn't able to observe the [code] or [code] behavior mentioned in the issue. The tool schema output was fully flattened and compatible with OpenAI's expected format in my environment. My guess is that the bug might have been resolved in a recent update, or it may depend on the specific [code] version being used. Could you confirm which versions of [code] and [code] you were using when this occurred? Happy to dig further once I have that info!"}, {"author": "ccurme", "created_at": "2025-07-28T17:28:21Z", "body_clean": "Thanks @Yash Tobre, I believe this was fixed in langchain core 0.3.72."}]}, {"ollama_summary": "The issue is a bug where the `@tool` function fails to correctly handle a dictionary input, causing an agent to fail during tool invocation. This is a problem within LangChain itself, not a coding issue in the user’s code. A minimal reproducible example demonstrates the failure with a specific configuration, and the bug is consistent across different tools and versions.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-07-25T13:50:08Z", "body_clean": "Hello, it may be the case that models struggle with unspecified [code] properties in tool schemas. If there is any expected structure, you might try typing it explicitly: [code] [code] You can debug by inspecting the underlying json schema as well: [code]"}]}, {"ollama_summary": "Okay, let's analyze this situation and figure out what's going on.\n\n**The Problem: Slow Hugging Face Endpoint Response**\n\nYou're experiencing a significant delay in getting a response from a Hugging Face endpoint. The `max new tokens` limit is being hit very quickly, and the output keeps growing. This suggests a potential issue with the endpoint's processing or caching.\n\n**Possible Causes & Troubleshooting Steps**\n\nHere’s a breakdown of potential causes and what you can try:\n\n1. **Endpoint Overload:** Hugging Face endpoints are often heavily utilized.  The endpoint might be struggling to handle the request volume.\n\n2. **Caching Issues:**  Hugging Face caches responses.  If the endpoint is caching a previous response, it might be serving an older version.\n\n3. **Network Issues:** Transient network problems could be causing delays.\n\n4. **Rate Limiting:**  The endpoint might be implementing rate limiting to prevent abuse.\n\n5. **Long-Running Requests:**  Your request might be too long, exceeding the endpoint's limits.\n\n6. **Incorrect Parameters:**  You might be using incorrect parameters in your request.\n\n**Here's a series of steps you can take to investigate and potentially resolve the issue:**\n\n1. **Check Endpoint Status:**\n   * Go to the Hugging Face Hub page for the specific endpoint you're using. Look for any reported issues or status updates.\n\n2. **Reduce Request Size:**\n   * **Simplify your prompt:** Try a shorter, simpler prompt.\n   * **Reduce the length of the input:** If the prompt is long, try shortening it.\n\n3. **Increase Timeout:**\n   * **Increase the `timeout` parameter in your request:**  This gives the endpoint more time to process your request. Start with a value like 60-120 seconds.\n\n4. **Retry with Exponential Backoff:**\n   * **Implement a retry mechanism:**  Instead of immediately failing, use a retry strategy with exponential backoff.  This means that you wait a short time, then retry after a delay, and so on.\n\n5. **Check for Rate Limits:**\n   * **Review the endpoint's rate limits:**  The endpoint might have limits on the number of requests you can make in a given time.  Consult the documentation for the specific endpoint.\n\n6. **Use a", "final_category": "bug", "comments": [{"author": "azibek", "created_at": "2025-07-29T04:22:09Z", "body_clean": "Seems like the params defined in [code] are not passed on to [code] method. Explicitly adding [code] to [code] does limit the output tokens. [code] I can take a deeper dive and do a proper fix."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `StructuredOutputParser` is failing to parse JSON output correctly, specifically due to missing opening and closing triple quotes.  The issue is a bug within the LangChain library itself, not a result of your code.  A minimal reproducible example has been provided to demonstrate the problem and allow for easy testing.", "final_category": "bug", "comments": [{"author": "Yash-Tobre", "created_at": "2025-07-24T18:38:18Z", "body_clean": "Hi, I am Yash Tobre, a data science professional. I would love to take on this bug, and work on it! I will update you soon"}, {"author": "Yash-Tobre", "created_at": "2025-07-25T01:47:53Z", "body_clean": "I have added a check, and I agree with you. I was debating whether I should have a Fallback output or not, but as of now just added a check. It should be done soon. Thank you for pointing it out!"}]}, {"ollama_summary": "This issue stems from a bug in the LangChain library where the \"default\" field value for JSON Schema is missing, causing issues with data parsing and potentially leading to unexpected errors. The code being tested is a minimal reproducible example that demonstrates this problem, and the issue is being addressed by a fix in a later stable release.", "final_category": "bug", "comments": [{"author": "injeniero", "created_at": "2025-07-24T16:38:06Z", "body_clean": "This maybe related to [link] and [link]"}, {"author": "injeniero", "created_at": "2025-07-24T16:38:35Z", "body_clean": "cc @jmaillefaud"}, {"author": "hugehoo", "created_at": "2025-08-09T16:35:58Z", "body_clean": "@injeniero hi, i would like to fix this issue. do you mind if i make PR ?"}, {"author": "eyurtsev", "created_at": "2025-09-12T16:51:12Z", "body_clean": "Should be resolved on master, will be available in next release"}]}], "business_insights": ["Focus on consistent error patterns across different scenarios.", "Identify potential root causes of bugs early in the development lifecycle.", "Prioritize bug fixes based on their impact and frequency.", "Monitor bug resolution progress to ensure effective mitigation.", "Establish a robust testing strategy to prevent future regressions."], "technical_insights": ["The StructuredOutputParser’s failure is a widespread issue impacting multiple LangChain models.", "The bug is specific to the JSON schema parsing logic, not a coding issue.", "The bug is reproducible with minimal changes, indicating a potential issue with the library’s internal implementation.", "The bug is consistent across different tools and versions, suggesting a fundamental problem.", "The lack of a default value for the default field in JSON Schema is a key source of the issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on consistent error patterns across different scenarios.\n2.  Identify potential root causes of bugs early in the development lifecycle.\n3.  Prioritize bug fixes based on their impact and frequency.\n4.  Monitor bug resolution progress to ensure effective mitigation.\n5.  Establish a robust testing strategy to prevent future regressions.\n\nTECHNICAL INSIGHTS:\n1.  The `StructuredOutputParser`’s failure is a widespread issue impacting multiple LangChain models.\n2.  The bug is specific to the JSON schema parsing logic, not a coding issue.\n3.  The bug is reproducible with minimal changes, indicating a potential issue with the library’s internal implementation.\n4.  The bug is consistent across different tools and versions, suggesting a fundamental problem.\n5.  The lack of a default value for the `default` field in JSON Schema is a key source of the issue.\n\n", "batch_number": 36, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This GitHub issue reports a bug in LangChain’s tool invocation that incorrectly recognizes Pydantic v2 schema within AIMessage.tool calls. This results in the arg schema being arbitrarily generated, causing errors when the tool attempts to interact with the model. The issue appears to be a fundamental bug within LangChain’s model binding mechanism, and while a minimal reproducible example has been provided, it doesn’t offer a solution beyond a straightforward fix within the library itself.", "final_category": "bug", "comments": [{"author": "diego-coder", "created_at": "2025-07-25T06:11:53Z", "body_clean": "Interested in this, I will check it out and try to reproduce it. Edit: I was able to reproduce it. It looks like the generated tool schema creates JSON [code] references for nested models, but the actual definitions aren’t included in a [code] block. As a result, the LLM gets an incomplete schema and can’t generate the correct argument structure. Given that, I would like to start working on a fix if no one else is working on it. Here's the output: <details <summary Click to view full test output</summary text Generated Tool Schema (for LLM) [ { \"type\": \"function\", \"function\": { \"name\": \"query datasoil data tool\", \"description\": \"Queries the DataSoil database with a complex payload.\", \"parameters\": { \"properties\": { \"payload\": { \"properties\": { \"apiCode\": { \"default\": \"\", \"type\": \"string\" }, \"requestId\": { \"default\": \"\", \"type\": \"string\" }, \"applicationCode\": { \"default\": \"\", \"type\": \"string\" }, \"applicationToken\": { \"default\": \"\", \"type\": \"string\" }, \"debug\": { \"default\": false, \"type\": \"boolean\" }, \"timeShift\": { \"$ref\": \" /$defs/DataSoilDashboardQueryPayloadTimeShift\", \"description\": \"Time comparison analysis config.\" }, \"dynamicQueryParam\": { \"properties\": { \"queryType\": { \"const\": \"DETAIL TABLE\", \"description\": \"This is the description about queryType...\", \"type\": \"string\" }, \"interval\": { \"description\": \"The time granularity for time based grouping analysis.\", \"enum\": [ \"BY ONE MINUTE\", \"BY FIVE MINUTE\", \"BY HOUR\", \"BY DAY\", \"BY WEEK\", \"BY MONTH\", \"SUM\" ], \"type\": \"string\" }, \"resultField\": { \"default\": [], \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, \"where\": { \"$ref\": \" /$defs/DataSoilDashboardQueryPayloadQueryParamWhere\", \"description\": \"Filtering condition for dimensions.\" }, \"groupBy\": { \"description\": \"A list of dimensions grouping analysis info...\", \"items\": { \"properties\": { \"field\": { \"description\": \"The dimension CODE in the selected dimension list for dimension grouping analysis.\", \"type\": \"string\" }, \"extendFields\": { \"default\": [], \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, \"orderBy\": { \"anyOf\": [ { \"properties\": { \"field\": { \"description\": \"The metric CODE in the selected metric list that requires metric sorting.\", \"title\": \"Field\", \"type\": \"string\" }, \"direction\": { \"description\": \"Sorting direction for specified metric.\", \"enum\": [ \"ASC\", \"DESC\" ], \"title\": \"Direction\", \"type\": \"string\" }, \"shift\": { \"default\": 0, \"title\": \"Shift\", \"type\": \"integer\" }, \"limit\": { \"default\": 50, \"description\": \"The number of rows to return...\", \"title\": \"Limit\", \"type\": \"integer\" } }, \"required\": [ \"field\", \"direction\" ], \"title\": \"DataSoilDashboardQueryPayloadQueryParamOrderBy\", \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Sorting config for query results...\" } }, \"required\": [ \"field\" ], \"type\": \"object\" }, \"type\": \"array\" }, \"orderBy\": { \"$ref\": \" /$defs/DataSoilDashboardQueryPayloadQueryParamOrderBy\", \"description\": \"Sorting config for query results...\" }, \"heavyQuery\": { \"default\": false, \"type\": \"boolean\" } }, \"required\": [ \"queryType\", \"interval\", \"where\", \"groupBy\", \"orderBy\" ], \"type\": \"object\" }, \"forceFlush\": { \"default\": false, \"type\": \"boolean\" } }, \"required\": [ \"dynamicQueryParam\" ], \"type\": \"object\" } }, \"required\": [ \"payload\" ], \"type\": \"object\" } } } ] Invoking LLM with prompt: 'Get the detail table for sales data from 2025 07 01 00:00:00 to 2025 07 08 00:00:00, grouped by city, and ordered by total revenue descending.' LLM Response content='' additional kwargs={'tool calls': [{'id': 'call UoT9CyYGE6aDIY6vkvu4QqSn', 'function': {'arguments': '{\"payload\":{\"dynamicQueryParam\":{\"queryType\":\"DETAIL\",\"interval\":\"BY DAY\",\"where\":{\"and\":[{\"field\":\"date\",\"gte\":\"2025 07 01 00:00:00\"},{\"field\":\"date\",\"lt\":\"2025 07 08 00:00:00\"}]},\"groupBy\":[{\"field\":\"city\",\"orderBy\":{\"field\":\"total revenue\",\"direction\":\"DESC\"}}],\"orderBy\":[]}}}', 'name': 'query datasoil data tool'}, 'type': 'function'}], 'refusal': None} response metadata={'token usage': {'completion tokens': 101, 'prompt tokens': 408, 'total tokens': 509, 'completion tokens details': {'accepted prediction tokens': 0, 'audio tokens': 0, 'reasoning tokens': 0, 'rejected prediction tokens': 0}, 'prompt tokens details': {'audio tokens': 0, 'cached tokens': 0}}, 'model name': 'gpt 4o 2024 08 06', 'system fingerprint': 'fp a288987b44', 'id': 'chatcmpl Bx6NWxGoR398nNxtSQrZNp8DGFvzw', 'service tier': 'default', 'finish reason': 'tool calls', 'logprobs': None} id='run 1ce88438 b51d 4747 a3a5 f06e57b54ef8 0' tool calls=[{'name': 'query datasoil data tool', 'args': {'payload': {'dynamicQueryParam': {'queryType': 'DETAIL', 'interval': 'BY DAY', 'where': {'and': [{'field': 'date', 'gte': '2025 07 01 00:00:00'}, {'field': 'date', 'lt': '2025 07 08 00:00:00'}]}, 'groupBy': [{'field': 'city', 'orderBy': {'field': 'total revenue', 'direction': 'DESC'}}], 'orderBy': []}}}, 'id': 'call UoT9CyYGE6aDIY6vkvu4QqSn', 'type': 'tool call'}] usage metadata={'input tokens': 408, 'output tokens': 101, 'total tokens': 509, 'input token details': {'audio': 0, 'cache read': 0}, 'output token details': {'audio': 0, 'reasoning': 0}} Generated Tool Call Arguments {'payload': {'dynamicQueryParam': {'queryType': 'DETAIL', 'interval': 'BY DAY', 'where': {'and': [{'field': 'date', 'gte': '2025 07 01 00:00:00'}, {'field': 'date', 'lt': '2025 07 08 00:00:00'}]}, 'groupBy': [{'field': 'city', 'orderBy': {'field': 'total revenue', 'direction': 'DESC'}}], 'orderBy': []}}}"}, {"author": "keenborder786", "created_at": "2025-09-09T22:16:29Z", "body_clean": "I tested it with [code] and it is providing me with the correct nested schema, Can I ask what model are you using?"}, {"author": "diego-coder", "created_at": "2025-09-10T00:53:31Z", "body_clean": "Hi @keenborder786, you're right that convert to openai tool can produce a valid schema. The bug I was addressing occurred specifically in the end to end .bind tools() flow. The final schema being passed to the model was malformed, it was generating $ref references for the nested Pydantic models but was failing to include their corresponding definitions in a top level $defs block. This sent an incomplete schema to the LLM, which then couldn't structure the arguments for the tool call correctly. To answer your question, I was using ChatOpenAI with gpt 4 turbo to reproduce the issue. The specific model is relevant here because different models have varying levels of tolerance for schema imperfections. A model that strictly follows the JSON Schema spec would fail to resolve a $ref without its definition, leading to the broken tool invocation. My PR aimed to fix the schema generation process within that bind tools pathway to ensure the definitions for nested models are always correctly included, making the schema valid for any model."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `@chain` decorator argument type is causing an error because it expects a `Callable[[ChatPromptValue], Coroutine[Any, Any, Never]]` but the provided function is expecting a `Callable[[ChatPromptValue], str]`. This is a bug within the LangChain library and doesn’t appear to be a matter of code usage. The issue is currently resolved by providing a minimal reproducible example demonstrating the incompatibility.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in LangChain where the `AttributeError: 'InferenceClient' object has no attribute 'post'` occurs when using the `huggingface hub` integration. This prevents the `post` method from being accessed, likely due to a compatibility issue with the Hugging Face endpoint.  The solution involves updating to the latest stable version of LangChain, which resolves the problem.", "final_category": "bug", "comments": [{"author": "meghajadav", "created_at": "2025-07-24T13:30:14Z", "body_clean": "I am also facing the same issue."}, {"author": "frolenkov-nikita", "created_at": "2025-09-03T05:35:53Z", "body_clean": "With [code] It works without any errors."}]}, {"ollama_summary": "The issue reports an `AttributeError` when attempting to access the `billed_units` attribute of a `ChatCohere` object within the `chat.stream` function. This occurs during the `chunk.content` printing process, specifically within the `BaseChatModel.stream` method. The code is attempting to access a dictionary within the `billed_units` attribute, which is not available for this type of object.  The suggested solution is to address the issue by ensuring the `billed_units` attribute is properly defined within the `ChatCohere` class or its related code.", "final_category": "bug", "comments": [{"author": "ishahroz", "created_at": "2025-08-23T04:08:32Z", "body_clean": "@web bhargavi Are you still facing this issue? It is working fine for me with the following dependencies: [code]"}]}, {"ollama_summary": "The issue was causing Materialized Views to be inaccessible, and a fix was implemented by @kittenkill that adds a line to the langchain/sql database.py to retrieve the names of materialized views. This change allows access to Oracle materialized views.  The fix was verified by the author and is now being deployed.", "final_category": "bug", "comments": []}], "business_insights": ["Model binding inconsistencies are a recurring problem.", "Dependency updates frequently introduce bugs.", "Database fixes often address fundamental issues.", "Integration issues can span multiple components.", "Consistent code review improves reliability."], "technical_insights": ["LangChain’s model binding mechanism requires careful attention.", "The Callable type mismatch is a frequent source of errors.", "Database fixes are vital for stability and compatibility.", "Dependency updates can trigger unexpected behavior.", "Database configuration is critical for model functionality."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model binding inconsistencies are a recurring problem.\n2. Dependency updates frequently introduce bugs.\n3. Database fixes often address fundamental issues.\n4. Integration issues can span multiple components.\n5. Consistent code review improves reliability.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s model binding mechanism requires careful attention.\n2. The `Callable` type mismatch is a frequent source of errors.\n3. Database fixes are vital for stability and compatibility.\n4. Dependency updates can trigger unexpected behavior.\n5. Database configuration is critical for model functionality.\n", "batch_number": 37, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a critical bug in LangChain's core library, specifically affecting the `status` and `default` properties of various models. The code outputs an error message indicating a missing dereference of a property, and the bug is not resolved by updating the library.  It’s a regression issue impacting several dependencies and requires immediate attention to ensure stability.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue stems from a bug in LangChain's `text-splitter` component that prevents it from correctly processing text within HTML `div` tags. A minimal reproducible example has been provided, and the developers are investigating a potential issue with the integration package.  The fix involves adding a specific line of code to handle the text within the `div` tag.", "final_category": "bug", "comments": [{"author": "priyanshbhalia", "created_at": "2025-07-23T15:45:47Z", "body_clean": "replace the content part : content = \" \".join(elem.find all(string=True, recursive=False)) if content: content = self. normalize and clean text(content) current content.append(content)"}, {"author": "SyedBaqarAbbas", "created_at": "2025-07-23T18:53:50Z", "body_clean": "@tanwirahmad I tested your fix and it works fine. Why don't you raise a PR?"}]}, {"ollama_summary": "This issue is a bug in LangChain that prevents the `Neo4jVector.from_existing_index()` function from working correctly with databases other than Neo4j. The bug stems from an empty variable and a missing Cypher statement within the function, leading to an error when attempting to query the indexes of other databases.  The issue is currently unresolved and requires a fix before the feature can be used.", "final_category": "bug", "comments": [{"author": "Jay-Patankar", "created_at": "2025-10-22T07:23:49Z", "body_clean": "@mdrxy I have got a fair understanding of this issue from the comments. Can I pick up this issue , if its still relevant?"}, {"author": "Jay-Patankar", "created_at": "2025-10-22T07:24:46Z", "body_clean": "@WOWCharlotte thanks for pointing out this issue, code hints provided in the description are really useful"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a lack of support for structured output using Pydantic models within the `langchain-huggingface` library.  The PydanticOutputParser component is not being utilized to generate structured data, hindering its functionality.  The solution is to implement and utilize the PydanticOutputParser to enable structured data output.", "final_category": "bug", "comments": [{"author": "bitsydarel", "created_at": "2025-07-23T02:08:39Z", "body_clean": "[code] Since we do have a retry logic, it cause the parsing to retry the prompt which is burning tokens/credits. <img width=\"676\" height=\"862\" alt=\"Image\" src=\" [link] /"}, {"author": "bitsydarel", "created_at": "2025-07-23T02:42:10Z", "body_clean": "Adding support for Pydantic models is quite straightforward. Therefore, I am curious to know why Pydantic support was not implemented. Is it an issue with the Hugging Face inference APIs or something else? [code] Our agentic RAG component is finally operational. <img width=\"681\" height=\"852\" alt=\"Image\" src=\" [link] /"}, {"author": "rahulmansharamani14", "created_at": "2025-09-22T18:38:10Z", "body_clean": "Hi @mdrxy , is someone working on it? If not, I'd love to investigate further and find the solution to this."}, {"author": "rahulmansharamani14", "created_at": "2025-09-28T22:10:03Z", "body_clean": "Hi @mdrxy, I’ve opened a draft PR 33141 for adding Pydantic structured output support in ChatHuggingFace. Could you take a look and share your thoughts on the approach / next steps? Thanks!"}]}, {"ollama_summary": "The GitHub issue highlights a critical bug in LangChain's `qdrantvectorstore` package, specifically preventing the use of the async client. This issue renders the package unusable for asynchronous operations, requiring a workaround to bypass the limitations of the Qdrant client.", "final_category": "bug", "comments": [{"author": "sglebs", "created_at": "2025-07-23T18:51:58Z", "body_clean": "@keenborder786 I just added a review to your patch: [link] I will keep testing it locally, with a local clone of the sources."}, {"author": "keenborder786", "created_at": "2025-07-29T01:06:28Z", "body_clean": "@sglebs okay will have a look."}, {"author": "keenborder786", "created_at": "2025-07-29T01:07:33Z", "body_clean": "@sglebs I cannot see your review???"}, {"author": "cdglissov", "created_at": "2025-08-18T07:46:08Z", "body_clean": "Any progress on this? Looking forward to being able to use Qdrant async as it's quite a blocker in Langchain."}, {"author": "nmakhotkin", "created_at": "2025-08-22T01:08:55Z", "body_clean": "I'm also waiting this to land so all async calls will be natural. Thank you for your work, @keenborder786 !"}, {"author": "SrilalS", "created_at": "2025-10-22T03:27:39Z", "body_clean": "Ran into the same issue. and since this has no progress, I used the qdrant client directly and wrote a wrapper around it instead of using Langchain's ."}]}], "business_insights": ["Dependency stability is paramount – addressing the core library bug is critical for overall system reliability.", "Pydantic integration hinders feature functionality – streamlining data output is essential for usability.", "Async client limitations necessitate workaround – addressing the Qdrant client issue is a priority.", "Regression testing is vital – ensuring stability after the bug fix is crucial.", "Addressing multiple dependencies – fixing the core bug will impact several parts of the system."], "technical_insights": ["Core library bug impacts multiple models – a systemic issue requiring immediate resolution.", "text-splitter integration failure – a separate bug impacting a vital component.", "Neo4jVector.from_existing_index() issue – a complex integration problem.", "PydanticOutputParser implementation – a missing feature impacting structured data output.", "Qdrant vectorstore async client limitations – impacting asynchronous operations."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency stability is paramount – addressing the core library bug is critical for overall system reliability.\n2.  Pydantic integration hinders feature functionality – streamlining data output is essential for usability.\n3.  Async client limitations necessitate workaround – addressing the Qdrant client issue is a priority.\n4.  Regression testing is vital – ensuring stability after the bug fix is crucial.\n5.  Addressing multiple dependencies – fixing the core bug will impact several parts of the system.\n\nTECHNICAL INSIGHTS:\n1.  Core library bug impacts multiple models – a systemic issue requiring immediate resolution.\n2.  `text-splitter` integration failure – a separate bug impacting a vital component.\n3.  Neo4jVector.from_existing_index() issue – a complex integration problem.\n4.  PydanticOutputParser implementation – a missing feature impacting structured data output.\n5.  Qdrant vectorstore async client limitations – impacting asynchronous operations.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 38, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `test_serdes` test in LangChain XAI fails due to a change in the protocol, specifically a new field being added to the serdes data.  The issue is a bug within the LangChain library itself, not a result of your code. A minimal reproducible example has been provided to demonstrate the failure and allow for debugging.", "final_category": "bug", "comments": [{"author": "pc099", "created_at": "2025-07-23T12:21:29Z", "body_clean": "Hey @mdrxy can i work on this bug ?"}, {"author": "mdrxy", "created_at": "2025-07-23T17:52:11Z", "body_clean": "@pc099 yep"}, {"author": "ccurme", "created_at": "2025-07-25T13:54:31Z", "body_clean": "@pc099 you may need to run [make test watch]( [link] to update snapshots."}, {"author": "Etelis", "created_at": "2025-09-01T09:54:39Z", "body_clean": "I see no progress made yet, Can I work on this? @pc099"}, {"author": "Etelis", "created_at": "2025-09-01T11:22:11Z", "body_clean": "Tried running, both tests (unit / integration) pass."}]}, {"ollama_summary": "This issue is a critical bug in LangChain that causes a failure during schema generation for pydantic data types, specifically when referencing references. The code snippet in question exhibits a `32088, line [58]` error, indicating a problem within the LangChain integration process.  The root cause appears to be a mismatch between the expected and actual data within the reference, leading to incorrect JSON output.  A minimal reproducible example has been provided to facilitate debugging.", "final_category": "bug", "comments": [{"author": "SyedBaqarAbbas", "created_at": "2025-07-22T19:39:31Z", "body_clean": "Hello @jmaillefaud I tried replicating this but the sample code worked fine at my end. Could you share a few more details? Also, appreciate your keen observation. Why don't you raise a PR to fix that? I was planning to solve it but it'd be injustice to solve a problem you already solved."}, {"author": "jmaillefaud", "created_at": "2025-07-23T08:14:54Z", "body_clean": "Hello [@jmaillefaud]( [link] I tried replicating this but the sample code worked fine at my end. Could you share a few more details? Also, appreciate your keen observation. Why don't you raise a PR to fix that? I was planning to solve it but it'd be injustice to solve a problem you already solved. I updated the code so that it breaks correctly and added expected behavior. I also created the PR."}, {"author": "radcliffkey", "created_at": "2025-07-23T12:16:31Z", "body_clean": "I think I also ran into this bug. I have a simple agent with tools and using Claude on Vertex. When I update to 0.3.70, calling Vertex fails with [code]"}, {"author": "jeremySrgt", "created_at": "2025-07-23T13:45:55Z", "body_clean": "Same problem here after upgrading langchain to 0.3.26"}, {"author": "injeniero", "created_at": "2025-07-23T20:33:29Z", "body_clean": "I also hit this, and created a bug report as well. [link]"}]}, {"ollama_summary": "This issue provides a guide for new contributors to LangChain, encouraging them to start by reading the full contributing guide ([link]) which covers repository structure, setup, review processes, and ways to contribute. It emphasizes collaboration through the community forum and Slack channel, and offers developer tips for a streamlined development experience.", "final_category": "other", "comments": []}, {"ollama_summary": "The LangChain community is experiencing increased issues and questions, requiring a shift in focus to the “code” repository. This change aims to improve triage and issue resolution by centralizing related issues and ensuring focus on core LangChain framework development.  Specifically, the repository should be used for issues concerning the LangChain framework itself, its tools, and integrations.", "final_category": "other", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a lack of support for adding Jinja2 template formats, specifically `PromptTemplate`s, which are currently not implemented.  Adding this functionality would significantly enhance the usability of Jinja2 for various applications.  The author is requesting a pull request to implement this feature.", "final_category": "question", "comments": []}], "business_insights": ["Addressing template support simplifies Jinja2 integration.", "Enhanced usability improves application development.", "Streamlined issue resolution is crucial for long-term maintainability.", "Template support is a key feature for advanced users.", "Improved workflow benefits the entire LangChain ecosystem."], "technical_insights": ["Template format integration is a critical feature.", "Jinja2 integration is currently lacking.", "Template support enhances application capabilities.", "Template implementation improves workflow.", "Template support requires a code change."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing template support simplifies Jinja2 integration.\n2. Enhanced usability improves application development.\n3. Streamlined issue resolution is crucial for long-term maintainability.\n4. Template support is a key feature for advanced users.\n5. Improved workflow benefits the entire LangChain ecosystem.\n\nTECHNICAL INSIGHTS:\n1. Template format integration is a critical feature.\n2. Jinja2 integration is currently lacking.\n3. Template support enhances application capabilities.\n4. Template implementation improves workflow.\n5. Template support requires a code change.\n", "batch_number": 39, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a bug in LangChain's `test_filecallback` that causes an error when the terminal writes to the output file. This issue is a bug, not a usage issue, and the solution involves updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "pc099", "created_at": "2025-07-23T03:24:44Z", "body_clean": "Hey @mdrxy Can i work on this ??"}, {"author": "mdrxy", "created_at": "2025-07-23T03:54:51Z", "body_clean": "@pc099 yes!"}, {"author": "mdrxy", "created_at": "2025-07-24T14:17:14Z", "body_clean": "Just wanted to check, I'm not able to reproduce this on my end. I use [code] . Pushing [code] now, can you upgrade and let me know if this problem still persists (without your fix in 32200) ? Thanks"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that prevents base64-encoded PDF files from being validated correctly. The code provided is a minimal reproducible example demonstrating this problem, and the issue is being addressed by a fix in the latest stable version of LangChain.", "final_category": "bug", "comments": []}, {"ollama_summary": "The LangChain community is experiencing a \"ModuleNotFoundError\" when using the `text splitter` module, specifically when running the provided minimal reproducible example. This issue appears to be a bug within the LangChain library itself, not a problem with the user's code. The solution involves providing a minimal, self-contained example that demonstrates the issue, allowing for easier debugging and identification of the root cause.", "final_category": "bug", "comments": [{"author": "diego-coder", "created_at": "2025-07-20T21:42:47Z", "body_clean": "langchain community is now a separate package and must be installed separately. pip install langchain community"}, {"author": "siddarthreddygsr", "created_at": "2025-07-21T04:13:23Z", "body_clean": "<img width=\"137\" height=\"59\" alt=\"Image\" src=\" [link] /"}]}, {"ollama_summary": "This issue addresses a problem with the `docs` repository where the `openai` library fails to correctly pass the `ttl` parameter when using the `lm studio` API, specifically when attempting to set the TTL value in the JSON payload. The code throws a `TypeError` when attempting to use `ttl` as a keyword argument, requiring the TTL to be passed as a separate parameter.", "final_category": "question", "comments": []}, {"ollama_summary": "The issue involves a bug where the reasoning model is producing incorrect output due to an inferred result. A minimal reproducible example demonstrating the problem was added, including a self-contained code snippet. The solution requires a fix to prevent the model from generating incorrect inferences.", "final_category": "bug", "comments": [{"author": "langcarl[bot]", "created_at": "2025-07-20T13:50:56Z", "body_clean": "This issue has been flagged as spam and will be closed. Please tag @ccurme if you feel this was done in error."}, {"author": "keenborder786", "created_at": "2025-07-20T15:40:47Z", "body_clean": "First, why are you using [code] , instead of ChatOpenAI. Second, can you share the system prompt, have you given explicity instruction to extract the structured output???"}]}], "business_insights": ["Updating to the latest stable version of LangChain resolves the test_filecallback bug.", "The fix in LangChain addresses the base64 PDF validation issue, improving code reliability.", "The LangChain community is now a separate package, requiring separate installation.", "The docs repository issue highlights a missing parameter for ttl in the lm studio API.", "The reasoning model output is incorrect due to inferred results, requiring a fix."], "technical_insights": ["LangChain's latest stable version includes a bug fix for the test_filecallback function.", "The fix in LangChain addresses a bug in base64 PDF validation.", "The LangChain library itself has a bug related to the ttl parameter in the lm studio API.", "The docs repository issue requires a minimal, self-contained example to debug the ttl parameter.", "The test_filecallback bug is a regression, impacting the entire LangChain testing environment."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Updating to the latest stable version of LangChain resolves the `test_filecallback` bug.\n2. The fix in LangChain addresses the base64 PDF validation issue, improving code reliability.\n3. The LangChain community is now a separate package, requiring separate installation.\n4. The `docs` repository issue highlights a missing parameter for `ttl` in the `lm studio` API.\n5. The reasoning model output is incorrect due to inferred results, requiring a fix.\n\nTECHNICAL INSIGHTS:\n1. LangChain's latest stable version includes a bug fix for the `test_filecallback` function.\n2. The fix in LangChain addresses a bug in base64 PDF validation.\n3. The LangChain library itself has a bug related to the `ttl` parameter in the `lm studio` API.\n4. The `docs` repository issue requires a minimal, self-contained example to debug the `ttl` parameter.\n5. The `test_filecallback` bug is a regression, impacting the entire LangChain testing environment.\n", "batch_number": 40, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The JSON data contains a detailed log of the changes made to the `JsonOutputKeyToolsParser` code, including the bug fixed, the test cases added, and verification steps. It also includes a summary of the changes made and the overall status of the task.", "final_category": "bug", "comments": []}, {"ollama_summary": "This is a good summary of the changes made to the `ChatDeepSeek` model in the `deepseek` module of the LangServe integration. Here’s a breakdown of what the summary highlights and why it’s effective:\n\n**Key Takeaways:**\n\n* **Problem:** The PydanticUserError was occurring when LangServe generated batch request classes when the `llm_type` property was set to `\"chat deepseek\"`.\n* **Solution:** The code was modified to change the `llm_type` property to `\"deepseek\"` within the `ChatDeepSeek` class.\n* **Impact:** This resolves the error and ensures the model generates valid Pydantic class names for batch requests.\n* **Verification:**  The summary includes steps taken to verify the fix – testing the new property and ensuring no remaining references to the old value.\n\n**Why it's a good summary:**\n\n* **Concise:** It quickly explains the problem, solution, and impact.\n* **Detailed:** It covers the specific changes made (property modification).\n* **Action-Oriented:** It highlights the steps taken to confirm the fix.\n* **Clear:** It uses straightforward language.\n\n**Overall, the summary effectively communicates the core of the update without being overly verbose.**\n\nDo you want me to elaborate on any specific aspect of the summary, such as:\n\n*   The specific code change?\n*   The testing process?", "final_category": "bug", "comments": [{"author": "CuberMessenger", "created_at": "2025-07-22T04:35:48Z", "body_clean": "Hi @zouw1, it seems your reported error happens in the [code] [code] [code] [code] [code] function in the current one. Anyway, I find the following code works fine: [code] <img width=\"1504\" height=\"880\" alt=\"Image\" src=\" [link] /"}, {"author": "zouw1", "created_at": "2025-07-26T08:01:06Z", "body_clean": "add routes is indented and has no indentation. The add routes statement in the code you provided was not executed @CuberMessenger [code]"}, {"author": "jasonvnit", "created_at": "2025-07-27T14:05:14Z", "body_clean": "I have the same problem. Can anyone help me? [code] Issue: [code]"}, {"author": "zhangxiaoli2001", "created_at": "2025-07-28T03:29:48Z", "body_clean": "I encountered a problem when learning langserver. Can you help me find out where the problem is? from fastapi import FastAPI from fastapi.responses import RedirectResponse from langchain openai import ChatOpenAI from langserve import add routes import os app = FastAPI(title=\"langchain服务器\", version=\"1.0\", description=\"使⽤ Langchain 的 Runnable 接⼝的简单 API 服务器\", ) @app.get(\"/\") async def redirect root to docs(): return RedirectResponse(\"/docs\") add routes( app, ChatOpenAI(model=\"gpt 3.5 turbo\", api key =\"。。\", base url=\"。。\" ), path=\"/aa\" ) if name == \"main\": import uvicorn uvicorn.run(app, host=\"localhost\", port=8000) INFO: Application startup complete. INFO: 127.0.0.1:55917 \"GET /docs HTTP/1.1\" 200 OK INFO: 127.0.0.1:55917 \"GET /openapi.json HTTP/1.1\" 500 Internal Server Error ERROR: Exception in ASGI application Traceback (most recent call last): File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\uvicorn\\protocols\\ [link] line 408, in run asgi result = await app( type: ignore[func returns value] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\uvicorn\\middleware\\proxy headers.py\", line 84, in call return await self.app(scope, receive, send) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\fastapi\\applications.py\", line 1054, in call await super().call(scope, receive, send) File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\starlette\\applications.py\", line 113, in call await self.middleware stack(scope, receive, send) File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\starlette\\middleware\\errors.py\", line 186, in call raise exc File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\starlette\\middleware\\errors.py\", line 164, in call await self.app(scope, receive, send) File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\starlette\\middleware\\exceptions.py\", line 63, in call await wrap app handling exceptions(self.app, conn)(scope, receive, send) File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\starlette exception handler.py\", line 53, in wrapped app raise exc File \"D:\\anaconda\\envs\\langchain\\Lib\\site packages\\starlette exception handler.py\", line 42, in wrapped app pydantic.errors.PydanticUserError: TypeAdapter[typing.Annotated[langserve.validation.aaInvokeRequest, <class 'langserve.validation.aaInvokeRequest' , Body(PydanticUndefined)]] is not fully defined; you should define typing.Annotated[langserve.validation.aaInvokeRequest, <class 'langserve.validation.aaInvokeRequest' , Body(PydanticUndefined)] and all referenced types, then call .rebuild() on the instance. For further information visit [link]"}, {"author": "CuberMessenger", "created_at": "2025-07-31T13:38:53Z", "body_clean": "Hi @zouw1, I've dived down a little, found something, but not solved the problem yet. To start, here's a minimal example to reproduce the problem: [code] And when accessing 127.0.0.1:8181/docs, one will get [code] Here are some findings, need some help to analyse deeper: The official document says this kind of error usually can be solved through calling model rebuild() of the relevant model ( [link] [code] [code] [code] at [link] and the model rebuild has been called."}, {"author": "deyou827", "created_at": "2025-08-03T12:43:53Z", "body_clean": "<img width=\"1347\" height=\"576\" alt=\"Image\" src=\" [link] / [code] [code] raise PydanticUserError(self. error message, code=self. code) pydantic.errors.PydanticUserError: [code] is not fully defined; you should define [code] and all referenced types, then call [code] on the instance. For further information visit [link] Please help me."}, {"author": "zouw1", "created_at": "2025-08-05T06:40:40Z", "body_clean": "@CuberMessenger I also am the mistake, but when I visit 127.0.0.1 / deepseek/playground, it is to be able to run normally."}, {"author": "JainHarsh00", "created_at": "2025-08-17T08:16:50Z", "body_clean": "[code] Same issue with my code too Have we found any way yet? or any combination of langserve and pydantic with overcome this error??"}, {"author": "Rezowanur-Rahman-Robin", "created_at": "2025-08-17T08:44:36Z", "body_clean": "I am also getting same issue. /docs giving 500 from openai. But the playground working perfectly. According to the langchain doc [link] it should work. [code]"}, {"author": "AlfredNing", "created_at": "2025-08-17T08:48:26Z", "body_clean": "pyproject.toml ： [tool.poetry] name = \"my langserve\" version = \"0.1.0\" description = \"\" authors = [\"Your Name <you@example.com \"] readme = \"README.md\" packages = [ { include = \"app\" }, ] [tool.poetry.dependencies] python = \"^3.11\" uvicorn = \"^0.23.2\" langserve = {extras = [\"server\"], version = \" =0.0.30\"} pydantic = \"^2.7\" langchain = \"^0.3.4\" langchain openai = \"^0.2.3\" [tool.poetry.group.dev.dependencies] langchain cli = \" =0.0.15\" [build system] requires = [\"poetry core\"] build backend = \"poetry.core.masonry.api\" server.py: from fastapi import FastAPI from fastapi.responses import RedirectResponse from langserve import add routes from fastapi.middleware.cors import CORSMiddleware from dotenv import load dotenv from langchain openai import ChatOpenAI load dotenv() app = FastAPI( title=\"LangChain 服务器\", version=\"1.0\", description=\"使用 Langchain 的 Runnable 接口的简单 API 服务器\", ) app.add middleware( CORSMiddleware, allow origins=[\" \"], allow credentials=True, allow methods=[\" \"], allow headers=[\" \"], expose headers=[\" \"], ) @app.get(\"/\") async def redirect root to docs(): return RedirectResponse(\"/docs\") add routes( app, ChatOpenAI(model=\"gpt 4\"), path=\"/openai\", ) Edit this to add the chain you want to add add routes(app, NotImplemented) if name == \" main \": import uvicorn uvicorn.run(app, host=\"0.0.0.0\", port=8000) it seems error : raise PydanticUserError(self. error message, code=self. code) pydantic.errors.PydanticUserError: [code] is not fully defined; you should define [code] and all referenced types, then call [code] on the instance. how can i solve it ?"}, {"author": "CuberMessenger", "created_at": "2025-08-18T03:59:45Z", "body_clean": "Hi @zouw1 @jasonvnit @zhangxiaoli2001 @deyou827, I have some updates to share. API service is running fine First things first, the api works fine, which means serving the service using the following code: [code] Then one can access it with the following script in another terminal/script: [code] Fix the pydantic error to prevent showing docs Problem statement It appears in langserve [code] [code] [code] [code] [code] [code] [code] [code] [code] [code] [code] in the rest of the file. After the fix, the docs page shows up: <img width=\"2193\" height=\"1232\" alt=\"Image\" src=\" [link] / PR See [link]"}, {"author": "manu-one", "created_at": "2025-09-11T00:24:21Z", "body_clean": "I see that @CuberMessenger 's PR hasn't been merged yet. Would really appreciate instructions on solving the issue, at the time of closing it."}, {"author": "CuberMessenger", "created_at": "2025-09-11T01:41:59Z", "body_clean": "Thanks for bringing it up @manu one. It seems the previous PR was refused due to a lint issue and a build issue during testing. I've committed another fix for the lint, but I have no idea how to fix the build issue, i.e. [code]"}, {"author": "liberty-1776", "created_at": "2025-09-14T14:15:29Z", "body_clean": "Thanks for it @CuberMessenger, it really works. I was trying to find the solution everywhere, but your code works. I hope your PR merges soon to the main branch. Good Luck. And again Thank you so much"}]}, {"ollama_summary": "The ClickHouse integration with the LangChain tutorial is failing due to an \"Unknown index type 'annoy'\" error, specifically related to a deprecated index structure.  The issue stems from a change in ClickHouse’s index design, requiring a newer version of LangChain. A minimal reproducible example has been provided to demonstrate the problem, and the support for older index types has been removed.", "final_category": "bug", "comments": [{"author": "Khosilmurod", "created_at": "2025-07-18T04:24:52Z", "body_clean": "Hi @maintainers, I’d like to work on this. Please assign me. Thanks!"}]}, {"ollama_summary": "The GitHub issue asks to create a `AGENTS.md` file within the repository root containing comprehensive guidelines for developers working with the LangChain monorepo. The file should cover general coding rules, repository structure, dependency management, testing instructions, and linting/packaging practices.  It’s a structured guide designed to help new developers understand and effectively utilize the LangChain ecosystem.", "final_category": "other", "comments": [{"author": "langcarl[bot]", "created_at": "2025-07-17T19:49:27Z", "body_clean": "This issue has been flagged as spam and will be closed. Please tag @ccurme if you feel this was done in error."}, {"author": "eyurtsev", "created_at": "2025-07-25T19:05:46Z", "body_clean": "lol"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue, focusing on the core problem, key details, and solution:\n\nThe code currently throws a KeyError when referencing JSON schema refs using list indices, causing unexpected errors. A fix has been implemented that converts list indices into numeric path segments, resolving these issues. This update addresses a known vulnerability and improves the code’s robustness.", "final_category": "bug", "comments": []}], "business_insights": ["Schema changes necessitate thorough code review and testing.", "Focus on specific code changes to pinpoint root causes.", "Testing is critical to confirm fixes and prevent regressions.", "Code review should prioritize stability and identify potential issues.", "Regression testing is vital after changes to schema."], "technical_insights": ["JSON data includes detailed log of changes – crucial for debugging.", "PydanticUserError resolution requires modifying llm_type.", "ClickHouse integration requires newer LangChain version.", "Deprecated index structure necessitates older index types.", "AGENTS.md file is a structured guide for LangChain developers."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Schema changes necessitate thorough code review and testing.\n2.  Focus on specific code changes to pinpoint root causes.\n3.  Testing is critical to confirm fixes and prevent regressions.\n4.  Code review should prioritize stability and identify potential issues.\n5.  Regression testing is vital after changes to schema.\n\nTECHNICAL INSIGHTS:\n1.  JSON data includes detailed log of changes – crucial for debugging.\n2.  PydanticUserError resolution requires modifying `llm_type`.\n3.  ClickHouse integration requires newer LangChain version.\n4.  Deprecated index structure necessitates older index types.\n5.  `AGENTS.md` file is a structured guide for LangChain developers.\n", "batch_number": 41, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where the Jupiter setup guide isn’t helpful for JavaScript developers because it’s not tailored to hands-on coding.  The developer has added a link to the documentation and included a title, but there’s no response to the request for content.  Currently, the guide doesn’t provide sufficient context for practical JavaScript development.", "final_category": "other", "comments": []}, {"ollama_summary": "This issue stems from a validation problem within LangChain's `StateLike` component when used with `Annotation`. The code snippet triggers a validation failure, potentially due to a discrepancy in how LangChain's runtime validation is configured. The proposed solution is to temporarily rely on an Any type for validation instead of Pydantic.", "final_category": "question", "comments": [{"author": "ArjunJagdale", "created_at": "2025-10-11T10:44:50Z", "body_clean": "@eyurtsev SO, Pydantic cannot validate StateLike because it’s not a real class Correct me if i am wrong. Will the minimal way we can consider is Use [code] in the model config for [code] , or Implement a custom [code] validator that checks the expected structure of [code] ."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe core team is proposing a change to prevent docstrings from inheriting from their parent classes, addressing a potential inconsistency in the codebase. This change is particularly noticeable in the BaseModel context, where docstrings are currently inherited. The proposed solution involves modifying the behavior to ensure docstrings are self-contained and distinct from their parent classes.", "final_category": "feature", "comments": [{"author": "chandrani121189", "created_at": "2025-07-17T04:17:52Z", "body_clean": "@mdrxy If you add a docstring to the base class does it not override?"}, {"author": "R-Fischer47", "created_at": "2025-10-16T20:04:27Z", "body_clean": "Hi @mdrxy & @eyurtsev, I'm a new contributor and I'd like to work on this issue. Can I be assigned?"}]}, {"ollama_summary": "The `num_gpu` functionality for the Ollama model is not working as expected, causing an error message. The issue appears to be a bug within the LangChain library, and the provided example code demonstrates a simple, reproducible scenario where a minimal example runs without issues.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-07-16T22:48:41Z", "body_clean": "New release being pushed thru the pipeline now give that an install and let me know if it works for ya."}]}, {"ollama_summary": "This issue reports a bug in LangChain where the `score_threshold` parameter in the `similarity_search_with_relevance_scores` function is causing issues with the `distance==DistanceStrategy.MAX_INNER_PRODUCT` logic, leading to unexpected results and potential errors.  The code attempts to drop documents based on a score threshold, but the threshold is being incorrectly applied, resulting in the dropping of documents.  The issue is reproducible with a minimal example and is likely a bug within the LangChain integration package.", "final_category": "bug", "comments": [{"author": "dtanalytic", "created_at": "2025-07-16T05:47:26Z", "body_clean": "Excuse me, forgot to add query variable to code sample query = \" execute malware loaders\""}, {"author": "siddarthreddygsr", "created_at": "2025-07-16T22:15:33Z", "body_clean": "Move this issue to [langchain community]( [link] langchain community is no longer a part of this repo."}, {"author": "dtanalytic", "created_at": "2025-07-17T04:20:27Z", "body_clean": "I put it here because one of 2 functions which can't get along is in this repo [similarity search with relevance scores]( [link]"}]}], "business_insights": ["Focus on tailored guidance for JavaScript developers to improve the Jupiter setup guide.", "Validate LangChain’s StateLike component with Annotation using a temporary Any type.", "Address potential inconsistencies in LangChain’s runtime validation configuration.", "Improve docstring handling to ensure self-contained and distinct docstrings.", "Address the issue of inherited docstrings in the BaseModel context.", "The Jupiter setup guide needs more specific guidance for JavaScript developers.", "Pydantic validation should not be applied to StateLike because it's not a real class.", "LangChain’s validation process requires a specific runtime configuration.", "Docstring handling needs to ensure self-contained and distinct docstrings.", "The model needs to provide more context for practical JavaScript development."], "technical_insights": ["LangChain’s validation process requires a specific runtime configuration for StateLike.", "Pydantic validation cannot be applied to StateLike because it’s not a real class.", "Temporarily use Any type for validation when using Pydantic to validate StateLike.", "Modify LangChain’s validation behavior to ensure docstrings are self-contained.", "Implement a minimal solution for validation using Any type.", "LangChain validation relies on a specific runtime configuration for StateLike.", "Pydantic validation is not applicable to StateLike as it is not a real class.", "A temporary solution to validate StateLike using Any type is necessary.", "Modify LangChain's validation behavior to ensure docstrings are self-contained.", "Implement a minimal validation workflow using Any type."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on tailored guidance for JavaScript developers to improve the Jupiter setup guide.\n2.  Validate LangChain’s `StateLike` component with `Annotation` using a temporary Any type.\n3.  Address potential inconsistencies in LangChain’s runtime validation configuration.\n4.  Improve docstring handling to ensure self-contained and distinct docstrings.\n5.  Address the issue of inherited docstrings in the BaseModel context.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s validation process requires a specific runtime configuration for `StateLike`.\n2.  Pydantic validation cannot be applied to `StateLike` because it’s not a real class.\n3.  Temporarily use Any type for validation when using Pydantic to validate `StateLike`.\n4.  Modify LangChain’s validation behavior to ensure docstrings are self-contained.\n5.  Implement a minimal solution for validation using Any type.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  The Jupiter setup guide needs more specific guidance for JavaScript developers.\n2.  Pydantic validation should not be applied to `StateLike` because it's not a real class.\n3.  LangChain’s validation process requires a specific runtime configuration.\n4.  Docstring handling needs to ensure self-contained and distinct docstrings.\n5.  The model needs to provide more context for practical JavaScript development.\n\nTECHNICAL INSIGHTS:\n1.  LangChain validation relies on a specific runtime configuration for `StateLike`.\n2.  Pydantic validation is not applicable to `StateLike` as it is not a real class.\n3.  A temporary solution to validate StateLike using Any type is necessary.\n4.  Modify LangChain's validation behavior to ensure docstrings are self-contained.\n5.  Implement a minimal validation workflow using Any type.\n", "batch_number": 42, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "I successfully fixed the JSON schema dereferencing bug where [code] paths with list indices (e.g., [code] ) were raising KeyError exceptions.\n\nChanges Made:\n\n1. Core Fix : Modified [code] in [code] to properly distinguish between list indices and dictionary keys by replacing the problematic logic with separate if/elif blocks that check [code] vs [code] .\\\n2. Test Coverage : Added comprehensive test function [code] in [code] covering the main bug scenario, edge cases, and regression testing.\n3. Code Quality : Fixed line length violations by breaking long conditional statements into separate if/elif blocks to meet the project's 88 character limit.\n4. Verification : The fix resolves the original KeyError and correctly dereferences JSON pointer paths like [code] while maintaining backward compatibility with existing dictionary based numeric keys.", "final_category": "bug", "comments": [{"author": "open-swe[bot]", "created_at": "2025-07-17T17:11:29Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"1f063311 4394 62ee bebb 0f5b40668cc0\", \"threadId\": \"74a94e82 2c6b 47d8 a789 c36167cbe2be\" } </details"}]}, {"ollama_summary": "This issue relates to a bug in LangChain's `BaseCallbackManager` that causes unexpected behavior when merging handlers and inheritable handlers. The code appears to be incorrectly combining these lists, leading to a potentially confusing and less functional system.  The issue is currently unresolved, and a minimal reproducible example exists to demonstrate the problem.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-07-14T16:38:09Z", "body_clean": "This might be unintended behavior. I looked briefly in the code in BaseCallbackManager and haven't been able to trace it. Would you mind adding a unit test that reproduces this behavior to langchain core and we can then investigate how to fix?"}, {"author": "Shibayan003", "created_at": "2025-07-15T11:31:10Z", "body_clean": "Got it. I'll add a failing test case for this and open a PR soon."}, {"author": "gjeltep", "created_at": "2025-10-17T19:42:51Z", "body_clean": "@mdrxy came across the TODO in codebase mind if i take a crack at a fix?"}]}, {"ollama_summary": "The issue reports a problem with the `astream_events` API, specifically when using LangChain. The tool artifact isn't being returned in the `on_tool_end` event, leading to a lack of information about the tool's completion. The code provided is a minimal, reproducible example that demonstrates this issue, and the developer suggests investigating potential bugs in LangChain or updating the version.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in the tool artifact that prevents it from returning the expected artifact in the `astream_events` event, causing an error message and stack trace.  The solution involves emitting a custom event directly from the tool, which is currently not intended.  Further investigation is needed to determine the root cause and potential fixes.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue involves a bug in LangChain/LangGraph where it incorrectly flags empty arguments as invalid, specifically in stream mode.  The problem only manifests in stream mode and hasn’t been resolved by recent updates.  The developer has provided a self-contained, reproducible example demonstrating the issue and suggests a potential fix through a change to the tool handling empty arguments.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-09-10T19:01:14Z", "body_clean": "Can you clarify the issue? I'm not recovering InvalidToolCalls: [code] I think if there is an issue here it should be fixed in the underlying integration. If there is a dedicated package designed to work with your chosen model (e.g., [langchain qwq]( [link] let's first try to use that. If that doesn't work, let's consider a patch in [code] that accommodates APIs that stream null tool call args— but from what I can tell it's already supported."}]}], "business_insights": ["Fixes JSON schema dereferencing errors, improving data integrity.", "Enhanced test coverage for the core fix, increasing confidence.", "Improved code quality by breaking long conditional statements.", "Verification of the fix resolves the original KeyError and maintains backward compatibility.", "Stream mode validation bug fixed, addressing a critical issue."], "technical_insights": ["JSON schema dereferencing fix: Corrected logic for list index handling.", "Comprehensive test coverage: Expanded test suite covering various scenarios.", "Code quality improvement: Reduced conditional statement length for better readability.", "Verification of fix: Resolves the original KeyError and maintains existing dictionary-based numeric keys.", "Stream mode validation: Corrected the error in the tool artifact's return."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Fixes JSON schema dereferencing errors, improving data integrity.\n2. Enhanced test coverage for the core fix, increasing confidence.\n3. Improved code quality by breaking long conditional statements.\n4. Verification of the fix resolves the original KeyError and maintains backward compatibility.\n5. Stream mode validation bug fixed, addressing a critical issue.\n\nTECHNICAL INSIGHTS:\n1. JSON schema dereferencing fix: Corrected logic for list index handling.\n2. Comprehensive test coverage: Expanded test suite covering various scenarios.\n3. Code quality improvement: Reduced conditional statement length for better readability.\n4. Verification of fix: Resolves the original KeyError and maintains existing dictionary-based numeric keys.\n5. Stream mode validation: Corrected the error in the tool artifact's return.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 43, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `_retrieve_ref` JSON schema is failing to process list elements containing dictionaries, specifically when the `ccRecipients` field refers to `bccRecipients`. This issue stems from an incorrect indexing mechanism when accessing the list element within the API definition.  The proposed solution involves implementing a check to use the index of the `ccRecipients` field during the lookup process.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue involves a problem where LangChain is failing to recognize the Tongyi Qianwen model, despite using the correct key format.  The error message indicates the model is not found, despite the model name being identical to OpenAI’s. A self-contained, reproducible example has been provided to demonstrate the problem and suggest a potential fix – updating to the latest LangChain version.", "final_category": "bug", "comments": [{"author": "siddarthreddygsr", "created_at": "2025-07-13T20:18:40Z", "body_clean": "Your code and description do not match. Your code is calling the gpt 4o model, and your error says it's using the qwq plus model. Please recheck and update it."}]}, {"ollama_summary": "The issue involves a problem where LangChain is failing to recognize the Tongyi Qianwen model, resulting in a \"model not found\" error.  The problem appears to be a mismatch between the model identifier and the expected format used by the Dashscope service. A maintainer provided a self-contained, reproducible example to demonstrate the issue and suggest a potential fix.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue stems from LangChain failing to recognize the Tongyi Qwen model, despite it being formatted identically to OpenAI keys.  The problem is likely a bug within the LangChain integration, and the solution involves a self-contained, minimal example that demonstrates the issue.  The root cause is likely a mismatch between the model identifier and the expected format used by the LangChain library.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical problem with LangChain's core packaging, specifically related to the `snip` and `big printout` dependency. The system is attempting to use an outdated version of `langchain core` (0.3.68b0) when the required version is 0.3.0, causing installation failures and requiring a manual workaround.", "final_category": "bug", "comments": [{"author": "ntjohnson1", "created_at": "2025-07-15T11:47:45Z", "body_clean": "Resolved by 32032"}]}], "business_insights": ["Dependency management issues can significantly impact project stability.", "Prioritize bug fixes based on impact and frequency.", "Ensure consistent and tested code across the entire codebase.", "Monitor dependency versions closely and proactively.", "Automate testing to reduce regression risks."], "technical_insights": ["LangChain dependency inconsistencies are a recurring problem.", "Incorrect model identifiers are a primary cause of errors.", "Version mismatches between dependencies are frequently observed.", "The core packaging issue necessitates a fix.", "Testing is crucial for dependency resolution."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management issues can significantly impact project stability.\n2.  Prioritize bug fixes based on impact and frequency.\n3.  Ensure consistent and tested code across the entire codebase.\n4.  Monitor dependency versions closely and proactively.\n5.  Automate testing to reduce regression risks.\n\nTECHNICAL INSIGHTS:\n1.  LangChain dependency inconsistencies are a recurring problem.\n2.  Incorrect model identifiers are a primary cause of errors.\n3.  Version mismatches between dependencies are frequently observed.\n4.  The core packaging issue necessitates a fix.\n5.  Testing is crucial for dependency resolution.\n\n", "batch_number": 44, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the Python LLM Chain tutorial (linked) is causing the code to fail when executed from a Python Notebook. The documentation instructs users to run the code from a notebook, which is the user’s current workflow.  The issue is a bug that prevents the code from returning correctly when launched from a notebook environment.", "final_category": "other", "comments": [{"author": "mdrxy", "created_at": "2025-07-14T15:18:21Z", "body_clean": "This is intended behavior; your VSCode should present a prompt where you enter your API key or project name. If you are not seeing this prompt, I'd encourage you to troubleshoot your VSCode installation. <img width=\"888\" height=\"299\" alt=\"Image\" src=\" [link] /"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nUsers are experiencing a broken link to the Langchain and Langsmith documentation, which results in an unnavigable website. The issue persists across browsers and devices, and only allows access to the Python/JavaScript documentation.  The issue is a longstanding problem requiring a solution to ensure users can access the necessary documentation.", "final_category": "other", "comments": [{"author": "nick-youngblut", "created_at": "2025-07-12T04:14:14Z", "body_clean": "The cause is AT&T Active Armor. It keeps blocking langchain urls, except for langgraph. I'm not sure what's going on with your docs, but however the site is configured, it appears shady to AT&T Active Armor."}, {"author": "eyurtsev", "created_at": "2025-07-14T14:35:59Z", "body_clean": "How are you trying to reach the docs? Is this from a web crawler?"}, {"author": "nick-youngblut", "created_at": "2025-07-14T15:18:18Z", "body_clean": "No, just from the browser on my laptop/phone. AT&T Active Armor just did this again for [link] I keep having to unblock various parts of the langchain docs. This issue with AT&T Active Armor does not occur for other websites."}, {"author": "nick-youngblut", "created_at": "2025-07-17T00:44:48Z", "body_clean": "Just to log into langsmith, I had to unblock the langsmith url, then the auth url, and then the api url"}, {"author": "adinhobl", "created_at": "2025-07-20T15:49:28Z", "body_clean": "I am also running into this issue. Internet is also AT&T."}]}, {"ollama_summary": "This issue stems from a bug in LangChain that incorrectly parses `mustache` format in the `get_template_variables` function. The function incorrectly identifies nested variables, leading to an incorrect output. The code doesn't handle the `mustache` format properly, resulting in unexpected behavior and a failure to return the expected output.", "final_category": "question", "comments": [{"author": "YantD729", "created_at": "2025-07-12T11:24:34Z", "body_clean": "I am fixing it here: [link]"}, {"author": "YantD729", "created_at": "2025-07-12T12:45:05Z", "body_clean": "Well...I initially implemented a fix that makes get template variables return full dot separated variable names (e.g., user.name, user.role) for Mustache templates. However, upon deeper inspection, this behavior causes breaking changes in parts of LangChain that rely on structured input validation, such as StructuredPrompt, which expects nested variables to be passed as top level objects (e.g., {\"user\": {\"name\": \"foo\"}}) rather than dot separated flat keys. Since Mustache is designed to work with structured input objects (not flattened dot strings), the original behavior of returning just the top level variable (e.g., user) aligns more closely with Mustache semantics. I’m now considering closing or revising this PR to respect Mustache’s structure driven design, and possibly add documentation or warnings instead of altering variable detection behavior in ways that break existing use cases."}, {"author": "eyurtsev", "created_at": "2025-10-10T21:22:40Z", "body_clean": "We can update the doc string to explain semantics. This does not appear like an issue based on the report so far"}, {"author": "eyurtsev", "created_at": "2025-10-10T21:23:33Z", "body_clean": "If someone wants to improve the doc strings to explain the behavior and practice good technical writing, we'd consider a PR for that"}, {"author": "keenborder786", "created_at": "2025-10-10T21:31:15Z", "body_clean": "@eyurtsev okay"}]}, {"ollama_summary": "This issue stems from a bug in the FakeMessagesListChatModel that prevents the sleep parameter from affecting latency.  The developer has tried updating LangChain but the problem persists. A minimal, reproducible example is provided, allowing users to test the issue independently.", "final_category": "bug", "comments": [{"author": "siddarthreddygsr", "created_at": "2025-07-13T20:34:00Z", "body_clean": "I would like to work on this"}]}, {"ollama_summary": "This issue report highlights a persistent problem with the LangChain agent tool, specifically when generating the `astream_events` output. The tool consistently fails to produce the expected output, often displaying incorrect results, and sometimes producing the correct output unexpectedly. The issue stems from a potential incompatibility with a recent LangChain update, and the reported dependency issues are causing the tool to malfunction.  The report suggests a need to investigate the specific integration package and potentially a more recent version of LangChain to resolve the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-07-13T02:41:31Z", "body_clean": "Rather than putting in the information in the prompt when to invoke the tool. Add Docstring to tool, to decide when to invoke tool."}, {"author": "qq745639151", "created_at": "2025-07-14T02:12:10Z", "body_clean": "而不是在何时调用该工具的提示中输入信息。将 Docstring 添加到 tool，以决定何时调用 tool。 @keenborder786 Thanks for your advices. Also, what I'd like to solve is that if something else is output before the tool is called, the framework won't be able to trigger the [code] event correctly. Is it a bug?"}, {"author": "qq745639151", "created_at": "2025-07-14T07:12:27Z", "body_clean": "而不是在何时调用该工具的提示中输入信息。将 Docstring 添加到 tool，以决定何时调用 tool。 [@keenborder786]( [link] Thanks for your advices. Also, what I'd like to solve is that if something else is output before the tool is called, the framework won't be able to trigger the [code] event correctly. Is it a bug? I check the code and find my mistake. the event [code] is triggered by llm tool action"}, {"author": "qq745639151", "created_at": "2025-07-16T08:43:32Z", "body_clean": "The reason for this error is a bug in the inference framework"}]}], "business_insights": ["Documentation inconsistencies can significantly impact user experience and workflow.", "Prioritize clear and consistent documentation to reduce user frustration.", "Maintain a robust and up-to-date documentation pipeline is critical.", "Address documentation gaps proactively to avoid future issues.", "Ensure documentation is easily accessible and searchable across all channels.", "Documentation inconsistencies can significantly impact user experience and workflow.", "Maintain a robust and up-to-date documentation pipeline is critical.", "Address documentation gaps proactively to avoid future issues.", "Ensure documentation is easily accessible and searchable across all channels.", "Develop a comprehensive documentation strategy for all LangChain components."], "technical_insights": ["Documentation inconsistencies hinder developer productivity and workflow.", "Maintaining a clear and consistent documentation pipeline is vital.", "The bug in the Python/JavaScript documentation is a major concern.", "LangChain’s documentation needs careful review and updates.", "The bug in the LangChain documentation is a persistent issue affecting users.", "Documentation inconsistencies hinder developer productivity and workflow.", "Maintaining a clear and consistent documentation pipeline is vital.", "The bug in the Python/JavaScript documentation is a major concern.", "LangChain’s documentation needs careful review and updates.", "Ensure documentation is easily accessible and searchable across all channels."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Documentation inconsistencies can significantly impact user experience and workflow.\n2.  Prioritize clear and consistent documentation to reduce user frustration.\n3.  Maintain a robust and up-to-date documentation pipeline is critical.\n4.  Address documentation gaps proactively to avoid future issues.\n5.  Ensure documentation is easily accessible and searchable across all channels.\n\nTECHNICAL INSIGHTS:\n1.  Documentation inconsistencies hinder developer productivity and workflow.\n2.  Maintaining a clear and consistent documentation pipeline is vital.\n3.  The bug in the Python/JavaScript documentation is a major concern.\n4.  LangChain’s documentation needs careful review and updates.\n5.  The bug in the LangChain documentation is a persistent issue affecting users.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Documentation inconsistencies can significantly impact user experience and workflow.\n2.  Maintain a robust and up-to-date documentation pipeline is critical.\n3.  Address documentation gaps proactively to avoid future issues.\n4.  Ensure documentation is easily accessible and searchable across all channels.\n5.  Develop a comprehensive documentation strategy for all LangChain components.\n\nTECHNICAL INSIGHTS:\n1.  Documentation inconsistencies hinder developer productivity and workflow.\n2.  Maintaining a clear and consistent documentation pipeline is vital.\n3.  The bug in the Python/JavaScript documentation is a major concern.\n4.  LangChain’s documentation needs careful review and updates.\n5.  Ensure documentation is easily accessible and searchable across all channels.\n", "batch_number": 45, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in the embedded model's input processing that causes an exception when attempting to get the length of the `embeddings` using `get_len_safe_embeddings`. The problem is specifically triggered when the input data is a string, and the `tokenize` step uses this string as input, leading to an error.  The solution involves a self-contained example demonstrating the issue and a fix that addresses the input data format.", "final_category": "bug", "comments": [{"author": "CuberMessenger", "created_at": "2025-07-14T12:54:13Z", "body_clean": "Hi @Yse D, have you solved the problem? However, the given code seems to be inside the function [code] : [link] Could you provide a small, self contained example that reproduces the issue? That would help a lot."}, {"author": "open-swe[bot]", "created_at": "2025-07-18T13:43:17Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"1f063dd2 8d2b 68c1 be07 e5486b53e9ca\", \"threadId\": \"ba4a9334 dd31 480b 8d37 abdd542c4dca\" } </details"}, {"author": "Yse-D", "created_at": "2025-07-25T06:25:18Z", "body_clean": "embedding 只支持字符串input时：langchain openai/embeddings/base.py:479 会产生异常， 我将 input=tokens[i : i + chunk size], client kwargs 改为： input=texts, client kwargs 才能正常工作。"}]}, {"ollama_summary": "This issue reports a critical bug in LangChain that prevents the state of a tool function from being updated correctly, specifically when using a tool that checks the user's name. The bug stems from a misconfiguration within the tool's state management, leading to the user details object not being created in the state. The issue is currently reproducible with a minimal example, and the solution involves a change to the tool's state initialization to ensure the user details object is always created.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue is preventing the LangChain model from processing ToolMessages with image inputs. It seems to be a bug in LangChain that doesn't correctly interpret the `messages[3]` data, leading to an error.  The code attempts to return a structured representation of the image, but the agent isn't able to understand it, resulting in the `invalid request error`.  The solution involves returning a simpler, text-based representation of the image, and the code provided is a minimal, reproducible example demonstrating this.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-07-10T15:12:41Z", "body_clean": "Hi @Papadopulus, please see my answer to your query on the LangChain forums [here]( [link]"}]}, {"ollama_summary": "The GitHub issue highlights a critical bug in LangChain's `set_llm_cache` function, specifically when using the LangGraph prebuilt agent. When using this agent, the cache doesn't seem to be utilized, leading to repeated full LLM calls and a lack of reuse of cached responses. The issue involves a temporary modification to the input data passed to the cache lookup, which resolves the problem.  The code added to test this workaround is included as an example.", "final_category": "bug", "comments": [{"author": "louisoutin", "created_at": "2025-08-05T20:16:47Z", "body_clean": "+1"}, {"author": "zhiyuan-zhang0206", "created_at": "2025-08-12T22:16:48Z", "body_clean": "Same issue here, and I used this code as a workaround: [code] I think they should merge this in, as I don't see the reason why we need to use message ids while looking up caches."}, {"author": "mdrxy", "created_at": "2025-09-10T14:51:08Z", "body_clean": "This will be addressed in v1"}]}, {"ollama_summary": "The user is experiencing a Runtime Error within the Duckduckgo integration using LangChain, which persists after updating to the latest version.  The error is reproducible with a minimal example code, suggesting a bug within the LangChain library itself.  The user is providing a self-contained example to demonstrate the issue and is seeking a solution.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-07-09T13:44:21Z", "body_clean": "PR merged will be available in next release"}]}], "business_insights": ["Input data format inconsistencies are the primary driver of the embedded model’s error.", "The tokenize step’s reliance on the input string triggers the bug.", "A self-contained example is crucial for demonstrating the issue and fixing it.", "Fix involves a data format change to mitigate the input string error.", "Addressing the data format is essential for stable model operation."], "technical_insights": ["Embedded model input data format is critical.", "tokenize step's reliance on input string causes the bug.", "Self-contained example is vital for demonstration and solution.", "The bug is specifically triggered by string input.", "Data format change addresses the core problem."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Input data format inconsistencies are the primary driver of the embedded model’s error.\n2. The `tokenize` step’s reliance on the input string triggers the bug.\n3. A self-contained example is crucial for demonstrating the issue and fixing it.\n4. Fix involves a data format change to mitigate the input string error.\n5. Addressing the data format is essential for stable model operation.\n\nTECHNICAL INSIGHTS:\n1. Embedded model input data format is critical.\n2. `tokenize` step's reliance on input string causes the bug.\n3. Self-contained example is vital for demonstration and solution.\n4. The bug is specifically triggered by string input.\n5. Data format change addresses the core problem.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 46, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a critical bug in the LangChain library where the `String Evaluation with labeled criteria` scoring mechanism is failing to correctly assess the output of a specific function. The code provided is minimal and self-contained, but it doesn't meet the requirements of the system, and the bug is not resolved by updating the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "chandrani121189", "created_at": "2025-07-05T05:19:20Z", "body_clean": "Hi @vinodreddy bs Could you please elaborate on your criteria and input, reference as well as mentioned below. As per my code with my criterion as Conciseness the code is working well and providing the expected outcome [code] [code] {'reasoning': 'The criterion for this task is conciseness. The submission states \"The Eiffel Tower is in Paris.\" This is a concise response as it directly answers the question without any unnecessary information or words. It is as concise as the reference answer \"It is located in Paris.\" Therefore, the submission meets the criterion.\\n\\nY', 'value': 'Y', 'score': 1} We can discuss more one I get your criterion and test from my side."}, {"author": "eyurtsev", "created_at": "2025-07-06T03:20:42Z", "body_clean": "@chandrani121189 your API key was included by accident in the code snippet you shared. i edited the response to remove the API key, but please assume that the API key has been compromised already and revoke its permissions"}, {"author": "vinodreddy-bs", "created_at": "2025-07-07T17:20:14Z", "body_clean": "I am using correctness as the criteria. For the above issue I don't think so input or anything is required as it is a clear issue as why the Response is returned as Y but reasoning says not meeting the criteria. This tells that the submission doesn't meets the criteria [code] . My input is asking to verify whether the output AI performed browser navigation steps intact with the AI prompt that I provided and along with some expected data that I have passed in input. It contains a Web scenario workflow that has to set the departure and return flight dates on UI but actual is having only the return dates selection. So it's a clear failure Note: Can't share more details on what is going on in input and the output"}, {"author": "chandrani121189", "created_at": "2025-07-08T00:49:34Z", "body_clean": "Hi @vinodreddy bs Can you please try placing a definition for correctness and try. The magic is indeed in the way we match the results [code] Also I got a N in response after I changed the definition of correctness [code] [code] {'reasoning': 'The criterion for this task is the correctness of the submitted answer in relation to the reference answer. \\n\\nThe input asks for the location of the Eiffel Tower. \\n\\nThe submitted answer states that the Eiffel Tower is in Paris, which is the correct and factual answer. \\n\\nHowever, the reference answer states that the Eiffel Tower is in the USA, which is incorrect. \\n\\nTherefore, even though the submitted answer is factually correct, it does not match the reference answer. \\n\\nSo, based on the given criterion, the submitted answer does not meet the criteria. \\n\\nN', 'value': 'N', 'score': 0}"}, {"author": "imrrohitt", "created_at": "2025-07-09T15:10:58Z", "body_clean": "Hi @maintainers 👋, I'd like to take this issue and work on a fix. I've reviewed the problem and understand that it's related to the RunnableSequence not correctly passing kwargs to the final runnable in the chain. I’ve already explored the related source code and believe I can resolve it with minimal side effects. Could you please assign it to me?"}]}, {"ollama_summary": "The issue reports a bug in LangChain where the price of `o3` (a key component) is incorrectly set to 10$ instead of the expected 2$. This affects various components like completions and cache, and the code provides a minimal reproducible example to demonstrate the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "The Langchain team is migrating away from the deprecated PGVector library, impacting the documentation and tutorials. The documentation needs to be updated to use the new PGVectorStore, and the developer is currently using the outdated 0.0.14 version.  The focus is on migrating to the newer PGVectorStore for compatibility and to leverage the latest features.", "final_category": "other", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue involves a frontend component needing to refactor a specific line of code in `smith/src/Pages/Settings/OrganizationApiKeys.tsx` to utilize Day.js for date calculations.  It’s currently a self-called function, requiring a component-based implementation to improve maintainability and readability.  The goal is to replace the existing function with a new component that handles the date calculations.", "final_category": "other", "comments": [{"author": "langcarl[bot]", "created_at": "2025-07-02T02:14:24Z", "body_clean": "This issue has been flagged as spam and will be closed. Please tag @ccurme if you feel this was done in error."}, {"author": "eric-langchain", "created_at": "2025-07-02T02:31:41Z", "body_clean": "i opened this issue in the wrong repo"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's tool schema generation, specifically missing crucial field descriptions for certain tool arguments. The bug is currently not resolved by updating the latest stable version of LangChain, and the developer has provided a minimal, reproducible example to demonstrate the problem.  The issue is impacting the ability to correctly pass field descriptions to LLMs, requiring the developer to manually add docstrings to pydantic models.", "final_category": "bug", "comments": [{"author": "sahiljagtap08", "created_at": "2025-07-02T03:09:32Z", "body_clean": "working on it!"}, {"author": "sahiljagtap08", "created_at": "2025-07-02T07:49:31Z", "body_clean": "its a bit pain in the butt , but trust me it will be worth it fixing this bug. <img width=\"243\" alt=\"Image\" src=\" [link] /"}, {"author": "VedankPurohit", "created_at": "2025-07-02T09:05:27Z", "body_clean": "@sahiljagtap08 How are you planing to solve this, would you have it so the Field description overwrites the doc string?"}, {"author": "sahiljagtap08", "created_at": "2025-07-02T17:28:40Z", "body_clean": "When field.description is None (which it is for parameter fields), it doesn't fall back to the field type's docstring!"}, {"author": "sahiljagtap08", "created_at": "2025-07-02T17:31:48Z", "body_clean": "@VedankPurohit Great question! Our approach is to use a fallback hierarchy for field descriptions, not overwriting: 1. First priority : Explicit [code] (if provided) 2. Second priority : Model docstring (if Field description is None/missing) 3. Fallback : Generic description based on type name So the Field description would take precedence over the docstring, not the other way around. The docstring only gets used when there's no explicit Field description. here's the logic we're implementing: [code] This way: Explicit Field descriptions are preserved (highest priority) Model docstrings provide fallback descriptions (when Field description is missing) Backward compatibility is maintained AI gets better context for tool usage The current bug is that when Field description is None, it stays None instead of falling back to the model's docstring, which leaves the AI without any context about what the parameter represents. Does this approach make sense ?"}, {"author": "sahiljagtap08", "created_at": "2025-07-02T17:50:54Z", "body_clean": "@VedankPurohit lol i think i spent quite a bit of time debugging through the codebase. After seeing your PR, I have to say nice work! Your approach in function calling.py with the get schema from model function is really elegant. I was going down the rabbit hole of trying to fix it in utils/pydantic.py at the create subset model level, but your solution at the schema generation level makes a lot more sense."}, {"author": "VedankPurohit", "created_at": "2025-07-03T02:57:31Z", "body_clean": "@VedankPurohit lol i think i spent quite a bit of time debugging through the codebase. After seeing your PR, I have to say nice work! Your approach in function calling.py with the get schema from model function is really elegant. I was going down the rabbit hole of trying to fix it in utils/pydantic.py at the create subset model level, but your solution at the schema generation level makes a lot more sense. Thanks! I actually spent quite a bit of time digging through pydantic.py as well before stepping back to look at the full pipeline, that’s when the idea to handle it in function calling.py came up. That said, while I’ve raised the PR, I’m still unsure if this is the ideal fix. Currently, the solution falls back to the parent field’s description only when the child doesn’t have its own docstring. I’m not certain if that fallback behavior is what the maintainers would prefer. What do you think, should we always overwrite the child’s description with the parent’s, or only do it as a fallback?"}, {"author": "Euni-Bot", "created_at": "2025-07-14T00:52:48Z", "body_clean": "Thank you for reporting this issue and providing such a detailed example. Our team has investigated the problem and implemented a fix. Understanding the Issue The issue occurs when generating tool schemas for LLM instances. Specifically, field descriptions for Pydantic model fields are not being properly included in the schema when accessed through [code] . This happens because the current implementation doesn't fall back to the model's docstring when a field description is missing. Implemented Solution We've modified the [code] function in [code] to include a fallback hierarchy for field descriptions: 1. First priority : Explicit [code] (if provided) 2. Second priority : Model docstring (if Field description is None/missing) 3. Fallback : Generic description based on type name Here's the change we made: [code] [code] Field [code] patch index=1 ) <details <summary <code libs/core/langchain core/utils/pydantic.py</code </summary [code] </details [Promethues AI]( [link] Response, Please Review Carefully."}, {"author": "leonardozilli", "created_at": "2025-08-11T14:28:08Z", "body_clean": "I'm interested in a fix for this. I think generally the fallback hierarchy proposed by @sahiljagtap08 seems to me like it could be the most flexible, since it would allow to provide more specific context for instances of the nested models (e.g. think about using the same nested model twice in a main model but for different purposes). Looking at the PR ( 31826) from @VedankPurohit, correct me if I'm wrong but I’m wondering if a full new recursive function to construct the schema is necessary, since [ [code] ]( [link] (and [ [code] ]( [link] specifically) already handles that part. I tried a [small change]( [link] that follows the fallback hierarchy proposed by @sahiljagtap08 (the first 2 levels at least, i'm not sure about that Generic description third point) and that seems to work for my use case, and I would happy to include it in a PR in case it’s helpful to move this forward soon. Note that this fix also allows other field parameters (such as [code] and [code] ) in addition to [code] to be included in the final function schema. Not sure if that's preferable or not, so I’d be interested in hearing thoughts on that."}]}], "business_insights": ["LangChain’s String Evaluation with labeled criteria scoring mechanism is failing, requiring immediate investigation and potentially a revised version.", "The bug’s impact is widespread, affecting multiple components – completion, cache, and potentially more.", "The bug’s root cause is likely a subtle coding error within the scoring logic, requiring deeper analysis."], "technical_insights": ["LangChain’s version is unstable, impacting core functionality.", "API key inclusion in code snippets is a recurring problem, necessitating robust code review and automated checks.", "PGVector library migration is a significant change, impacting documentation and developer workflows."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s `String Evaluation with labeled criteria` scoring mechanism is failing, requiring immediate investigation and potentially a revised version.\n2. The bug’s impact is widespread, affecting multiple components – completion, cache, and potentially more.\n3. The bug’s root cause is likely a subtle coding error within the scoring logic, requiring deeper analysis.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s version is unstable, impacting core functionality.\n2. API key inclusion in code snippets is a recurring problem, necessitating robust code review and automated checks.\n3. PGVector library migration is a significant change, impacting documentation and developer workflows.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 47, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a critical bug in the `maximal_marginal_relevance()` function that silently returns incorrect results when encountering `[code]` within the input data. This issue impacts vector retrieval and can lead to silent failures and incorrect results, potentially causing problems with downstream processes.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in LangChain that prevents the `secrets_map` from correctly replacing placeholder values in plain dictionary keys, leading to potential security vulnerabilities and inconsistent behavior.  The issue is reproducible with a minimal example and is currently not resolved by updating the LangChain version.", "final_category": "bug", "comments": [{"author": "akritipriyaa18", "created_at": "2025-07-07T17:56:09Z", "body_clean": "“Hi, I would love to work on this. Can I take this up?”"}, {"author": "Alioth99", "created_at": "2025-07-08T11:45:13Z", "body_clean": "Sure, feel free to take it on!"}, {"author": "npage902", "created_at": "2025-10-16T21:17:38Z", "body_clean": "@mdrxy I would like to work on this, if you don't mind."}]}, {"ollama_summary": "This issue reports a critical bug in the `EvaluationResult.feedback_config` module that silently drops dictionary fields during data processing, leading to unpredictable behavior and potential data loss. The bug is currently present in a specific LangChain integration, and attempts to resolve it through version updates have been unsuccessful.", "final_category": "bug", "comments": [{"author": "SyedBaqarAbbas", "created_at": "2025-07-03T13:09:29Z", "body_clean": "The [code] class is defined as follows [link to code]( [link] [code] As long as your dictionary contains any one of the fields present in [code] class, your dictionary's data relevant to the FeedbackConfig class will be preserved unless you violate its type checking. Example 1 Violates the literal condition for [code] [code] Output: [code] Example 2 Follows the literal condition for [code] [code] Output: [code] Since this follows the conditions set in [code] , your extra data is removed. Previously, your data was discarded because the parameter [code] is set to [code] in [code]"}, {"author": "Alioth99", "created_at": "2025-07-08T11:41:42Z", "body_clean": "Thanks, I get it now. But I still think this is a pretty misleading design — at the very least, it doesn’t match the documented behavior: [link]( [link] The param is typed as [code] , but it doesn't truly accept arbitrary dicts. Instead, it silently tries to coerce them into a [code] , without any warning or error if the fields don't match."}, {"author": "kanishk2106", "created_at": "2025-09-22T22:09:02Z", "body_clean": "Hi, I’d like to work on this issue as my first contribution to LangChain. From the discussion and examples, I understand the problem is that EvaluationResult.feedback config silently discards unknown dict fields, which feels misleading. My plan is to: Adjust the implementation so that passing unsupported keys raises a clear ValueError (instead of silently discarding), Add tests to confirm both valid and invalid cases are handled properly, and Update the documentation to clarify the intended behavior. Please let me know if it’s okay for me to take this up. Thanks!"}]}, {"ollama_summary": "This issue addresses a critical bug in LangChain that causes an agent invocation to fail due to an incorrect message format. The code incorrectly uses `HumanMessage` objects when it should be using a tuple of `('user', 'content')`. The fix involves removing the MessageGraph wrapper, updating the agent invocation to use the correct tuple format, and ensuring the agent returns the expected data structure.  The solution involves a restructuring of the agent setup to align with LangGraph's design, resolving the core issue of schema incompatibility.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-07-04T12:54:27Z", "body_clean": "[code] creates its own [code] with a schema that uses the keys [code] and [code] . However, in your current implementation, you're trying to use it as a child node inside a parent [code] that uses a different schema—with only the key [code] . You have two options to fix this: 1. Use the agent directly with its expected schema: [code] 2. Align the schemas of both the agent and the main graph: Here’s an example using a unified schema ( [code] ) that includes a [code] key: [code]"}, {"author": "open-swe[bot]", "created_at": "2025-07-18T13:49:48Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"1f063de1 1d6c 6d53 8386 d56712c2c5fd\", \"threadId\": \"d6b4cb3f caf9 4c0d a2f8 b587c9a9ce53\" } </details"}, {"author": "VivekMalipatel", "created_at": "2025-08-15T17:13:42Z", "body_clean": "Summary After updating my langgraph and langchain dependencies to the latest stable versions, I started encountering the following error during streaming: 12:01:41 api.routes.chat ERROR Streaming error: Message dict must contain 'role' and 'content' keys, got { 'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': { 'content': 'who is obama', 'type': 'human', 'id': 'ee832276 4cda 4d6e aacd b996504097a7' } } ⸻ Code <details <summary <code app/agents/base agents/base agent.py</code </summary import typing import asyncio import logging import json from dataclasses import dataclass, field from functools import wraps from typing import Any, Sequence, Union, Optional, Callable, AsyncIterator, Literal from langgraph.typing import ContextT, InputT, OutputT, StateT from langgraph.types import ( All, Checkpointer, Command, ) from langgraph.graph import StateGraph, START, END from langgraph.graph.state import CompiledStateGraph from langgraph.prebuilt import ToolNode, tools condition from langgraph.store.base import BaseStore, IndexConfig from langgraph.types import All, StreamMode, Durability from langgraph.config import get store from langgraph.cache.base import BaseCache from langchain core.tools import BaseTool from langchain core.runnables import RunnableConfig from langchain core.runnables.schema import StreamEvent from langchain core.runnables.utils import Output from langchain core.runnables.base import Input from langchain core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage from langgraph.config import get stream writer from openai import BaseModel from agents.utils import load prompt from pathlib import Path from llm.llm import LLM from embed.embed import JinaEmbeddings from agents.base agents.base state import BaseState from agents.base agents.memory.base checkpointer import BaseMemorySaver from agents.base agents.memory.base store import BaseMemoryStore from agents.base agents.utils import ( optimize messages for tokens, get messages to save, generate message id, should trim state, find second last ai index ) from db.redis import redis from config import config as envconfig @dataclass(frozen=True) class AgentConfig: model kwargs: dict[str, Any] = field(default factory=dict) vlm kwargs: dict[str, Any] = field(default factory=dict) node kwargs: dict[str, Any] = field(default factory=dict) debug: bool = False def requires compile(fn): @wraps(fn) async def wrapper(self, args, kwargs): if not self. compiled graph or self. needs compilation: await self.compile() self. needs compilation = False return await fn(self, args, kwargs) return wrapper def requires compile generator(fn): @wraps(fn) async def wrapper(self, args, kwargs): if not self. compiled graph or self. needs compilation: await self.compile() self. needs compilation = False async for item in fn(self, args, kwargs): yield item return wrapper class BaseAgent: def init (self, prompt: Optional[str] = \"You are a helpful assistant.\", , config: RunnableConfig, model kwargs: Optional[dict[str, Any]] = None, vlm kwargs: Optional[dict[str, Any]] = None, node kwargs: Optional[dict[str, Any]] = None, recursion limit: Optional[int] = 25, debug: bool = False): if not config: raise ValueError(\"Runnable Config with user id, thread id, org id and/or checkpoint id must be provided.\") self. config = AgentConfig( model kwargs=model kwargs or {}, vlm kwargs=vlm kwargs or {}, node kwargs=node kwargs or {}, debug=debug ) self. compiled graph: Optional[CompiledStateGraph] = None self. llm = LLM(self. config.model kwargs, self. config.vlm kwargs) self. tools: Sequence[Union[typing.Dict[str, Any], type, Callable, BaseTool]] = [] self. logger = logging.getLogger( name ) self. needs compilation = False self. memory tasks: list[asyncio.Task] = [] self. checkpointer = None self. store = None self. interrupt before = None self. interrupt after = None self. name = None self. is structured output = False self. resursion limit = recursion limit self.config = config if prompt is None: prompt = \"You are a helpful assistant.\" base prompt = load prompt(\"base agent\", base dir=Path( file ).parent) self.prompt = f\"User ID : {config['configurable']['user id']}, Org ID : {config['configurable']['org id']}\" + prompt + base prompt def validate tools(self, tools: Sequence[Union[typing.Dict[str, Any], type, Callable, BaseTool]]): for tool in tools: if hasattr(tool, 'run') or hasattr(tool, 'arun') or isinstance(tool, BaseTool): continue elif callable(tool): continue elif isinstance(tool, dict): continue else: raise ValueError(f\"Invalid tool: {tool}. Tools must be callable, BaseTool instances, or dictionaries.\") def with structured output(self, schema: Union[dict, type[BaseModel]], kwargs: Any) 'BaseAgent': self. llm = self. llm.with structured output(schema=schema, kwargs) self. is structured output = True return self def bind tools(self, tools: Sequence[Union[typing.Dict[str, Any], type, Callable, BaseTool]], , tool choice: Optional[Union[str]] = None, kwargs: Any) 'BaseAgent': self. validate tools(tools) self. tools = tools self. llm = self. llm.bind tools(tools, tool choice=tool choice, kwargs) self. needs compilation = True return self async def remember(self, state: BaseState, config: RunnableConfig): user id = config[\"configurable\"][\"user id\"] org id = config[\"configurable\"][\"org id\"] messages = state[\"messages\"] messages to save = get messages to save(messages) task = asyncio.create task(self. remember background(user id, org id, messages to save, config)) self. memory tasks.append(task) if should trim state(messages): second last ai index = find second last ai index(messages) if second last ai index != 1: return {\"messages\": messages[second last ai index:]} return state async def remember background(self, user id: str, org id: str, messages to save: list, config: RunnableConfig): try: namespace = (\"memories\", user id) checkpoint id = config.get(\"checkpoint id\") tasks = [] for i, message in enumerate(messages to save): message id = generate message id(checkpoint id, org id, user id, i) task = asyncio.create task(get store().aput( namespace, message id, {\"data\": message.content} )) tasks.append(task) if tasks: await asyncio.gather( tasks) except Exception as e: self. logger.error(f\"Background remember task failed: {e}\") async def wait for memory tasks(self): if self. memory tasks: try: await asyncio.gather( self. memory tasks, return exceptions=True) self. logger.debug(f\"Completed {len(self. memory tasks)} memory tasks\") except Exception as e: self. logger.error(f\"Error waiting for memory tasks: {e}\") finally: self. memory tasks.clear() async def retrieve memory(self, state: BaseState, config: RunnableConfig): user id = config[\"configurable\"][\"user id\"] org id = config[\"configurable\"][\"org id\"] last message: BaseMessage = state[\"messages\"][ 1] writer = get stream writer() writer(f\"Retrieving memory.....\\n\\n\") store = get store() async def get user memory(): namespace = (\"memories\", user id) try: search query = last message.content result = await store.asearch(namespace, query=search query, limit=envconfig.MAX MEMORY SEARCH RESULTS) return result except Exception as e: self. logger.error(f\"User memory search failed: {e}\") return [] async def get org memory(): namespace = (\"memories\", org id) try: search query = last message.content result = await store.asearch(namespace, query=search query, limit=envconfig.MAX MEMORY SEARCH RESULTS) return result except Exception as e: self. logger.error(f\"Org memory search failed: {e}\") return [] user memory task = asyncio.create task(get user memory()) org memory task = asyncio.create task(get org memory()) user memory = await user memory task org memory = await org memory task if not user memory and not org memory: writer(f\"Memory retrieved......\\n\\n\") return [] memory messages = [] async def process user memory(): if not user memory: return [SystemMessage(content=\"No user memory found.\")] return [SystemMessage(content=user msg.value.get(\"data\", \"\")) for user msg in user memory] async def process org memory(): if not org memory: return [SystemMessage(content=\"No organization memory found.\")] return [SystemMessage(content=org msg.value.get(\"data\", \"\")) for org msg in org memory] user messages task = asyncio.create task(process user memory()) org messages task = asyncio.create task(process org memory()) user messages = await user messages task org messages = await org messages task memory messages.extend(user messages) memory messages.extend(org messages) writer(f\"Memory retrieved......\\n\\n\") return memory messages async def llm node(self, state: BaseState, config: RunnableConfig): memory messages = await self.retrieve memory(state, config) system messages = [SystemMessage(content=self.prompt)] memory wrapper = [ SystemMessage(content=\"<Retrieved Messages from Memory Start \"), memory messages, SystemMessage(content=\"<Retrieved Messages from Memory End \") ] state messages = state[\"messages\"] optimized system, optimized memory, optimized state, was optimized, trimmed messages = optimize messages for tokens( system messages, memory wrapper, state messages, envconfig.MAX STATE TOKENS, self. logger ) if trimmed messages: user id = config[\"configurable\"][\"user id\"] org id = config[\"configurable\"][\"org id\"] self. logger.debug(f\"Storing {len(trimmed messages)} trimmed messages in background\") task = asyncio.create task(self. remember background(user id, org id, trimmed messages, config)) self. memory tasks.append(task) messages = optimized system + optimized memory + optimized state response = await self. llm.ainvoke(messages, self. config.node kwargs) if self. is structured output: response = AIMessage(content=json.dumps(response)) if was optimized and optimized state != state messages: self. logger.debug(f\"Returning optimized state: {len(optimized state)} messages + new response\") return {\"messages\": optimized state + [response]} return {\"messages\": [response]} def compile graph(self, has tools: bool, compile kwargs) CompiledStateGraph[StateT, ContextT, InputT, OutputT]: graph builder = StateGraph(BaseState) llm node name = f\"llm${self.config.get('configurable').get('user id')}\" graph builder.add node(llm node name, self.llm node) graph builder.add node(\"remember node\", self.remember) if has tools: graph builder.add node(\"tools\", ToolNode(self. tools)) graph builder.add edge(START, llm node name) graph builder.add conditional edges( llm node name, tools condition, {\"tools\": \"tools\", \" end \": \"remember node\"} ) graph builder.add edge(\"tools\", llm node name) graph builder.add edge(\"remember node\", END) else: graph builder.add edge(START, llm node name) graph builder.add edge(llm node name, \"remember node\") graph builder.add edge(\"remember node\", END) compiled graph = graph builder.compile( compile kwargs) return compiled graph async def compile(self, checkpointer: Checkpointer = None, , cache: BaseCache | None = None, store: BaseStore | None = None, interrupt before: All | list[str] | None = None, interrupt after: All | list[str] | None = None, debug: bool = False, name: str | None = None) CompiledStateGraph[StateT, ContextT, InputT, OutputT]: self. checkpointer = checkpointer if checkpointer is None: checkpointer = BaseMemorySaver(redis client=redis.get session()) self. checkpointer = checkpointer await self. checkpointer.asetup() self. store = store if store is None: index config: IndexConfig = { \"dims\": envconfig.MULTIMODEL EMBEDDING MODEL DIMS, \"embed\": JinaEmbeddings( model=envconfig.MULTIMODEL EMBEDDING MODEL, base url=envconfig.OPENAI BASE URL, api key=envconfig.OPENAI API KEY ), \"ann index config\": {\"vector type\": \"vector\"}, \"distance type\": \"cosine\", } store = BaseMemoryStore( redis client=redis.get session(), index=index config, ) self. store = store await self. store.setup() self. interrupt before = interrupt before self. interrupt after = interrupt after self. name = name compile kwargs = { \"checkpointer\": checkpointer, \"cache\": cache, \"store\": store, \"interrupt before\": interrupt before, \"interrupt after\": interrupt after, \"debug\": debug if debug is not None else self. config.info, \"name\": name } self. compiled graph = self. compile graph(bool(self. tools), compile kwargs) return self @requires compile async def ainvoke(self, input: InputT | Command | None, config: RunnableConfig | None = None, , context: ContextT | None = None, stream mode: StreamMode = \"values\", print mode: StreamMode | Sequence[StreamMode] = (), output keys: str | Sequence[str] | None = None, interrupt before: All | Sequence[str] | None = None, interrupt after: All | Sequence[str] | None = None, durability: Durability | None = None, kwargs: Any ) dict[str, Any] | Any: config[\"recursion limit\"] = self. resursion limit TODO : Temperorily disable thinking if \"extra body\" not in config: config[\"extra body\"] = {} if \"chat template kwargs\" not in config[\"extra body\"]: config[\"extra body\"][\"chat template kwargs\"] = {} config[\"extra body\"][\"chat template kwargs\"][\"enable thinking\"]=True config[\"extra body\"][\"top k\"]=envconfig.REASONING LLM TOP K config[\"extra body\"][\"min p\"]=envconfig.REASONING LLM MIN P config[\"extra body\"][\"repetition penalty\"] = envconfig.REASONING LLM REPETITION PENALTY result = await self. compiled graph.ainvoke( input, config=config, context=context, stream mode=stream mode, output keys=output keys, print mode=print mode, interrupt before=interrupt before, interrupt after=interrupt after, durability=durability, kwargs ) return result @requires compile generator async def astream(self, input: InputT | Command | None, config: RunnableConfig | None = None, , context: ContextT | None = None, stream mode: StreamMode | Sequence[StreamMode] | None = None, print mode: StreamMode | Sequence[StreamMode] = (), output keys: str | Sequence[str] | None = None, interrupt before: All | Sequence[str] | None = None, interrupt after: All | Sequence[str] | None = None, durability: Durability | None = None, subgraphs: bool = False, debug: bool | None = None, kwargs: Any) AsyncIterator[dict[str, Any] | Any]: if isinstance(stream mode, str): async for chunk in self. compiled graph.astream( input, config=config, context=context, stream mode=stream mode, print mode=print mode, output keys=output keys, interrupt before=interrupt before, interrupt after=interrupt after, durability=durability, debug=debug, subgraphs=subgraphs, kwargs ): yield chunk elif isinstance(stream mode, list): async for stream mode, chunk in self. compiled graph.astream( input, config=config, context=context, stream mode=stream mode, print mode=print mode, output keys=output keys, interrupt before=interrupt before, interrupt after=interrupt after, durability=durability, debug=debug, subgraphs=subgraphs, kwargs ): yield stream mode, chunk @requires compile generator async def astream events(self, input: Any, config: Optional[RunnableConfig] = None, , version: Literal[\"v1\", \"v2\"] = \"v2\", include names: Optional[Sequence[str]] = None, include types: Optional[Sequence[str]] = None, include tags: Optional[Sequence[str]] = None, exclude names: Optional[Sequence[str]] = None, exclude types: Optional[Sequence[str]] = None, exclude tags: Optional[Sequence[str]] = None, kwargs: Any) AsyncIterator[StreamEvent]: async for event in self. compiled graph.astream events( input, config=config, version=version, include names=include names, include types=include types, include tags=include tags, exclude names=exclude names, exclude types=exclude types, exclude tags=exclude tags, kwargs ): yield event @requires compile async def abatch(self, inputs: list[Input], config: Optional[Union[RunnableConfig, list[RunnableConfig]]] = None, , return exceptions: bool = False, kwargs: Optional[Any]) list[Output]: return await self. compiled graph.abatch( inputs, config=config, return exceptions=return exceptions, kwargs ) @property def graph(self) Optional[CompiledStateGraph]: \"\"\"Access the compiled graph. Returns None if not compiled.\"\"\" return self. compiled graph if name == \" main \": async def test base agent(): output lines = [] config = { \"configurable\": { \"thread id\": \"test thread1\", \"user id\": \"test user1\", \"org id\": \"test org1\" } } base agent = BaseAgent( model kwargs={}, vlm kwargs={}, node kwargs={}, debug=False, config=config ) compiled agent: BaseAgent = await base agent.compile(name=\"test agent\") async def capture checkpoints(round name): output lines.append(f\"\\n=== CHECKPOINTS AFTER {round name} ===\") try: checkpoints = [checkpoint async for checkpoint in compiled agent. checkpointer.alist(config)] output lines.append(f\"Total checkpoints: {len(checkpoints)}\") for i, checkpoint tuple in enumerate(checkpoints): output lines.append(f\"\\n Checkpoint {i+1} \") output lines.append(str(checkpoint tuple)) except Exception as e: output lines.append(f\"Error capturing checkpoints: {e}\") output lines.append(\"=== Testing Immutable BaseAgent ===\") await capture checkpoints(\"INITIAL\") output lines.append(\"\\n Round 1: Initial image question \") round1 input = { \"messages\": [ HumanMessage(content=[ {\"type\": \"text\", \"text\": \"What do you see in this image?\"}, {\"type\": \"image url\", \"image url\": {\"url\": \" [link] ]) ], \"user id\": config[\"configurable\"][\"user id\"], \"org id\": config[\"configurable\"][\"org id\"] } result1 = await compiled agent.ainvoke(round1 input, config=config) print(f\"Result 1: {result1}\") output lines.append(f\"Result 1: {result1}\") await capture checkpoints(\"ROUND 1\") output lines.append(\"\\n Round 2: Follow up about colors \") round2 input = {\"messages\": [HumanMessage(content=\"Can you describe the colors in more detail?\")]} result2 = await compiled agent.ainvoke(round2 input, config=config) print(f\"Result 2: {result2}\") output lines.append(f\"Result 2: {result2}\") with open(\"single shot output.txt\", \"w\", encoding=\"utf 8\") as f: f.write(\"\\n\".join(output lines)) print(f\"\\nOutput saved to single shot output.txt ({len(output lines)} lines)\") asyncio.run(test base agent()) </details ⸻ <details <summary <code app/agents/base agents/base state.py</code </summary from typing extensions import TypedDict from typing import Annotated from langgraph.graph.message import add messages from langchain core.messages import AnyMessage class BaseState(TypedDict): messages: Annotated[list[AnyMessage], add messages] </details ⸻ <details <summary <code app/agents/base agents/memory/base checkpointer.py</code </summary from langgraph.checkpoint.redis import AsyncRedisSaver from redis.asyncio import Redis as AsyncRedis from redis.asyncio.cluster import RedisCluster as AsyncRedisCluster from typing import Optional, Union, Dict, Any class BaseMemorySaver(AsyncRedisSaver): def init ( self, redis url: Optional[str] = None, , redis client: Optional[Union[AsyncRedis, AsyncRedisCluster]] = None, connection args: Optional[Dict[str, Any]] = None, ttl: Optional[Dict[str, Any]] = None, ) None: super(). init ( redis url=redis url, redis client=redis client, connection args=connection args, ttl=ttl, ) </details ⸻ <details <summary <code app/agents/base agents/memory/base store.py</code </summary from langgraph.store.redis import AsyncRedisStore from langgraph.store.base import IndexConfig, TTLConfig from redis.asyncio import Redis as AsyncRedis from typing import Optional, Any class BaseMemoryStore(AsyncRedisStore): def init ( self, redis url: Optional[str] = None, , redis client: Optional[AsyncRedis] = None, index: Optional[IndexConfig] = None, connection args: Optional[dict[str, Any]] = None, ttl: Optional[dict[str, Any]] = None, cluster mode: Optional[bool] = None, ) None: super(). init ( redis url=redis url, redis client=redis client, index=index, connection args=connection args, ttl=ttl, cluster mode=cluster mode ) </details ⸻ Environment I am using the latest stable versions of: fastapi uvicorn[standard] pydantic pydantic settings openai langgraph langchain core langchain openai typing extensions redis[hiredis] redisvl langgraph checkpoint langchain community langgraph checkpoint redis scrapegraphai langchain mcp adapters tiktoken"}, {"author": "filipehsilva", "created_at": "2025-08-15T20:40:01Z", "body_clean": "Summary After updating my langgraph and langchain dependencies to the latest stable versions, I started encountering the following error during streaming: 12:01:41 api.routes.chat ERROR Streaming error: Message dict must contain 'role' and 'content' keys, got { 'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': { 'content': 'who is obama', 'type': 'human', 'id': 'ee832276 4cda 4d6e aacd b996504097a7' } } ⸻ Code [code] ⸻ [code] ⸻ [code] ⸻ [code] ⸻ Environment I am using the latest stable versions of: fastapi uvicorn[standard] pydantic pydantic settings openai langgraph langchain core langchain openai typing extensions redis[hiredis] redisvl langgraph checkpoint langchain community langgraph checkpoint redis scrapegraphai langchain mcp adapters tiktoken Same error here!"}, {"author": "VivekMalipatel", "created_at": "2025-08-18T06:18:13Z", "body_clean": "I found that the issue was actually from the Checkpointer. langgraph checkpoint redis 0.1.1 has fixed this and I don't have that issue anymore"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\nThe issue is a request to fix a documentation page for the `google_vertexai` library due to a lack of descriptive titles and a missing link to the relevant documentation.  The documentation page currently lacks a title and doesn't provide context for the content, leading to a lack of clarity for users.  The issue proposes updating the title and adding a link to the documentation.", "final_category": "other", "comments": []}], "business_insights": ["Correct documentation improves user experience and reduces support requests.", "Clear documentation is crucial for adoption of new libraries.", "Addressing this issue will enhance user satisfaction and library adoption.", "Streamlining documentation is a cost-effective improvement.", "Improved user experience directly impacts business value."], "technical_insights": ["Missing links hinder user navigation and discoverability.", "Inconsistent documentation creates confusion and errors.", "Documentation quality directly affects user adoption.", "Lack of clear titles reduces user understanding.", "Accurate documentation is vital for usability and maintainability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correct documentation improves user experience and reduces support requests.\n2. Clear documentation is crucial for adoption of new libraries.\n3. Addressing this issue will enhance user satisfaction and library adoption.\n4. Streamlining documentation is a cost-effective improvement.\n5. Improved user experience directly impacts business value.\n\nTECHNICAL INSIGHTS:\n1. Missing links hinder user navigation and discoverability.\n2. Inconsistent documentation creates confusion and errors.\n3. Documentation quality directly affects user adoption.\n4. Lack of clear titles reduces user understanding.\n5. Accurate documentation is vital for usability and maintainability.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 48, "num_issues": 5}
{"batch_issues": [{"ollama_summary": ".\n\n.", "final_category": "other", "comments": [{"author": "langcarl[bot]", "created_at": "2025-06-29T18:03:25Z", "body_clean": "This issue has been flagged as spam and will be closed. Please tag @ccurme if you feel this was done in error."}]}, {"ollama_summary": ".\n\n.", "final_category": "other", "comments": []}, {"ollama_summary": "The issue reports a bug in Google’s `include_thoughts` setting that prevents the correct generation of thinking tokens when using chains with Gemini 2.5 Pro.  The bug only manifests in chains, not with the core model, and is not resolved by updating LangChain. A self-contained, reproducible example demonstrates the problem – a chain invocation returns a result without thinking tokens, despite the `include_thoughts` attribute being correctly set.", "final_category": "bug", "comments": [{"author": "chandrani121189", "created_at": "2025-06-28T05:36:24Z", "body_clean": "Hi @FilippTrigub @langcarl , I tried the scenario with the versions you provided but unfortunately found no issues. But to my surprise the streaming parameter was not present, instead I had to use disable streaming. Both did not give any thought tokens Please find the code below [code] and find the output as [code] [code] Requirement.txt content goes below [code] If you find this useful please feel free to leave a recommendation on Linekdin [link]"}, {"author": "FilippTrigub", "created_at": "2025-06-28T14:23:54Z", "body_clean": "It is the scratchpad, I think. Remioving it removed the \"thinking tokens\". These were most likely not actually the reasoning tokens, but bad output. Thanks!"}, {"author": "chandrani121189", "created_at": "2025-06-29T04:55:49Z", "body_clean": "Hi @FilippTrigub Shall we close this issue then?"}]}, {"ollama_summary": "The issue proposes clarifying the purpose of the `disable_streaming` parameter in the documentation, as it’s currently unclear why it’s used. The proposed solution is to expand the docstring or create a separate page explaining its function. This addresses a potential lack of understanding regarding the parameter’s intended use.", "final_category": "other", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a bug in LangChain where the `invoke()` method returns the full image response, including the base64 data, even when it should not. This inconsistency affects the behavior of the code, specifically when using `invoke()` and `ainvoke()`.  The solution involves ensuring the `invoke()` and `ainvoke()` methods return the same complete result as the `execute()` method, allowing access to the base64 data field.", "final_category": "bug", "comments": [{"author": "taylorn-ai", "created_at": "2025-06-26T23:22:22Z", "body_clean": "Closing as I have opened in the [code] repo"}]}], "business_insights": ["Documentation clarity is key to avoid confusion and potential bugs.", "Consistent API behavior across different parts of the LangChain ecosystem is crucial.", "Understanding the invoke() and ainvoke() methods’ roles is vital.", "Addressing documentation gaps proactively prevents future issues.", "Clear and concise documentation minimizes ambiguity."], "technical_insights": ["invoke() and ainvoke() methods must return complete results.", "disable_streaming parameter requires precise documentation.", "Base64 data retrieval should be consistent across the entire process.", "LangChain’s core logic needs to be aligned with the documented behavior.", "API inconsistency impacts code stability and debugging."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Documentation clarity is key to avoid confusion and potential bugs.\n2. Consistent API behavior across different parts of the LangChain ecosystem is crucial.\n3. Understanding the `invoke()` and `ainvoke()` methods’ roles is vital.\n4. Addressing documentation gaps proactively prevents future issues.\n5. Clear and concise documentation minimizes ambiguity.\n\nTECHNICAL INSIGHTS:\n1. `invoke()` and `ainvoke()` methods must return complete results.\n2. `disable_streaming` parameter requires precise documentation.\n3. Base64 data retrieval should be consistent across the entire process.\n4. LangChain’s core logic needs to be aligned with the documented behavior.\n5. API inconsistency impacts code stability and debugging.\n\n", "batch_number": 49, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue is triggered by a bug in LangChain that causes a multi-tool handoff failure when multiple tools are involved in a chain of operations. The problem manifests as an exception and stack trace related to the `langgraph supervisor py` feature, specifically when more than one tool is used.  The issue is reproducible with a minimal example code and is currently being addressed by the maintainers, but it's a significant bug impacting the core functionality of LangChain.", "final_category": "bug", "comments": [{"author": "a595859893", "created_at": "2025-06-26T19:41:05Z", "body_clean": "example code have some mistake... ignore it"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a \"ValidationError\" in Azure OpenAI Embeddings when the `OPENAI_API_BASE` variable is set, causing an error when attempting to instantiate the LangChain model.  The problem is not resolved by updating LangChain, and the developer has provided a self-contained, reproducible example demonstrating the error.  The error specifically indicates the need to specify the API endpoint via the `OPENAI_API_BASE` variable, which is already present in the code.", "final_category": "bug", "comments": []}, {"ollama_summary": "Perplexity is experiencing a bug where the metadata parsing for its model fails to correctly extract information from the chat model, resulting in an error. The issue appears to be a problem within LangChain and not directly coded, and a minimal, reproducible example has been provided.  The fix involves updating to the latest stable version of LangChain, but the bug persists.", "final_category": "bug", "comments": [{"author": "eugeneo17", "created_at": "2025-07-17T17:23:15Z", "body_clean": "I'd like to take this issue and submit a fix. Let me know if anyone is already working on it!"}]}, {"ollama_summary": "This issue reports a critical problem: PyMuPDF is not installed, preventing the LangChain library from functioning correctly. The installation process fails due to a mismatch between the installed package version and the required version of PyMuPDF, requiring a shim package to resolve the dependency issue.", "final_category": "bug", "comments": [{"author": "chandrani121189", "created_at": "2025-06-26T05:01:16Z", "body_clean": "Hi @rsys rkathpal Could you please tell us few more details on whether you tried any other version or not. I tried the code and its working perfectly fine with langchain community==0.3.25 [code] Find the package details I have used [code] Please feel free to let us know if these versions are working for you in order to further investigate on the issue"}, {"author": "rsys-rkathpal", "created_at": "2025-06-26T05:26:52Z", "body_clean": "Hi @chandrani121189 , thanks for giving it a try for debugging it out. Version for langchain community is latest one only, where this issue occured. pip show langchain community Name: langchain community Version: 0.3.26 Loader pymupdf was also at latest, pip show pymupdf Name: PyMuPDF Version: 1.23.26 Rest versions used Name: langchain Version: 0.3.26 Name: langchain core Version: 0.3.66 Name: langchain text splitters Version: 0.3.8 Name: langsmith Version: 0.4.1 langcodes and langchain openai are not used (using model installed locally) However the traceback printed of loader gave the needed details, as I pointed in the issue. Do let me know if any other info needed for a specific package. Thanks"}, {"author": "chandrani121189", "created_at": "2025-06-28T04:24:32Z", "body_clean": "Hi @rsys rkathpal , Hope you are doing good. I tries to execute the code using the versions you mentioned which are [code] Could please try the below steps 1. Create a new Virtual Environment [code] 2. Activate this virtual env 3. Install the above packages using pip install r requirement.txt 4. Run the below code [code] Also I used Python Version 3.12.5 Let me know if you find this code not working on your laptop. Connect me on linkedin and we can have a call setup to investigate on the same on your env [link]"}, {"author": "rsys-rkathpal", "created_at": "2025-06-30T07:02:52Z", "body_clean": "Thanks @chandrani121189 for next follow up. I am using pod and docker env, hence in a fresh pod of Ubuntu. Created a new Virtual Environment python m venv venvpymupdf Activate this virtual env Installed the packages using pip install r requirement.txt (containing langchain==0.3.26 langchain community==0.3.26 langchain core==0.3.66 langchain openai==0.3.21 langchain text splitters==0.3.8 langcodes==3.5.0 langsmith==0.3.45 langchain text splitters==0.3.8) installed pymupdf separately = version 1.26.1 Ran the below code to read a single PDF and print trace import os, traceback from langchain community.document loaders import PyMuPDFLoader, Docx2txtLoader, TextLoader filename = \"BSES Bill.pdf\" if filename.lower().endswith(\".pdf\"): try: loader = PyMuPDFLoader(filename) docs = loader.load() print(docs) except Exception as e: print(str(e)) print(traceback.format exc()) Error of traceback below not able to find the pymupdf.table though pymupdf is installed (venvpymupdf) root@pymupdf pod:/workspace python pymupdf.py pymupdf package not found, please install it with [code] Traceback (most recent call last): File \"/workspace/venvpymupdf/lib/python3.12/site packages/langchain community/document loaders/parsers/pdf.py\", line 958, in lazy parse from pymupdf.table import ( ModuleNotFoundError: No module named 'pymupdf.table'; 'pymupdf' is not a package During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"/workspace/pymupdf.py\", line 8, in <module docs = loader.load() ^^^^^^^^^^^^^ File \"/workspace/venvpymupdf/lib/python3.12/site packages/langchain community/document loaders/pdf.py\", line 853, in load return list(self. lazy load( kwargs)) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/workspace/venvpymupdf/lib/python3.12/site packages/langchain community/document loaders/pdf.py\", line 850, in lazy load yield from parser. lazy parse(blob, text kwargs=kwargs) File \"/workspace/venvpymupdf/lib/python3.12/site packages/langchain community/document loaders/parsers/pdf.py\", line 991, in lazy parse raise ImportError( ImportError: pymupdf package not found, please install it with [code] pymupdf package not found, please install it with [code] Traceback (most recent call last): File \"/workspace/venvpymupdf/lib/python3.12/site packages/langchain community/document loaders/parsers/pdf.py\", line 958, in lazy parse from pymupdf.table import ( ModuleNotFoundError: No module named 'pymupdf.table'; 'pymupdf' is not a package During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"/workspace/pymupdf.py\", line 8, in <module docs = loader.load()"}, {"author": "CuberMessenger", "created_at": "2025-07-12T09:11:23Z", "body_clean": "Hi @rsys rkathpal, has your issue been resolved? I tested this on both Windows 11 and WSL2 (Ubuntu 24.04) with the following steps: [code] It worked without issue. Additionally, in both environments, running [code] [code] [code] [code] [code] after completing those steps? I’d be happy to investigate further if the issue persists."}]}, {"ollama_summary": "The GitHub issue reports a `TypeError: 'NoneType' object is not iterable` error when calling `tokenize()` within the `OpenAIEmbeddings` class, specifically when attempting to send text to the OpenAI API. This issue stems from a potential issue with the LangChain integration, likely related to the `text` parameter in the `embeddings.client.create()` method. The code attempts to use `text` as a parameter to the embedding function, but the `text` parameter is not iterable, causing the error. The fix involves modifying the `text` parameter to be a string, which is then passed to the embedding function.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-07-06T22:43:36Z", "body_clean": "If you are using a Custom Base URL, it is a problem with a proxy or service you are using. Since directly using OpenAI seems to be causing no issues whatsoever."}]}], "business_insights": ["LangChain’s multi-tool handoff failure is a systemic issue impacting core functionality, requiring immediate attention.", "The OPENAI_API_BASE variable is a recurring source of errors, indicating a potential dependency issue requiring investigation.", "The TypeError related to tokenize() suggests a fundamental integration problem, potentially involving the text parameter.", "The pyMuPDF installation issue highlights a broader dependency problem, potentially affecting multiple parts of the LangChain ecosystem.", "The NoneType error in tokenize() suggests a potential issue with the underlying embedding mechanism."], "technical_insights": ["LangChain’s multi-tool handoff failure impacts core functionality, demanding a comprehensive root cause analysis.", "The OPENAI_API_BASE variable is a critical dependency, potentially requiring a review of its configuration.", "The TypeError related to tokenize() points to a fundamental integration issue within the LangChain model.", "pyMuPDF installation is a recurring issue, necessitating a targeted fix or dependency update.", "NoneType error in tokenize() signals a potential issue with the embedding function's implementation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s multi-tool handoff failure is a systemic issue impacting core functionality, requiring immediate attention.\n2.  The `OPENAI_API_BASE` variable is a recurring source of errors, indicating a potential dependency issue requiring investigation.\n3.  The `TypeError` related to `tokenize()` suggests a fundamental integration problem, potentially involving the `text` parameter.\n4.  The `pyMuPDF` installation issue highlights a broader dependency problem, potentially affecting multiple parts of the LangChain ecosystem.\n5.  The `NoneType` error in `tokenize()` suggests a potential issue with the underlying embedding mechanism.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s multi-tool handoff failure impacts core functionality, demanding a comprehensive root cause analysis.\n2.  The `OPENAI_API_BASE` variable is a critical dependency, potentially requiring a review of its configuration.\n3.  The `TypeError` related to `tokenize()` points to a fundamental integration issue within the LangChain model.\n4.  `pyMuPDF` installation is a recurring issue, necessitating a targeted fix or dependency update.\n5.  `NoneType` error in `tokenize()` signals a potential issue with the embedding function's implementation.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 50, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The LangChain library's `litellm` component fails when streaming is enabled, specifically when generating text with a specific pattern. A detailed, reproducible example has been provided, demonstrating the issue with a minimal, self-contained code snippet.  The issue appears to be a bug within the LangChain library itself, not due to the user's code.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-22T02:58:39Z", "body_clean": "Thanks for this, I'd recommend opening the issue in [link]"}, {"author": "amaiya", "created_at": "2025-06-22T12:40:06Z", "body_clean": "It looks like this issue is a duplicate of [link] I've confirmed that [link] resolves the problem described above, so I will close this issue. Thanks for the quick response."}]}, {"ollama_summary": "The code is encountering a TypeError when passing a `Timeout` object to the ChatOpenAI constructor, resulting in an unhashable type. This issue started manifesting in a nightly CI job and was not previously reported. A minimal, reproducible example has been provided, allowing for easy debugging and confirms the problem is a bug within the LangChain library.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-23T15:12:48Z", "body_clean": "Hello, thanks very much for reporting this. I've released a fix in langchain openai 0.3.25. Please ping me if your issue isn't resolved or you run into anything else."}]}, {"ollama_summary": "This issue indicates a critical problem with the LangChain `azure.py` component, specifically when using the Azure Chat Open AI model. The `AttributeError: 'list' object has no attribute 'model dump'` message suggests that the model dump function is not being called correctly, leading to an unexpected `list` object being returned. This likely stems from an incompatibility or a bug within the Azure Chat OpenAI integration within LangChain.  The code snippet demonstrates the problem, and the issue is being addressed by the developers, but it's a significant hurdle for users.", "final_category": "bug", "comments": [{"author": "do-roemer", "created_at": "2025-06-20T12:27:39Z", "body_clean": "Was my fault in the end. I forgot to set the model parameter when initializing the AzureChatOpenAI object. So it works fine"}]}, {"ollama_summary": "The issue reports a bug in LangChain’s ChatGoogleGenerativeAI Playground that consistently triggers a validation error when attempting to run local scripts, specifically when using the default metadata input. This error seems to stem from LangSmith's internal tracing mechanisms attempting to re-run or rehydrate the trace, potentially due to the default metadata input. The provided example code and stack trace demonstrate the issue’s consistency across various simple examples.", "final_category": "bug", "comments": [{"author": "chandrani121189", "created_at": "2025-06-25T05:07:48Z", "body_clean": "Hi @delight2004 I tried executing your steps and it worked for me. However few versions were different , please find the versions at the end. Also would like to share the observations <img width=\"924\" alt=\"Image\" src=\" [link] / I also tried on local it worked for me <img width=\"641\" alt=\"Image\" src=\" [link] / [code] Response: The capital of France is Paris . [code] Let me know if this helps you"}, {"author": "mackcooper1408", "created_at": "2025-07-07T20:05:48Z", "body_clean": "@delight2004 I had this exact same issue... I'm not sure how to resolve permanently, but I did stop this from happening in my Playground by opening the \"Prompt Settings\" \"Model Configuration\" \"Extra Parameters\" and setting [code] to an empty array. Seems like Pydantic just wants this to be a [code] type (list or tuple), but the Playground defaults to having this set as [code] 🤷 <img width=\"659\" height=\"222\" alt=\"Image\" src=\" [link] /"}]}, {"ollama_summary": "This issue addresses a bug in LangChain where the 'outputs' field from the OpenAI Code Interpreter tool call is not being included in the LangChain response object. The code attempts to call the OpenAI Responses API, but the `outputs` field is missing, leading to an inconsistency in the output. The issue is likely a bug in the LangChain integration, potentially related to how the tool's output is handled. The provided example demonstrates the problem and offers a solution by explicitly requesting the output from the Code Interpreter tool.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-20T18:34:36Z", "body_clean": "We need to do either: [code] or ideally as of the latest langchain openai: [code]"}]}], "business_insights": ["LangChain’s litellm component is failing with streaming enabled, likely a library bug.", "The bug is reproducible with a minimal code snippet, indicating a bug within the LangChain library itself.", "The issue is a bug, not user-driven, suggesting a library issue.", "Duplicate issue identified, resolved, so closing.", "Potential for future updates to address the bug."], "technical_insights": ["LangChain library bug affecting litellm component with streaming.", "TypeError occurs when passing Timeout to ChatOpenAI constructor.", "AttributeError: 'list' object has no attribute 'model dump' in Azure Chat OpenAI integration.", "LangChain integration bug related to Azure Chat OpenAI model.", "Potential for future fixes and updates to address the bug."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s `litellm` component is failing with streaming enabled, likely a library bug.\n2. The bug is reproducible with a minimal code snippet, indicating a bug within the LangChain library itself.\n3. The issue is a bug, not user-driven, suggesting a library issue.\n4. Duplicate issue identified, resolved, so closing.\n5. Potential for future updates to address the bug.\n\nTECHNICAL INSIGHTS:\n1. LangChain library bug affecting `litellm` component with streaming.\n2. `TypeError` occurs when passing `Timeout` to `ChatOpenAI` constructor.\n3. `AttributeError: 'list' object has no attribute 'model dump'` in Azure Chat OpenAI integration.\n4. LangChain integration bug related to Azure Chat OpenAI model.\n5. Potential for future fixes and updates to address the bug.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 51, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a `BadRequestError` occurring when using OpenAI LLMs with structured output in LangChain, specifically when the code snippet is run in a development environment. The problem is not related to the code itself but appears to be a bug within LangChain’s OpenAI integration. The maintainer has provided a minimal, reproducible example to demonstrate the issue and is seeking assistance understanding the root cause.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-19T11:29:36Z", "body_clean": "Hello, thanks for reporting this. I'm unable to reproduce the issue. To help debug, I'm wondering if you could try a slight adjustment: [code] This behavior should be identical to [code] , so I'd expect the error to raise again here. However, you can run [code] to see the exact payload that is sent to [code] . When I run locally it is the same as the payload you construct for the raw client. (I just changed to the Responses API here because that's what you're comparing with). It would also be helpful to know what version of the [code] sdk you're running, I just checked with latest off pypi."}, {"author": "LoveCatc", "created_at": "2025-06-19T11:42:06Z", "body_clean": "Hi ccurme, thank you for your quick and helpful response! Strangely enough, your code using [code] works just as expected, while the code I presented at the beginning still runs into the same error. I also tried the [code] method, and the output is [code] . Is the [code] key containing the correct value here?"}, {"author": "ccurme", "created_at": "2025-06-19T12:23:53Z", "body_clean": "That looks correct for the Responses API. LangChain by default uses the Chat Completions API. Could you try using the [Chat Completions example]( [link] in the OpenAI docs? [code] Here is the LangChain equivalent: [code] If you still run into errors with LangChain and not the OpenAI SDK, this will give you the exact payload, this time sent to [code] . [code]"}, {"author": "LoveCatc", "created_at": "2025-06-19T13:06:04Z", "body_clean": "Hi ccurme, thank you for your further clarification! I have some observations: now I would encounter the same errors (and exactly the one I provided at the beginning) in both OpenAI SDK and LangChain SDK. The interesting thing is, I asked one of my friends and used his personal API key for test and with his key, both code snippets run without any error. I am using an organization plan, and I am suspecting there might be some limitations or something tricky with the API I use. I will ask the customer service tomorrow. And I would appreciate any further information or suggestions."}, {"author": "ccurme", "created_at": "2025-06-19T19:21:41Z", "body_clean": "Thanks. It sounds like this is an issue with OpenAI's API and not specific to LangChain, so I'll close the issue but feel free to ping or open a new issue if something comes up. In the meantime, you might just set [code] , as OpenAI [recommends]( [link] it for new projects."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe MistralAI chunk parsing system fails to include the `finish_reason` field in the parsed chunks, preventing proper analysis.  The issue appears to be a bug within the LangChain integration, as it’s not being resolved by updating the library. A minimal, reproducible example is provided to demonstrate the problem and highlight the necessity of including the `finish_reason` in the code.", "final_category": "bug", "comments": []}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a potential problem with the documentation regarding the `supported_usage_metadata_details` dropdown, where the title and link to the documentation are not correctly formatted.  The core request is to update the dropdown’s title and link to ensure clarity and consistency with the documentation.", "final_category": "other", "comments": [{"author": "ccurme", "created_at": "2025-06-18T21:29:23Z", "body_clean": "The source has them typed as [code] . So if they are not included in the dict, you still have a valid UsageMetadata."}]}, {"ollama_summary": "This issue stems from a bug in Anthropic's LangChain library that causes the tool calling flow to fail when the initial message contains a `[code]` followed by a sequence of `[code]`s, leading to an unexpected error and a 400 response. The bug is consistently observed with Anthropic models via OpenRouter and normal API usage.  The fix involves replacing the initial message with a placeholder, or adding a dummy message.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-23T14:54:47Z", "body_clean": "Tool calling flows should allow SystemMessage as the first message, followed by AIMessages and tool results, without requiring a manual user message patch. Is this a common usage pattern? Can you point me to documentation from a provider or otherwise featuring this pattern? I believe typically the system message includes general instructions— the \"rules of engagement\"— and individual queries are then conveyed with user messages. Following this, why not just structure your input the usual way: [code] Put another way, my first step would be to put everything in a HumanMessage (the first workaround you mention, which IMO is preferable), and failing this, prepend it with a system message clarifying instructions. Fabricating messages under the hood obfuscates the prompts sent to the LLM and complicates things for users managing context windows, token consumption, etc."}, {"author": "tamirda", "created_at": "2025-06-23T19:11:41Z", "body_clean": "Hi @ccurme Thank you for your response! I’m not sure how common this pattern is across all implementations, but both OpenAI and Gemini APIs support starting a session with only a SystemMessage, and I’ve found it quite useful. As you mentioned, this helps save context window space and avoids cluttering the conversation history with unnecessary user messages. In my use case, most of the time the agent would ignore important instructions (like output formatting or tool usage requirements) unless they were placed in the SystemMessage. Using a HumanMessage instead often led to inconsistent behavior. Also, since the system I’m building runs entirely automatically (no user interaction at all) falling back to manual user message injection or validation isn’t feasible. I’ve tried using a validation agent to check outputs, but unless the requirements were enforced via the SystemMessage, the agent sometimes got stuck in a validation loop. Hope that clarifies why supporting a SystemMessage as the first message is important for my setup. Thanks again for looking into this!"}]}, {"ollama_summary": "The issue reports a problem with using the `use_responses_api=True` setting with AzureChatOpenAI in LangChain.  The code is failing due to an APIStatusError, and a self-contained, reproducible example has been provided to demonstrate the issue.  The problem appears to be a compatibility issue between the LangChain integration and the AzureChatOpenAI API.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-18T12:40:49Z", "body_clean": "Hi, thanks for reporting this. Can you share: What version of the [code] sdk you're running If you get the same error with [code] If possible, relevant output from OpenAI's logging (setting logging to debug should show): [link] I'm unable to reproduce the issue, here is my attempt: [code] Two other observations I have: You're including [code] , which is a [legacy attribute]( [link] for openai<1.0.0 support. You may need to include [code] in your init params, though I don't believe that would lead to the error you're seeing."}, {"author": "matthias-verlinde", "created_at": "2025-07-25T08:10:39Z", "body_clean": "@ccurme, I am experiencing a similar issue. Hopefully you can help me. If you need more information, let me know. Example code llm gpt41 = AzureChatOpenAI( openai api base=' [link] use responses api=True, api version='2025 04 01 preview', ) messages = [ SystemMessage( content=system message, ), HumanMessage( content=\"Hello\", ), ] response = llm gpt41.invoke(messages) Error Trace BadRequestError Traceback (most recent call last) Cell In[7], [line 33](vscode notebook cell:?execution count=7&line=33) 22 messages = [ 23 SystemMessage( 24 content=system message, (...) 28 ), 29 ] 32 Invoke the query with the current state [33](vscode notebook cell:?execution count=7&line=33) response = llm gpt41.invoke(messages) File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\langchain core\\language models\\chat models.py:378, in BaseChatModel.invoke(self, input, config, stop, kwargs) 366 @override 367 def invoke( 368 self, (...) 373 kwargs: Any, 374 ) BaseMessage: 375 config = ensure config(config) 376 return cast( 377 \"ChatGeneration\", [378](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/langchain core/language models/chat models.py:378) self.generate prompt( 379 [self. convert input(input)], 380 stop=stop, 381 callbacks=config.get(\"callbacks\"), 382 tags=config.get(\"tags\"), 383 metadata=config.get(\"metadata\"), 384 run name=config.get(\"run name\"), 385 run id=config.pop(\"run id\", None), 386 kwargs, 387 ).generations[0][0], 388 ).message File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\langchain core\\language models\\chat models.py:963, in BaseChatModel.generate prompt(self, prompts, stop, callbacks, kwargs) 954 @override 955 def generate prompt( 956 self, (...) 960 kwargs: Any, 961 ) LLMResult: 962 prompt messages = [p.to messages() for p in prompts] [963](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/langchain core/language models/chat models.py:963) return self.generate(prompt messages, stop=stop, callbacks=callbacks, kwargs) File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\langchain core\\language models\\chat models.py:782, in BaseChatModel.generate(self, messages, stop, callbacks, tags, metadata, run name, run id, kwargs) 779 for i, m in enumerate(input messages): 780 try: 781 results.append( [782](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/langchain core/language models/chat models.py:782) self. generate with cache( 783 m, 784 stop=stop, 785 run manager=run managers[i] if run managers else None, 786 kwargs, 787 ) 788 ) 789 except BaseException as e: 790 if run managers: File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\langchain core\\language models\\chat models.py:1028, in BaseChatModel. generate with cache(self, messages, stop, run manager, kwargs) 1026 result = generate from stream(iter(chunks)) 1027 elif inspect.signature(self. generate).parameters.get(\"run manager\"): [1028](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/langchain core/language models/chat models.py:1028) result = self. generate( 1029 messages, stop=stop, run manager=run manager, kwargs 1030 ) 1031 else: 1032 result = self. generate(messages, stop=stop, kwargs) File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\langchain openai\\chat models\\base.py:1118, in BaseChatOpenAI. generate(self, messages, stop, run manager, kwargs) 1116 generation info = {\"headers\": dict(raw response.headers)} 1117 else: [1118](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/langchain openai/chat models/base.py:1118) response = self.root client.responses.create( payload) 1119 return construct lc result from responses api( 1120 response, 1121 schema=original schema obj, 1122 metadata=generation info, 1123 output version=self.output version, 1124 ) 1125 elif self.include response headers: File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\openai\\ utils\\ utils.py:287, in required args.<locals .inner.<locals .wrapper( args, kwargs) 285 msg = f\"Missing required argument: {quote(missing[0])}\" 286 raise TypeError(msg) [287](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/openai/ utils/ utils.py:287) return func( args, kwargs) File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\openai\\resources\\responses\\responses.py:690, in Responses.create(self, input, model, background, include, instructions, max output tokens, metadata, parallel tool calls, previous response id, reasoning, service tier, store, stream, temperature, text, tool choice, tools, top p, truncation, user, extra headers, extra query, extra body, timeout) 659 @required args([\"input\", \"model\"], [\"input\", \"model\", \"stream\"]) 660 def create( 661 self, (...) 688 timeout: float | [link] | None | NotGiven = NOT GIVEN, 689 ) Response | Stream[ResponseStreamEvent]: [690](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/openai/resources/responses/responses.py:690) return self. post( 691 \"/responses\", 692 body=maybe transform( 693 { 694 \"input\": input, 695 \"model\": model, 696 \"background\": background, 697 \"include\": include, 698 \"instructions\": instructions, 699 \"max output tokens\": max output tokens, 700 \"metadata\": metadata, 701 \"parallel tool calls\": parallel tool calls, 702 \"previous response id\": previous response id, 703 \"reasoning\": reasoning, 704 \"service tier\": service tier, 705 \"store\": store, 706 \"stream\": stream, 707 \"temperature\": temperature, 708 \"text\": text, 709 \"tool choice\": tool choice, 710 \"tools\": tools, 711 \"top p\": top p, 712 \"truncation\": truncation, 713 \"user\": user, 714 }, 715 response create params.ResponseCreateParamsStreaming 716 if stream 717 else response create params.ResponseCreateParamsNonStreaming, 718 ), 719 options=make request options( 720 extra headers=extra headers, extra query=extra query, extra body=extra body, timeout=timeout 721 ), 722 cast to=Response, 723 stream=stream or False, 724 stream cls=Stream[ResponseStreamEvent], 725 ) File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\openai\\ base client.py:[1242](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/openai/ base client.py:1242), in SyncAPIClient.post(self, path, cast to, body, options, files, stream, stream cls) 1228 def post( 1229 self, 1230 path: str, (...) 1237 stream cls: type[ StreamT] | None = None, 1238 ) ResponseT | StreamT: 1239 opts = FinalRequestOptions.construct( 1240 method=\"post\", url=path, json data=body, files=to [link] options 1241 ) 1242 return cast(ResponseT, self.request(cast to, opts, stream=stream, stream cls=stream cls)) File c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\openai\\ base client.py:[1037](file:///C:/Users/matthiave/AppData/Local/anaconda3/envs/knowledge base processing/lib/site packages/openai/ base client.py:1037), in SyncAPIClient.request(self, cast to, options, stream, stream cls) 1034 err.response.read() 1036 log.debug(\"Re raising status error\") 1037 raise self. make status error from response(err.response) from None 1039 break 1041 assert response is not None, \"could not resolve response (should never happen)\" BadRequestError: Unsupported data type OpenAI logging DEBUG:openai. base client:Request options: {'method': 'post', 'url': '/responses', 'headers': {'api key': '<redacted '}, 'files': None, 'idempotency key': 'stainless python retry 41762fe0 7b44 4988 bdaf 6c7a96d8cdc1', 'json data': {'input': [{'content': \"system prompt\", 'role': 'system'}, {'content': 'Hello?', 'role': 'user'}], 'model': None, 'stream': False}} DEBUG:openai. base client:Sending HTTP Request: POST [link] DEBUG: [link] host='azure openai swedencentral mv.openai.azure.com' port=443 local address=None timeout=None socket options=None DEBUG: [link] return value=< [link] object at 0x0000020C055D5C00 DEBUG: [link] ssl context=<ssl.SSLContext object at 0x0000020C04E7F8C0 server hostname='azure openai swedencentral mv.openai.azure.com' timeout=None [llm/start] [llm:AzureChatOpenAI] Entering LLM run with input: { \"prompts\": [ \"System: system prompt ] } DEBUG: [link] return value=< [link] object at 0x0000020C055D5C90 DEBUG: [link] request=<Request [b'POST'] DEBUG: [link] DEBUG: [link] request=<Request [b'POST'] DEBUG: [link] DEBUG: [link] request=<Request [b'POST'] DEBUG: [link] return value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Content Length', b'22'), (b'Content Type', b'text/plain; charset=utf 8'), (b'x content type options', b'nosniff'), (b'x ms rai invoked', b'true'), (b'apim request id', b'cd200768 5ce2 48ba 9a08 325923df9cb6'), (b'Strict Transport Security', b'max age=31536000; includeSubDomains; preload'), (b'x ms deployment name', b'gpt 4.1 July'), (b'x ms region', b'Sweden Central'), (b'x ratelimit remaining requests', b'146'), (b'x ratelimit limit requests', b'150'), (b'x ratelimit remaining tokens', b'149968'), (b'x ratelimit limit tokens', b'150000'), (b'Date', b'Fri, 25 Jul 2025 07:55:38 GMT')]) INFO: [link] Request: POST [link] \"HTTP/1.1 400 Bad Request\" DEBUG: [link] request=<Request [b'POST'] DEBUG: [link] DEBUG: [link] DEBUG: [link] DEBUG:openai. base client:HTTP Response: POST [link] \"400 Bad Request\" Headers({'content length': '22', 'content type': 'text/plain; charset=utf 8', 'x content type options': 'nosniff', 'x ms rai invoked': 'true', 'apim request id': 'cd200768 5ce2 48ba 9a08 325923df9cb6', 'strict transport security': 'max age=31536000; includeSubDomains; preload', 'x ms deployment name': 'gpt 4.1 July', 'x ms region': 'Sweden Central', 'x ratelimit remaining requests': '146', 'x ratelimit limit requests': '150', 'x ratelimit remaining tokens': '149968', 'x ratelimit limit tokens': '150000', 'date': 'Fri, 25 Jul 2025 07:55:38 GMT'}) DEBUG:openai. base client:request id: None DEBUG:openai. base client:Encountered [link] Traceback (most recent call last): File \"c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\openai\\ base client.py\", line 1017, in request response.raise for status() File \"c:\\Users\\matthiave\\AppData\\Local\\anaconda3\\envs\\knowledge base processing\\lib\\site packages\\ [link] line 829, in raise for status raise HTTPStatusError(message, request=request, response=self) [link] Client error '400 Bad Request' for url ' [link] For more information check: [link] DEBUG:openai. base client:Not retrying DEBUG:openai. base client:Re raising status error [llm/error] [llm:AzureChatOpenAI] [368ms] LLM run errored with error: \"BadRequestError('Unsupported data type')Traceback (most recent call last):\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\langchain core\\\\language models\\\\chat models.py\\\", line 782, in generate\\n self. generate with cache(\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\langchain core\\\\language models\\\\chat models.py\\\", line 1028, in generate with cache\\n result = self. generate(\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\langchain openai\\\\chat models\\\\base.py\\\", line 1118, in generate\\n response = self.root client.responses.create( payload)\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\openai\\\\ utils\\\\ utils.py\\\", line 287, in wrapper\\n return func( args, kwargs)\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\openai\\\\resources\\\\responses\\\\responses.py\\\", line 690, in create\\n return self. post(\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\openai\\\\ base client.py\\\", line 1242, in post\\n return cast(ResponseT, self.request(cast to, opts, stream=stream, stream cls=stream cls))\\n\\n\\n File \\\"c:\\\\Users\\\\matthiave\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\knowledge base processing\\\\lib\\\\site packages\\\\openai\\\\ base client.py\\\", line 1037, in request\\n raise self. make status error from response(err.response) from None\\n\\n\\nopenai.BadRequestError: Unsupported data type\" Description The above error only occurs when specifying 'use responses api=True' in the AzureChatOpenAI initialization. Removing this clears the error and the example runs fine. The error does not get resolved when trying .stream() System Info langchain==0.3.26 langchain community==0.3.27 langchain core==0.3.67 langchain openai==0.3.27 openai==1.86.0 model used GPT 4.1"}]}], "business_insights": ["LangChain’s OpenAI integration exhibits a bug where structured output data is incorrectly processed, requiring a minimal example to reproduce.", "Addressing this bug proactively will improve the usability of LangChain’s LLM integration.", "Debugging the issue requires a focus on the initial message’s structure.", "LangChain’s OpenAI integration needs refinement to handle structured output correctly.", "Identifying the root cause will enhance the development process for LangChain."], "technical_insights": ["LangChain’s OpenAI integration is experiencing a bug related to structured output data processing.", "The bug is specifically within the LangChain integration, impacting the code snippet's functionality.", "A minimal, reproducible example is crucial for debugging the bug within LangChain.", "The bug is consistent across multiple models and API usage, suggesting a library-level issue.", "The bug is affecting the initial message, requiring a change to the initial message structure."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s OpenAI integration exhibits a bug where structured output data is incorrectly processed, requiring a minimal example to reproduce.\n2. Addressing this bug proactively will improve the usability of LangChain’s LLM integration.\n3. Debugging the issue requires a focus on the initial message’s structure.\n4.  LangChain’s OpenAI integration needs refinement to handle structured output correctly.\n5.  Identifying the root cause will enhance the development process for LangChain.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s OpenAI integration is experiencing a bug related to structured output data processing.\n2.  The bug is specifically within the LangChain integration, impacting the code snippet's functionality.\n3.  A minimal, reproducible example is crucial for debugging the bug within LangChain.\n4.  The bug is consistent across multiple models and API usage, suggesting a library-level issue.\n5.  The bug is affecting the initial message, requiring a change to the initial message structure.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 52, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue proposes a new operator, `||`, to improve the readability of RunnableParallel by allowing sequential chains to be expressed as parallel chains.  This will enhance the code’s structure and make it more aligned with functional composition patterns found in other languages. The developer is proposing implementation and a pull request for this change.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-06-26T18:53:28Z", "body_clean": "We're generally guiding users away from relying on LCEL for orchestration. It's fun to write, but hard to work with when the application gets big. Instead if you're trying to create a custom workflow you can use langgraph for orchestration."}]}, {"ollama_summary": "The issue reports a problem where the LangChain library is calling the wrong tool calls when using the `stream=true` mode. The code is failing to correctly interpret the `tool calls` list, resulting in an `invalid tool call` error. A minimal, reproducible example has been provided to demonstrate the issue.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-06-26T18:55:56Z", "body_clean": "Please refer to this discussion: [link]"}]}, {"ollama_summary": "This issue reports a bug in LangChain where the Qwen3 Extended Thinking Support feature doesn’t correctly close the thinking model. The developer has provided a self-contained example demonstrating the issue, and they are actively working to resolve it by providing a fix.  Currently, the bug appears to be a fundamental issue within the LangChain integration, not a result of code changes.", "final_category": "feature", "comments": [{"author": "mdrxy", "created_at": "2025-07-11T15:27:06Z", "body_clean": "[This is now supported by setting [code] ]( [link] either in the class param or during invocation."}]}, {"ollama_summary": "The issue reports a bug in LangChain that prevents the use of the Azure Chat OpenAI API due to a missing argument in the `stream` parameter within the `create()` method. The solution involves providing the necessary arguments to the `create()` function, and a self-contained example demonstrates the problem and its fix.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-17T20:24:11Z", "body_clean": "Hello, thanks for the report. This issue should be resolved in the latest version of [code] . Please shout if you run into anything else!"}, {"author": "sneharosegeorge1", "created_at": "2025-06-18T11:01:43Z", "body_clean": "Thanks @ccurme for the Update.I have upgraded [code] to the latest version and now see a different error. here is the ticket raised for that [ [link]"}]}, {"ollama_summary": "The React agent with ChatOpenAI is not streaming tool call arguments (specifically the `message` stream) as intended, despite attempts to update LangChain. The issue stems from a bug in the integration package that prevents the correct stream of these arguments. A self-contained, reproducible example demonstrates the problem and confirms it’s not a code-level issue, suggesting a potential LangChain issue.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-17T20:32:08Z", "body_clean": "[Tool call]( [link] args are dicts, so during streaming they'll only be parsed correctly if the chunk contains valid json. You can use [.tool call chunks]( [link] to stream the raw args as json substrings: [code] You can then access the full parsed tool calls in the [code] branch of your code."}, {"author": "chandrani121189", "created_at": "2025-06-24T03:52:57Z", "body_clean": "Hi @teshnizi . Hope you are doing good. Please find a langraph version where we get the arguments printed using aync stream [code] Output Goes Below [code] You can see the args 4 printed"}]}], "business_insights": ["Understanding sequential chains improves code structure and aligns with functional composition.", "Managing large applications requires careful orchestration strategies.", "Developers need tools that support complex workflows effectively.", "Code readability is crucial for maintainability and collaboration.", "Correct tool call interpretation is essential for application stability."], "technical_insights": ["LangChain integration requires careful attention to stream argument parsing.", "The invalid tool call error indicates a fundamental issue within the LangChain framework.", "The stream=true mode impacts the correct interpretation of tool calls.", "The create() method's argument missing is a core bug in the LangChain integration.", "The bug is affecting the core functionality of the LangChain library."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Understanding sequential chains improves code structure and aligns with functional composition.\n2. Managing large applications requires careful orchestration strategies.\n3. Developers need tools that support complex workflows effectively.\n4. Code readability is crucial for maintainability and collaboration.\n5. Correct tool call interpretation is essential for application stability.\n\nTECHNICAL INSIGHTS:\n1. LangChain integration requires careful attention to stream argument parsing.\n2. The `invalid tool call` error indicates a fundamental issue within the LangChain framework.\n3. The `stream=true` mode impacts the correct interpretation of tool calls.\n4. The `create()` method's argument missing is a core bug in the LangChain integration.\n5. The bug is affecting the core functionality of the LangChain library.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 53, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the “How to convert Runnables to Tools” guide currently uses the outdated Pydantic `.schema()` method, which is deprecated in V2.  The issue proposes updating the documentation to utilize the new Pydantic V2 method, specifically replacing the deprecated `.schema()` with `.model json schema()` in the tool runtime examples.", "final_category": "other", "comments": []}, {"ollama_summary": "The issue involves a problem where the `mcp tools` model returns data to the `AIMessage` but doesn't pass it back to the `ToolMessage` as expected. This happens across different models, including GPT-4, and is specifically affecting the retrieval of data from the `mcp tools` server.  The current solution attempts to fix this with custom nodes, but the root cause remains unclear – potentially a limitation in how the model handles ToolMessage transmission.", "final_category": "bug", "comments": [{"author": "avinash-aub", "created_at": "2025-06-17T11:37:51Z", "body_clean": "It looks like llama 3 3 70b instruct doesn’t handle ToolMessage outputs natively like gpt 4o does. The tools run and return data, but the model ignores the results unless I manually inject the tool output into the prompt. So, you have to handle it manually as Update your call model function, it will resolve the issue IG. [code]"}, {"author": "AUK608", "created_at": "2025-06-20T14:35:45Z", "body_clean": "It looks like llama 3 3 70b instruct doesn’t handle ToolMessage outputs natively like gpt 4o does. The tools run and return data, but the model ignores the results unless I manually inject the tool output into the prompt. So, you have to handle it manually as Update your call model function, it will resolve the issue IG. [code] Thank you for the reply With this modification, its not entering into \"if tool messages:\", and due to this, its not even executing any tools, previously it used to execute all tools but didn't used to return tool outputs to model below is the modified code according to your suggestion : [code] Can you help with this issue I'm facing now as I'm new to this? Thank you"}, {"author": "eyurtsev", "created_at": "2025-09-10T14:42:15Z", "body_clean": "I'm transferring this issue to langchain as it does not appear to be related to MCP, but to the chat model used."}]}, {"ollama_summary": "This issue stems from a critical bug in LangChain that causes the same documents to be duplicated and overwritten, leading to data contamination and incorrect vector store entries. The bug is rooted in the way the code calculates hashes, resulting in identical hashes being generated for identical content, causing the system to incorrectly store duplicate documents.  The code attempts to handle this by using a `hashedDocument` object, but this approach fails to account for the collection context, resulting in the duplicated documents.  The issue is currently unresolved and requires a fix to ensure accurate data integrity.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-10T14:41:01Z", "body_clean": "See the comment in the linked PR"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nRockset, a vector database option, has been removed from the documentation due to its acquisition by OpenAI and subsequent closure. The issue stems from the service’s complete discontinuation, rendering all references to Rockset.com invalid.  The core problem is inaccurate documentation referencing Rockset’s status.", "final_category": "other", "comments": [{"author": "shivnathtathe", "created_at": "2025-06-16T03:15:20Z", "body_clean": "@ZainRizvi, Instead of removing the Rockset integration docs entirely, I’ve added a clear deprecation notice at the top of the page. This preserves historical context for developers who may encounter legacy projects using Rockset, while making it clear that the service is no longer active. Happy to remove the page fully if maintainers prefer, but this approach aligns with how deprecated features are often archived."}, {"author": "ZainRizvi", "created_at": "2025-06-17T19:35:49Z", "body_clean": "Should the code also be updated?"}, {"author": "shivnathtathe", "created_at": "2025-06-24T05:13:40Z", "body_clean": "We need to think about it?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the Pydantic library is outdated, using the deprecated `.schema()` method instead of the newer `.model_json_schema()` method. This causes a deprecation warning and requires updating the documentation to reflect the current best practices. The issue is being addressed by updating the documentation to use the new method, which includes replacing the deprecated code with the recommended approach.", "final_category": "other", "comments": [{"author": "shivnathtathe", "created_at": "2025-06-15T04:33:47Z", "body_clean": "@97tkddnjs, Hi! Let me know if any other changes are needed — happy to improve it. Thanks for maintaining LangChain 🙌"}, {"author": "97tkddnjs", "created_at": "2025-06-15T14:37:27Z", "body_clean": "Hi @shivnathtathe! Thank you so much for the quick fix! 🙌 Your PR looks great and addresses the issue perfectly. I really appreciate you taking the time to contribute to this. While working on documentation improvements, I've been finding quite a few similar deprecated method usages across the codebase. If you're interested in continuing to help improve LangChain's documentation quality, there might be other similar issues to tackle!"}]}], "business_insights": ["Update documentation for Pydantic to use .model_json_schema() for deprecated .schema() method.", "Improve documentation clarity regarding Pydantic’s .schema() usage to align with current best practices.", "Standardize the use of .model_json_schema() across the V2 documentation."], "technical_insights": ["Implement the updated Pydantic V2 .model_json_schema() method in the documentation.", "Update the documentation to explicitly state the replacement of the deprecated .schema() method.", "Ensure consistent application of .model_json_schema() throughout the V2 documentation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Update documentation for Pydantic to use `.model_json_schema()` for deprecated `.schema()` method.\n2. Improve documentation clarity regarding Pydantic’s `.schema()` usage to align with current best practices.\n3. Standardize the use of `.model_json_schema()` across the V2 documentation.\n\nTECHNICAL INSIGHTS:\n1. Implement the updated Pydantic V2 `.model_json_schema()` method in the documentation.\n2. Update the documentation to explicitly state the replacement of the deprecated `.schema()` method.\n3. Ensure consistent application of `.model_json_schema()` throughout the V2 documentation.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 54, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue addresses a bug where Pydantic models with no docstrings are incorrectly displaying the `docstring` for the BaseModel. The fix involves ensuring the docstring for the BaseModel itself is used instead of the docstring of the BaseTool class. This ensures the model’s documentation is accurately represented.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-06-14T01:09:04Z", "body_clean": "@ccurme patched"}, {"author": "eyurtsev", "created_at": "2025-06-26T18:51:43Z", "body_clean": "[code] For 0.4 release we could consider updating the behavior so that doc strings are not inherited from their parents. It's fairly odd that doc strings are inherited for BaseModels as in general the descriptions need to be different"}]}, {"ollama_summary": "This issue proposes a change to dynamically set the `max_tokens` parameter in Anthropic's messages API to a value of 64,000 for Claude 3.7 and beyond, which is currently set to 1024. This change is necessary to accommodate newer models with potentially higher token limits and better reasoning capabilities. The change requires a breaking change to the API and should be implemented to ensure compatibility with the models.", "final_category": "feature", "comments": [{"author": "shivnathtathe", "created_at": "2025-06-15T03:31:44Z", "body_clean": "@ccurme I suggest making max tokens: [code] but defaulting to 1024 if not provided. This keeps the current behavior unchanged and lets users set a higher limit manually when needed. Example: [code] This avoids any breaking change while adding flexibility."}, {"author": "keenborder786", "created_at": "2025-08-02T12:43:20Z", "body_clean": "@ccurme this issue has been resolved in the above PR. Can you please check?"}]}, {"ollama_summary": "This issue reports a bug where the `thinking_model` component fails to correctly process input, potentially impacting the core functionality of the application. It highlights a lack of reasoning messages and suggests investigating potential issues with the model itself, rather than focusing on specific usage questions.  The code itself is running as is, requiring a minimal reproducible example to demonstrate the problem.", "final_category": "bug", "comments": [{"author": "Kabir2005", "created_at": "2025-06-23T12:27:53Z", "body_clean": "Looking at your code and the output, the issue is that LangChain's AIMessage class doesn't have a built in field for reasoning content, which seems specific to Qwen3. When LangGraph processes the raw response from the model, it extracts the standard fields like content, tool calls, etc., but it doesn't know about or preserve the reasoning content field. You can see in the raw JSON response that reasoning content is present, but LangChain's message parsing doesn't include it in the AIMessage object. Try to access via response metadata Some providers store additional fields in the response metadata. Check if it's there: [code]"}, {"author": "NiuBlibing", "created_at": "2025-06-23T13:03:31Z", "body_clean": "Could langchain add it by default like openai's client?"}, {"author": "sydney-runkle", "created_at": "2025-06-27T15:48:52Z", "body_clean": "Thanks for flagging, forwarding this over to langchain. We're working on standardized output for reasoning content!"}, {"author": "ccurme", "created_at": "2025-06-27T15:58:03Z", "body_clean": "Hello, I'd suggest using [code] or [code] . If you look at [langchain deepseek]( [link] it is not doing much more than extending BaseChatOpenAI and parsing out reasoning content. See the comment [here]( [link] for additional discussion. Let me know if I've misunderstood the issue."}, {"author": "NiuBlibing", "created_at": "2025-06-30T07:12:44Z", "body_clean": "Hello, I'd suggest using or . If you look at [langchain deepseek]( [link] it is not doing much more than extending BaseChatOpenAI and parsing out reasoning content. [code] [code] See the comment [here]( [link] for additional discussion. Let me know if I've misunderstood the issue. It works but not beautiful for that I should change the environments of [code] to [code]"}, {"author": "chandrani121189", "created_at": "2025-07-03T04:48:42Z", "body_clean": "Hi @NiuBlibing , I tried calling init chat model with verbose=True and it prints the execution functions [code] Please find the execution output below [code] Please let me know if I missed anything which you might be keen on"}]}, {"ollama_summary": "The `ChatPromptValue.to_string()` function is currently returning stringified raw content structure instead of the extracted text from a prompt, despite being a LangChain issue.  The issue highlights a bug in LangChain that doesn't appear to be fixed by updating the library. A minimal, reproducible example demonstrates the problem with a simple code snippet.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue stems from a bug in the ExperimentalMarkdownSyntaxTextSplitter library where it consistently misinterprets the hierarchical structure of markdown documents, leading to incorrect header splitting. The code provides a minimal, reproducible example demonstrating this issue, and the developers are actively working on a fix.", "final_category": "bug", "comments": [{"author": "raghukapur9", "created_at": "2025-06-16T03:44:32Z", "body_clean": "The problem was that when splitting markdown, the [code] was keeping old headers (like ) even after a new higher level header (like ) appeared. This caused chunks to have the wrong metadata. I updated the [code] function to remove any headers that are at the same or deeper level before adding the new one. This way, each chunk only keeps the correct headers in its metadata."}]}], "business_insights": ["Pydantic documentation inconsistencies are a recurring issue, requiring consistent formatting across models.", "Anthropic’s message API’s token limits are increasing, necessitating API updates to accommodate newer models.", "LangChain’s thinking_model lacks reasoning content, potentially impacting core functionality.", "ChatPromptValue.to_string() returns raw content, requiring a fix in LangChain.", "ExperimentalMarkdownSyntaxTextSplitter misinterprets markdown structure, causing header splitting errors."], "technical_insights": ["LangChain’s thinking_model needs a default reasoning content field.", "Anthropic’s message API’s token limits are increasing, requiring API updates.", "Pydantic’s docstring handling requires consistent formatting across models.", "ChatPromptValue.to_string() needs a fix to correctly parse prompt structure.", "ExperimentalMarkdownSyntaxTextSplitter’s hierarchical structure handling requires improvement."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Pydantic documentation inconsistencies are a recurring issue, requiring consistent formatting across models.\n2. Anthropic’s message API’s token limits are increasing, necessitating API updates to accommodate newer models.\n3. LangChain’s `thinking_model` lacks reasoning content, potentially impacting core functionality.\n4. `ChatPromptValue.to_string()` returns raw content, requiring a fix in LangChain.\n5. ExperimentalMarkdownSyntaxTextSplitter misinterprets markdown structure, causing header splitting errors.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s `thinking_model` needs a default reasoning content field.\n2.  Anthropic’s message API’s token limits are increasing, requiring API updates.\n3.  Pydantic’s docstring handling requires consistent formatting across models.\n4.  `ChatPromptValue.to_string()` needs a fix to correctly parse prompt structure.\n5.  ExperimentalMarkdownSyntaxTextSplitter’s hierarchical structure handling requires improvement.\n", "batch_number": 55, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe API documentation uses a different import path (`[code]` instead of `[code]`) for the `create_retrieval_chain` function, causing inconsistencies between the documentation and examples. This discrepancy is leading to users encountering \"ImportError\" and blank descriptions when using IDE extensions to understand the API. The core request is to clarify and update the documentation to ensure a consistent and accurate representation of the API’s functionality.", "final_category": "other", "comments": [{"author": "keenborder786", "created_at": "2025-06-12T22:45:15Z", "body_clean": "Can you post the error, because I have verified from the repository the imports should work."}, {"author": "asherk7", "created_at": "2025-06-13T00:43:50Z", "body_clean": "The error was fixed, there was an issue in my virtual environment, and I had to recreate it and reinstall Langchain. The error message was \"cannot import name 'create retrieval chain' from 'langchain.chains'. Apologies for the confusion. On this topic, though, I noticed some documentation examples use 'from langchain.chains' while the API documentation uses 'from langchain.chains.retrieval'. Would it make sense to standardize the import path across examples and the reference docs? Even if both are valid, aligning them could help avoid confusion for new Langchain users (like me), and for IDE extensions. Example on VSCode using Pylance: langchain.chains: ![Image]( [link] langchain.chains.retrieval: ![Image]( [link] I'd be happy to contribute to these if it's useful, otherwise, thanks for the reply."}, {"author": "BorisQuanLi", "created_at": "2025-07-03T02:08:58Z", "body_clean": "Hi! I'd like to work on this issue. I'll standardize the import path for [code] across the docs and examples, and clarify the recommended usage. Please let me know if anyone is already working on it—otherwise, I'll get started!"}]}, {"ollama_summary": "The issue describes a problem where the GitHub repository documentation suggests initializing Milvus with a database file, but the code cannot do so.  The developer has attempted to resolve the issue with a self-contained example and a detailed description, but the bug persists.  Currently, the code throws an error when attempting to use a non-existent Milvus URI, requiring a local database file for vector storage.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-06-12T23:28:22Z", "body_clean": "Please do the following: [code]"}, {"author": "paperview", "created_at": "2025-06-13T12:12:29Z", "body_clean": "Thanks, can I not use different embeddings with the db file approach? For instance HuggingFaceEmbeddings(model name=\"all mpnet base v2\") Below throws the error, for instance: [code]"}, {"author": "paperview", "created_at": "2025-06-13T12:39:41Z", "body_clean": "FYI to anyone with the same problem I got this working in an isolated test by importing the embeddings properly from langchain, before I was importing from pymilvus. it still isnt working in my flask worker but must be a separate issue. thanks for the response."}]}, {"ollama_summary": "The issue involves a structural output problem with LangChain, specifically generating incorrect JSON output when using a thinking model.  A maintainer provided a minimal, reproducible example demonstrating this, but the bug hasn’t been resolved by updating LangChain.  The bug manifests as `<think> and </think` tags in the generated answers, potentially causing errors when using the code with Pydantic.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a bug in LangChain where a handler function raises an `IndexError` when it interacts with a specific component, causing a hidden error message. This problem is currently being addressed by the maintainer, and the code is designed to be easily testable by copying and running it as-is.", "final_category": "bug", "comments": [{"author": "x612skm", "created_at": "2025-06-13T07:19:59Z", "body_clean": "Hi, I'm giving it a try and will be submitting a PR soon today. Thanks!"}, {"author": "x612skm", "created_at": "2025-06-13T14:31:03Z", "body_clean": "This is what I understood from the stackTrace [code] Also, when we only give an argument inside [code] it fails with ValueError When we give both arguments let's say [code] it passes. [Maybe this is expected] I'm not sure I tried to check it with condition [code] before the message strings but seems to be of no help. Also I don't want to tweak anything inside for the message strings, but I have a question Is it valid for args to have fewer than 2 elements? If so, we might want to skip fallback instead of crashing? I wrapped the fallback logic with if len(args) 1: as a guard, but this doesn’t fully clarify what structure of args is expected during a fallback from on chat model start to on llm start. so, could you please confirm what the expected shape of args is when calling handle event with on chat model start? Apologies if I get anything wrong here this is my first issue in this repo and new to open source as well. Just want to clarify few of those things also any hints/feedbacks towards to solve this problem is highly appreciated. Thanks!"}, {"author": "Alioth99", "created_at": "2025-06-14T12:33:06Z", "body_clean": "@x612skm Thanks for looking into this! Your fix sounds reasonable — mind sending a quick PR? It’d make the fallback logic more robust. If not, maybe a maintainer could take a look?"}, {"author": "x612skm", "created_at": "2025-06-16T04:33:54Z", "body_clean": "[@x612skm]( [link] Thanks for looking into this! Your fix sounds reasonable — mind sending a quick PR? It’d make the fallback logic more robust. If not, maybe a maintainer could take a look? @Alioth99 Hey yeah sure! I'll be pushing my PR till the progress that I did today itself for further insights.. TY!"}, {"author": "x612skm", "created_at": "2025-06-18T13:25:49Z", "body_clean": "@Alioth99 this is my approach above would you mind to take a look and any feedback here would be appreciated this is my first PR for this repo so trying to understand the stuffs. Thanks! 🙇"}]}, {"ollama_summary": "This issue reports a bug where the `state` is not being injected into the tool when using custom input schemas, causing confusion and potentially hindering the tool's functionality. The root cause appears to be a discrepancy between the input schema and the tool's internal state management, leading to unexpected behavior.", "final_category": "bug", "comments": [{"author": "Fly-Playgroud", "created_at": "2025-06-13T03:39:51Z", "body_clean": "Yes, I have the same problem: [code] [code]"}, {"author": "Fly-Playgroud", "created_at": "2025-06-13T06:39:18Z", "body_clean": "I found that problem is [code] if is setted custom [code] . It can't parse func's signature for [code] ."}, {"author": "Fly-Playgroud", "created_at": "2025-06-13T06:49:40Z", "body_clean": "But the [code] decorator currently allows this and does not do such a check, which causes such a problem. I have two solutions: 1. When checking for a custom [code] , also check if the function has [code] , and merge the [code] into the customSchema. 2. When checking for a custom [code] , also check if the function has [code] , if so, throw an exception. @nfcampos @sydney runkle"}, {"author": "KodyKendall", "created_at": "2025-06-14T17:41:53Z", "body_clean": "I'm running into similar issues where the full state isn't showing up using InjectedState and ToolNode. [code] UPDATE: My issue was due to my own mistake: I was using the wrong state class definition when building the graph in the the [code] call, I had to change it to [code] and also in the actual function signature input was the wrong state class type. I had to change from [code] to [code] . After changing those, the full state was being passed into the tool call correctly after adding [code] ."}, {"author": "apoorvkk", "created_at": "2025-06-20T08:03:50Z", "body_clean": "+1 having the same issue"}, {"author": "LokeshShelva", "created_at": "2025-06-27T07:26:41Z", "body_clean": "But the [code] decorator currently allows this and does not do such a check, which causes such a problem. I have two solutions: 1. When checking for a custom [code] , also check if the function has [code] , and merge the [code] into the customSchema. 2. When checking for a custom [code] , also check if the function has [code] , if so, throw an exception. [@nfcampos]( [link] [@sydney runkle]( [link] Well i would prefer the first approach. That is how i expect argSchema and injection to work. My understanding was [code] was the explicit context to LLM on the arguments to the tool and it does not make sense to add the injection argument too to the [code] . It should be merged in the tool. Would love others' take on this."}, {"author": "L9qmzn", "created_at": "2025-07-01T11:23:09Z", "body_clean": "But the [code] decorator currently allows this and does not do such a check, which causes such a problem. I have two solutions: 1. When checking for a custom [code] , also check if the function has [code] , and merge the [code] into the customSchema. 2. When checking for a custom [code] , also check if the function has [code] , if so, throw an exception. [@nfcampos]( [link] [@sydney runkle]( [link] Well i would prefer the first approach. That is how i expect argSchema and injection to work. My understanding was [code] was the explicit context to LLM on the arguments to the tool and it does not make sense to add the injection argument too to the [code] . It should be merged in the tool. Would love others' take on this. Agree! And, is there any way to temporarily work around this bug for now?"}, {"author": "LokeshShelva", "created_at": "2025-07-02T10:28:04Z", "body_clean": "@L9qmzn, for now you can add the [code] and [code] in the [code] like so [code] As far as I have tested, the [code] or the [code] are not added as part of the prompt to the llm. But I do suggest you test it yourself to be sure."}]}], "business_insights": ["API documentation inconsistencies require clear and accurate documentation for consistent API usage.", "Integration errors indicate a need for improved documentation and developer support.", "The bug’s fix highlights a crucial step in documentation updates.", "The bug’s root cause reveals a need for better input schema validation.", "Documentation updates improve developer experience and reduce errors."], "technical_insights": ["Missing [code] in import statement is causing ImportError.", "Milvus database initialization failure is impacting vector storage.", "LangChain’s think tag generation is producing incorrect JSON.", "LangChain handler index error is hindering code testing.", "Custom input schema injection failure is disrupting tool functionality."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. API documentation inconsistencies require clear and accurate documentation for consistent API usage.\n2. Integration errors indicate a need for improved documentation and developer support.\n3. The bug’s fix highlights a crucial step in documentation updates.\n4. The bug’s root cause reveals a need for better input schema validation.\n5. Documentation updates improve developer experience and reduce errors.\n\nTECHNICAL INSIGHTS:\n1.  Missing `[code]` in import statement is causing `ImportError`.\n2.  Milvus database initialization failure is impacting vector storage.\n3.  LangChain’s `think` tag generation is producing incorrect JSON.\n4.  LangChain handler index error is hindering code testing.\n5.  Custom input schema injection failure is disrupting tool functionality.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 56, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a `AttributeError: 'dict' object has no attribute 'model_dump'` error when using LangChain's `stream_mode=[\"debug\", \"messages\"]` with the `openai` built-in web search.  The problem seems to stem from a potential incompatibility between the LangChain integration and the specific `langsmith` library, potentially related to a recent update or a bug in the integration package.  The code attempts to leverage the `langsmith` library for logging and text streaming, and this error suggests a conflict with its internal workings.", "final_category": "bug", "comments": [{"author": "sumansuhag", "created_at": "2025-06-12T01:04:34Z", "body_clean": "This bug report is really clear and well put together. The detailed description, easy to follow example, and exact stack trace are super helpful for troubleshooting, especially the note about the failure with stream mode=[debug, messages]. This AttributeError shows there's a problem with data types in the streaming pipeline of langchain openai, which affects how LangGraph works."}, {"author": "romaljose38", "created_at": "2025-06-14T07:32:34Z", "body_clean": "This issue has been fixed in [code] version 0.3.23 . [ [link] The cause was a breaking change introduced in the [code] package starting from version 1.82.0 . If you're using an OpenAI version earlier than 1.82.0, you shouldn't encounter this issue. Context Up to version 1.81.x, the response object looked like this: [code] Starting from version 1.82.0, it changed to: [code] The annotation field was changed from a typed object (AnnotationURLCitation) to a plain dictionary in version 1.82.0, which caused the compatibility issue."}]}, {"ollama_summary": "This issue addresses a bug in the `HTMLSemanticPreservingSplitter` library that causes it to ignore child elements during splitting. The code is designed to preserve the semantic structure of HTML documents, and this bug leads to incorrect results and a lack of reproducible examples.  The issue is currently unresolved and requires a fix through a new stable release of LangChain.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-06-11T23:32:08Z", "body_clean": "It looks like your HTML contains improperly nested tags. Specifically, there's a <body tag inside a <p tag, which is invalid HTML."}, {"author": "strawgate", "created_at": "2025-06-12T01:10:05Z", "body_clean": "The issue occurs with valid html as the preservation code does not check child elements I was trying to share a minimum reproduction of the issue. I will replace the example with valid html and an example using a real webpage."}, {"author": "keenborder786", "created_at": "2025-06-12T23:30:44Z", "body_clean": "@strawgate please do"}]}, {"ollama_summary": "This issue relates to a bug in the `HTMLSemanticPreservingSplitter` library, specifically a problem with its reverse replacement order. The code attempts to split HTML elements based on a specific order, but it’s encountering inconsistencies and errors, potentially requiring a re-evaluation of the original implementation.  The code is currently failing to install dependencies and is not resolving itself, and the issue is reproducible through a minimal example.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue involves a broken link within the Langchain Hub API reference tutorial, specifically pointing to the Hub API.  The issue stems from Sphinx automatically generating the link, preventing the correct URL from being displayed.  The user is seeking assistance in modifying the URL within the Sphinx IDE to resolve this problem.", "final_category": "other", "comments": []}, {"ollama_summary": "This issue stems from a `TypeError` occurring when a `GenerationChunk` instance contains duplicate keys within its `generation_info` dictionary. This problem is causing the code to fail when attempting to add multiple `GenerationChunk` instances with the same metadata, and it’s impacting the functionality of the LangChain library.", "final_category": "bug", "comments": [{"author": "rawathemant246", "created_at": "2025-06-11T16:38:23Z", "body_clean": "hey i tried to reproduce your raised but it indeed raises type error when concatenating two generation chunk let me fix the issue."}]}], "business_insights": ["Integration package updates frequently introduce bugs, requiring careful testing.", "Compatibility issues between libraries are a recurring problem.", "Static code analysis can identify subtle bugs before runtime.", "Dependency management is critical for ensuring consistent behavior.", "Testing is essential for identifying and resolving issues early."], "technical_insights": ["LangChain integration package updates frequently; testing is vital.", "Recent changes in the langsmith library package are causing conflicts.", "The AttributeError indicates a potential incompatibility issue.", "The HTMLSemanticPreservingSplitter library's splitting logic is failing.", "Static code analysis is a proactive method to find bugs."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Integration package updates frequently introduce bugs, requiring careful testing.\n2.  Compatibility issues between libraries are a recurring problem.\n3.  Static code analysis can identify subtle bugs before runtime.\n4.  Dependency management is critical for ensuring consistent behavior.\n5.  Testing is essential for identifying and resolving issues early.\n\nTECHNICAL INSIGHTS:\n1.  LangChain integration package updates frequently; testing is vital.\n2.  Recent changes in the `langsmith` library package are causing conflicts.\n3.  The `AttributeError` indicates a potential incompatibility issue.\n4.  The `HTMLSemanticPreservingSplitter` library's splitting logic is failing.\n5.  Static code analysis is a proactive method to find bugs.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 57, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code is incompatible with OpenAI reasoning models because it doesn’t correctly handle the `max_completion_tokens` parameter, leading to an `InvalidRequestError`. The issue stems from a bug within LangChain that prevents the model from utilizing this crucial setting. A self-contained, reproducible example demonstrates the problem with a minimal, working implementation.", "final_category": "bug", "comments": [{"author": "rawathemant246", "created_at": "2025-06-11T07:45:44Z", "body_clean": "[code] [code] Hey i have tried you example code to reporduce the error but it seems that you are using the deprecated version i have use the langchain openai and i got the response from the model itself use max completion token instead of max token the model will support it. the code works correctly even with reasoning models like o1 mini 2024 09 12 If you’re using the old langchain imports or max tokens, you will get errors, because: max tokens is not supported with these models. The new API requires the parameter max completion tokens. Solution: Upgrade to langchain openai Use max completion tokens Use invoke() instead of calling the model directly Hope this helps!"}, {"author": "Dhruv-Sood-Probo", "created_at": "2025-07-02T19:17:03Z", "body_clean": "When using LangChain with ChatOpenAI, particularly with newer OpenAI reasoning models like gpt 4o or o4 mini, an issue arises due to the way LangChain internally handles and forwards the stop parameter during prompt generation. LangChain’s internal logic in the generate prompt method (or its subclasses) automatically forwards the stop argument—even when not explicitly provided by the user. This causes problems when invoking OpenAI models that do not support the stop parameter, such as reasoning capable chat models (e.g., o4 mini 2025 04 16). The relevant method in LangChain looks like this: [code] Even when stop=None, it still gets passed into the underlying OpenAI API call through kwargs. This becomes problematic for models that reject the presence of the stop argument entirely. To resolve this, I patched the internal generate method of ChatOpenAI to explicitly remove unsupported parameters like stop from kwargs before making the API call. [code] This resolved the issue in my case. The model now runs as expected without errors related to unsupported parameters."}, {"author": "mdrxy", "created_at": "2025-09-10T14:35:31Z", "body_clean": "If this isn't resolved, happy to re open"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the \"Managing Conversation History\" section on the \"Build a Chatbot\" page is currently inaccurate, specifically with a bug in the code related to storing and retrieving conversation history. The issue involves a faulty code snippet that’s not displaying the expected content.  Currently, the documentation lacks a clear link to the relevant code section.", "final_category": "other", "comments": [{"author": "rawathemant246", "created_at": "2025-06-11T15:43:42Z", "body_clean": "Hey i think the probelm is with this trimmer = trim messages(...) trimmer.invoke(messages) that's incorrect. trim messages returns pure Python function, not a Runnable object with .invoke(). So calling .invoke(messages) fails because trimmer is just a function, not a Runnable. this explain why you get the startswith so i will update the documentation accordingly."}]}, {"ollama_summary": "The `qwen3-14b` model returns `None` when validating, causing a validation error. This issue appears to be a bug in LangChain, specifically in the `ai.py` and `tool.py` files, which doesn’t handle `None` input values correctly. The proposed solution involves modifying the code to explicitly check for `None` and ensure proper validation.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue proposes adding documentation for Claude’s extended thinking feature within ChatBedrock, as the current LangChain documentation is incomplete. The core problem is that users might mistakenly believe Claude’s extended thinking isn’t supported, potentially leading to confusion and wasted effort. The solution involves creating detailed documentation and examples to illustrate this capability.", "final_category": "question", "comments": [{"author": "capDoYeonLee", "created_at": "2025-07-22T01:45:02Z", "body_clean": "Hi, @jasonkang14 is this issue valid?? Can I try work on? Is it possible for beginners? I'll try my best!"}]}, {"ollama_summary": "The issue reports a circular import problem within LangChain that persists even after updating to the latest stable version.  The problem stems from a specific, reproducible example that triggers the import error, suggesting a bug within the LangChain library itself.  A maintainer has provided a minimal, self-contained example to demonstrate the issue and facilitate debugging.", "final_category": "bug", "comments": [{"author": "MichaelLi65535", "created_at": "2025-06-08T13:20:20Z", "body_clean": "Hi @Tusenka , you are using an outdated Python version. Can you please upgrade it to the latest 3.11.13 or 3.12 , and try again? I tested the same using Python 3.12, no issue found."}, {"author": "RAJTripathi3030", "created_at": "2025-06-09T03:23:09Z", "body_clean": "Hey there @Tusenka , I too checked the same code on my machine and I'm on linux too and it seems to be working fine, there were no cyclic errors on my machine ![Image]( [link]"}, {"author": "zameel7", "created_at": "2025-06-09T09:36:45Z", "body_clean": "Example Code The following code: [code] @Tusenka, is this the only code you have in the page? From the log, it seems that this import is in the third line. Something else above the third line might be causing an issue?"}]}], "business_insights": ["LangChain’s bug regarding max_completion_tokens impacts OpenAI reasoning models, requiring precise setting handling.", "Documentation inaccuracies in the “Manage Conversation History” section hinder chatbot development.", "qwen3-14b returns None validation, demanding code modifications for robust validation.", "Claude’s extended thinking feature documentation is incomplete, causing user confusion.", "LangChain circular import issue persists after updates, suggesting library bug."], "technical_insights": ["LangChain’s ai.py and tool.py need modifications to handle None input values correctly.", "The InvalidRequestError is linked to the max_completion_tokens parameter in the langchain.LLM class.", "The qwen3-14b model returns None validation, impacting the core LangChain model.", "Claude’s extended thinking feature documentation lacks a clear link to the relevant code.", "LangChain circular import problem persists after updates, indicating a library issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s bug regarding `max_completion_tokens` impacts OpenAI reasoning models, requiring precise setting handling.\n2.  Documentation inaccuracies in the “Manage Conversation History” section hinder chatbot development.\n3.  `qwen3-14b` returns `None` validation, demanding code modifications for robust validation.\n4.  Claude’s extended thinking feature documentation is incomplete, causing user confusion.\n5.  LangChain circular import issue persists after updates, suggesting library bug.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s `ai.py` and `tool.py` need modifications to handle `None` input values correctly.\n2.  The `InvalidRequestError` is linked to the `max_completion_tokens` parameter in the `langchain.LLM` class.\n3.  The `qwen3-14b` model returns `None` validation, impacting the core LangChain model.\n4.  Claude’s extended thinking feature documentation lacks a clear link to the relevant code.\n5.  LangChain circular import problem persists after updates, indicating a library issue.\n", "batch_number": 58, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `with_structured_output()` function in LangChain is causing a 422 UnprocessableEntityError when used with Azure-hosted Deepseek V3, specifically when it’s expecting a string input.  The issue is reproducible with a minimal example and doesn’t appear to be a bug in LangChain itself, suggesting a potential issue with the Deepseek V3 integration.  Currently, the solution is not addressed through recent LangChain updates.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-06-08T01:34:43Z", "body_clean": "Can you share your messages that you are passing?"}, {"author": "finboard-dev", "created_at": "2025-06-08T02:51:59Z", "body_clean": "Sure! Here's the exact message I sent(I am not using any tool or system prompt): [code]"}, {"author": "finboard-dev", "created_at": "2025-06-13T18:25:00Z", "body_clean": "Any update on this?"}, {"author": "organic1337", "created_at": "2025-07-03T09:01:31Z", "body_clean": "Any update?"}, {"author": "AhmedTammaa", "created_at": "2025-07-12T22:09:02Z", "body_clean": "@finboard dev CC: @organic1337 @keenborder786 I found the issue. It's an incompatibility issue. I will create a PR to fix it. Until then, you can try this workaround [code] please let me know if it fixed the issue for you"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that causes inconsistent tool call indices when using the Qwen3 streaming output. When the model invokes a second tool, it generates two incorrect tool calls instead of one, leading to a specific error message and stack trace. The solution involves a self-contained, reproducible example demonstrating the problem with the provided code.", "final_category": "bug", "comments": [{"author": "yaozhicheng", "created_at": "2025-06-11T05:06:47Z", "body_clean": "I encountered a similar issue where when using Qwen3 with ChatOpenAI(..., streaming=True ), it throws tool related errors. These errors don't occur when streaming=False . Error info: [code] vllm: [code]"}, {"author": "mdrxy", "created_at": "2025-07-29T14:20:01Z", "body_clean": "Actually, reverting this. Original issue stems from using [code] to interact with a [code] model. Recommended to use [langchain qwq]( [link] which is built for Qwen"}, {"author": "1723229", "created_at": "2025-10-13T06:00:49Z", "body_clean": "请问目前已经修复了吗，需要升级langchain版本吗"}, {"author": "Superhors", "created_at": "2025-10-13T06:09:26Z", "body_clean": "请问目前已经修复了吗，需要升级langchain版本吗 我是自己改的源码，最新版本没试过。最新的sglang部署llm好像会解决这个问题，你可以试试"}, {"author": "1723229", "created_at": "2025-10-13T06:19:23Z", "body_clean": "请问目前已经修复了吗，需要升级langchain版本吗 我是自己改的源码，最新版本没试过。最新的sglang部署llm好像会解决这个问题，你可以试试 可否提供下改源码的方案呢，谢谢"}]}, {"ollama_summary": "This issue involves integrating the Claude Sonnet 4 language model into LangChain agents using Postgres SQL. The model is experiencing issues with intermediate node outputs, specifically missing tool messages, and the current implementation doesn't correctly handle the model's output. The issue is currently being addressed by the developer, and the code is designed to be run as-is.", "final_category": "bug", "comments": [{"author": "isaacwasserman", "created_at": "2025-06-06T15:19:07Z", "body_clean": "I am also experiencing this with Sonnet 4 and Bedrock. ~~I'm not sure if this is truly a LangChain bug or a Bedrock bug. To the best of my knowledge, the XML portion should be extracted and parsed by by Bedrock, not LangChain.~~"}, {"author": "isaacwasserman", "created_at": "2025-06-06T16:51:37Z", "body_clean": "I can see from my Bedrock logs that LangChain adds this to the system prompt on Sonnet 4, but not on Sonnet 3.5 v2: [link] It's misinforming Claude on which tool calling format to use."}, {"author": "isaacwasserman", "created_at": "2025-06-06T17:24:12Z", "body_clean": "Solution: Update [code] package to at least 0.2.23. Was resolved last week with this commit: [link]"}]}, {"ollama_summary": "The code snippet is a Python script that contains a series of `print()` statements. Each statement prints a different value, including:\n\n*   `\"Hello\"`\n*   `\"world\"`\n*   `\"123\"`\n*   `\"456\"`\n*   `\"789\"`\n*   `\"0\"`\n*   `\"1\"`\n*   `\"2\"`\n*   `\"3\"`\n*   `\"4\"`\n*   `\"5\"`\n*   `\"6\"`\n*   `\"7\"`\n*   `\"8\"`\n*   `\"9\"`\n*   `\"0\"`\n*   `\"1\"`\n*   `\"2\"`\n*   `\"3\"`\n*   `\"4\"`\n*   `\"5\"`\n*   `\"6\"`\n*   `\"7\"`\n*   `\"8\"`\n*   `\"9\"`\n*   `\"0\"`\n*   `\"1\"`\n*   `\"2\"`\n*   `\"3\"`\n*   `\"4\"`\n*   `\"5\"`\n*   `\"6\"`\n*   `\"7\"`\n*   `\"8\"`\n*   `\"9\"`\n*   `\"0\"`\n*   `\"1\"`\n*   `\"2\"`\n*   `\"3\"`\n*   `\"4\"`\n*   `\"5\"`\n*   `\"6\"`\n*   `\"7\"`\n*   `\"8\"`\n*   `\"9\"`\n*   `\"0\"`\n*   `\"1\"`\n*   `\"2\"`\n*   `\"3\"`\n*   `\"4\"`\n*   `\"5\"`\n*   `\"6\"`\n*   `\"7\"`\n*   `\"8\"`\n*   `\"9\"`\n*   `\"0\"`\n*   `\"1\"`\n*   `\"2\"`\n*   `\"3\"`\n*   `\"4\"`\n*   `\"5\"`\n*   `\"6\"`\n*   `\"7\"`\n*   `\"8\"`\n*   `\"9\"`\n*   `\"0\"`\n*   `\"", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in the LangGraph agent, specifically a `missing_required_parameter` error when using LangChain to pass multimodal data to models. The bug is present in the latest stable version of LangChain and doesn't appear to be related to code changes. It requires a self-contained, minimal example to reproduce the issue, and the error occurs when using images versus files.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-06-05T20:27:36Z", "body_clean": "Hello, thanks for reporting this. Could you upgrade your [code] to latest to see if that resolves your issue? I see you have 0.3.48 installed, but the format used for the PDF there was introduced in 0.3.52."}, {"author": "FedericoCampe8", "created_at": "2025-06-05T20:52:40Z", "body_clean": "same here with version 0.3.63 (for core)"}, {"author": "EandrewJones", "created_at": "2025-06-05T22:13:15Z", "body_clean": "Version 0.3.63, minimum reproducible example. [code] The above fails with: [code] But calling openai [code] with the same payload: [code] Response: json { \"id\": \"chatcmpl BfD5RLiOYlfcsy22Hoi9adf6S6veJ\", \"object\": \"chat.completion\", \"created\": 1749161453, \"model\": \"gpt 4o 2024 08 06\", \"choices\": [ { \"index\": 0, \"message\": { \"role\": \"assistant\", \"content\": \"The document contains the text \\\"Dummy PDF.\\\"\", \"refusal\": null, \"annotations\": [] }, \"logprobs\": null, \"finish reason\": \"stop\" } ], \"usage\": { \"prompt tokens\": 230, \"completion tokens\": 9, \"total tokens\": 239, \"prompt tokens details\": { \"cached tokens\": 0, \"audio tokens\": 0 }, \"completion tokens details\": { \"reasoning tokens\": 0, \"audio tokens\": 0, \"accepted prediction tokens\": 0, \"rejected prediction tokens\": 0 } }, \"service tier\": \"default\", \"system fingerprint\": \"fp 07871e2ad8\" }"}, {"author": "ccurme", "created_at": "2025-06-05T22:21:55Z", "body_clean": "@EandrewJones I'm unable to reproduce the error on latest [code] , can you confirm what version you're running? @brunoshine I see your version of [code] is also old, are you able to update as well? Thanks all for the reports!"}, {"author": "EandrewJones", "created_at": "2025-06-05T23:32:09Z", "body_clean": "@ccurme, I updated to latest and it's working now. Thanks. Best Evan Jones On Thu, Jun 5, 2025 at 3:22 PM ccurme @ . wrote: ccurme left a comment (langchain ai/langchain 31505) < [link] @EandrewJones < [link] I'm unable to reproduce the error on latest langchain openai, can you confirm what version you're running? @brunoshine < [link] I see your version of langchain openai is also old, are you able to update as well? Thanks all for the reports! — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you were mentioned.Message ID: @ ."}, {"author": "brunoshine", "created_at": "2025-06-06T10:21:39Z", "body_clean": "Hi @ccurme thanks for the quick response. some updates: Updated packages to latest versions [code] Google model: gemini 1.5 flash (Azure) OpenAI model: GPT 4o URL Path Test [code] Google ✅ (Azure) OpenAI 🛑 error: [code] Base64 Test if I use: [code] Google ✅ (Azure) OpenAI 🛑 error: [code] Any thoughts? Thanks"}, {"author": "brunoshine", "created_at": "2025-06-07T08:42:34Z", "body_clean": "As additional support, here is a notebook that showcases the error: [gist]( [link] I can also confirm that: the error also happens with the [code] class (additionally to the Azure one shown above) if I change the message format from the one [described on the documentation]( [link] to the [example above]( [link] provided by @EandrewJones, the model starts responding correctly but only for [code] class. For the [code] it throws [code]"}, {"author": "ccurme", "created_at": "2025-06-10T20:11:45Z", "body_clean": "Hi @brunoshine, I believe the first example fails because OpenAI does not support loading PDFs from URLs (see their docs [here]( [link] LangChain's Google integration may have extra logic to pull the PDF client side and upload the bytes in line. For the second issue, OpenAI requires a filename attached to PDFs. You should be seeing a warning with your requests. There's a note on this in the guide here: [link]"}, {"author": "brunoshine", "created_at": "2025-06-11T10:16:43Z", "body_clean": "Hi @ccurme, thank you for the reply. I've updated the tests and these are the results. Google and OpenAI works. Azure OpenAI does not work . I believe the first example fails because OpenAI does not support loading PDFs from URLs (see their docs [here]( [link] LangChain's Google integration may have extra logic to pull the PDF client side and upload the bytes in line. Shouldn't this work the same across the board? Meaning, LangChain model providers have the same behaviour, being that its already making an abstraction over how to send the files to the models. Thanks Message format [code] Google ✅ [code] Output: [code] OpenAI ✅ [code] Output: [code] Azure OpenAI 🛑 [code] Output: [code]"}, {"author": "ccurme", "created_at": "2025-06-14T20:02:21Z", "body_clean": "What model is deployed under [code] ? That error is from the server and is saying that file inputs aren't compatible with that specific model."}, {"author": "brunoshine", "created_at": "2025-06-16T10:14:15Z", "body_clean": "Hi @ccurme. Im using Azure OpenAI gpt 4o."}, {"author": "brunoshine", "created_at": "2025-07-08T16:53:10Z", "body_clean": "Hi @ccurme any update on this? Thanks."}, {"author": "greixs", "created_at": "2025-08-28T06:07:31Z", "body_clean": "bumping this as I am also getting the same issue"}]}], "business_insights": ["Focus on consistent error patterns across issues – a recurring UnprocessableEntityError suggests a deeper underlying issue than isolated bugs.", "LangChain’s integration with Deepseek V3 might be a shared vulnerability – a unified solution is needed to address it across all modules.", "The Qwen3 streaming output issue highlights a potential problem with the model’s output formatting – a refined integration strategy is critical.", "Claude Sonnet 4 model inconsistencies suggest a problem with the model’s input processing – a robust, repeatable test suite is required.", "The Postgres SQL integration presents a significant risk – comprehensive testing across all database interactions is essential."], "technical_insights": ["Deepseek V3’s with_structured_output() function is the root cause of the UnprocessableEntityError.", "The Qwen3 streaming output inconsistency involves tool call indexing, requiring a reproducible example.", "LangChain’s integration with Postgres SQL is failing to correctly handle model outputs – a self-contained test is needed.", "The Python script’s print statements are a symptom of a broader issue; debugging and isolating the source of the error is required.", "The Claude Sonnet 4 integration presents a potential model-specific issue; a regression test is needed to confirm this."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on consistent error patterns across issues – a recurring `UnprocessableEntityError` suggests a deeper underlying issue than isolated bugs.\n2.  LangChain’s integration with Deepseek V3 might be a shared vulnerability – a unified solution is needed to address it across all modules.\n3.  The `Qwen3 streaming output` issue highlights a potential problem with the model’s output formatting – a refined integration strategy is critical.\n4.  Claude Sonnet 4 model inconsistencies suggest a problem with the model’s input processing – a robust, repeatable test suite is required.\n5.  The Postgres SQL integration presents a significant risk – comprehensive testing across all database interactions is essential.\n\nTECHNICAL INSIGHTS:\n1.  Deepseek V3’s `with_structured_output()` function is the root cause of the `UnprocessableEntityError`.\n2.  The Qwen3 streaming output inconsistency involves tool call indexing, requiring a reproducible example.\n3.  LangChain’s integration with Postgres SQL is failing to correctly handle model outputs – a self-contained test is needed.\n4.  The Python script’s print statements are a symptom of a broader issue; debugging and isolating the source of the error is required.\n5.  The Claude Sonnet 4 integration presents a potential model-specific issue; a regression test is needed to confirm this.\n\n", "batch_number": 59, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in the `cosine_similarity` function where it returns an empty array when the input array is empty, causing compatibility problems and potentially impacting downstream functionality. The issue is currently resolved by a stable version of LangChain, but the bug persists across different versions.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a subtle but critical bug in the `cosine_similarity` function that silently returns `0.0` for vectors with `inf` and `nan` values, potentially leading to incorrect results in LangChain applications.  The bug is currently unresolved and requires a fix, and the code provides a minimal, reproducible example for testing.", "final_category": "bug", "comments": []}, {"ollama_summary": "Okay, let's break down this error message and what it means.\n\n**Understanding the Error**\n\nThe error message \"OpenAI.BadRequestError: Error code: 400\" indicates that OpenAI is returning an error because your request to the OpenAI API is not formatted correctly. Specifically, it's a 400 Bad Request error, meaning the API is rejecting your request.\n\n**The Root Cause**\n\nThe core issue is that you're using the `langchain` library, which is designed to interact with the OpenAI API. The `langchain` library has a specific format for sending requests to the OpenAI API. The error message points to a mismatch between the format of your request and what the OpenAI API expects.\n\n**What's Happening (Likely)**\n\nThe most probable cause is that you're inadvertently sending data in a way that's not compliant with the `langchain` API requirements.  The error message suggests that the `langchain` library is interpreting your request as something different than it's intended to receive.\n\n**How to Fix It**\n\n1.  **Review the `langchain` Documentation:**  The most important thing is to carefully read the official documentation for the `langchain` library.  It will have detailed instructions on the expected format of requests.\n\n2.  **Check Your Code:**  Examine your code where you're making the API call to OpenAI.  Make sure you're sending the data in the correct format.  The `langchain` library usually expects data in a specific structure (often a JSON object with keys and values).\n\n3.  **Simplify Your Request:**  If you're using a complex request, try simplifying it to the bare minimum required to make the API call.\n\n4.  **Update `langchain`:** Ensure you are using the latest version of the `langchain` library.\n\n**Example of Correct Request Format (Illustrative - Refer to the Official Documentation)**\n\nThe `langchain` documentation provides a sample request format.  Here's a simplified example (you'll need to adapt it to your specific use case):\n\n```json\n{\n  \"model\": \"gpt-3.5-turbo\",\n  \"prompt\": \"Write a short story about a cat.\",\n  \"max_tokens\": 100\n}\n```\n\n**Important Note:**", "final_category": "bug", "comments": [{"author": "rvasa779", "created_at": "2025-06-04T11:20:09Z", "body_clean": "Model that I am using is gpt 4o version: 2025 03 01 preview"}, {"author": "mdrxy", "created_at": "2025-07-16T18:16:30Z", "body_clean": "You should try a different model that supports json mode"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's `langchain-core` version 0.3.63 that causes the \"text\" field to be missing from the `text` object when using `load()`.  The fix involves reverting to the previous stable version of LangChain.  The code example demonstrates how to reproduce the issue and provides a minimal, reproducible test case.", "final_category": "bug", "comments": [{"author": "sydney-runkle", "created_at": "2025-06-05T01:52:16Z", "body_clean": "Hi! Thanks for the report definitely a bug. Will look into a fix!"}]}, {"ollama_summary": "Okay, let's break down this error and how to fix it.\n\n**The Problem**\n\nThe error message \"langchains considers it as unique string instead of parsing the json schema provided by the agent\" indicates that the `tool.run()` function is interpreting the input data (the JSON structure) as a single, unique value instead of treating it as a series of individual elements.  This is a common issue when working with tools that expect a specific format for input.\n\n**Root Cause**\n\nThe problem stems from the way `tool.run()` handles the input data.  It's likely that the agent is expecting a specific structure within the JSON data, and it's interpreting the entire input as a single unit, rather than breaking it down into its constituent parts.\n\n**Solution**\n\nYou need to ensure that the `tool.run()` function is correctly parsing the JSON data and extracting the individual elements that make up the expected input format.  Here's a breakdown of the steps:\n\n1. **Examine the Agent's Documentation:** The most crucial step is to carefully review the documentation for the specific tool you're using.  It should clearly define the expected input format.  Look for examples of how the tool expects the JSON data to be structured.\n\n2. **Inspect the Input Data:**  Print out the `tool.run()` input data to see exactly what the agent is receiving.  This will help you understand the structure and identify any unexpected elements.\n\n3. **Modify `tool.run()`:**  Adjust the `tool.run()` function to correctly parse the JSON data.  This might involve:\n   -  Adding or removing elements from the input data.\n   -  Transforming the data into a specific format that the agent expects.\n   -  Using a more specific parsing method.\n\n4. **Handle Errors Gracefully:**  If the input data is not in the expected format, you should handle the error gracefully.  Instead of crashing, you can log the error, provide a default value, or take other appropriate actions.\n\n**Example (Illustrative - Adapt to your specific tool)**\n\nLet's say the agent expects a JSON object with a `name` and `age` field.  You might modify the `tool.run()` function like this:\n\n```python\ndef tool_run(input_data):\n    try:\n        data =", "final_category": "bug", "comments": [{"author": "martin-san03", "created_at": "2025-06-04T01:40:56Z", "body_clean": "I'm not sure is the good approach, but I was able to call my tool doing this change in .venv\\Lib\\site packages\\langchain core\\tools\\base.py:547 python def parse input( self, tool input: Union[str, dict], tool call id: Optional[str] ) Union[str, dict[str, Any]]: \"\"\"Convert tool input to a pydantic model. Args: tool input: The input to the tool. tool call id: The id of the tool call. \"\"\" input args = self.args schema if isinstance(tool input, str): if input args is not None: if isinstance(input args, dict): msg = ( \"String tool inputs are not allowed when \" \"using tools with JSON schema args schema.\" ) raise ValueError(msg) key = next(iter(get fields(input args).keys())) if hasattr(input args, \"model validate\"): +++ tool input = json.loads(tool input) +++ input args.model validate(tool input) input args.model validate({key : tool input}) else: input args.parse obj({key : tool input}) return tool input"}, {"author": "eyurtsev", "created_at": "2025-06-05T14:50:35Z", "body_clean": "Please move to the langgraph for agents. AgentExecutor is very old now. It's very straight forward: [link]"}, {"author": "martin-san03", "created_at": "2025-06-06T13:28:24Z", "body_clean": "Oh, I see...thanks! Will do"}]}], "business_insights": ["Proper input data validation is crucial for reliable agent behavior.", "The langchain library’s format mismatch is a significant bug, impacting usability.", "Addressing the langchain bug will improve overall system stability.", "A clear error message and specific fix are vital for developer understanding.", "The tool.run() function’s format specification needs refinement."], "technical_insights": ["The langchain library's format mismatch is a critical bug, potentially leading to unexpected behavior.", "The langchain library’s format mismatch is causing the text field to be missing when using load().", "The langchain library’s format mismatch is causing an \"OpenAI.BadRequestError: Error code: 400\" response for OpenAI API requests.", "The langchain library’s format mismatch is causing the agent to misinterpret data.", "The langchain library’s format mismatch requires a fix to the tool.run() function."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Proper input data validation is crucial for reliable agent behavior.\n2.  The `langchain` library’s format mismatch is a significant bug, impacting usability.\n3.  Addressing the `langchain` bug will improve overall system stability.\n4.  A clear error message and specific fix are vital for developer understanding.\n5.  The `tool.run()` function’s format specification needs refinement.\nTECHNICAL INSIGHTS:\n1.  The `langchain` library's format mismatch is a critical bug, potentially leading to unexpected behavior.\n2.  The `langchain` library’s format mismatch is causing the `text` field to be missing when using `load()`.\n3.  The `langchain` library’s format mismatch is causing an \"OpenAI.BadRequestError: Error code: 400\" response for OpenAI API requests.\n4.  The `langchain` library’s format mismatch is causing the agent to misinterpret data.\n5.  The `langchain` library’s format mismatch requires a fix to the `tool.run()` function.\n", "batch_number": 60, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The agent executor consistently fails to return a 'normal' text response, resulting in an empty string. This issue is likely caused by a bug within LangChain, specifically related to the `langsmith` integration package.  The code is designed to generate a text response, but the `[code]` key is consistently populated with an empty string, leading to the error.  The issue is reproducible with a minimal example and is being addressed by the maintainers.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-07-22T15:15:15Z", "body_clean": "Hey @FieteO, I believe it's how you're passing input into the agent. Try: [code] Instead of: [code]"}]}, {"ollama_summary": "The USearch index is malfunctioning and failing to function correctly when attempting to create an empty index.  The issue appears to be a bug within the LangChain library, specifically related to its index management. A self-contained, reproducible example demonstrates the problem – attempting to create an empty index results in an error.  The developers are investigating and working to resolve this issue.", "final_category": "bug", "comments": []}, {"ollama_summary": "The `pipenv run langgraph dev` command fails with an \"ImportError: attempted relative import with no known parent package\" error, specifically when running within a LangChain project.  The issue appears to be a bug within LangChain itself, not directly caused by the user's code, and is reproducible with a minimal example.  The solution involves updating to the latest stable version of LangChain, which doesn’t resolve the problem.", "final_category": "bug", "comments": [{"author": "khteh", "created_at": "2025-07-12T03:24:03Z", "body_clean": "Move to langgraph"}]}, {"ollama_summary": "This issue focuses on adding the ability to pass template values (specifically, `enable thinking` in Qwen3) to the LangChain `llm.invoke` function. The current implementation doesn't correctly utilize these values, potentially leading to unexpected behavior or errors when interacting with the model.  The issue highlights a bug in the LangChain library that needs to be addressed to ensure proper model invocation and integration with the open-source model.", "final_category": "feature", "comments": [{"author": "Aristote-code", "created_at": "2025-06-04T08:41:45Z", "body_clean": "Hi, I’d like to pick this up."}, {"author": "deepyes02", "created_at": "2025-06-05T10:05:37Z", "body_clean": "Thanks ! Hope to see this in action soon !"}, {"author": "mohsen-goodarzi", "created_at": "2025-08-04T09:51:15Z", "body_clean": "@deepyes02, you can also consider passing the [code] argument to the [code] , as described here: [link]"}]}, {"ollama_summary": "The Groq parser is consistently failing with a 400 Bad Request error, even with a valid output.  The issue appears to be a bug within the LangChain integration for Groq, potentially related to the way it handles the output of the `llama.cpp` model. A self-contained example demonstrates the problem with a minimal, reproducible setup.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-06-02T20:15:33Z", "body_clean": "Could you try sleeping between request to just make sure it's not rate limiting in reality and getting thrown as the wrong error?"}, {"author": "MagMueller", "created_at": "2025-06-03T05:04:30Z", "body_clean": "@eyurtsev Just happened in the very first request. This is not rate limiting error. <img width=\"1298\" alt=\"Image\" src=\" [link] / <img width=\"896\" alt=\"Image\" src=\" [link] /"}, {"author": "mdrxy", "created_at": "2025-07-11T15:34:16Z", "body_clean": "I'm running this code locally and am not encountering any errors. Please ensure your environment is up to date and let me know if the issue persists, and we can investigate further."}]}], "business_insights": ["Integration package bugs frequently impact core functionality, requiring immediate attention.", "LangChain’s indexing mechanisms are susceptible to errors, impacting model performance.", "The pipenv run command’s failure highlights a potential dependency issue.", "Feature integration requires careful testing and validation of new functionality.", "Bug fixes should prioritize stability and prevent regressions in future releases."], "technical_insights": ["LangChain’s langsmith integration package is a known source of bugs.", "The index management bug is likely related to the LangChain library.", "pipenv run command errors suggest a problem with LangChain’s internal management.", "The llm.invoke bug highlights a potential issue with LangChain's model invocation.", "Groq parser errors necessitate specific updates and debugging within LangChain."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Integration package bugs frequently impact core functionality, requiring immediate attention.\n2.  LangChain’s indexing mechanisms are susceptible to errors, impacting model performance.\n3.  The `pipenv run` command’s failure highlights a potential dependency issue.\n4.  Feature integration requires careful testing and validation of new functionality.\n5.  Bug fixes should prioritize stability and prevent regressions in future releases.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s `langsmith` integration package is a known source of bugs.\n2.  The index management bug is likely related to the LangChain library.\n3.  `pipenv run` command errors suggest a problem with LangChain’s internal management.\n4.  The `llm.invoke` bug highlights a potential issue with LangChain's model invocation.\n5.  Groq parser errors necessitate specific updates and debugging within LangChain.\n", "batch_number": 61, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Pydantic library has deprecated the `schema` method, requiring users to switch to `model_json_schema`.  The issue highlights a documented change and provides a checklist for implementing the new method.  Currently, the documentation doesn’t provide a clear explanation of the change, prompting a request for more detail.", "final_category": "other", "comments": [{"author": "97tkddnjs", "created_at": "2025-06-08T10:25:25Z", "body_clean": "Hi @khteh! I'd like to help fix this documentation issue. I can see that the problem is caused by using the deprecated [code] method in the tool runtime documentation, which leads to JSON schema generation failures with complex types like [code] . I'm planning to: 1. Update all instances of [code] to [code] in the documentation 2. Add proper error handling examples for complex types 3. Include a troubleshooting section for schema generation issues 4. Test all code examples to ensure they work with Pydantic V2 Would it be okay if I work on this? I can submit a PR within the next few days. Thanks for reporting this issue!"}, {"author": "khteh", "created_at": "2025-06-08T10:28:35Z", "body_clean": "Did you read my post \"After the change advised by the error:\" part of it?"}, {"author": "97tkddnjs", "created_at": "2025-06-08T10:49:47Z", "body_clean": "@khteh Sorry, I didn't read your post carefully enough! I focused too much on the error log and the BaseStore issue, so I thought this was just a simple documentation fix. I missed that you already tried the [code] change and it still failed with the BaseStore schema generation error. Let me take a proper look at the actual problem and see if I can find a working solution for this specific issue. Thanks for pointing that out!"}, {"author": "khteh", "created_at": "2025-06-08T10:56:27Z", "body_clean": "The code in question is here: [link]"}]}, {"ollama_summary": "The issue reports a `ModuleNotFoundError` when attempting to import the `langchain.output_parsers.schema` module, specifically in the `langchain` project.  The problem persists even after updating to the latest stable version of LangChain and the provided example code consistently produces the same error.  The issue suggests a potential bug within the LangChain library itself.", "final_category": "bug", "comments": [{"author": "97tkddnjs", "created_at": "2025-06-02T12:04:53Z", "body_clean": "\"I think this import statement is correct for your LangChain version: from langchain.output parsers.structured import ResponseSchema\""}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a bug in LangChain’s relative imports that prevents the code from running correctly.  The developer has identified a problem that isn’t being addressed by updating the LangChain version, and has provided a self-contained example demonstrating the issue.  The core problem is a lack of proper handling of relative imports within the LangChain framework.", "final_category": "question", "comments": [{"author": "eyurtsev", "created_at": "2025-06-02T20:16:34Z", "body_clean": "Follow the instructions here [code] The issue is that you didn't install the dependencies, so python can't resolve the code that you're referencing"}, {"author": "khteh", "created_at": "2025-06-03T03:12:47Z", "body_clean": "WTF, have you even tried this yourself!?!"}, {"author": "sumanthakkala", "created_at": "2025-08-08T02:11:33Z", "body_clean": "@khteh did you figure out the solution? I am facing the same issue & I can't seem to understand how to fix this thing!!"}]}, {"ollama_summary": "This issue relates to a critical bug in AzureChatOpenAI that prevents it from supporting the reasoning summary flag required for the o4-mini model.  The code is experiencing a problem where it fails to properly integrate with this feature, necessitating a workaround without modifying the core LangChain library.  The issue is currently unresolved, and a minimal, reproducible example exists for testing.", "final_category": "feature", "comments": [{"author": "ccurme", "created_at": "2025-05-31T11:54:06Z", "body_clean": "Hi, thanks for reporting this. It looks like things are routing through the chat completions API. Can you try specifying [code] when initializing [code] ? This is arguably a bug in that we could infer that you intend to use Responses by checking for the [code] param in this function: [link]"}, {"author": "willxie", "created_at": "2025-06-02T22:25:31Z", "body_clean": "That did the trick! Thanks for getting back so quickly. [code] There's also an additional step to request summary access for both Azure and Openai to. Example output: [code] A small request is to make the Langchain wrapper more ergonomic. It's somewhat challenging to both debug what's supported by the API provider, then again look at how Lanchain handles the request wrapping. The official documentation abstracted out the difference between [Request and Chat endpoints]( [link] using [code] , which makes debugging harder."}, {"author": "andrewdoro", "created_at": "2025-06-10T15:33:10Z", "body_clean": "Same issue is happening on langchain js"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes BaseOpenAI and BaseChatOpenAI to incorrectly interpret and pass parameters to various OpenAI APIs, leading to inconsistent behavior and potentially breaking compatibility. The code provides a minimal, reproducible example demonstrating this issue, and the developers are actively working on a fix.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-05-31T13:28:04Z", "body_clean": "BaseOpenAI is using the following client endpoint: [link] which is now legacy, therefore you should just use BaseChatOpenAI and providers built on top on that parent class"}, {"author": "cfytrok", "created_at": "2025-06-02T07:26:52Z", "body_clean": "I use OpenAI compatible API from LiteLLM Proxy. It proxies requests to Qwen2.5 coder. I use FIM completion feature. Is it possible to use suffix parameter in BaseChatOpenAI? [link] endpoint also doesn't support suffix."}]}], "business_insights": ["Documentation needs clearer explanations of the change in schema deprecation.", "Consistent error handling for the langchain.output_parsers.schema module is crucial.", "The bug within LangChain’s library itself might be the root cause.", "Dependency management and relative import handling are a significant concern.", "The lack of documentation hinders developer understanding and troubleshooting.", "Hi @khteh! I’d like to help fix this documentation issue. I can see that the problem is caused by using the deprecated [code] method in the tool runti", "Did you read my post \"After the change advised by the error:\" part of it?", "Did you read my post \"After the change advised by the error:\" part of it?", "Follow the instructions here [code] The issue is that you didn’t install the dependencies, so python can’t resolve the code that you’re referencing", "That did the trick! Thanks for getting back so quickly. [code] There’s also an additional step to request summary access for both Azure and Openai to", "Hi, thanks for reporting this. It looks like things are routing through the chat completions API. Can you try specifying [code] when initializing [cod", "I use OpenAI compatible API from LiteLLM Proxy. It proxies requests to Qwen2.5 coder. I use FIM completion feature. Is it possible to use suffix param"], "technical_insights": ["LangChain’s library has a deprecated schema method.", "ModuleNotFoundError persists when importing langchain.output_parsers.schema.", "The bug originates within the LangChain library's core.", "Relative import issues are hindering code execution.", "The bug is affecting the integration of the langchain.output_parsers.schema module."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Documentation needs clearer explanations of the change in schema deprecation.\n2. Consistent error handling for the `langchain.output_parsers.schema` module is crucial.\n3. The bug within LangChain’s library itself might be the root cause.\n4. Dependency management and relative import handling are a significant concern.\n5. The lack of documentation hinders developer understanding and troubleshooting.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s library has a deprecated schema method.\n2. `ModuleNotFoundError` persists when importing `langchain.output_parsers.schema`.\n3. The bug originates within the LangChain library's core.\n4. Relative import issues are hindering code execution.\n5.  The bug is affecting the integration of the `langchain.output_parsers.schema` module.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Hi @khteh! I’d like to help fix this documentation issue. I can see that the problem is caused by using the deprecated [code] method in the tool runti\n2.  Did you read my post \"After the change advised by the error:\" part of it?\n3.  Did you read my post \"After the change advised by the error:\" part of it?\n4.  Follow the instructions here [code] The issue is that you didn’t install the dependencies, so python can’t resolve the code that you’re referencing\n5.  That did the trick! Thanks for getting back so quickly. [code] There’s also an additional step to request summary access for both Azure and Openai to\n6.  Hi, thanks for reporting this. It looks like things are routing through the chat completions API. Can you try specifying [code] when initializing [cod\n7.  I use OpenAI compatible API from LiteLLM Proxy. It proxies requests to Qwen2.5 coder. I use FIM completion feature. Is it possible to use suffix param\n", "batch_number": 62, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This GitHub issue reports a critical bug in the HuggingFaceEndpoint library, specifically related to the `mlastralai/Mistral 7B Instruct v0.3` model. The bug causes errors when attempting to use this model with LangChain and Jupyter Notebooks, leading to a `ValueError: Model mistralai/Mistral 7B Instruct v0.3 is not supported for task text generation` message. The issue suggests a potential incompatibility with the model and the LangChain integration, and the developer has provided a minimal, reproducible example to help diagnose the problem.", "final_category": "bug", "comments": [{"author": "daniau23", "created_at": "2025-05-30T14:51:41Z", "body_clean": "I just re ran the jupyter notebook code and the same error occurred saying ValueError: Model mistralai/Mistral 7B Instruct v0.3 is not supported for task text generation and provider together. Supported task: conversational. I have used this same model to make an information grabber and had no issues with it. So why the issue ? Jupyter code snippets [code] Error [code]"}, {"author": "keenborder786", "created_at": "2025-05-31T13:41:42Z", "body_clean": "Yes, it's does not support text genenration, but only support conversational task. Please have a look here: [link]"}, {"author": "daniau23", "created_at": "2025-05-31T14:33:24Z", "body_clean": "@keenborder786 I understand but I have used this same model for text generation. Just on Wednesday I ran it using with Langchain QApipeline and have used this same model for most of my projects for QA pipeline last year. Even the Langcahin docs made used of it as so [code] [HuggingFace Endpoints]( [link] But could you suggest some models, which can be used on the HuggingFace Endpoints on free tier?"}, {"author": "keenborder786", "created_at": "2025-06-01T00:40:44Z", "body_clean": "I just tried mistralai/Mistral 7B Instruct v0.3, and it works for text generation. By default, HuggingFaceEndpoint is configured for text generation, and the task parameter is essentially ignored—it always defaults to text generation. Can you please try the following code: [code]"}, {"author": "daniau23", "created_at": "2025-06-01T07:57:53Z", "body_clean": "I don't have an openai subscription so I made use of cohere embeddings instead and still got the same error code [code] Error messages It still defaults to this error message ValueError: Model mistralai/Mistral 7B Instruct v0.3 is not supported for task text generation and provider together. Supported task: conversational. I also tried this same code in a newly created virtual environment on my system and got the same error message once again [code]"}, {"author": "daniau23", "created_at": "2025-06-01T08:01:57Z", "body_clean": "Just tried replacing the embeddings with [code] but still defaults to the previously stated error code"}, {"author": "sperezacuna", "created_at": "2025-06-03T16:57:08Z", "body_clean": "It appears that HuggingFace has recently (?) stopped supporting the [code] task for Inference Endpoints , even for all of the recommended models listed in their official [documentation]( [link] To verify which tasks are currently supported for a given model by specific providers, you can do something like this: [code] Currently, the [code] class internally uses the [code] method from the [code] [code] . This will fail for models that no longer have a provider supporting the [code] task — thence this is not a LangChain issue . As a workaround, you can wrap the [code] in a [code] instance and leverage the [code] task instead: [code] Nevertheless, we may consider implementing an [code] to allow for a more flexible [code] that can dynamically support either the [code] or [code] task based on availability and use case."}, {"author": "daniau23", "created_at": "2025-06-03T22:05:12Z", "body_clean": "@sperezacuna Many thanks for your suggestions and comments. I did as you suggested and here's what I got. Thought it would nice sharing incase anyone faces same problem. Below is the codebase Text Generation Checker [code] Output (output was truncated) [code] Using the ChatHuggingFace to Leverage the Conversational Model Model Setup [code] Embeddings and Vetor database [code] The Prompt [code] RetrievalQAWithSourcesChain With Both Reranker and Prompting [code] Sample Output [code]"}, {"author": "daniau23", "created_at": "2025-06-03T22:13:56Z", "body_clean": "@sperezacuna I am sill surprised by the sudden change by HuggingFace via the HuggingFaceEndpoint. It was working perfectly last week Wednesday until when I tried running my code again on Friday which gave me loads of headache."}, {"author": "sperezacuna", "created_at": "2025-06-04T14:48:48Z", "body_clean": "@daniau23 Glad to hear that helped! I actually ran into the issue about three weeks ago while working with the [code] model — it seems like they may have started a gradual rollout of the task without prior notice. I think we can go ahead and mark this issue as resolved."}]}, {"ollama_summary": "This issue reports a critical AttributeError within the `defusedxml` module, specifically when attempting to use the `ElementTree` class. This prevents the module from functioning correctly, likely due to a dependency conflict or incompatibility with the LangChain library.  The code attempts to use `ElementTree` which is not available in `defusedxml`.  The issue is currently unresolved and requires a fix, potentially involving a re-installation or a change to the `defusedxml` library.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-05-30T13:10:24Z", "body_clean": "Hello, if you're using OpenAI directly here it's very likely that their dedicated structured output feature is what you want. You can interact with it using LangChain's [with structured output]( [link] method. Is there a reason we aren't using that?"}, {"author": "yosheng", "created_at": "2025-05-30T13:20:59Z", "body_clean": "Thank you for your response. With your help, I was able to use the [with structured output]( [link] method. However, I'm just beginning to learn Langchain. I mainly wanted to try using the XML parser and see the results."}, {"author": "keenborder786", "created_at": "2025-06-01T00:52:26Z", "body_clean": "@yosheng Why are you using [code] , when you don't have XML in your input. You can modify your code to following: [code]"}, {"author": "yosheng", "created_at": "2025-06-01T06:22:17Z", "body_clean": "@keenborder786 You're absolutely right! I was just testing out the XMLOutputParser and happened to notice this issue. JSON is still the primary format in our current projects anyway. Thanks for your help! :)"}]}, {"ollama_summary": "This issue reports a bug where the `llm.with_structured_output()` function consistently returns an empty JSON object for prompts, often resulting in a failure to generate a response. It’s suspected to be a problem within LangChain itself, and attempts to resolve it through version updates haven't been effective.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-05-29T22:39:59Z", "body_clean": "Does [code] supports JSON schema, try tool calling?"}, {"author": "markemus", "created_at": "2025-05-29T22:56:08Z", "body_clean": "Yes, Gemini supports json output. [link] It does work occasionally, maybe once out of fifteen attempts."}, {"author": "markemus", "created_at": "2025-07-22T05:10:53Z", "body_clean": "@mdrxy is this fixed now?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the `@tool` decorator in LangChain incorrectly specifies the required type and docstring for functions, leading to a contradiction in examples.  The issue stems from a bug in the LangChain documentation that ignores the specified return type, hindering the LLM’s ability to correctly utilize the decorator.  The maintainer has provided a self-contained, reproducible example to illustrate the problem and suggest a potential solution.", "final_category": "other", "comments": [{"author": "keenborder786", "created_at": "2025-05-29T23:47:43Z", "body_clean": "Specifying return type is not supported in OpenAI Tool Call Format. And if you think about it, LLM does not that need that information for tool execution."}, {"author": "krassowski", "created_at": "2025-05-30T07:02:30Z", "body_clean": "And if you think about it, LLM does not that need that information for tool execution. It does in [link] It also does if user requests something where the tool to call can be discriminated based on the return type: [code] Hi LLM, get me some tea please!"}, {"author": "RichardKlem", "created_at": "2025-07-02T09:11:24Z", "body_clean": "I strongly agree with @krassowski. Another benefit of parsing the [code] section is that the agent(LLM) can better understand the content and work with it further correctly."}, {"author": "JulianoLagana", "created_at": "2025-09-05T12:05:44Z", "body_clean": "To add to the discussion, up until today I relied on LangChain to stringify the output from my [code] decorated functions for me. But now I noticed that LangChain does that in [ [code] ]( [link] when calling [code] , which will fail to stringify a [code] output from the tool (because the [code] in [code] evaluates to True for an empty list). In my case, my tool was returning a list of documents, which were being correctly stringified automatically by LangChain. Until it returned an empty list (failed to find any relevant documents). This was not stringified, and LangChain created a ToolMessage with [code] set to [code] (not a string). This might be a bug, or maybe it was indeed intended for [code] to only decorate [code] functions."}]}, {"ollama_summary": "The GitHub issue reports a bug in LangChain's `deepseek` library that prevents the use of function calling with `with_structured_output`. This issue stems from an outdated model version (v3) lacking the necessary tool invocation capability, causing errors when attempting to utilize the feature. The issue is being addressed by updating the model to the latest version and correcting the code to support function calling.", "final_category": "bug", "comments": [{"author": "TBice123123", "created_at": "2025-06-01T05:23:59Z", "body_clean": "This issue solved,when I set params disable params like [code]"}]}], "business_insights": ["Model incompatibility is a recurring issue, requiring specific model versions.", "Documentation inconsistencies hinder correct usage of decorators.", "Update model versions to resolve the bug is a priority.", "Debugging requires a focused approach to the ValueError message.", "Version updates are crucial for addressing the issue."], "technical_insights": ["defusedxml incompatibility is a significant factor.", "llm.with_structured_output() returns empty JSON.", "deepseek model version conflict is the root cause.", "Debugging requires analyzing the ValueError message.", "Updating model versions is a reactive solution."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model incompatibility is a recurring issue, requiring specific model versions.\n2. Documentation inconsistencies hinder correct usage of decorators.\n3. Update model versions to resolve the bug is a priority.\n4. Debugging requires a focused approach to the `ValueError` message.\n5. Version updates are crucial for addressing the issue.\n\nTECHNICAL INSIGHTS:\n1. `defusedxml` incompatibility is a significant factor.\n2. `llm.with_structured_output()` returns empty JSON.\n3. `deepseek` model version conflict is the root cause.\n4. Debugging requires analyzing the `ValueError` message.\n5. Updating model versions is a reactive solution.", "batch_number": 63, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain's opentelemetry instrumentation that prevents context maintenance across both synchronous and asynchronous calls. The bug manifests as a context being modified in async scenarios but not properly passed to subsequent operations, causing a test failure. The developer has provided a reproducible example and is investigating the root cause through logging analysis.", "final_category": "bug", "comments": [{"author": "open-swe[bot]", "created_at": "2025-07-22T20:18:49Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @eyurtsev) <details <summary Dev Metadata</summary { \"runId\": \"1f067391 3fe6 6823 bc80 8f8517cc3373\", \"threadId\": \"6314be6f 5c17 43f8 a03f 97f19de6fcdc\" } </details"}, {"author": "armanckeser", "created_at": "2025-09-08T20:48:25Z", "body_clean": "I believe this also breaks libraries like [code] working with langchain. Do you have a workaround?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue arises when the `ChatDeepSeek` tool returns an empty list (`[]`) when creating an Agent, causing a deserialization error. This problem is reproducible with specific tool combinations and code snippets.  The root cause appears to be a failure in handling empty JSON responses from the tool, requiring a fix to ensure proper deserialization.", "final_category": "bug", "comments": [{"author": "sydney-runkle", "created_at": "2025-05-28T13:43:28Z", "body_clean": "Seems like a [code] issue @ccurme so moving here."}, {"author": "ddsstt", "created_at": "2025-06-17T09:31:05Z", "body_clean": "Same for me, confirming this is an issue. Same use case as mine — create react agent + empty list from tool response"}, {"author": "nikk0o046", "created_at": "2025-06-19T06:59:45Z", "body_clean": "Hello @vdack, @sydney runkle The root of the problem is that ChatDeepSeek uses BaseChatOpenAI internally, but the APIs are not identical: OpenAI v1/chat/completions accepts arrays as tool results, but Deepseek API does not. A straight forward solution could be to add [code] method to ChatDeepSeek, which would inherit the behavior from BaseChatOpenAI but add a step to process tool messages in case their content is an array. I would still have to look at the details, but I'd like to create a PR for this. Please let me know if you're okay with this. Source: [Deepseek docs]( [link] ![Image]( [link] Source: [OpenAI docs]( [link] ![Image]( [link]"}]}, {"ollama_summary": "This issue is caused by a bug in LangChain's `openai` package that causes an AttributeError when attempting to access the `model_dump` method. The code in question is a minimal example that triggers the error, and the issue is not resolved by updating the LangChain version.", "final_category": "bug", "comments": [{"author": "mikiwong", "created_at": "2025-05-28T11:42:47Z", "body_clean": "it works with [code]"}, {"author": "brisacoder", "created_at": "2025-05-29T15:38:33Z", "body_clean": "I have the same issue with web search tool. The combination of Responses API + Built in OpenAI tools + Streaming causes a crash. [code] 3424 content.append( 3425 {\"type\": \"text\", \"text\": chunk.delta, \"index\": chunk.content index} 3426 ) 3427 elif chunk.type == \"response.output text.annotation.added\": 3428 content.append( 3429 { 3430 \"annotations\": [ 3431 chunk.annotation.model dump(exclude none=True, mode=\"json\") 3432 ], 3433 \"index\": chunk.content index, 3434 } 3435 ) 3436 elif chunk.type == \"response.created\": 3437 response metadata[\"id\"] = chunk.response.id AttributeError: 'dict' object has no attribute 'model dump'"}, {"author": "jitokim", "created_at": "2025-06-21T12:37:54Z", "body_clean": "Fixed in 31597 ."}]}, {"ollama_summary": "This issue stems from a bug in the `langchain_openai.BaseChatOpenAI` class where it incorrectly counts tokens when counting the model name. This results in the model name being incorrectly assigned to the `[code]` utility method, causing a problem in the `[code]` block.  The suggested fix involves a change to the `[code]` method to correctly handle the model name and the code is a question about whether to default to a base tokenizer.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights discrepancies between the documentation and implementation of the `ChatSnowflakeCortex` class due to inconsistent parameter naming and representation. Specifically, the documentation lists parameters as `[code]` and `[code]` while the implementation uses different names.  The core request is to update the documentation to accurately reflect the actual parameter values as defined in the API reference.", "final_category": "other", "comments": [{"author": "ningargiola", "created_at": "2025-05-28T01:01:37Z", "body_clean": "Hey! I'd like to open a PR to fix the parameter names in the docs so they match the implementation. Let me know if that works!"}, {"author": "iliasterzis", "created_at": "2025-05-28T08:21:16Z", "body_clean": "Hello @ningargiola ! Yes, it definitely works for me. I guess the team will accept your PR. Thank you!"}, {"author": "eyurtsev", "created_at": "2025-06-02T16:53:53Z", "body_clean": "The fix should be in the chat model implementation itself. It should be sufficient to swap the names of the attributes and the aliases. It might require updates some other references to the attribute inside the chat model. [code] to [code]"}]}], "business_insights": ["Consistent parameter naming discrepancies across documentation and implementation are a recurring problem.", "Lack of standardization in parameter representation can lead to confusion and errors.", "Documentation must accurately reflect the API’s intended usage.", "Clear and precise documentation is crucial for usability and maintainability.", "Addressing parameter name inconsistencies proactively improves developer experience."], "technical_insights": ["Open SWE is experiencing a high number of issues related to LangChain’s opentelemetry instrumentation.", "ChatDeepSeek returns empty lists when creating agents, requiring a fix for JSON deserialization.", "LangChain’s openai package has an AttributeError when accessing model_dump.", "langchain_openai.BaseChatOpenAI incorrectly counts tokens, affecting the [code] utility method.", "Documentation and implementation of ChatSnowflakeCortex parameters are inconsistent."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent parameter naming discrepancies across documentation and implementation are a recurring problem.\n2. Lack of standardization in parameter representation can lead to confusion and errors.\n3. Documentation must accurately reflect the API’s intended usage.\n4. Clear and precise documentation is crucial for usability and maintainability.\n5. Addressing parameter name inconsistencies proactively improves developer experience.\n\nTECHNICAL INSIGHTS:\n1. Open SWE is experiencing a high number of issues related to `LangChain`’s `opentelemetry` instrumentation.\n2. `ChatDeepSeek` returns empty lists when creating agents, requiring a fix for JSON deserialization.\n3. `LangChain`’s `openai` package has an `AttributeError` when accessing `model_dump`.\n4. `langchain_openai.BaseChatOpenAI` incorrectly counts tokens, affecting the `[code]` utility method.\n5. Documentation and implementation of `ChatSnowflakeCortex` parameters are inconsistent.\n", "batch_number": 64, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue is preventing the installation of the `ChatHuggingFace` library due to a missing model ID. The problem stems from a bug in LangChain that causes this, potentially related to a version conflict or an issue with the integration package.  The code example provides a minimal, reproducible test case to demonstrate the issue, and the developer is actively investigating and working on a fix.", "final_category": "bug", "comments": []}, {"ollama_summary": "The model is reporting a discrepancy in the token usage. The `total tokens` reported in the `usage metadata` is 4419, but the `Completion Tokens` reported in the `usage metadata` is 3569. This suggests the model might be using more tokens than it's returning as the completion. This could be due to various factors, including caching, optimization, or potential issues with the model's internal state.  It's a relatively minor issue, but it's worth investigating to ensure the model's output is accurate.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-05-26T07:31:42Z", "body_clean": "The callback is being called at every iteration of loop and cummulatively updating [code] and [code] . If you do the following, you will get the correct results: [code]"}, {"author": "frankoo21", "created_at": "2025-05-26T11:52:56Z", "body_clean": "i think the problem is due to streaming , because i test it with get openai callback() , i got also a false number [code] Actual Token Usage: Prompt Tokens: 850 Completion Tokens: 3569 Total Tokens: 4419 i got also a false number when i test it with invoke i can get the correct output [code] {content='Okay, the user just said \"hey can u help me.\" I should respond in a friendly and approachable way. Maybe start with a greeting and ask how I can assist them today. Keeping it simple and open ended should encourage them to share what they need help with.\\n\\n\\nHey! Of course, I'd be happy to help. What do you need assistance with?' additional kwargs={'refusal': None} response metadata={'token usage': {'completion tokens': 77, 'prompt tokens': 10, 'total tokens': 87, 'completion tokens details': None, 'prompt tokens details': None}, 'model name': 'deepseek r1 distill llama 70b', 'system fingerprint': None, 'id': 'chatcmpl 51b03a34 96e8 4f2b 9314 9e553d4a3d69', 'service tier': None, 'finish reason': 'stop', 'logprobs': None} id='run b5d15c02 a33b 4bfa 97a0 cdc2c325bdbb 0' usage metadata={'input tokens': 10, 'output tokens': 77, 'total tokens': 87, 'input token details': {}, 'output token details': {}} Actual Token Usage: Prompt Tokens: 10 Completion Tokens: 77 Total Tokens: 87"}]}, {"ollama_summary": "This GitHub issue reports a warning in the `langchain` library regarding the outdated import of `verbose` from the LangChain root module. The warning suggests using `langchain.globals.set_verbose()` or `langchain.globals.get_verbose()` instead.  The issue is likely a bug in LangChain and isn’t easily resolved by updating the library version, and a self-contained example is provided to demonstrate the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a problem where the LangChain library is generating an incorrect number of tokens, specifically failing to consume the expected prompt and completion tokens.  The developer has identified this as a bug within the LangChain library itself and provided a self-contained example to reproduce the issue.  The solution involves updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-05-25T01:48:14Z", "body_clean": "What do you mean by false number of tokens?"}, {"author": "frankoo21", "created_at": "2025-05-25T01:53:16Z", "body_clean": "In one request , in my prompt i just wrote ´hello’ I get these larges numbers of Tokens Used: Prompt Tokens: 4640553 Completion Tokens: 1165100 Successful Requests: 1 Which are irrealistic in one prompt"}, {"author": "keenborder786", "created_at": "2025-05-25T02:13:50Z", "body_clean": "But your chain is retriving relevant context from your vector DB as well which might not be properly indexes and the retrived context might be too large"}, {"author": "frankoo21", "created_at": "2025-05-25T02:17:56Z", "body_clean": "That’s right brother , but the chunk size is 128 tokens so the input prompt it will be 2000 tokens , not millions of tokens in one request, btw i have tested without rag chain just with chatopenai() , i got same problem in tokens counting"}, {"author": "mdrxy", "created_at": "2025-07-16T18:16:56Z", "body_clean": "Duplicate of 31351"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a discrepancy between the documentation for the LangGraph Platform and the LangGraph website. A link to the LangGraph Platform is incorrectly linking to the same page as the LangGraph page, requiring a change to the documentation to ensure accurate navigation.  The developer has added a descriptive title and a link to the documentation, but the fix is needed to resolve this issue.", "final_category": "other", "comments": [{"author": "MichaelLi65535", "created_at": "2025-05-24T03:13:48Z", "body_clean": "Hi @staypufd , thanks for raising this up. The PR to fix this has been raised at [link] , waiting for PR review."}]}], "business_insights": ["Dependency conflicts can significantly impact development stability; proactive dependency management is crucial.", "Library updates frequently introduce regressions; thorough testing and regression analysis are vital.", "Documentation inconsistencies can confuse users and hinder adoption; clear and accurate documentation is essential.", "Bug fixes should be tested thoroughly to prevent future regressions; a robust testing strategy is necessary.", "Documentation updates require careful consideration of existing code and functionality; maintain a clear understanding of the impact."], "technical_insights": ["LangChain's version conflict issue may be linked to a specific update or configuration.", "The usage metadata discrepancy suggests a potential caching issue or model state corruption.", "The verbose import issue highlights a bug within the LangChain library itself.", "The token consumption issue suggests a problem with the model's internal processing.", "The incorrect token usage indicates a potential issue with the model's generation process."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency conflicts can significantly impact development stability; proactive dependency management is crucial.\n2.  Library updates frequently introduce regressions; thorough testing and regression analysis are vital.\n3.  Documentation inconsistencies can confuse users and hinder adoption; clear and accurate documentation is essential.\n4.  Bug fixes should be tested thoroughly to prevent future regressions; a robust testing strategy is necessary.\n5.  Documentation updates require careful consideration of existing code and functionality; maintain a clear understanding of the impact.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's version conflict issue may be linked to a specific update or configuration.\n2.  The `usage metadata` discrepancy suggests a potential caching issue or model state corruption.\n3.  The `verbose` import issue highlights a bug within the LangChain library itself.\n4.  The token consumption issue suggests a problem with the model's internal processing.\n5.  The incorrect token usage indicates a potential issue with the model's generation process.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 65, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a problem with LangChain's structured output generation using the Qwen3-32B model, specifically when deployed via vLLM. It’s suspected to be a model compatibility issue, though the code works fine with other models. The code attempts to generate a joke, and the error occurs when the model fails to produce the expected output.", "final_category": "bug", "comments": [{"author": "Ronald-Huang-CS", "created_at": "2025-05-23T16:25:54Z", "body_clean": "After testing, even when using the Qwen3 32B model from OpenRoute, the above issue still occurs."}, {"author": "keenborder786", "created_at": "2025-05-25T01:50:36Z", "body_clean": "Can you try making all fields None? [code]"}, {"author": "Ronald-Huang-CS", "created_at": "2025-05-25T02:23:39Z", "body_clean": "Can you try making all fields None? class Joke(BaseModel): setup: Optional[str] = Field(description=\"The setup of the joke\") punchline: Optional[str] = Field(description=\"The punchline to the joke\") rating: Optional[int] = Field(description=\"How funny the joke is, from 1 to 10\") After testing, I got the same error： [code] [code]"}, {"author": "LKChenLK", "created_at": "2025-06-15T16:38:34Z", "body_clean": "I also encountered this issue, it might be related to the chat template: [link] We got it working by using the chat template specified in the reddit post and specifying its path with the cli arg [code] when serving vLLM ( =0.9.0) , in addition to [code]"}, {"author": "diego-coder", "created_at": "2025-07-31T05:10:20Z", "body_clean": "This was not a langchain issue, but an issue that was caused by a bug in the Qwen3/early Qwen2.x chat template, which assumed that [code] would always be present in every assistant/tool call message. When running structured outputs or tool calling via OpenAI compatible APIs (e.g., LangChain, Roo, LM Studio, etc.), this would throw errors such as: [code] or [code] Background & Patch: This problem is documented in detail here: [Reddit: The Qwen3 chat template is still bugged ]( [link] The root cause: The chat template did not guard against missing or [code] content in assistant tool call entries. Resolution: As of the latest release, the [Qwen2.5 32B Instruct]( [link] and newer Qwen models have this fix included in their default chat template. The template now checks [code] before outputting it, preventing the error described in this issue. The fix is to ensure that template lines referencing [code] are wrapped in an [code] block, like so: [code] If you are still seeing this problem: Make sure you are using the latest Qwen2.5 or newer models . If using Qwen3 or an older model, you can patch the template as shown above and provide it to your backend (e.g., via [code] in vLLM). More information on chat template overrides: [vLLM docs]( [link] Request to close: Given that this issue resided in/has been fixed upstream in the model template, this issue can be closed. (Tagging @mdrxy) Refs: [Reddit: Qwen3 chat template bug]( [link] [vLLM Chat Template Docs]( [link]"}, {"author": "mdrxy", "created_at": "2025-09-10T00:35:38Z", "body_clean": "@diego coder many thanks!"}]}, {"ollama_summary": "This issue reports a critical problem with the LangChain retriever library when using `retriever.invoke()` – specifically, it's encountering a `None` value returned from the vector database. This likely stems from a bug in the LangChain integration, causing the retriever to fail to retrieve documents correctly.  The code attempts to retrieve documents from a vector database, but the database returns a `None` value for the `page content` field, leading to an error.  The issue is reproducible with a minimal example, and the developers are actively working on a fix.", "final_category": "bug", "comments": [{"author": "nagarajRPoojari", "created_at": "2025-05-27T08:43:08Z", "body_clean": "I would like to work on this, can you please assign me"}]}, {"ollama_summary": "The code exhibits a bug where the `langchain-openai` library fails to return the `reasoning_content` field for responses from the OpenAI library. This issue is impacting the functionality of the code, and the provided example demonstrates a straightforward way to reproduce the problem.", "final_category": "bug", "comments": [{"author": "li1553770945", "created_at": "2025-05-26T10:12:07Z", "body_clean": "I also encountered the same problem. Please let me know if you found a solution?"}, {"author": "liuli870906", "created_at": "2025-05-27T06:33:23Z", "body_clean": "I checked the source code, and the BaseMessage class in langchain core does not encapsulate the reasoning content field."}, {"author": "Ronald-Huang-CS", "created_at": "2025-05-30T02:02:38Z", "body_clean": "I also encountered the same problem. Please let me know if you found a solution? So far, there is no solution"}, {"author": "vincent-winner", "created_at": "2025-06-03T13:03:59Z", "body_clean": "same problem, plz"}, {"author": "qpjtmdnft", "created_at": "2025-06-07T05:20:42Z", "body_clean": "I think you should use another interface. like Deepseek, or corresponding interface to qwq."}, {"author": "Ronald-Huang-CS", "created_at": "2025-06-07T08:23:51Z", "body_clean": "I think you should use another interface. like Deepseek, or corresponding interface to qwq. langchain qwq solved my problem, but I find it a bit hard to understand that langchain openai itself doesn't support reasoning model outputs. Even without considering locally deployed reasoning models, OpenAI's official models like o3 also have reasoning output capabilities. @vincent winner @li1553770945"}, {"author": "qpjtmdnft", "created_at": "2025-06-08T01:44:24Z", "body_clean": "I think you should use another interface. like Deepseek, or corresponding interface to qwq. langchain qwq solved my problem, but I find it a bit hard to understand that langchain openai itself doesn't support reasoning model outputs. Even without considering locally deployed reasoning models, OpenAI's official models like o3 also have reasoning output capabilities. [@vincent winner]( [link] [@li1553770945]( [link] yes, I think maybe langchain should support a common domain represent reasoning content in AIMessageChunk, and langchain open ai should support this too."}, {"author": "loctempt", "created_at": "2025-06-08T09:09:17Z", "body_clean": "I checked the source code, and the BaseMessage class in langchain core does not encapsulate the reasoning content field. I’m working on streaming response, and it turns out that only the field [code] in the LLM’s response is preserved in the [code] instance. Since [code] also has an [code] attribute, I wondered that if I can get reasoning messages here. Unfortunately the implementation doesn’t include any LLM response contents except the regular ones. However, every time LLM returns a chunk, an [code] is built (with empty [code] and [code] attributes) meaning that reasoning contents are actually here but discarded. The source code suggests that it might help to extend [code] and rewrite [code] , in which we can add [code] to the attribute [code] and utilize this attribute when reassembling LLM stream responses. I didn’t look into non stream scenarios, but I believe the idea is the same."}, {"author": "Aegean-C", "created_at": "2025-06-09T08:12:08Z", "body_clean": "I checked the source code, and the BaseMessage class in langchain core does not encapsulate the reasoning content field. I’m working on streaming response, and it turns out that only the field [code] in the LLM’s response is preserved in the [code] instance. Since [code] also has an [code] attribute, I wondered that if I can get reasoning messages here. Unfortunately the implementation doesn’t include any LLM response contents except the regular ones. However, every time LLM returns a chunk, an [code] is built (with empty [code] and [code] attributes) meaning that reasoning contents are actually here but discarded. The source code suggests that it might help to extend [code] and rewrite [code] , in which we can add [code] to the attribute [code] and utilize this attribute when reassembling LLM stream responses. I didn’t look into non stream scenarios, but I believe the idea is the same. Yes, [code] did it using this method, by inheriting from BaseChatOpenAI and rewriting the convert chunk to generation chunk method <img width=\"559\" alt=\"Image\" src=\" [link] /"}, {"author": "vincent-winner", "created_at": "2025-06-09T08:41:54Z", "body_clean": "I haven't found a better solution yet, so I've temporarily modified the convert delta to message chunk function in langchain openai/chat models/base.py to enable the use of reasoning content within ChatOpenAI. Currently, this works for some vLLM models I've launched locally and for Claude Sonnet accessed via OpenRouter. I'll be using this as a temporary workaround until langchain openai fixes the issue. ![Image]( [link]"}, {"author": "ccurme", "created_at": "2025-06-23T22:17:12Z", "body_clean": "Hello, thanks all for the suggestions here. My recommendation is to use [code] or [code] . If you look at [langchain deepseek]( [link] it is not doing much more than extending [code] and parsing out [code] . Please let me know if there are any issues with this. [code] is not returned by the OpenAI or Azure OpenAI Chat Completions APIs. OpenAI's Chat Completions API [does not support reasoning output]( [link] OpenAI does offer reasoning summaries as part of its Responses API, and that is supported by ChatOpenAI (see docs [here]( [link] langchain openai would become unwieldy if we attempted to accommodate all variants of Chat Completions APIs inside it. So instead we just extend BaseChatOpenAI in other libraries (e.g., langchain deepseek) and parse out reasoning content there."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nUsers of ChatAnthropic are encountering issues with OpenRouter due to a bug in LangChain that prevents the correct URL formatting.  The issue appears to be a fundamental issue within the LangChain library itself, and attempts to update to the latest version haven’t resolved it. A self-contained, minimal example demonstrates the problem – specifically, the request for a URL is failing due to invalid formatting.", "final_category": "bug", "comments": [{"author": "byteakp", "created_at": "2025-05-23T06:42:19Z", "body_clean": "Hi @jiwonmik, the 405 error occurs because [code] is designed for Anthropic's official api ( [code] ), but you're using openrouter's API, which expects requests at [code] . The double [code] in the logged URL ( [code] ) suggests a potential URL construction issue, but the core problem is endpoint incompatibility. To fix this, u should use [code] from [code] , which is built for OpenRouter's API. Here's the corrected code: python from langchain community.chat models import ChatOpenRouter llm = ChatOpenRouter( model name=\"anthropic/claude 3 7 sonnet 20250219\", temperature=0, max tokens=1024, timeout=None, max retries=2, openrouter api key=\"your api key here\", Replace with your OpenRouter API key ) response = llm.invoke(\"hello..?\") print(response)"}, {"author": "jiwonmik", "created_at": "2025-05-23T20:50:52Z", "body_clean": "@byteakp Hmm,, is that [code] class existing one? FYI I found [this]( [link] will try with this one."}, {"author": "byteakp", "created_at": "2025-05-24T10:03:49Z", "body_clean": "[@byteakp]( [link] Hmm,, is that [code] class existing one? FYI I found [this]( [link] will try with this one. Yes, that ChatOpenRouter class isn’t part of the official LangChain repo — it’s a custom workaround shared in the GitHub discussion [ 27964]( [link] It subclasses ChatOpenAI and overrides the base url and API key handling to work with OpenRouter. If you’re integrating OpenRouter into a LangGraph project or want to use tools, this workaround should definitely help!"}, {"author": "1099271", "created_at": "2025-06-13T06:43:54Z", "body_clean": "[@byteakp]( [link] Hmm,, is that [code] class existing one? FYI I found [this]( [link] will try with this one. [code] you also can use openrouter like this, but when you use this, something error when you use langgraph with response format param"}]}, {"ollama_summary": "The issue reports a TypeError occurring when using the LangChain Hugging Face pipeline, specifically when specifying the model. The code attempts to use a model, but the pipeline function returns multiple values for the 'model' keyword, leading to the error. The developer has provided a minimal reproducible example to demonstrate the problem and is seeking assistance to resolve it.", "final_category": "bug", "comments": [{"author": "johnwroge", "created_at": "2025-05-27T01:26:13Z", "body_clean": "Hi Aryan. The error occurs because the 'model' parameter is being passed twice once implicitly through the model id parameter, and once explicitly in pipeline kwargs as \"model\": model. The from model id() method automatically handles model and tokenizer loading, so you don't need to pass them manually in pipeline kwargs. [code]"}]}], "business_insights": ["Model compatibility issues are a recurring challenge, impacting deployed models across various platforms.", "LangChain’s structured output generation is sensitive to model variations, requiring careful management of model choices.", "The Qwen3-32B model’s compatibility issue highlights potential model-specific vulnerabilities.", "Model integration testing is crucial for identifying and addressing compatibility problems early.", "Thorough testing across multiple models is vital to ensure robust deployment."], "technical_insights": ["LangChain’s model versioning and compatibility matrix need improved documentation.", "The None value return from the vector database is a significant bug, requiring investigation.", "The langchain-openai library integration is a critical point of failure, impacting retrieval.", "The None return from the retriever is impacting the core functionality, requiring a fix.", "The reasoning_content field is missing from the langchain core, requires a fix."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model compatibility issues are a recurring challenge, impacting deployed models across various platforms.\n2. LangChain’s structured output generation is sensitive to model variations, requiring careful management of model choices.\n3. The Qwen3-32B model’s compatibility issue highlights potential model-specific vulnerabilities.\n4. Model integration testing is crucial for identifying and addressing compatibility problems early.\n5. Thorough testing across multiple models is vital to ensure robust deployment.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s model versioning and compatibility matrix need improved documentation.\n2. The `None` value return from the vector database is a significant bug, requiring investigation.\n3. The `langchain-openai` library integration is a critical point of failure, impacting retrieval.\n4. The `None` return from the retriever is impacting the core functionality, requiring a fix.\n5. The `reasoning_content` field is missing from the langchain core, requires a fix.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 66, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where the overview table description of retrievers is truncated, preventing users from accessing the full documentation.  The solution involves adding a more descriptive title and a link to the relevant documentation page when hovering over the description.  Currently, the description is incomplete and inaccessible without navigating to the specific retriever page.", "final_category": "other", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `core: RunnablePick` function currently returns a dictionary instead of a list when keys are a string. This issue stems from a bug in LangChain that doesn’t gracefully handle string keys, causing it to return the value of the key rather than a dictionary. A self-contained example demonstrates the problem and provides a solution – either modifying the signature or changing the behavior to always return a dictionary.", "final_category": "bug", "comments": [{"author": "neel2299", "created_at": "2025-05-25T12:47:53Z", "body_clean": "Hello, I was wondering if you preferred swastik's PR [31309]( [link] Or whether permanently returning dictionaries is being considered?"}, {"author": "eyurtsev", "created_at": "2025-05-28T16:15:30Z", "body_clean": "@cbornet i assume there's no way to introduce type dependency in this case? (i.e., Any if passed as a string, and dict if passed a list of str?)"}, {"author": "cbornet", "created_at": "2025-05-28T22:14:30Z", "body_clean": "I don't know how to do it. I'm not sure it's possible..."}, {"author": "mdrxy", "created_at": "2025-07-16T15:23:19Z", "body_clean": "Any movement on this? Are we totally blocked? If so we should close this and 31321"}, {"author": "cbornet", "created_at": "2025-07-16T16:38:01Z", "body_clean": "We are not blocked. We would need a decision between changing the signature and changing the behaviour."}, {"author": "eugeneo17", "created_at": "2025-07-17T17:20:47Z", "body_clean": "I'd like to take this issue and submit a fix. Let me know if anyone is already working on it!"}, {"author": "mdrxy", "created_at": "2025-07-17T17:37:46Z", "body_clean": "@eugeneo17 go for it!"}, {"author": "cbornet", "created_at": "2025-07-17T18:47:40Z", "body_clean": "Note that there is a PR opened if the choice is to change the signature : [link]"}, {"author": "eugeneo17", "created_at": "2025-07-17T19:17:21Z", "body_clean": "Thanks. I'm starting work on 31309"}, {"author": "cbornet", "created_at": "2025-08-04T15:26:04Z", "body_clean": "@eyurtsev @mdrxy there are PRs for both alternatives ([change signature]( [link] or [change implementation with breaking change]( [link] Which solution do you prefer ? Maybe the breaking change could be done in v1.0 ?"}]}, {"ollama_summary": "This issue reports a critical bug in the AzureChatOpenAI library that prevents reasoning models from being used effectively. The code requires an updated validator for the `langsmith.validator` which is currently not compatible with newer reasoning models like o1.  A self-contained, minimal example demonstrates the problem, and the developers are actively working on a fix.", "final_category": "bug", "comments": [{"author": "0xtotem", "created_at": "2025-08-07T15:37:05Z", "body_clean": "does actually work and is a temporary workaround. is there a long term workaround now?"}]}, {"ollama_summary": "This issue reports a critical bug in the AzureChatOpenAI Responses API in LangChain that causes errors when attempting to stream response data for AzureChatOpenAI. The bug is unresponsive to the `invoke` method, requiring the user to use the `stream` method for reasoning summary extraction.  The issue is currently unresolved with recent updates to the LangChain library and is reproducible through a self-contained example code snippet.", "final_category": "bug", "comments": [{"author": "butterflock", "created_at": "2025-06-09T14:31:19Z", "body_clean": "Is there any update here? I'm starting to doubt, what is the value of langchain if core functionality is not working such as Responses API on Azure.."}, {"author": "ccurme", "created_at": "2025-06-17T20:24:07Z", "body_clean": "Hello, thanks for the report. This issue should be resolved in the latest version of [code] . Please shout if you run into anything else!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a critical bug in LangChain that causes WatsonX Models to consistently call a tool, regardless of the agent’s input.  The problem isn’t related to the user’s code but rather a fundamental issue within the LangChain integration, preventing the models from correctly utilizing the specified tool.  The developer has provided a self-contained example demonstrating the issue and is seeking a solution.", "final_category": "bug", "comments": []}], "business_insights": ["Addressing truncated descriptions proactively improves user experience, leading to increased engagement with the documentation.", "Quickly resolving the overview table issue demonstrates a focus on usability and accessibility – a crucial aspect of a successful application.", "Recognizing the core bug in RunnablePick necessitates a robust validation strategy for string keys, a fundamental aspect of data handling.", "Addressing the langsmith.validator incompatibility is a critical issue impacting reasoning model capabilities – a priority for maintaining model stability.", "Recognizing the WatsonX Model issue highlights a fundamental integration problem impacting model functionality – requires immediate attention."], "technical_insights": ["Implement a more descriptive title and documentation link for truncated descriptions – enhance user experience.", "Modify the RunnablePick function signature to always return a dictionary – resolve the bug in LangChain.", "Investigate and fix the langsmith.validator compatibility issue – ensure seamless integration of reasoning models.", "Implement a self-contained example demonstrating the langsmith.validator incompatibility – improve testing and debugging.", "Consider permanently returning dictionaries as a standard practice – maintain consistent data handling across the library."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing truncated descriptions proactively improves user experience, leading to increased engagement with the documentation.\n2. Quickly resolving the overview table issue demonstrates a focus on usability and accessibility – a crucial aspect of a successful application.\n3. Recognizing the core bug in `RunnablePick` necessitates a robust validation strategy for string keys, a fundamental aspect of data handling.\n4. Addressing the `langsmith.validator` incompatibility is a critical issue impacting reasoning model capabilities – a priority for maintaining model stability.\n5. Recognizing the WatsonX Model issue highlights a fundamental integration problem impacting model functionality – requires immediate attention.\n\nTECHNICAL INSIGHTS:\n1. Implement a more descriptive title and documentation link for truncated descriptions – enhance user experience.\n2. Modify the `RunnablePick` function signature to always return a dictionary – resolve the bug in LangChain.\n3. Investigate and fix the `langsmith.validator` compatibility issue – ensure seamless integration of reasoning models.\n4. Implement a self-contained example demonstrating the `langsmith.validator` incompatibility – improve testing and debugging.\n5. Consider permanently returning dictionaries as a standard practice – maintain consistent data handling across the library.\n", "batch_number": 67, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a 403 error when using a service account to access the Google Drive Loader API. This is occurring with the LangChain library, specifically within the `google-community-drive.py` file. The problem seems to stem from a missing or incorrect file from the `ids()` function, leading to a `Requested entity was not found` error.  The code attempts to load a file from the `ids()` function, which is causing the error.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical bug in the `_convert_dict_to_message` function within the LangChain library, specifically when using the `model` within a custom node. The bug causes the internal method to receive a repeated string of role names, leading to a parsing error and preventing the message from being successfully constructed.  The issue is reproducible with a minimal example and suggests a potential fix involving a patch, but the root cause remains unclear.", "final_category": "bug", "comments": [{"author": "kryvokhyzha", "created_at": "2025-05-16T21:12:10Z", "body_clean": "Also, it can be fixed on my side by changing [code] to [code]"}, {"author": "ccurme", "created_at": "2025-05-27T18:50:16Z", "body_clean": "Hi, thanks for submitting this. My suspicion is that this is an issue with the API you are calling. The reasons I suspect this: 1. I cannot reproduce the issue locally, using [link] for the base URL; 2. In your fix, you are modifying the object returned by the OpenAI SDK. Let me know if I'm mistaken here. Otherwise, to debug this, I'd suggest running the request through the API or OpenAI SDK directly. You can use [code] to obtain the payload exactly as it's sent to the openai client."}, {"author": "kryvokhyzha", "created_at": "2025-05-27T20:07:07Z", "body_clean": "Hi! I double checked, and you’re right. I’m using the [code] proxy to call Azure OpenAI models. I changed the model initialization to call Azure directly, bypassing the proxy — and it works. So yes, it looks like the issue is on [code] 's side. [code] I'll take a closer look and reopen the issue if necessary."}]}, {"ollama_summary": "This issue reports a critical problem with the `with_structured_output()` function within the LangChain library, specifically when used with Pydantic schemas. The code attempts to return structured output, but the function consistently produces unstructured content instead, hindering the intended data transformation process.  The issue is currently unresolved, and the provided example code demonstrates a straightforward, self-contained test case that consistently fails.", "final_category": "bug", "comments": [{"author": "jennyluciav", "created_at": "2025-05-29T23:05:04Z", "body_clean": "Is someone working on this? @dosubot"}, {"author": "dosubot[bot]", "created_at": "2025-05-29T23:11:24Z", "body_clean": "<! Greeting Hi @jennyluciav! I'm [Dosu]( [link] and I’m helping the langchain team. <! Answer Based on my research, there is no indication that someone is currently assigned or actively working on the issue with [code] not working with configurable fields in LangChain. I did not find any recent updates, pull requests, or commits addressing this specific problem. While there are related discussions and workarounds for structured output issues in general, none directly address this bug or confirm ongoing development for it. If you need this resolved urgently, you may want to comment on the issue to raise its visibility or consider contributing a fix. <! Dosu Comment Footer To reply, just mention my name [@dosu]( [link] <sup How did I do? [Good]( [link] | [Irrelevant]( [link] | [Incorrect]( [link] | [Verbose]( [link] | [Hallucination]( [link] | [Report 🐛]( [link] | [Other]( [link] Discord]( [link] on X]( [link]"}, {"author": "jma-hdz", "created_at": "2025-06-26T20:34:02Z", "body_clean": "The reason is that you're using the previous instance. To get a structured output, you need to use the [code] instance [code]"}, {"author": "kryvokhyzha", "created_at": "2025-06-26T20:52:40Z", "body_clean": "The reason is that you're using the previous instance. To get a structured output, you need to use the [code] instance result = model so.invoke(\"Who is the president of Brasil?\", config={\"temperature\": 0.5}) Yes, you are right. That was my mistake. So the actual output of the fixed script is: [code] But I decided to check the created request itself and noticed that the default value of the [code] parameter was not overridden when model was invoked. [code]"}, {"author": "keenborder786", "created_at": "2025-10-10T20:49:28Z", "body_clean": "@kryvokhyzha I have confirmed the temperature is being updated. @mdrxy we can close this issue"}]}, {"ollama_summary": "This issue reports a critical problem with the `create_react_agent()` function, which is failing to correctly pass prompts to the LangChain agent. The code attempts to use a `system prompt` parameter, but this parameter is being deprecated and removed by LangChain, leading to an unexpected error. The issue stems from a mismatch between the expected and actual behavior of the LangChain integration, potentially due to a bug in the integration package itself.", "final_category": "bug", "comments": [{"author": "mfiqihalayubi", "created_at": "2025-05-16T05:05:17Z", "body_clean": "My langgraph version : langgraph 0.4.1 langgraph checkpoint 2.0.26 langgraph prebuilt 0.1.8 langgraph sdk 0.1.69"}, {"author": "gmunhoz0810", "created_at": "2025-05-19T21:52:41Z", "body_clean": "Hi @mfiqihalayubi, thanks for the detailed report. The error you're seeing: [code] likely means you're not importing [code] from the correct module. Even though [code] supports the [code] argument, this function signature only applies when you import from: [code] Can you confirm that's the import you're using? Other modules (like [code] or older examples) may expose a version of [code] that doesn't accept [code] . If you're using a different import, switching to [code] should resolve the error. Documentation reference: [LangGraph Agents API]( [link] Let me know if that helps or if you're still running into issues."}]}, {"ollama_summary": "The GitHub issue reports a widespread incompatibility between the `doctran` library and other Python libraries used in LangChain, specifically due to conflicting version requirements for pydantic and Tiktoken. The issue provides a minimal reproducible example and a maintainer has offered a solution by adding a title to the issue, but the core problem remains unresolved.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-05-15T13:26:46Z", "body_clean": "Doctran hasn't had a release [since 2023]( [link] and appears to be still on Pydantic v1. It is likely incompatible with many libraries, not just langchain (there are several [open issues]( [link] regarding its compatibility with other libraries). Although LangChain is also on Pydantic v2 it's still compatible with v1 in many places, you could try forcing an install of Pydantic v1 (most dependency managers will let you set overrides to resolve discrepancies like this). But given the lack of development in Doctran I'd caution building something that relies on it."}]}], "business_insights": ["Addressing the Google Drive Loader API issue with the missing ids() function is a fundamental bug requiring immediate resolution.", "The _convert_dict_to_message bug is a critical issue impacting message construction, potentially affecting a broader range of LangChain applications.", "The with_structured_output() issue highlights a structural problem in LangChain’s data transformation logic.", "The create_react_agent() bug necessitates a fix to the LangChain integration, focusing on deprecated parameters.", "The incompatibility between doctran and other libraries is a significant challenge requiring a patch or solution."], "technical_insights": ["The ids() function's missing component is a core bug, impacting data loading and the core functionality of the google-community-drive.py file.", "The _convert_dict_to_message bug is a critical bug that could affect the entire LangChain application.", "The with_structured_output() bug represents a structural problem within LangChain's data processing pipeline.", "The create_react_agent() bug is a bug in the LangChain integration package.", "The doctran and pydantic version conflict is a significant incompatibility issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing the Google Drive Loader API issue with the missing `ids()` function is a fundamental bug requiring immediate resolution.\n2. The `_convert_dict_to_message` bug is a critical issue impacting message construction, potentially affecting a broader range of LangChain applications.\n3. The `with_structured_output()` issue highlights a structural problem in LangChain’s data transformation logic.\n4. The `create_react_agent()` bug necessitates a fix to the LangChain integration, focusing on deprecated parameters.\n5. The incompatibility between `doctran` and other libraries is a significant challenge requiring a patch or solution.\n\nTECHNICAL INSIGHTS:\n1.  The `ids()` function's missing component is a core bug, impacting data loading and the core functionality of the `google-community-drive.py` file.\n2.  The `_convert_dict_to_message` bug is a critical bug that could affect the entire LangChain application.\n3.  The `with_structured_output()` bug represents a structural problem within LangChain's data processing pipeline.\n4.  The `create_react_agent()` bug is a bug in the LangChain integration package.\n5.  The `doctran` and `pydantic` version conflict is a significant incompatibility issue.\n", "batch_number": 68, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, let's break down this error message and figure out how to resolve it.\n\n**Understanding the Error**\n\nThe error message \"TypeError: 'NoneType' object is not subscriptable\" indicates that you're trying to access an element of a sequence (like a list or tuple) using square brackets (`[]`) as if it were a Python object with a subscript (meaning an index).  In this case, it's happening inside a function that's expecting a sequence, but it's getting `None`.\n\n**Root Cause**\n\nThe most likely cause is that the function you're calling is returning `None` under certain circumstances, and you're trying to use that `None` value as a list or tuple.\n\n**Possible Solutions & Debugging Steps**\n\n1. **Identify the Problematic Code:**  The error message doesn't give us the exact line of code where the `None` is being returned.  You need to examine the code that's calling the function and see where it's expecting a sequence.\n\n2. **Trace the Function's Return Value:**  Inside the function, *before* the line that causes the error, check the return value.  Is it *always* returning `None`?  If so, that's the problem.\n\n3. **Check for Implicit Returns:** Sometimes, functions have implicit returns.  If a function is supposed to return a list or tuple, but it's returning `None` implicitly, it can lead to this error.\n\n4. **Debugging with Print Statements:** Add `print()` statements to your code to see the values of variables at different points.  Specifically, print the value of the variable that's being used in the `[]` expression *before* the error occurs.\n\n5. **Isolate the Issue:**  If you have a complex function, try to simplify it to a minimal example that reproduces the error.  This will help you pinpoint the exact location of the problem.\n\n**Example Scenario and Solution**\n\nLet's say you have this code (simplified):\n\n```python\ndef my_function(data):\n  if some_condition:\n    return [1, 2, 3]  # This is where the error is likely\n  else:\n    return None\n\nresult = my_function(my_data)\nprint(result)\n```", "final_category": "bug", "comments": [{"author": "DogukanAltay", "created_at": "2025-05-14T17:53:43Z", "body_clean": "I can second this issue. I had to change the [code] attribute of [code] with a really small value. The issue is [code] function is not splitting the documents based on the token limit. It is just sending (by default chunk size=1000). So if your texts length is less than 1000 and each of your document is heavy on tokens, the openAI request fails"}, {"author": "adambenari", "created_at": "2025-05-15T04:28:33Z", "body_clean": "I can second this issue. I had to change the [code] attribute of [code] with a really small value. The issue is [code] function is not splitting the documents based on the token limit. It is just sending (by default chunk size=1000). So if your texts length is less than 1000 and each of your document is heavy on tokens, the openAI request fails This also solved my issue. OpenAI states that there is a \"max 300000 tokens per request\". You are splitting your documents into chunks of 1000 tokens. So, you will need to adjust [code] to [code] . [code] so I would set your [code] to 299 to ensure your embeddings API call is successful. Good luck!"}, {"author": "Gauraviitkgp", "created_at": "2025-08-10T03:38:46Z", "body_clean": "Is there any update on the request ? except for reducing [code] workaround?"}]}, {"ollama_summary": "The GitHub issue reports a 400 Bad Request error occurring when using the Anthropic API, specifically when attempting to retrieve Horizon server names. The error seems to be triggered by an unexpected input requirement within the LangChain framework, potentially related to the Anthropic API's integration.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-05-13T12:47:35Z", "body_clean": "Hello, thanks for reporting this. Can you please provide a minimal reproducible example as requested in the issue template? Here is my attempt: [code] and an associated LangSmith trace: [link] (this is running latest [code] SDK and [code] ). You can see the [code] field in the input but no errors or warnings. It may make sense to remove that field from the input anyway but reproducing the issue would help prioritize."}, {"author": "Gnori", "created_at": "2025-05-13T13:18:38Z", "body_clean": "langchain/libs/partners/anthropic/langchain anthropic/chat models.py What about the last part of the following code? ============================================== elif event.type == \"content block delta\": if event.delta.type in (\"text delta\", \"citations delta\"): if coerce content to string and hasattr(event.delta, \"text\"): text = event.delta.text message chunk = AIMessageChunk(content=text) else: content block = event.delta.model dump() content block[\"index\"] = event.index content block[\"type\"] = \"text\" if \"citation\" in content block: content block[\"citations\"] = [content block.pop(\"citation\")] message chunk = AIMessageChunk(content=[content block]) elif event.delta.type == \"thinking delta\": content block = event.delta.model dump() if \"text\" in content block and content block[\"text\"] is None: content block.pop(\"text\") content block[\"index\"] = event.index content block[\"type\"] = \"thinking\" message chunk = AIMessageChunk(content=[content block]) elif event.delta.type == \"signature delta\": content block = event.delta.model dump() if \"text\" in content block and content block[\"text\"] is None: content block.pop(\"text\") content block[\"index\"] = event.index content block[\"type\"] = \"thinking\" message chunk = AIMessageChunk(content=[content block]) elif event.delta.type == \"input json delta\": content block = event.delta.model dump() content block[\"index\"] = event.index content block[\"type\"] = \"tool use\" tool call chunk = create tool call chunk( index=event.index, id=None, name=None, args=event.delta.partial json, ) message chunk = AIMessageChunk( content=[content block], tool call chunks=[tool call chunk], type: ignore ) ============================== add code : print(\"message chunk\", message chunk) 2025 05 13 22:37:30,741 [link] INFO HTTP Request: POST [link] \"HTTP/1.1 200 OK\" message chunk content=[{'partial json': '', 'type': 'tool use', 'index': 1}] additional kwargs={} response metadata={} tool calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool call'}] tool call chunks=[{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool call chunk'}]"}, {"author": "ccurme", "created_at": "2025-05-13T19:02:03Z", "body_clean": "Yes, the [code] keys are definitely there, but I'm not seeing any errors or warnings so I'm asking if you can help me reproduce them."}]}, {"ollama_summary": "The LLMListwiseRerank issue currently crashes with an IndexError when the list of documents is empty.  The problem appears to be a bug within the LangChain library, as attempts to update to the latest version haven’t resolved it. A minimal, reproducible example is provided to demonstrate the error.", "final_category": "bug", "comments": [{"author": "skabbit", "created_at": "2025-05-12T13:46:59Z", "body_clean": "I debugged and found this prompt inaccurate and possible reason for the error: [link] This make LLM return 0 even when there is no documents, and this leads to error."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue currently presents a problem when pulling RAG prompts – specifically, it fails when using the EU endpoint. The documentation suggests using a specific code snippet, but this code is required for the US endpoint.  The proposed solution is to add a note to the documentation clarifying this requirement for EU usage.", "final_category": "other", "comments": [{"author": "alialvii", "created_at": "2025-05-12T18:01:15Z", "body_clean": "Hi, Id be happy to work on this!"}, {"author": "HummdG", "created_at": "2025-05-15T16:41:15Z", "body_clean": "Hi, Id be happy to work on this! Hi, are you still working on this? Would love to help out if you are!"}]}, {"ollama_summary": "This issue reports a 403 Forbidden error when using the Azure AI Search Retriever, specifically when running the `langchain community.retrievers.azure ai search` script. The bug appears to be linked to a problem with the `langchain` community v0.3.22 release, and it's not consistently reproducible across older versions (0.3.21 and earlier).  The code snippet in question is failing to correctly parse the Azure AD token parameter, leading to the 403 error.", "final_category": "bug", "comments": [{"author": "csnarain", "created_at": "2025-05-24T08:54:15Z", "body_clean": "Is someone facing this? Can someone comment on this pls?"}, {"author": "mchoilab", "created_at": "2025-07-16T14:21:49Z", "body_clean": "Have you checked whether you are using AI search API password (AzureSearch azure search key)? It is different from AZURE OPENAI API KEY that you use for AzureOpenAIEmbeddings."}, {"author": "csnarain", "created_at": "2025-07-16T16:08:45Z", "body_clean": "Have you checked whether you are using AI search API password (AzureSearch azure search key)? It is different from AZURE OPENAI API KEY that you use for AzureOpenAIEmbeddings. If that's the case, the same key should not work with earlier versions of this library right?"}, {"author": "mdrxy", "created_at": "2025-07-16T18:18:42Z", "body_clean": "Closing, please comment if issue persists and it is related to a LangChain implementation."}]}], "business_insights": ["Thorough code review is crucial for identifying unexpected None values.", "Trace function return values to pinpoint the source of None.", "Explicitly check for implicit returns and potential None assignments.", "Debugging with print statements helps identify the exact location of the issue.", "Isolate the problem by simplifying code to focus on the root cause."], "technical_insights": [], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Thorough code review is crucial for identifying unexpected `None` values.\n2. Trace function return values to pinpoint the source of `None`.\n3. Explicitly check for implicit returns and potential `None` assignments.\n4. Debugging with print statements helps identify the exact location of the issue.\n5. Isolate the problem by simplifying code to focus on the root cause.\n", "batch_number": 69, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue involves a bug in LangChain that causes the RAG application to fail when streaming is enabled. The code attempts to utilize a tool request, but the integration fails due to a subtle issue with the `[code]` parameter, leading to an unhandled error. The solution requires a fix to the LangChain integration, specifically addressing the incorrect handling of the `[code]` parameter.", "final_category": "bug", "comments": [{"author": "xuzexin-hz", "created_at": "2025-05-09T08:17:17Z", "body_clean": "I think it should be a problem with Litellm, changing it to the local Ollama model is ok"}, {"author": "fgiuba", "created_at": "2025-05-09T14:56:44Z", "body_clean": "@xuzexin hz yes, I confirm, it also works with [code] , the problem is I have to use the LiteLLM router so I need to rely on [code] ."}, {"author": "AmanBhattShorthillsAI", "created_at": "2025-05-11T17:31:18Z", "body_clean": "Please assign this issue to me @fgiuba and @maintainers"}, {"author": "fgiuba", "created_at": "2025-05-12T07:41:33Z", "body_clean": "Will the [fix]( [link] be imported also in [code] ?"}, {"author": "AmanBhattShorthillsAI", "created_at": "2025-05-12T07:46:31Z", "body_clean": "Import the chat models from langchain litellm"}, {"author": "Akshay-Dongare", "created_at": "2025-05-12T08:01:05Z", "body_clean": "@fgiuba The [code] and [code] integration is going to be [deprecated from langchain community]( [link] since it is being maintained at [langchain litellm]( [link] as per the request of @ccurme in this issue [link] Using [code] ≥ 0.2.1 (where the ChatLiteLLM/ChatLiteLLMRouter code now lives), streaming + tool calls work end to end. The copies in langchain community are being deprecated, so please import from the stand alone package going forward. Let me know if anything’s still off!"}, {"author": "fgiuba", "created_at": "2025-05-12T08:35:42Z", "body_clean": "Fixed by [link]"}]}, {"ollama_summary": "This GitHub issue reports an \"Unauthorized\" error when using the `sentence transformers` library, specifically when attempting to access a URL. The error occurs when the API key for Hugging Face is changed, requiring investigation into the specific code causing the problem. The issue is currently focused on identifying the root cause of the error and suggests a potential content update.", "final_category": "question", "comments": [{"author": "pebabion", "created_at": "2025-05-13T01:36:08Z", "body_clean": "The problem arises because the HuggingFaceEmbeddings class ultimately relies on Hugging Face Hub to fetch the embedding model. If an invalid or expired token is set in your environment (e.g., via HUGGINGFACEHUB API TOKEN or CLI login), the request to download the model fails with a 401 Unauthorized, even if the model is public. To resolve this for public models, you can force the download to proceed without using any token: [code] Alternatively, if you’re using a private model, make sure to pass a valid token explicitly: [code] By the way, when I created my environment with python3.13, and using the following package versions, the error does not happen. Hope it helps! [code]"}]}, {"ollama_summary": "This issue reports a bug in LangChain where the `keep_separator=False` setting causes the splitter to re-insert regex separators, leading to unexpected output. This behavior only manifests under specific conditions involving large chunks and a large regex separator. The code provides a minimal, reproducible example demonstrating the issue, and the issue is currently unresolved, suggesting a potential fix or update is needed.", "final_category": "bug", "comments": []}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a grammatical error in a documentation sentence – “A chat prompt is made up a of a list of messages.”  The fix is to correct it to “A chat prompt is made up of a list of messages.” This is a minor correction intended to improve the documentation’s clarity and professionalism.  Currently, there’s no specific request for content beyond this fix.", "final_category": "other", "comments": [{"author": "tushar-nitave", "created_at": "2025-05-06T19:22:28Z", "body_clean": "I will be issuing the fix."}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes a validation error when using the Chatgroq library. The error is triggered by a specific integration package, and the code is working correctly previously. The issue is reproducible with a minimal example and is being addressed by the developers, requiring a recent LangChain update or specific package version.", "final_category": "bug", "comments": []}], "business_insights": ["LangChain integration issues frequently impact RAG applications, requiring specific code fixes.", "The [code] parameter is a critical point of failure, indicating a potential integration problem.", "The Litellm router complicates the integration process, necessitating reliance on the [code] parameter.", "The Hugging Face API key change is a likely root cause, requiring investigation of the impacted code.", "The issue highlights a potential bug in the splitter’s regex handling, impacting large chunks."], "technical_insights": ["LangChain integration failures are a recurring issue, demanding code updates.", "The [code] parameter is a core component, potentially causing issues with the integration.", "The Litellm router complicates the integration, needing the [code] parameter.", "Hugging Face API key changes are a likely root cause, requiring investigation.", "The splitter's regex handling is a bug that affects large chunks, needing resolution."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain integration issues frequently impact RAG applications, requiring specific code fixes.\n2.  The `[code]` parameter is a critical point of failure, indicating a potential integration problem.\n3.  The Litellm router complicates the integration process, necessitating reliance on the `[code]` parameter.\n4.  The Hugging Face API key change is a likely root cause, requiring investigation of the impacted code.\n5.  The issue highlights a potential bug in the splitter’s regex handling, impacting large chunks.\n\nTECHNICAL INSIGHTS:\n1.  LangChain integration failures are a recurring issue, demanding code updates.\n2.  The `[code]` parameter is a core component, potentially causing issues with the integration.\n3.  The Litellm router complicates the integration, needing the `[code]` parameter.\n4.  Hugging Face API key changes are a likely root cause, requiring investigation.\n5.  The splitter's regex handling is a bug that affects large chunks, needing resolution.\n", "batch_number": 70, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a critical bug in the custom Mistral model endpoint, causing it to return `\"content\": null` for a tool call. This issue involves a problem with the LangChain integration, specifically related to the `duckduckgo search run` function. The issue details a potential issue with the `toolbelt` package, which is causing the model to return the unexpected result. The code is designed to handle the call, but the model is failing to return the expected content.", "final_category": "bug", "comments": [{"author": "MiraiKami", "created_at": "2025-10-14T13:30:08Z", "body_clean": "I encountered the same error. My workaround was to change the model method [code] where the error occured by replacing the None value with an empty string. Here is an example: [code] Then the AI Message containing the tool invocation will not crash the application."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a persistent problem where outdated Sambaverse models are still appearing in the API documentation, despite their removal from the codebase.  The documentation is incorrectly referencing these models, creating a confusing and potentially misleading experience for developers.  The core request is to remove these outdated models from the API reference.", "final_category": "other", "comments": [{"author": "mdrxy", "created_at": "2025-07-16T18:20:32Z", "body_clean": "This appears to be an outdated version of the API refs, the new one is [here]( [link]"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe user is encountering an import error when attempting to build the API documentation using the `docs clean` command, specifically with the second command. They’ve cloned the repository and run the commands, but aren’t receiving the expected output.  The user is seeking guidance on how to view the generated documentation files and understand their purpose.", "final_category": "other", "comments": [{"author": "mateencog", "created_at": "2025-05-08T06:07:58Z", "body_clean": "Hello, I hope you are doing well. Welcome to this awesome community! I could successfully replicate your problem. There are two issues you need to resolve before you can build the docs; 1. You need to separately install the packages required for building the API docs [code] Now after running [code] you will see an error about a missing pyproject.toml file in community library. 2. Since, the repositories experimental and community have been removed from the current repository, you must manually delete those folders (empty) before building the docs. [code] [code] Now the docs building workflow will skip these empty folders. The PR I mentioned resolves this issue by checking for a pyproject.toml file in the [code] folder and skipping those which don't have it. After a successful build you will see the following message: The HTML pages are in build/html. make[1]: Leaving directory '/langchain/docs/api reference' uv run no group test python docs/api reference/scripts/custom formatter.py docs/api reference/ build/html/ Now you can browse the docs by opening [code] in a browser"}, {"author": "vhxs", "created_at": "2025-05-19T22:29:50Z", "body_clean": "I ran [code] and [code] instead, but I can confirm that I can build the docs after doing this."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the Milvus Hybrid Retrieval feature is inconsistent across two separate pages, leading to confusion and potential errors.  The issue highlights a need to clarify the accurate information by removing the outdated documentation page.  Currently, the team is seeking a response to this inconsistency.", "final_category": "other", "comments": [{"author": "MichaelLi65535", "created_at": "2025-05-07T19:29:59Z", "body_clean": "I've raised [link] to remove it"}, {"author": "zc277584121", "created_at": "2025-05-08T11:25:16Z", "body_clean": "The use of MilvusCollectionHybridSearchRetriever is no longer recommended, but the code can still run and it has not been taken offline yet. The recommended approach for hybrid retrieval in langchain milvus is here [link] we do suggest taking down the document related to MilvusCollectionHybridSearchRetriever: [link]"}, {"author": "MichaelLi65535", "created_at": "2025-05-11T18:29:08Z", "body_clean": "Hi @JakeMY coder , the PR has been merged. You may close this issue."}, {"author": "JakeMY-coder", "created_at": "2025-05-12T13:48:57Z", "body_clean": "Thank you"}]}, {"ollama_summary": "This issue involves a bug in the LangChain library where the `dict` function is consistently used instead of the `model_dump` function within specific classes and functions. This is causing deprecation warnings and potentially impacting the code's functionality.  The issue is currently being addressed through a self-contained example, and further version updates are not providing a solution.", "final_category": "bug", "comments": []}], "business_insights": ["Model endpoint bug impacts Mistral’s core functionality, requiring immediate attention.", "LangChain integration vulnerability necessitates a thorough review of the model’s behavior.", "Deprecation warnings highlight a critical design flaw in the library.", "Model returns unexpected content, impacting downstream workflows.", "Correcting the bug will improve the model’s reliability and user experience."], "technical_insights": ["LangChain integration is the primary source of the issue.", "Model method replacement addresses the core bug.", "Sambaverse models are outdated, requiring removal.", "Documentation references are incorrect, creating confusion.", "docs clean command is failing to generate correct documentation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model endpoint bug impacts Mistral’s core functionality, requiring immediate attention.\n2. LangChain integration vulnerability necessitates a thorough review of the model’s behavior.\n3. Deprecation warnings highlight a critical design flaw in the library.\n4. Model returns unexpected content, impacting downstream workflows.\n5. Correcting the bug will improve the model’s reliability and user experience.\n\nTECHNICAL INSIGHTS:\n1. LangChain integration is the primary source of the issue.\n2. Model method replacement addresses the core bug.\n3. Sambaverse models are outdated, requiring removal.\n4. Documentation references are incorrect, creating confusion.\n5. `docs clean` command is failing to generate correct documentation.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 71, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain that causes the model to repeatedly output data, leading to a loop and potentially causing issues with the application. The code uses a `loop` construct, and the problem is likely related to the model's internal state or processing, potentially due to a memory issue or a bug in the loop's execution.  The issue is reproducible with a minimal example and is currently being addressed by the developers.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-05-04T00:36:47Z", "body_clean": "Can you use [code] ?"}]}, {"ollama_summary": "The issue reports a validation error when using ChatGroq, specifically related to a missing required field within the model initialization process.  The error occurs regardless of the API key, and a minimal, reproducible example has been provided to demonstrate the problem.  Currently, the issue appears to be a bug within the LangChain integration package.", "final_category": "bug", "comments": [{"author": "maxkaustav", "created_at": "2025-05-02T06:13:19Z", "body_clean": "closing this issue change in parameter name to model"}]}, {"ollama_summary": "This issue stems from a `ImportError` occurring when attempting to use the `is_data_content_block` function from the `langchain_core.messages` library within a specific Python version and LangChain integration. The code being used is version 0.3.56, and the error is specifically linked to a discrepancy between the system version and the library version, potentially indicating a bug within the LangChain library itself.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-05-01T13:41:34Z", "body_clean": "Hi @franklinselva, the version of langchain core running in your session is likely older than the minimum set by langchain ollama. I would suggest: Restart the kernel [code] should force an update of langchain core Failing that, [code] Let me know if issues persist after doing these steps."}, {"author": "franklinselva", "created_at": "2025-05-10T10:16:44Z", "body_clean": "@ccurme Thanks for the direction. The problem is happening only on my Ubuntu machine. My environment is based on [pixi]( [link] Can we keep this issue open so I can refer to this on their tickets?"}, {"author": "mdrxy", "created_at": "2025-09-10T00:27:36Z", "body_clean": "@franklinselva what's the status? Is this able to be closed?"}]}, {"ollama_summary": "This issue is a bug in the `create-react-agent` tool that causes the argument descriptions for the agent's metadata to be missing after passing through. It’s a specific problem related to the internal handling of tools within the agent, and it’s impacting the agent’s functionality.  The issue is reproducible with a minimal example and can be addressed by ensuring the tool’s internal logic is correctly configured.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2025-04-29T13:52:21Z", "body_clean": "hm, do you have a langsmith trace you can share? not sure how you're tracing API call logs you can also verify the tool call schema that is being sent to openai by using this command: [code] it shows this for me: [code]"}, {"author": "Rai220", "created_at": "2025-04-29T14:03:52Z", "body_clean": "Yeah, you can check it here: [link] Also print(llm.bind tools([Think]).kwargs) works well. This bug only in create react agent function, because it did not use .bing tools directly, but implements some additional logic around tools."}, {"author": "vbarda", "created_at": "2025-04-29T14:11:40Z", "body_clean": "ah, i can reproduce. it's not a but in [code] , but rather in langchain core here is a reproducible example: [code]"}, {"author": "CtrlMj", "created_at": "2025-04-29T16:38:46Z", "body_clean": "@Rai220 Did you adapt this code from an example in the docs? Aren't tools supposed to be a subclass of the BaseTool or functions tool decorations? what would the [code] method of this tool do?"}, {"author": "Rai220", "created_at": "2025-04-30T06:52:11Z", "body_clean": "@CtrlMj you can find such type of examples here: [link] Not all cases need run to work. For example you can use tools for feature extraction."}, {"author": "labdmitriy", "created_at": "2025-05-15T13:31:00Z", "body_clean": "Hi @vbarda, I've tested different versions of the tools and 2 versions of agents prebuilt agent using [code] and minimal custom implementation with the similar functionality. For each tool I provide the following information: [code] [code] if I didn't find that configuration in the official documentation, I specified \"?\", but some unofficial configurations here are working or official configuration that have weird errors and worth mentioning [code] Results of experiment for both types of the agent (true tool arg description is passed, false tool arg description is not passed, error error was raised) [code] Error description (if any) Here is the code and the results (you just need uncomment specific tool and agent for running an experiment): [code] Main conclusions: For the tool 1 (the case that @Rai220 found) only custom agent is working, but for tool 2 both agents are failed Tool 3 with Annotated is from official documentation, but it is not working for both agents For tools as functions there are cases where it is working correctly even without [code] (tools 6 and 8) We can use Field for function arguments and it is working although I didn't find any information in the official documentation (tools 8 and 9) There was an error for both agents if I tried to create custom tool based on BaseTool class (tool 12) Could you please help to clarify the best and bad practices how to create tools in different cases with prebuilt and custom agents? Thank you."}, {"author": "labdmitriy", "created_at": "2025-05-15T15:54:16Z", "body_clean": "Hi @vbarda, I think I've found more information about the issue. You provided the example with [code] , but this transformation is used as tool decorator or as a function in ToolNode for conversion, but in our case we lose the tool arg description when make a request to the tool, so it seems that the problem is not only in tool definition or conversion, but also in binding tools logic which is used in [code] . This is the definition of the agent will work with the code above (just added binding tools to llm explicitly): [code] So probably the example with [code] demostrates related issue but not give the full picture. I think the root problem is [here]( [link] [code] The first [code] condition, the second branch, defines [code] variable which stores list of tools from ToolNode, not original tools, and there is no tool arg description after this conversion. An the last 2 lines will bind tools only if llm has no tools yet, and we pass to [code] not original tools but converted information about tools from ToolNode, already with missing tool arg description. So based on the first [code] condition, the following code will also not work (if we pass [code] as tools and will not bind any tools to llm explicitly): [code] But if I change last 2 lines to the following code (replace [code] with [code] , then it will work correctly for all cases except when we pass [code] as tools: [code] So probably this is additional place in code to consider. Thank you."}]}, {"ollama_summary": "This issue is caused by a dependency conflict within the LangChain library, specifically with the `asyncCallbackManagerForLLMRun` package.  It's failing to import this package, requiring a recent update to LangChain to resolve the problem.", "final_category": "bug", "comments": [{"author": "LucianoPereira", "created_at": "2025-04-29T12:50:45Z", "body_clean": "It seems that the problem was that I created a file called [code] and that conflicted with the python package name"}]}], "business_insights": ["Dependency conflicts are a recurring issue across multiple issues, suggesting potential instability in LangChain’s dependency management.", "Addressing these conflicts proactively will improve overall application reliability.", "A consistent update strategy for LangChain is crucial for mitigating future bugs.", "Thorough dependency analysis is essential before deploying new code.", "Automated dependency checking tools can be implemented to streamline this process."], "technical_insights": ["LangChain’s dependency management is a significant point of concern, potentially leading to inconsistent behavior across different environments.", "The asyncCallbackManagerForLLMRun package is a critical dependency, and its conflict highlights potential issues with LangChain’s internal state.", "Dependency conflicts are frequently triggered by changes in LangChain releases, necessitating a robust update process.", "Updating LangChain is a priority, as it's a core component for many applications.", "Maintaining a well-defined dependency graph is vital for debugging and stability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency conflicts are a recurring issue across multiple issues, suggesting potential instability in LangChain’s dependency management.\n2. Addressing these conflicts proactively will improve overall application reliability.\n3. A consistent update strategy for LangChain is crucial for mitigating future bugs.\n4. Thorough dependency analysis is essential before deploying new code.\n5. Automated dependency checking tools can be implemented to streamline this process.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s dependency management is a significant point of concern, potentially leading to inconsistent behavior across different environments.\n2. The `asyncCallbackManagerForLLMRun` package is a critical dependency, and its conflict highlights potential issues with LangChain’s internal state.\n3. Dependency conflicts are frequently triggered by changes in LangChain releases, necessitating a robust update process.\n4. Updating LangChain is a priority, as it's a core component for many applications.\n5. Maintaining a well-defined dependency graph is vital for debugging and stability.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 72, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in LangChain that causes the `partition_pdf()` function to return incorrect results when extracting images from PDF files. The code attempts to extract tables and text, but the function consistently produces composite elements instead of the expected table format. The issue is reproducible with a minimal example, and the developer is investigating a potential issue with the integration package, but hasn't found a specific fix.", "final_category": "bug", "comments": [{"author": "johannesrosenberger", "created_at": "2025-06-25T14:48:44Z", "body_clean": "I ran in the exact same problem as described above. Unfortunatelly, I was not able to resolve the problem but my workaround was to redefine [code] [code] [code] strategy. [code]"}, {"author": "dz-dot", "created_at": "2025-08-19T14:14:37Z", "body_clean": "I have same problem. No workaround yet("}]}, {"ollama_summary": "This issue reports a critical bug in LangChain that causes annotation strings to be incorrectly handled during runtime, leading to errors and a lack of response. The bug is present when writing code with the `py` file extension and requires a self-contained, reproducible example to demonstrate the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue involves a significant performance slowdown in LangChain applications, specifically when calling the Google GenAI API. The code is experiencing a 5-minute delay without any updates to the LangChain library itself, suggesting a potential bug within the LangChain implementation.  The issue is reproducible with a minimal example, and the developers are investigating the root cause using a self-contained, minimal example to isolate the problem.", "final_category": "bug", "comments": [{"author": "shengegeshen1130", "created_at": "2025-06-11T03:36:54Z", "body_clean": "+1"}]}, {"ollama_summary": "This issue stems from a critical incompatibility between the latest Chroma server release and the langchain-chroma library. The Chroma server requires a specific Rust version (1.x), and the langchain package is using a different version, causing errors and requiring a manual workaround to resolve the problem.", "final_category": "bug", "comments": [{"author": "sydney-runkle", "created_at": "2025-04-28T15:11:46Z", "body_clean": "This looks pretty related to: [link]"}, {"author": "sandipsahoo2k2", "created_at": "2025-04-29T18:09:58Z", "body_clean": "I have same problem, some one said pip install upgrade chromadb or pip install upgrade chromadb client resolved it and closed the issue. = But No it's not resolved .. I have been struggling with this I did so many combinations without any luck so far and using Redis as my backup !!"}, {"author": "Dseal95", "created_at": "2025-05-05T12:09:12Z", "body_clean": "I just wanted to confirm the same issue as @andreivladmatei. Seems like [code] is pinned to [code] version 0.6.3 but there is an error retrieving collections from [code] when using [code] : [code] The error is fixed in newer versions of [code] see [link]"}, {"author": "jairad26", "created_at": "2025-05-15T20:11:13Z", "body_clean": "Hi, this is now fixed as part of langchain chroma 0.2.4 To upgrade, run [code]"}]}, {"ollama_summary": "This issue stems from a bug in Pydantic where fields with the 'alias' attribute are silently passing to LLM inference, despite not being intended for use. The code is provided as a minimal reproducible example, and the installation of various LLM libraries (Langchain, etc.) is failing to provide the expected version information, indicating a potential issue with the alias generation process.", "final_category": "bug", "comments": [{"author": "hinthornw", "created_at": "2025-04-26T21:00:00Z", "body_clean": "Seems unrelated to LangGraph so moving to the LangChain repo."}, {"author": "hinthornw", "created_at": "2025-04-26T21:04:01Z", "body_clean": "Confirmed / can reproduce with this: [code] [code] The field should not be dropped"}, {"author": "YashalShakti", "created_at": "2025-04-26T21:09:03Z", "body_clean": "It would be good to add a Warning to [link] meanwhile"}, {"author": "CtrlMj", "created_at": "2025-04-30T18:41:34Z", "body_clean": "The bug stems from [line1087]( [link] [code] in the [code] method: [code] In this case, [code] is the following dictionary: [code] However, [code] in line 1087 is the Alias [code] which is not the key in the dictionary for the first parameter. This is because in [line 1081]( [link] [code] returns an [code] : [code] For fields with alias like above, inspect sets the alias as the key in the dictionary and skips over the original parameter name. Therefore I think it's related to the [code] package. I can open an issue there. However, I can implement a workaround in the meanwhile if we'd prefer that. One workaround could be to have a dictionary that maps the aliases if they exists to the original variable name and use that in the for loop: [code] cc: @ccurme edit1: Added proposed workaround. I have tested and it works edit2: typo"}, {"author": "ccurme", "created_at": "2025-05-03T19:43:26Z", "body_clean": "@CtrlMj want to PR your workaround? :)"}, {"author": "keenborder786", "created_at": "2025-05-04T00:26:57Z", "body_clean": "@ccurme I have already patched a fix"}, {"author": "CtrlMj", "created_at": "2025-05-04T01:23:34Z", "body_clean": "@ccurme please find it [here]( [link]"}]}], "business_insights": ["Identify and address the root cause of the partition_pdf() bug to improve data extraction accuracy.", "Investigate the integration package issue to ensure consistent code across all LangChain projects.", "Prioritize performance bottlenecks in the Google GenAI API to optimize application responsiveness.", "Resolve the Chroma server compatibility issue to maintain data integrity and prevent regressions.", "Ensure the alias generation process within Pydantic is correctly handled across all LLM integrations."], "technical_insights": ["Focus on the partition_pdf() function’s specific error handling and table extraction logic.", "Trace the integration package’s code to pinpoint the source of inconsistencies.", "Analyze the Google GenAI API’s latency and identify potential bottlenecks.", "Verify the Chroma server’s Rust version compatibility with LangChain.", "Deep dive into the Pydantic alias generation process to identify the cause of the data loss."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Identify and address the root cause of the `partition_pdf()` bug to improve data extraction accuracy.\n2.  Investigate the integration package issue to ensure consistent code across all LangChain projects.\n3.  Prioritize performance bottlenecks in the Google GenAI API to optimize application responsiveness.\n4.  Resolve the Chroma server compatibility issue to maintain data integrity and prevent regressions.\n5.  Ensure the alias generation process within Pydantic is correctly handled across all LLM integrations.\n\nTECHNICAL INSIGHTS:\n1.  Focus on the `partition_pdf()` function’s specific error handling and table extraction logic.\n2.  Trace the integration package’s code to pinpoint the source of inconsistencies.\n3.  Analyze the Google GenAI API’s latency and identify potential bottlenecks.\n4.  Verify the Chroma server’s Rust version compatibility with LangChain.\n5.  Deep dive into the Pydantic alias generation process to identify the cause of the data loss.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 73, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue relates to a bug in LangChain's `ZhipuAiImageModel` component, specifically a problem with the `model` parameter. The code attempts to use a `Cogview` model, but the model name is not correctly formatted. The issue also includes a stack trace indicating a potential issue with the `ZhipuChatModel` and `ConnectionPool` classes.  The code attempts to handle a `WINDOW UPDATE` event, which is causing a deserialization error.  The issue is being addressed through a fix, potentially involving updating the model name and ensuring proper data formatting.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-26T12:40:53Z", "body_clean": "@Sword40 please raise this issue in Langraph"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a lack of comprehensive tutorials on Python within the /docs/integrations/chat/deepseek documentation. The core problem is the absence of helpful content for new users learning Python, and the request is for more detailed tutorials.  Currently, the documentation doesn’t adequately cover the basics of using the deepseek feature.", "final_category": "other", "comments": [{"author": "benjamincburns", "created_at": "2025-04-28T02:53:00Z", "body_clean": "You've filed this issue in the LangChain JS repo. For LangChain python you want to go [here]( [link] The [current DeepSeek integration docs for the Python version of the LangChain project]( [link] are a bit sparse, though. I'll migrate this issue over to the correct repo and perhaps the team can look to improve this."}, {"author": "langcarl[bot]", "created_at": "2025-04-28T02:53:27Z", "body_clean": "This issue has been flagged as spam and will be closed. Please tag @ccurme if you feel this was done in error."}, {"author": "ccurme", "created_at": "2025-04-28T03:14:58Z", "body_clean": "Hi @THEYBL, you can find the LangChain python docs here: [link] If you are looking for the Python integration with DeepSeek, see guide [here]( [link] for basic usage as well as the [API reference]( [link]"}]}, {"ollama_summary": "This issue involves a critical bug where the `create_tool_calling_agent` script fails to invoke the required tools for both Bedrock LLama and Mistral models, despite the code snippet remaining unchanged.  It's currently impacting the integration of these models, and the solution requires a change to the LangChain agent annotation to handle tool invocation correctly.", "final_category": "bug", "comments": []}, {"ollama_summary": "The PGVector `as_retriever` tool is failing with an \"Assertion Error: '_async_engine not found'\" when used with the ReAct agent.  The issue appears to be a bug within LangChain, as attempts to update to the latest version haven’t resolved it. A minimal, reproducible example has been provided, allowing for easy testing of the problem.", "final_category": "bug", "comments": [{"author": "khteh", "created_at": "2025-04-23T09:07:39Z", "body_clean": "[code]"}]}, {"ollama_summary": "The PGVector project is experiencing a lack of asynchronous `aadd_documents` functionality, hindering its ability to work with other vector stores.  The issue stems from a potential bug within LangChain, and the maintainer has provided a self-contained, reproducible example to demonstrate the problem.  Currently, there’s no solution provided beyond the fact that the bug isn’t being addressed through updates to the LangChain library.", "final_category": "feature", "comments": [{"author": "khteh", "created_at": "2025-04-23T09:07:30Z", "body_clean": "[code]"}]}], "business_insights": ["Model name formatting inconsistencies can trigger critical errors across components.", "Lack of comprehensive tutorial content hinders new Python user adoption.", "Tool invocation issues in the agent annotation are a significant bug.", "Asynchronous aadd_documents is missing, impacting vector store integration.", "Delayed bug fixes impact existing integrations."], "technical_insights": ["ZhipuAiImageModel bug impacts core model functionality.", "Cogview model name mismatch causes ZhipuChatModel errors.", "Deserialization error within ZhipuChatModel and ConnectionPool causes issues.", "WINDOW UPDATE deserialization error necessitates model update.", "Agent annotation bug prevents proper tool invocation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model name formatting inconsistencies can trigger critical errors across components.\n2. Lack of comprehensive tutorial content hinders new Python user adoption.\n3. Tool invocation issues in the agent annotation are a significant bug.\n4. Asynchronous `aadd_documents` is missing, impacting vector store integration.\n5. Delayed bug fixes impact existing integrations.\n\nTECHNICAL INSIGHTS:\n1.  ZhipuAiImageModel bug impacts core model functionality.\n2.  `Cogview` model name mismatch causes `ZhipuChatModel` errors.\n3.  Deserialization error within `ZhipuChatModel` and `ConnectionPool` causes issues.\n4.  `WINDOW UPDATE` deserialization error necessitates model update.\n5.  Agent annotation bug prevents proper tool invocation.\n", "batch_number": 74, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a critical error in OpenAI's function calling mechanism within strict mode, specifically when using `Union[Objects]` as arguments. This manifests as an \"invalid_function_parameters error\" due to the type mismatch between the arguments and the expected structure of the function. A self-contained, reproducible example demonstrates the problem with Pydantic schema output, highlighting a potential bug within LangChain.", "final_category": "bug", "comments": [{"author": "shengbo-ma", "created_at": "2025-04-22T22:52:37Z", "body_clean": "Please review this PR fixing the issue: [link]"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a problem where the browser is failing to recognize a dialog within a LangChain application, despite a descriptive title and a self-contained example.  The problem isn’t directly related to a bug in LangChain itself, but rather a potential issue with the browser’s rendering of the dialog.  The solution involves a minimal, reproducible example demonstrating the issue, and the maintainer is actively working to resolve it.", "final_category": "bug", "comments": [{"author": "MichaelLi65535", "created_at": "2025-04-23T15:33:16Z", "body_clean": "Hi @zhouEva1218 , there's not enough information to look into the issue. Can you please add more details such as the steps to replicate the issue and the exact error message?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports an error when assigning a \"thinking\" model (Claude 3.7) to a supervisor and a worker agent, while simultaneously utilizing GPT-4 for another worker agent. This results in a failure to properly integrate these models, causing a compilation error.  The developers are investigating the potential issue and proposing a fix to ensure seamless model integration within the Langgraph-Supervisor environment.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2025-04-21T13:27:19Z", "body_clean": "Will look into this!"}, {"author": "kfirco-jit", "created_at": "2025-05-07T09:19:53Z", "body_clean": "I'm encountering a similar issue when switching from the claude 3.7 thinking to claude 3.7 non thinking. The error returned is: [code]"}, {"author": "ccurme", "created_at": "2025-05-19T14:34:18Z", "body_clean": "I'm encountering a similar issue when switching from the claude 3.7 thinking to claude 3.7 non thinking. The error returned is: [code] @kfirco jit would you mind opening a separate issue in the [langchain repo]( [link] for this?"}]}, {"ollama_summary": "The GitHub issue highlights a compatibility problem with OpenAI's LangChain SDK version 1.0 and later, specifically related to the `openai.BaseModel` reference breaking. This issue results in an `AttributeError` when attempting to use the `BaseModel` class, requiring a temporary workaround to resolve the issue.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-04-20T22:18:07Z", "body_clean": "Hi, thanks for reporting this. I'm unable to replicate with latest [code] (1.75.0). I also still see [code] exported in the source: [link] Can you share where you're seeing it's deprecated?"}]}, {"ollama_summary": "The issue involves intermittent `LengthFinishReasonError` exceptions in the `AzureChatOpenAI` integration, specifically when the combined token count exceeds 10,000 tokens. This problem is reproducible with a minimal example and seems to hang for approximately 3 minutes, despite the output appearing quickly in LangSmith traces. The team is seeking insights into the root cause and potential solutions to address this bug.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-20T22:31:18Z", "body_clean": "@chanjeon dev Are you sure, each of your call in the batch is below the token limit. Note that since you are doing a request in single batch, that's why their might be a delay in the output trace on langsmith."}, {"author": "znat", "created_at": "2025-06-02T20:09:20Z", "body_clean": "I think the reason it takes significantly longer is because the model goes on generating tokens until it reaches the limit. If you set [code] you will get the error faster."}]}], "business_insights": ["Type mismatch in function parameters triggers critical errors, impacting OpenAI’s core functionality.", "LangChain’s bug highlights a potential issue with browser rendering of dialogs, requiring proactive debugging.", "Model integration failures necessitate a fix for seamless model combination within Langgraph-Supervisor.", "SDK version incompatibility with OpenAI’s LangChain SDK (1.0+) causes compilation errors.", "AzureChatOpenAI integration suffers from LengthFinishReasonError with token limit exceeding 10,000."], "technical_insights": [], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Type mismatch in function parameters triggers critical errors, impacting OpenAI’s core functionality.\n2.  LangChain’s bug highlights a potential issue with browser rendering of dialogs, requiring proactive debugging.\n3.  Model integration failures necessitate a fix for seamless model combination within Langgraph-Supervisor.\n4.  SDK version incompatibility with OpenAI’s LangChain SDK (1.0+) causes compilation errors.\n5.  AzureChatOpenAI integration suffers from `LengthFinishReasonError` with token limit exceeding 10,000.\n", "batch_number": 75, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The error message indicates a version mismatch between the `langchain` library and the `deepseek` library. Specifically, the `deepseek` library requires a specific version of `langchain` (0.1.3) while the system is running an older version (0.2.0). This incompatibility is causing the system to fail to resolve the version of `langchain` needed for the `deepseek` library.", "final_category": "bug", "comments": [{"author": "MichaelLi65535", "created_at": "2025-04-24T08:00:54Z", "body_clean": "Hi @bazingaedward , what's your Python version? What's the langchain community and langchain core version you are trying to install?"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe tool call functionality in LangChain fails when the function accepts dictionary arguments, regardless of the underlying LLM's performance. This issue is reproducible with a minimal example code and doesn’t appear to be related to updates to the LangChain library itself.  The core problem is that the function is incorrectly interpreting dictionary arguments as a different type, causing it to fail.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-20T22:39:24Z", "body_clean": "Rather than following: [code] Please try following: [code]"}, {"author": "DebajitKumarPhukan", "created_at": "2025-04-21T02:57:05Z", "body_clean": "@keenborder786 I am aware that the suggested option will work, but my requirement is to be able to invoke a function having a dictionary of arguments. Is it a limitation of current tool calling that it can parse only individual parameters and not dictionary of arguments ?."}, {"author": "DebajitKumarPhukan", "created_at": "2025-05-06T13:10:57Z", "body_clean": "@keenborder786 Any updates ?."}, {"author": "diego-coder", "created_at": "2025-07-19T08:36:00Z", "body_clean": "@DebajitKumarPhukan Just letting you know that I've submitted a PR to address this issue: [ 32109]( [link] It adds support for parsing Python style dicts (with single quotes) in tool calls, as discussed above. Thanks for raising the problem, hopefully this makes working with tool arguments much smoother! If you have any feedback or test cases I should consider, please let me know."}, {"author": "DebajitKumarPhukan", "created_at": "2025-07-27T07:10:17Z", "body_clean": "@diego coder Thank you so much."}]}, {"ollama_summary": "This issue reports a bug in LangChain where it fails to provide cost information for new Open AI 4.1 and o4 model versions. The code attempts to retrieve these costs, but the system returns 0, indicating a lack of data. The issue is suspected to be a bug within the LangChain library itself, rather than a direct issue with the provided code.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue is related to a bug in LangChain that causes an error when creating a custom output class, specifically with the `AIMessage` object. The code attempts to implement a custom BaseModel with a `pydantic` validation, leading to runtime errors. The issue is currently unresolved and requires a fix involving LangChain level changes.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-04-16T23:39:44Z", "body_clean": "What I'm trying to do: create a custom output class while maintaining the original output Can you give an example or say more about what you mean here? If you want to get both the structured response and the raw AIMessage that generated it, you can pass [code] to [code] (see [API ref]( [link]"}, {"author": "CodenameReality", "created_at": "2025-04-17T08:17:09Z", "body_clean": "Thank you for the potential workaround. However, it seems include raw doesn't quite work identical to a situation without with structured output. My test class (for include raw) is [code] Where it's used in the following scenario: [code]"}, {"author": "MichaelLi65535", "created_at": "2025-04-24T08:07:47Z", "body_clean": "Hi @CodenameReality , do you mean the above codes don't work? If so, can you please upgrade your langchain packages? The codes work for me with the below versions: langchain core==0.3.55 langchain openai==0.3.14"}]}, {"ollama_summary": "The issue focuses on a restrictive and limiting filter syntax in LangChain's Chroma library, specifically impacting the ability to query data with metadata filtering. The code type hints are inconsistent with the actual filter syntax, causing MyPy and pylance warnings. The maintainers haven't responded to the problem, and the developer has provided a minimal reproducible example to illustrate the issue. The developer requests a fix to the type hints to maintain compatibility with the existing functionality, while also considering the potential impact of a fix on future development.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-10T00:09:49Z", "body_clean": "Looks to be addressed? If not, let me know and I can reopen"}]}], "business_insights": ["Version mismatches between langchain and deepseek significantly impact the system’s functionality.", "Early error messages reveal a fundamental incompatibility requiring a specific version of langchain.", "The core issue is incorrect interpretation of dictionary arguments as a different type, causing failure.", "A clear, reproducible bug necessitates a fix to the LangChain library’s core logic.", "Addressing the incompatibility will enhance system stability and reliability."], "technical_insights": ["Version incompatibility is a primary driver of the reported bug.", "The deepseek library’s requirement for a specific langchain version is the root cause.", "The function’s dictionary argument interpretation is the critical point of failure.", "The bug is reproducible with minimal code examples, suggesting a library-level issue.", "The bug’s scope is limited to the langchain library, suggesting a potential update issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Version mismatches between `langchain` and `deepseek` significantly impact the system’s functionality.\n2. Early error messages reveal a fundamental incompatibility requiring a specific version of `langchain`.\n3. The core issue is incorrect interpretation of dictionary arguments as a different type, causing failure.\n4. A clear, reproducible bug necessitates a fix to the LangChain library’s core logic.\n5. Addressing the incompatibility will enhance system stability and reliability.\n\nTECHNICAL INSIGHTS:\n1. Version incompatibility is a primary driver of the reported bug.\n2. The `deepseek` library’s requirement for a specific `langchain` version is the root cause.\n3. The function’s dictionary argument interpretation is the critical point of failure.\n4. The bug is reproducible with minimal code examples, suggesting a library-level issue.\n5. The bug’s scope is limited to the `langchain` library, suggesting a potential update issue.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 76, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `llm.ainvoke` tracer is not being correctly traced by `llm.invoke`, despite the two tools using similar tracer implementations.  The issue stems from a difference in the tracer's behavior between the two tools, leading to a specific error message and stack trace.  The developer has provided a minimal, reproducible example to demonstrate the problem and suggest a potential fix.", "final_category": "bug", "comments": [{"author": "hinthornw", "created_at": "2025-04-17T00:04:07Z", "body_clean": "Good spot. The fallback behavior isn't implemented in run coros, which is used when you run an async callback handler in a sync function. As a temporary fix, any of the following should work for your custom tracer: implement that on chat model start as it asks use async code for your nodes/calls so you're not doing async within sync within async"}, {"author": "mdrxy", "created_at": "2025-09-10T00:09:02Z", "body_clean": "Low prio for us, if you or anyone else would like to make an attempt at this let me know and I can assign."}]}, {"ollama_summary": "This issue is preventing the `from langchain_openai` package from being imported, likely due to a conflict with a recent update to LangChain. It’s causing an `ImportError: cannot import name 'convert to openai image block'` traceback, suggesting a problem with the LangChain core library.  The code being used is `from langchain openai import ChatOpenAI`, and the issue seems to stem from a recent update or change within the LangChain library itself.", "final_category": "bug", "comments": [{"author": "sydney-runkle", "created_at": "2025-04-16T13:04:27Z", "body_clean": "Thanks for the report hmm, I'm unable to reproduce this issue with the versions you've listed above :(. Looking into this further."}, {"author": "ccurme", "created_at": "2025-04-16T13:14:36Z", "body_clean": "I suspect you are running a version of [code] that is lower than the minimum specified by the latest [code] ([0.3.52]( [link] Can you try: Restarting the kernel [code] (should force an update of langchain core) [code] And let me know if that does not resolve the issue?"}, {"author": "Akinola92", "created_at": "2025-04-16T19:58:49Z", "body_clean": "pip install upgrade langchain openai & pip install upgrade langchain core Looks to have solved it Thanks @ccurme !"}]}, {"ollama_summary": "The GitHub issue reports a bug in the `base.py` module where the `get_response()` function from the OpenAI assistant returns the generated file ID instead of the text content, hindering the ability to retrieve the file. This issue stems from LangChain's trimming of the response, which is causing the assistant to not include the file ID.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-10T00:08:07Z", "body_clean": "Looks to be addressed? If not, let me know and I can reopen"}]}, {"ollama_summary": "The code is experiencing a `KeyError: 'page content'` error when querying Azure Cosmos DB using the custom `text_key`, `metadata_key`, and `embedding_key` when projecting fields. This issue stems from a potential problem with how the projection mapping is handled during the similarity search process, potentially leading to incorrect key extraction.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports that AWS OSS Doc ID and Filter are not working as expected, consistently returning different doc IDs after adding documents.  The problem appears to be a bug within the LangChain integration, specifically with the filter's logic, and isn't being addressed by updating the library. A reproducible example has been provided to demonstrate the issue.", "final_category": "bug", "comments": []}], "business_insights": ["Focus on consistent errors across issues – potential code refactoring is needed.", "LangChain updates are frequently causing regressions; monitoring is crucial.", "The llm.ainvoke issue highlights the importance of robust tracer implementations.", "The from langchain_openai import issue suggests a potential library upgrade issue.", "The base.py bug points to a module-level problem requiring thorough testing."], "technical_insights": ["LangChain updates are frequently causing regressions; monitoring is crucial.", "The llm.ainvoke issue highlights the importance of robust tracer implementations.", "The from langchain_openai issue suggests a potential library upgrade issue.", "The base.py bug points to a module-level problem requiring thorough testing.", "The keyError in the Azure Cosmos DB projection suggests a mapping issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on consistent errors across issues – potential code refactoring is needed.\n2.  LangChain updates are frequently causing regressions; monitoring is crucial.\n3.  The `llm.ainvoke` issue highlights the importance of robust tracer implementations.\n4.  The `from langchain_openai` import issue suggests a potential library upgrade issue.\n5.  The `base.py` bug points to a module-level problem requiring thorough testing.\n\nTECHNICAL INSIGHTS:\n1.  LangChain updates are frequently causing regressions; monitoring is crucial.\n2.  The `llm.ainvoke` issue highlights the importance of robust tracer implementations.\n3.  The `from langchain_openai` issue suggests a potential library upgrade issue.\n4.  The `base.py` bug points to a module-level problem requiring thorough testing.\n5.  The `keyError` in the Azure Cosmos DB projection suggests a mapping issue.\n", "batch_number": 77, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue involves a bug in the LangChain library that causes the `SystemInfo` query to return URLs that are not properly stripped. The code attempts to extract information about the system, but the `SystemInfo` query is generating incorrect results, leading to the problem.  The issue is currently unresolved and requires a fix, potentially involving a specific LangChain integration package.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue addresses inaccurate perplexity cost tracking in Langsmith, which is currently based on the deprecated langsmith platform documentation. Users are seeing inflated costs due to factors beyond just input and output tokens, requiring a solution to accurately calculate these costs.  Proposed solutions involve either integrating cost calculation directly into the Langsmith platform or allowing users to manually update the cost during LLM calls.", "final_category": "feature", "comments": [{"author": "vaibhav-artisan", "created_at": "2025-04-14T11:36:09Z", "body_clean": "Seems like the [code] from the [code] doesn't even contain the keys needed to accurately calculate cost ( [code] , [code] , [code] and [code] ) so users probably won't be able to override the cost calculation even if langsmith allowed custom cost tracking."}, {"author": "sydney-runkle", "created_at": "2025-04-16T12:58:05Z", "body_clean": "Thanks for the report! Happy to take a look at this. Definitely a bug with [code] . Will leave this issue here for tracking purposes as well."}, {"author": "Nightbr", "created_at": "2025-06-20T13:29:18Z", "body_clean": "Same issue here, would love to have the cost tracking for Perplexity. let us know if you need help on this."}, {"author": "keenborder786", "created_at": "2025-10-12T00:55:01Z", "body_clean": "@sydney runkle please see the above PR, I have added the keys as per the preplexity docs. <img width=\"813\" height=\"571\" alt=\"Image\" src=\" [link] /"}]}, {"ollama_summary": "The ChatAnthropic Streaming Functionality is failing to work as expected, producing the error \"No generation chunks were returned\" when using Claude models.  The issue appears to be a bug within the LangChain integration, not directly related to the code itself. A reproducible example has been provided, allowing for easy testing and debugging.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-13T10:02:53Z", "body_clean": "@HyxiaoGe your base url is a empty string which is throwing this error."}, {"author": "HyxiaoGe", "created_at": "2025-04-13T10:53:35Z", "body_clean": "@keenborder786 Thank you for your response. I should clarify that in my actual implementation, I'm not using an empty string for base url. I replaced the actual URL with an empty string in my example code to avoid exposing sensitive information. In my real code, I'm using a valid base url for Anthropic's API. The issue with streaming persists regardless. To be clear, with the proper base url configured: 1. Non streaming works correctly (model.invoke()) 2. Streaming fails with \"No generation chunks were returned\" (model.stream()) This suggests there's an issue specific to the streaming implementation that isn't related to the base url parameter. Could there be something else causing the streaming functionality to fail? I'd be happy to provide additional information that might help diagnose this issue."}, {"author": "ccurme", "created_at": "2025-04-13T14:48:26Z", "body_clean": "@HyxiaoGe what base URL are you using? I can't reproduce the issue with the default, which is [code] . [code] [code] I believe you will only get this error if no chunks are emitted during the entire stream: [link] To debug you can try against Anthropic's SDK: [link]"}, {"author": "keenborder786", "created_at": "2025-04-13T21:01:24Z", "body_clean": "@HyxiaoGe Same I was not able to reproduce the issue with [code]"}, {"author": "HyxiaoGe", "created_at": "2025-04-14T11:41:54Z", "body_clean": "@ccurme @keenborder786 Okay, it should be my base url. I'll check it myself. Thank you for your reply."}]}, {"ollama_summary": "The issue involves a `vectorContent` error when using the `as_retriever()` method of AzureCosmosDBVectorSearch with LangChain, resulting in no traceback. This problem appears to be related to the configuration of the vector index and retrieval process, specifically the `vectorContent` key within the configuration. The proposed solution is to verify and potentially update the LangChain integration package and ensure the correct `vectorContent` key is defined within the `db` object.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a `TypeError: SemanticSimilarityExampleSelector.from examples() missing required positional argument: 'vectorstore cls'` error in the `vectorstore_cls` module, likely related to the `SemanticSimilarityExampleSelector` class. The code attempts to create a `Chroma` vectorstore instance, but it's missing the required `vectorstore cls` argument. The solution requires providing this argument when initializing the `Chroma` object.", "final_category": "bug", "comments": [{"author": "NaveenVinayakS", "created_at": "2025-04-12T02:03:37Z", "body_clean": "Hi team the issue is closed kindly delete this issue"}]}], "business_insights": ["LangChain integration package needs review for specific errors.", "Vectorstore configuration is crucial for the SemanticSimilarityExampleSelector to function correctly.", "Correct vectorContent key definition is essential for Chroma vectorstore initialization.", "Potential issue with the as_retriever() method’s configuration.", "Code requires careful attention to the vectorContent key within the Chroma object."], "technical_insights": ["LangChain integration package – thoroughly analyze the specific errors.", "Vectorstore configuration – verify vectorContent key for correct Chroma initialization.", "SemanticSimilarityExampleSelector class – ensure the required vectorstore cls argument is present.", "LangChain integration – investigate potential errors in the integration process.", "as_retriever() method – examine configuration for potential issues."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain integration package needs review for specific errors.\n2. Vectorstore configuration is crucial for the `SemanticSimilarityExampleSelector` to function correctly.\n3. Correct `vectorContent` key definition is essential for `Chroma` vectorstore initialization.\n4. Potential issue with the `as_retriever()` method’s configuration.\n5. Code requires careful attention to the `vectorContent` key within the `Chroma` object.\n\nTECHNICAL INSIGHTS:\n1. LangChain integration package – thoroughly analyze the specific errors.\n2. Vectorstore configuration – verify `vectorContent` key for correct `Chroma` initialization.\n3. `SemanticSimilarityExampleSelector` class – ensure the required `vectorstore cls` argument is present.\n4. LangChain integration – investigate potential errors in the integration process.\n5. `as_retriever()` method – examine configuration for potential issues.\n", "batch_number": 78, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\n**Summary:** The issue addresses a bug where a specific code snippet, designed to generate recursive tool schemas, is causing problems with schema generation due to a reference dereference. This is hindering the ability to create these schemas effectively, specifically because the code attempts to leverage OpenAI’s support for recursive schemas. \n\n**Key Details:** The code snippet involves referencing a specific set of refs that are causing an error during schema generation. \n\n**Proposed Solution:** The issue requests a fix to ensure the code correctly handles these references, allowing for proper schema generation.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-13T13:21:37Z", "body_clean": "@ccurme Why don't we just remove the [dereference refs]( [link] since OpenAI fully Supports JSON Schema, it will support def and ref therefore helping us with recursive schema definition."}, {"author": "keenborder786", "created_at": "2025-04-13T20:59:51Z", "body_clean": "@ccurme ?"}, {"author": "ccurme", "created_at": "2025-04-14T16:04:34Z", "body_clean": "We will need to test all providers to see if behavior before / after removing [code] is unchanged."}, {"author": "keenborder786", "created_at": "2025-04-20T22:33:22Z", "body_clean": "@ccurme okay will do it."}, {"author": "ccurme", "created_at": "2025-04-21T22:03:56Z", "body_clean": "[@ccurme]( [link] okay will do it. @keenborder786 not sure it's worth it to get all the required creds (AWS, Google, Azure, etc). OK to leave for maintainers."}, {"author": "keenborder786", "created_at": "2025-04-26T12:40:16Z", "body_clean": "okay closed"}]}, {"ollama_summary": "This issue relates to a bug in the `o3-mini` package, specifically concerning the price calculation for input and output in the agent's completions process. The bug causes incorrect output when the agent adds input parameters to the mode name, requiring a fix to account for different pricing models.  The issue includes a minimal reproducible example and a request for a PR to address the problem.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `create_base_retry_decorator` function in LangChain fails to await a critical task, leading to potential inconsistencies in task execution.  This issue is a bug within the LangChain library, and while updates to the latest version don’t fix it, a self-contained example demonstrates the problem.  The core issue stems from asyncio's garbage collection potentially removing references to the awaited task, causing it to be lost.", "final_category": "bug", "comments": [{"author": "mdrxy", "created_at": "2025-09-10T00:03:39Z", "body_clean": "Looks to be closed?"}, {"author": "cbornet", "created_at": "2025-09-10T07:45:27Z", "body_clean": "I had a look and the issue is still present: [link] Can we reopen the issue ?"}]}, {"ollama_summary": "The issue reports a critical problem with LangChain's streaming output, specifically when using specific OpenAI models (gpt-4o, o3 mini, o1 mini, gpt-4o). The code throws a `TypeError` due to an unexpected `NoneType` value during the `total tokens` calculation, preventing the program from completing successfully.  The problem appears to be related to a bug within the LangChain library itself, and a self-contained example helps to reproduce the error.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-04-11T13:00:32Z", "body_clean": "Hello, I've redacted the API key you included in the body of the issue. I'd consider it compromised and rotate it. My suspicion is that the endpoint you are using does not conform to the specification OpenAI uses to manage usage metadata in a streaming context. This will work with OpenAI's API: [code] I'm also not sure [code] is the correct way to enable streaming usage for the endpoint you are using."}]}, {"ollama_summary": "This issue reports a bug in LangChain where the runtime fails to retrieve custom global variables from the environment defined via “LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT”. The bug manifests as an error message and stack trace, and the fix is achieved by configuring the environment variables during runtime. The provided example code demonstrates the setup and the resulting error, and the issue is currently unresolved with updates to the LangChain version.", "final_category": "feature", "comments": [{"author": "eyurtsev", "created_at": "2025-04-11T17:35:50Z", "body_clean": "Could you file an issue with langflow? Langflow is not associated with langchain in anyway. Langchain's tracing product is langsmith."}]}], "business_insights": ["Addressing core code errors early is crucial for stability and user experience.", "Focusing on specific code snippets reveals potential vulnerabilities.", "Understanding dependencies and potential refactoring is vital.", "Prioritizing bug fixes based on impact and frequency is key.", "Comprehensive testing throughout the development lifecycle is essential."], "technical_insights": ["dereference refs issue highlights potential memory management problems.", "o3-mini pricing model bug necessitates precise pricing model handling.", "create_base_retry_decorator failure suggests asynchronous task management issues.", "LangChain streaming output error related to OpenAI models requires thorough testing.", "TypeError in total tokens calculation indicates library bug."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Addressing core code errors early is crucial for stability and user experience.\n2.  Focusing on specific code snippets reveals potential vulnerabilities.\n3.  Understanding dependencies and potential refactoring is vital.\n4.  Prioritizing bug fixes based on impact and frequency is key.\n5.  Comprehensive testing throughout the development lifecycle is essential.\n\nTECHNICAL INSIGHTS:\n1.  `dereference refs` issue highlights potential memory management problems.\n2.  `o3-mini` pricing model bug necessitates precise pricing model handling.\n3.  `create_base_retry_decorator` failure suggests asynchronous task management issues.\n4.  `LangChain` streaming output error related to OpenAI models requires thorough testing.\n5.  `TypeError` in `total tokens` calculation indicates library bug.\n", "batch_number": 79, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code is throwing an `AttributeError: 'ChatCompletion' object has no attribute 'citations'` error when using the `r1-1776` model in LangChain's Perplexity module. This is likely due to the model not having access to the perplexity search engine or web, resulting in missing citations. The issue is reproducible with a minimal example code snippet and is suspected to be a bug within the LangChain library itself.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain that prevents the use of System Messages, causing an error message from Anthropic. The issue suggests a potential issue with the LangChain integration, and the author has provided a minimal reproducible example to demonstrate the problem.  The author believes this should be caught before sending a request, but the current implementation doesn’t handle it effectively.", "final_category": "bug", "comments": [{"author": "dhruva71", "created_at": "2025-04-10T15:25:21Z", "body_clean": "Verifiied. Happens only with Anthropic, not with OpenAI. @ccurme, this is an error raised by the Anthropic client library, and is an error returned by their API. Should this be caught and handled by [code] as well? If we add a check in [code] , and Anthropic changes their API implementation later, this might create issues down the line. I'll be happy to add the check if you are okay with it."}, {"author": "ccurme", "created_at": "2025-04-13T13:56:17Z", "body_clean": "What is the motivation for accepting a single system message? Issue [link] originated from a tutorial that mistakenly prompted chat models with a single system message. The tutorial has since been corrected. If we want to catch this specific error (i.e., BadRequestError with text [code] ) and clarify that system messages don't count in Anthropic's case, I'm not opposed, but IMO it's low priority: Passing single system messages is not a typical usage pattern; The error message is somewhat clear. Let me know if there are common situations in which you'd end up passing a single system message."}, {"author": "mathislindner", "created_at": "2025-04-14T10:10:44Z", "body_clean": "Let me know if there are common situations in which you'd end up passing a single system message. In my situation i am running a simulation where you'd have the details about \"the game rules\" which would ideally be only coming from the system. But point being: if you want the model to write something first, but give it some instructions on how to behave before, you would run into this. You can definitely just make it come from the human pretending to explain the game rules, but IMO, first reflex would be having this as a SystemMessage and because of the Anthropic \"no message\" error, you can easily lose yourself debugging the wrong things at first."}]}, {"ollama_summary": "The code is experiencing a TypeError because the `HTTPTransport` class expects a different set of keyword arguments than it currently has.  The issue stems from a bug in the LangChain library, specifically related to the `socket_options` argument, which hasn't been resolved through updates. A minimal, reproducible example has been provided to demonstrate the error.", "final_category": "bug", "comments": [{"author": "dhruva71", "created_at": "2025-04-10T07:21:05Z", "body_clean": "I am unable to reproduce this locally, however I notice that your version of [code] , and [code] are very old. [code] added support for [code] in v0.25.0, which is newer than what you have installed. Update that and let's see how it goes from there."}, {"author": "ericrobinson-indeed", "created_at": "2025-04-10T13:32:06Z", "body_clean": "Thanks, I upgraded those packages to their latest versions and am still getting the issue. I think this may be related to the specific environment in which I'm running the jupyter notebook and package issues there"}, {"author": "dhruva71", "created_at": "2025-04-10T14:53:30Z", "body_clean": "Could be. I tried in a notebook as well, works fine. Can you provide the updated package versions?"}, {"author": "ericrobinson-indeed", "created_at": "2025-04-10T14:55:36Z", "body_clean": "[link] 1.0.7 [link] 0.22.0 [link] 0.28.1 Don't worry about continuing to troubleshoot. I'm going to debug in my environment and if that doesn't fix it I'll reach out again. But for now I assume this is an issue on my end and not with langchain itself"}, {"author": "dhruva71", "created_at": "2025-04-10T14:57:07Z", "body_clean": "Very well. Hope you manage to fix it 👍"}, {"author": "ericrobinson-indeed", "created_at": "2025-04-10T15:31:20Z", "body_clean": "I ran this in a different jupyter environment and everything worked correctly. thanks again for helping me"}, {"author": "dhruva71", "created_at": "2025-04-10T15:35:49Z", "body_clean": "Glad it worked out :D"}]}, {"ollama_summary": "This issue reports a `ModuleNotFoundError: No module named 'langchain.server'` error, indicating that the LangChain server library is not installed correctly. The code attempts to import it, but the module isn't found, potentially due to an outdated or misconfigured installation.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-04-09T19:37:30Z", "body_clean": "we need to remove it from the scripts it's an old relic. Got replaced by [code] which is a full tracing platform now ( [link]"}]}, {"ollama_summary": "This issue proposes a solution to standardize and abstract prompt/context caching across different LLM providers (Gemini and Claude). Currently, the syntax differs significantly, hindering a unified approach. LangChain is intended to facilitate this abstraction, and the team is investigating this to improve compatibility and flexibility.", "final_category": "feature", "comments": [{"author": "lkuligin", "created_at": "2025-04-16T12:42:14Z", "body_clean": "@ccurme should we move this to the main repo maybe?"}]}], "business_insights": ["Standardizing prompt/context caching improves LLM compatibility and reduces development time.", "Enhanced LangChain’s abstraction capabilities will streamline LLM integration.", "A unified approach simplifies model deployment and management.", "Improved collaboration and code reuse across providers are crucial.", "Increased developer efficiency leads to faster innovation."], "technical_insights": ["LangChain’s current architecture lacks a robust caching mechanism.", "The HTTPTransport class needs a revised keyword argument set.", "The socket_options argument is a critical bug requiring a fix.", "The ModuleNotFoundError suggests an outdated LangChain installation.", "Standardization is vital for long-term maintainability and scalability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Standardizing prompt/context caching improves LLM compatibility and reduces development time.\n2. Enhanced LangChain’s abstraction capabilities will streamline LLM integration.\n3. A unified approach simplifies model deployment and management.\n4. Improved collaboration and code reuse across providers are crucial.\n5. Increased developer efficiency leads to faster innovation.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s current architecture lacks a robust caching mechanism.\n2. The `HTTPTransport` class needs a revised keyword argument set.\n3. The `socket_options` argument is a critical bug requiring a fix.\n4. The `ModuleNotFoundError` suggests an outdated LangChain installation.\n5. Standardization is vital for long-term maintainability and scalability.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 80, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in LangChain where the response content returns a string instead of a list, hindering its ability to handle different response types effectively. The developer has provided a minimal, reproducible example to demonstrate the problem.  Currently, the bug isn't addressed by updates to the LangChain library, and the developer is actively working on a solution.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-20T22:47:34Z", "body_clean": "That behaviour is intentional since it depends on LLM providers"}]}, {"ollama_summary": "The user is encountering a 400 Bad Request error when attempting to connect a Redshift database to LangChain's Claude LLM using the provided tutorial. The error specifically requires at least one message to be provided, indicating a problem with the request itself.  The user has provided a self-contained, minimal example demonstrating the issue, suggesting a bug within the LangChain package or its integration with Anthropic.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a bug in LangChain where `Chroma` is incorrectly treating it as a `store: Annotated[BaseStore, InjectedStore()]` when it should be a `base: Store` instance.  The problem isn't related to the code itself and is likely a bug within the LangChain integration. A self-contained example demonstrates the error and provides a solution – using a basic `base: Store` instance.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-04-08T12:48:06Z", "body_clean": "Thanks for submitting this. The store in question is not a vector store but a LangGraph [store]( [link] object. See this [how to guide]( [link] for more detail."}, {"author": "khteh", "created_at": "2025-06-03T03:25:17Z", "body_clean": "What does \"LangGraph store object\" mean? Does it have a persistence store, like PostgreSQL?"}, {"author": "ccurme", "created_at": "2025-06-10T20:45:26Z", "body_clean": "What does \"LangGraph store object\" mean? Does it have a persistence store, like PostgreSQL? It is an abstraction for a persistent store. It supports multiple backends (in memory, Postgres, Redis, SQLite, Mongo, for example)."}]}, {"ollama_summary": "The issue reports a bug in LangChain where the system consistently requires an 8192 embedding size, despite attempts to resolve it with updated versions. A self-contained, minimal example demonstrates the problem with Neo4J graph databases, prompting the user to switch to a different integration. The user is seeking a solution to this limitation.", "final_category": "bug", "comments": [{"author": "dhruva71", "created_at": "2025-04-08T07:25:09Z", "body_clean": "Can you provide a minimal code sample to show how you are using it with ChromaDB and how you are initializing your collection? That would help debug the issue. I have tried this minimal code sample, and it works fine locally: [code]"}, {"author": "khteh", "created_at": "2025-04-08T07:43:51Z", "body_clean": "Update my post."}, {"author": "dhruva71", "created_at": "2025-04-08T08:29:26Z", "body_clean": "Can you try with a fresh collection? If the collection has existing embeddings, that can cause this issue. You can refer to this comment: [link]"}, {"author": "khteh", "created_at": "2025-04-08T08:39:08Z", "body_clean": "It is fresh. I restarted the k8s STS and volume"}, {"author": "khteh", "created_at": "2025-04-08T09:07:32Z", "body_clean": "Can you try with a fresh collection? If the collection has existing embeddings, that can cause this issue. You can refer to this comment: [ 5046 (comment)]( [link] The error in this post is NOT [code] but [code]"}, {"author": "khteh", "created_at": "2025-04-08T09:17:46Z", "body_clean": "Sorry, my mistake. I missed the line which delete the k8s [code] in my restart script."}, {"author": "dhruva71", "created_at": "2025-04-08T09:18:55Z", "body_clean": "Glad it is resolved :)"}, {"author": "khteh", "created_at": "2025-04-08T09:21:30Z", "body_clean": "Glad it is resolved :) Thanks."}]}, {"ollama_summary": "The code has been successfully implemented. A class based context manager has been created for [code] that replaces the generator based implementation. The code now includes comprehensive unit tests, improved error handling, and full code quality compliance.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-04-08T22:04:09Z", "body_clean": "what's the context? how did you bump into this?"}, {"author": "Alioth99", "created_at": "2025-04-09T03:24:14Z", "body_clean": "Thanks for your reply! I'm a researcher and currently working on LLM related framework bug. I hope this clarifies the context!"}, {"author": "open-swe[bot]", "created_at": "2025-09-09T23:48:45Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"019930e1 c195 703f 9e5f 34f8403413fe\", \"threadId\": \"98a4b332 17c7 4663 aaf2 87e55d316fad\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Fix set config context to raise RuntimeError instead of AttributeError on context manager reuse Task 1: [code] Task 2: [code] Task 3: [code] Proceeding to implementation... </open swe plan message"}]}], "business_insights": ["Addressing LLM provider behavior is crucial for stable integration.", "Early bug detection mitigates wider impact on users.", "Understanding the root cause of integration issues helps prioritize fixes.", "Focus on consistent bug fixes across libraries is key.", "Comprehensive testing and validation are essential for stability."], "technical_insights": ["LangChain’s integration with Anthropic’s Claude LLM is a primary focus.", "Redshift database connection failure requires a specific message.", "Chroma instance type mismatch is a core integration bug.", "Embedding size limitation is a persistent problem.", "Neo4J integration requires a different approach."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing LLM provider behavior is crucial for stable integration.\n2. Early bug detection mitigates wider impact on users.\n3. Understanding the root cause of integration issues helps prioritize fixes.\n4. Focus on consistent bug fixes across libraries is key.\n5. Comprehensive testing and validation are essential for stability.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s integration with Anthropic’s Claude LLM is a primary focus.\n2. Redshift database connection failure requires a specific message.\n3. `Chroma` instance type mismatch is a core integration bug.\n4. Embedding size limitation is a persistent problem.\n5. Neo4J integration requires a different approach.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 81, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a critical bug in the `Graph.draw_png()` function that silently returns `None` when encountering invalid node types, leading to a crash and difficult debugging. The bug is present in the `langchain core` package, and the code relies on the `Graph` class for visualization, causing a TypeError when attempting to use `.draw png()` with invalid node types.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue addresses a bug in LangChain related to using `chromadb.AsyncHttpClient` with `langchain_chroma`. It details a problem where the Chroma class lacked proper async client support, requiring a significant modification to enable asynchronous data retrieval. The solution involves adding an async method to the Chroma class, updating type hints, and implementing comprehensive unit tests to ensure compatibility with existing synchronous operations. The code has been thoroughly reviewed and formatted to adhere to LangChain's coding standards, including type hints and docstrings.", "final_category": "feature", "comments": [{"author": "open-swe[bot]", "created_at": "2025-09-09T23:47:47Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"019930e0 dfc6 717f 87e5 5d1f6608cb35\", \"threadId\": \"85274b45 c90f 4502 b1ff b4e44b9b1825\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Add async client support to langchain chroma.Chroma vector store to enable usage with chromadb.AsyncHttpClient Task 1: [code] Task 2: [code] Task 3: [code] Task 4: [code] Task 5: [code] Task 6: [code] Proceeding to implementation... </open swe plan message"}]}, {"ollama_summary": "The issue stems from a bug in the `create_react_agent` method, which causes an error when attempting to retrieve event data for the tool. This results in an output of the error event and stack trace, highlighting a missing mechanism to handle the event type.  The code attempts to access a method that doesn't explicitly define the event type, leading to an error.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2025-04-07T14:45:54Z", "body_clean": "Thanks for reporting this is an issue in [code] , fix incoming"}, {"author": "781574155", "created_at": "2025-10-12T03:59:16Z", "body_clean": "When will this bug can be fixed?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nAnthropic’s `on_llm_new_token` function is returning a list of dictionaries instead of strings, causing issues with Langchain callbacks. The issue stems from a bug within LangChain’s integration, not directly related to the developer’s code. A self-contained example is provided to demonstrate the problem and facilitate debugging.", "final_category": "bug", "comments": [{"author": "antonyscerri", "created_at": "2025-09-16T12:05:28Z", "body_clean": "Any progress with this issue? It impacts AWS Bedrock converse clients also. Anywhere that model responses are including a list in the content field and not a simple string can cause this. Even though on llm new token is declared as accepting a string the providers are simply passing msg.content which can be the lists as described above, rather than maybe using msg.text()."}, {"author": "ccurme", "created_at": "2025-10-21T16:41:09Z", "body_clean": "I think it's possible that the type itself is wrong, coercing to string will likely have a substantial impact which needs to be understood and scoped. It would be helpful to hear broader context— if the type were expanded to [str | list[str | dict]]( [link] would this resolve issues on your end?"}]}, {"ollama_summary": "This issue reports a critical `KeyError: 'reasoning_content'` occurring within the LangChain library when using the `stream_mode=\"messages\"` configuration for the `langgraph` component. This likely stems from a bug in the `tongyi.py` file, causing the code to fail to correctly interpret the `reasoning_content` parameter.  The issue is reproducible with a minimal example and is being addressed by the maintainer to resolve the underlying bug.", "final_category": "bug", "comments": [{"author": "wyy-holding", "created_at": "2025-04-15T03:15:29Z", "body_clean": "When will Langchain community be updated?"}]}], "business_insights": ["Focus on Graph.draw_png()’s failure – potential for subtle data corruption impacting visualization.", "chromadb.AsyncHttpClient’s asynchronous client support requires careful testing and optimization.", "create_react_agent’s event type handling needs more robust error management.", "on_llm_new_token’s list to string conversion impacts callbacks – data integrity concerns.", "Tongyi.py’s reasoning_content interpretation bug needs immediate attention."], "technical_insights": ["Graph.draw_png()'s failure suggests a potential data corruption issue affecting graph visualization.", "chromadb.AsyncHttpClient’s asynchronous client support highlights a need for efficient data retrieval.", "create_react_agent’s event type handling suggests a missing mechanism for event data interpretation.", "on_llm_new_token’s list to string conversion affects callback processing and data integrity.", "Tongyi.py’s reasoning_content bug demands thorough testing and bug fixing to ensure accurate event interpretation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on `Graph.draw_png()`’s failure – potential for subtle data corruption impacting visualization.\n2.  `chromadb.AsyncHttpClient`’s asynchronous client support requires careful testing and optimization.\n3.  `create_react_agent`’s event type handling needs more robust error management.\n4.  `on_llm_new_token`’s list to string conversion impacts callbacks – data integrity concerns.\n5.  `Tongyi.py`’s `reasoning_content` interpretation bug needs immediate attention.\n\nTECHNICAL INSIGHTS:\n1.  `Graph.draw_png()`'s failure suggests a potential data corruption issue affecting graph visualization.\n2.  `chromadb.AsyncHttpClient`’s asynchronous client support highlights a need for efficient data retrieval.\n3.  `create_react_agent`’s event type handling suggests a missing mechanism for event data interpretation.\n4.  `on_llm_new_token`’s list to string conversion affects callback processing and data integrity.\n5.  `Tongyi.py`’s `reasoning_content` bug demands thorough testing and bug fixing to ensure accurate event interpretation.\n", "batch_number": 82, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a \"vector.dimensions\" error in the `Neo4jVector.from_existing_graph` function, specifically requiring a dimension size between 1 and 4096, which is not currently supported by the library.  The problem appears to be a bug within the LangChain integration, and the developer has provided a self-contained example demonstrating the error.  Currently, the solution is not being addressed through updates to the LangChain library.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-06T08:25:19Z", "body_clean": "@khteh most likely your Llama 3.3 is not running properly. Can you please do the following: [code]"}, {"author": "khteh", "created_at": "2025-04-06T08:56:16Z", "body_clean": "I keep getting [code] . I run ollama in a container in local k8s cluster. This is what I have configured: [code]"}, {"author": "khteh", "created_at": "2025-04-08T10:25:09Z", "body_clean": "Switch to [code]"}]}, {"ollama_summary": "The UsageMetadataCallbackHandler is reporting incorrect token counts, returning character counts instead of tokens.  The issue stems from a bug in LangChain that doesn't appear to be fixed by updates to the latest version.  The code example demonstrates the problem – the callback handler incorrectly counts characters.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-04-04T20:29:53Z", "body_clean": "The callback handler is not returning the number of characters, it is returning token counts as reported from the provider. You can test it yourself without LangChain: [code] [code] The first method, [code] , is using tiktoken to count tokens locally. It's true that [code] is a single token. Azure OpenAI is telling you that there is an additional token cost to the input (e.g., a fixed overhead). This is a good distinction to clarify, thank you for submitting this. I will update the docs."}, {"author": "ccurme", "created_at": "2025-04-04T20:44:51Z", "body_clean": "More precisely, there are token costs associated with [message objects]( [link] in modern LLMs. [code] will count the tokens in a string. [llm.get num tokens from messages]( [link] will account for overhead from message objects (e.g., specification of roles, tools, etc.). You can recover the 8 token input using this method as well: [code]"}, {"author": "DJ2695", "created_at": "2025-04-04T21:32:40Z", "body_clean": "@ccurme my bad, I didn't notice this change in token counts, thank you for clarifying!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe code exhibits a memory leak within the `RunnableSequence` when a member of an object attempts to invoke another Runnable. This leak stems from an object reference lingering in memory after the initial Runnable is completed, causing garbage collection to fail.  The issue is impacting the app's performance and stability, and the proposed solution involves creating separate Runnable instances to mitigate the problem.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-04-04T20:42:18Z", "body_clean": "cc @sydney runkle / @ccurme"}, {"author": "maxfriedrich", "created_at": "2025-04-05T15:41:02Z", "body_clean": "I dug around a bit more, the cause for this is the [code] on [code] [link] [link] [code] holds on to the [code] argument forever like here: [link] If I comment out that decorator, my demo script works as expected. I would still consider this a bug, the cache should not strongly reference objects and keep them alive forever (or until 256 are created), what do you think?"}]}, {"ollama_summary": "The issue reports an `AttributeError: 'str' object has no attribute 'get'` error within the `_convert_messages_to_ollama_messages` function of the `langchain_ollama/chat_models.py` file, specifically on line 535. This suggests a problem with how the code is interacting with the Ollama model, likely due to an unexpected data type.  The developer is attempting to use a specific Ollama model and is encountering this error while attempting to process messages.", "final_category": "bug", "comments": [{"author": "khteh", "created_at": "2025-04-04T11:44:02Z", "body_clean": "Anyone looking into this? This is an impediment for me."}, {"author": "eyurtsev", "created_at": "2025-04-04T20:44:40Z", "body_clean": "Could you include a minimal reproducible example? (the example code that you posted is not self contained)"}, {"author": "khteh", "created_at": "2025-04-06T08:44:37Z", "body_clean": "I found the culprit. I previously used [code] with the following message format in [code] : [code] The error reported in this issue happens when I switch to [code] model. This seems to work: [code] The [code] expected by [code] : [code] Why is there such a discrepenacy from the same [code] . [code] ? Why is this not caught when I run the application? Is this an integration issue of your API with the different models?"}]}, {"ollama_summary": "This issue relates to a critical bug in the LangChain `qdrant` interface that causes the `QdrantVectorStore` to ignore shard key selectors, leading to incorrect data distribution and potential errors in complex deployments with multiple tenants. The code relies on `langchain qdrant/qdrant`’s internal operations, and a lack of proper shard key handling is causing the issue.  The fix involves updating the `QdrantVectorStore` to support optional shard key selection, which will resolve the problem.", "final_category": "bug", "comments": [{"author": "simpliatanu", "created_at": "2025-04-04T00:56:28Z", "body_clean": "figured out the usage should be , vector store.add documents([document 1], shard key selector=\"Movo\") vector store.add documents([document 2], shard key selector=\"Bravo\") closing the issue, may be docs should be updated."}]}], "business_insights": ["Focus on the Neo4jVector.from_existing_graph error – it’s a fundamental bug impacting the core functionality.", "LangChain integration stability is crucial; address the bug promptly.", "The RunnableSequence memory leak suggests a potential performance bottleneck.", "The AttributeError highlights a data type mismatch during message processing.", "The Qdrant shard key issue necessitates a specific fix for data distribution."], "technical_insights": ["LangChain library bug: Address the Neo4jVector.from_existing_graph error.", "RunnableSequence memory leak: Investigate and fix the underlying bug affecting the RunnableSequence.", "Callback handler token counting: Verify the callback handler’s token count logic.", "Qdrant shard key handling: Update the QdrantVectorStore to support shard key selection.", "AttributeError in _convert_messages_to_ollama_messages: Fix the data type mismatch issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on the `Neo4jVector.from_existing_graph` error – it’s a fundamental bug impacting the core functionality.\n2.  LangChain integration stability is crucial; address the bug promptly.\n3.  The `RunnableSequence` memory leak suggests a potential performance bottleneck.\n4.  The `AttributeError` highlights a data type mismatch during message processing.\n5.  The `Qdrant` shard key issue necessitates a specific fix for data distribution.\n\nTECHNICAL INSIGHTS:\n1.  LangChain library bug: Address the `Neo4jVector.from_existing_graph` error.\n2.  `RunnableSequence` memory leak: Investigate and fix the underlying bug affecting the `RunnableSequence`.\n3.  Callback handler token counting: Verify the callback handler’s token count logic.\n4.  `Qdrant` shard key handling: Update the `QdrantVectorStore` to support shard key selection.\n5.  `AttributeError` in `_convert_messages_to_ollama_messages`: Fix the data type mismatch issue.\n", "batch_number": 83, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue involves a `ValueError` occurring when attempting to remove a handler from the `BaseCallbackManager` in LangChain. The problem is likely related to the `langchain.core.callbacks.base.remove()` function, potentially due to a mismatch between the handler's added parameters and the `remove()` method's expected structure.  The code is attempting to remove a handler that was only added through the constructor, causing the error.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue involves a bug in LangChain's `gitbookloader` component that causes it to fail to process nested sitemap files, resulting in zero documents returned. The code doesn't correctly differentiate between index files and regular content pages, leading to an incorrect parsing process.  The issue is a continuation of a previous fix, and the root cause is a lack of recursive processing for nested sitemap files.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-04-03T00:08:08Z", "body_clean": "I got this one"}, {"author": "keenborder786", "created_at": "2025-04-03T01:08:01Z", "body_clean": "@andrasfe do this: [code]"}, {"author": "andrasfe", "created_at": "2025-04-04T21:24:00Z", "body_clean": "[@andrasfe]( [link] do this: loader = GitbookLoader( web page=\" [link] load all paths=True, sitemap url=\" [link] content selector=\"url\" ) @keenborder786 , perhaps I am missing something but that does not work."}, {"author": "keenborder786", "created_at": "2025-04-20T22:40:34Z", "body_clean": "@andrasfe is it working now?"}, {"author": "andrasfe", "created_at": "2025-04-21T04:05:14Z", "body_clean": "[@andrasfe]( [link] is it working now? It was not but a fix is pending merge approval, @keenborder786 ."}]}, {"ollama_summary": "The issue highlights a bug where the feature table for vectorstore integrations incorrectly sets \"IDs in add Documents\" to False, potentially leading to incorrect document ID handling. The bug is primarily affecting ChromaDB, where uploading documents with IDs results in the document ID being used as the vectorstore ID.  The issue requests a review and update of the feature table to ensure accuracy.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-07-02T16:01:36Z", "body_clean": "Hi, @hesreallyhim. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue highlights an inconsistency in the LangChain documentation regarding the \"IDs in add Documents\" feature for vectorstore integrations. The documentation incorrectly states that this feature is false for several integrations, while implementation and other sources suggest it should be true. You provided examples and references to support the claim that the feature table needs correction. There have been no further comments or updates on this issue. Next Steps Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue is preventing the LangChain `docling/loader` from loading `.docx` files. The error message indicates a `ConversionError` due to an unsupported file format within the `.docx` document.  The code attempts to use `docling.loader.convert` to process the file, but it's failing because the file contains a `f039ddd7f6fc6150729aa8d94d526846.docx` format.  The issue appears to be a compatibility problem with the `docling/loader` library and the specific `.docx` format.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-04-02T18:48:52Z", "body_clean": "@joaoassalim dot file the issue here: [link]"}]}, {"ollama_summary": "The issue is that the `AgentExecutor` is repeatedly calling a tool with the exact same input, causing a loop.  The proposed solution – changing the code to `[code]` – resolves this by eliminating the repeated input, effectively stopping the loop.  The full details, including the error message, stack trace, minimal reproducible code, and dependencies, are provided in a separate file `[del.txt]`.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-04-03T01:11:19Z", "body_clean": "Functions are deprecated in favor of Tools, therefore I will encourage to use that over functions. See this: [link]"}]}], "business_insights": ["Consistent error patterns across different issues suggest a fundamental issue with the ValueError handling logic in the BaseCallbackManager.", "Nested sitemap file processing reveals a need for more robust recursive parsing to ensure all documents are accounted for, especially within the gitbookloader component.", "Feature table inconsistencies impacting document ID handling highlight a critical data integrity concern, requiring immediate review and correction.", "ChromaDB’s incorrect ID assignment demonstrates a potential bug in the integration logic between document IDs and vectorstore IDs, necessitating a fix.", "The AgentExecutor loop issue points to a potential problem with the agent's input, requiring a solution focused on input validation."], "technical_insights": ["ValueError in BaseCallbackManager likely stems from incompatible parameter structure within the remove() function.", "gitbookloader’s nested sitemap file processing is a continuation of a previous fix, indicating a need for comprehensive recursive handling.", "Feature table inconsistency in Vectorstore Integrations necessitates a review and update of the feature table to guarantee accurate document ID management.", "docling/loader’s failure with .docx files highlights compatibility issues with the library and specific file format.", "AgentExecutor loop requires a code change to eliminate repeated input, demonstrating a need for robust input validation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent error patterns across different issues suggest a fundamental issue with the `ValueError` handling logic in the `BaseCallbackManager`.\n2. Nested sitemap file processing reveals a need for more robust recursive parsing to ensure all documents are accounted for, especially within the `gitbookloader` component.\n3. Feature table inconsistencies impacting document ID handling highlight a critical data integrity concern, requiring immediate review and correction.\n4. ChromaDB’s incorrect ID assignment demonstrates a potential bug in the integration logic between document IDs and vectorstore IDs, necessitating a fix.\n5. The `AgentExecutor` loop issue points to a potential problem with the agent's input, requiring a solution focused on input validation.\n\nTECHNICAL INSIGHTS:\n1. `ValueError` in `BaseCallbackManager` likely stems from incompatible parameter structure within the `remove()` function.\n2. `gitbookloader`’s nested sitemap file processing is a continuation of a previous fix, indicating a need for comprehensive recursive handling.\n3. Feature table inconsistency in `Vectorstore Integrations` necessitates a review and update of the feature table to guarantee accurate document ID management.\n4. `docling/loader`’s failure with `.docx` files highlights compatibility issues with the library and specific file format.\n5. `AgentExecutor` loop requires a code change to eliminate repeated input, demonstrating a need for robust input validation.\n", "batch_number": 84, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The LangGraph streaming example is failing with an error in the `ConsoleCallbackHandler.on_llm_new_token` callback, triggered by a tracer exception. This issue appears to be related to the LLM node's progress being displayed in real-time, potentially causing a confusing UX.  The code involves a loop of error messages and stack traces, suggesting a bug within the LangChain integration.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue stems from a bug in LangChain that prevents the `HumanMessage` class from rendering variables within the `messages` template format. The code attempts to create a prompt template, but the variable formatting fails, leading to the observed error.  The issue is currently unresolved by a recent update to the LangChain library, and the code relies on the manual construction of the prompt, suggesting a potential issue with the template engine itself.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-04-04T19:59:23Z", "body_clean": "This is not a bug! Bad design in terms of variable naming / intuition, but overall correct design in terms of desired behavior. We have 2 types of messages: [code] Not a template [code] a template when you use 'human' with from messages it uses template by default for convenience since that's the common use case However, we want to support cases where there's no need to interpolate and the message should just be the literal [code] or [code] ."}, {"author": "adamhadani", "created_at": "2025-04-21T21:18:28Z", "body_clean": "Got stung hard by this myself now. I would argue that its worth making this behavior much louder, currently you get extremely hard to debug behavior unless you use LangFuse / LangSmith and even then you need to dig deep and can easily miss the fact. @eyurtsev can we perhaps raise a Warning when a [code] contains a string matching [code] or anything of the like? seems like a decent stopgap solution until naming / usage of this framework stabilizes. Also I would mention this in a big fat red warning box on the documentation pages. The fact that [code] works but [code] doesn't is very misleading. cheers!"}]}, {"ollama_summary": "The issue involves a critical bug in the LangChain `ConsoleCallbackHandler` that causes an error when attempting to retrieve the LLM node of a graph invoking streaming progress. This results in a `TracerException` indicating a missing run ID.  The problem appears to be a bug within the LangChain library itself, and attempts to resolve it by updating to the latest stable version have failed.", "final_category": "bug", "comments": [{"author": "qmz", "created_at": "2025-04-01T12:24:47Z", "body_clean": "The astream events function also fails with an AssertionError code [code] trace 7317828cd not found in run map.') Error in ConsoleCallbackHandler.on llm new token callback: TracerException('No indexed run ID 13a8c64a 3d02 497f ba77 2ad7317828cd.') Error in AstreamEventsCallbackHandler.on llm new token callback: AssertionError('Run ID 13a8c64a 3d02 497f ba77 2ad7317828cd not found in run map.') Error in ConsoleCallbackHandler.on llm new token callback: TracerException('No indexed run ID 13a8c64a 3d02 497f ba77 2ad7317828cd.') Error in AstreamEventsCallbackHandler.on llm new token callback: AssertionError('Run ID 13a8c64a 3d02 497f ba77 2ad7317828cd not found in run map.') Error in ConsoleCallbackHandler.on llm new token callback: TracerException('No indexed run ID 13a8c64a 3d02 497f ba77 2ad7317828cd.')"}, {"author": "qmz", "created_at": "2025-04-02T01:11:07Z", "body_clean": "I submitted the issue in the wrong place and have now reported it again in LangGraph. [link]"}]}, {"ollama_summary": "The `RecursiveCharacterTextSplitter` is throwing a `TypeError` because it's being used with an integer instead of a string, causing it to fail to access a character within a text document.  The issue appears to be a bug within LangChain’s integration, as attempts to update to the latest version haven’t fixed it.  Currently, the code example demonstrates the error when attempting to split a document with an integer value.", "final_category": "bug", "comments": [{"author": "ArmaanjeetSandhu", "created_at": "2025-04-03T21:43:55Z", "body_clean": "Use named parameters instead of positional ones: [code] The [code] constructor expects specific parameter types, and when you use positional arguments, the parameters get assigned in the wrong order: First parameter ( [code] ) expects a list, but you're passing an integer ( [code] ) This causes the error when the code tries to access [code] on what's actually an integer"}]}, {"ollama_summary": "The issue involves a segmentation fault (core dumped) while using the Chroma library from LangChain. The code attempts to embed documents using HuggingFaceInferenceAPIEmbeddings, and a search query reveals a similar issue reported in another resource.  The problem persists even after updating to the latest stable LangChain version and specific integration package.", "final_category": "bug", "comments": [{"author": "DvGils", "created_at": "2025-04-14T20:07:06Z", "body_clean": "I had a very similar issue using DuckDB. It was fixed when i installed pandas. Might work for you as well. See 29933 (and related PRs 30435 & 30445)"}]}], "business_insights": ["Consistent bug patterns across multiple issues highlight a fundamental issue with the LangChain library’s integration with LLM nodes.", "The ConsoleCallbackHandler bug is a significant symptom, indicating a potential issue with real-time UX updates impacting the LLM node’s progress.", "The RecursiveCharacterTextSplitter error suggests a problem with the library’s internal data handling or integration logic.", "The TracerException in the ConsoleCallbackHandler points to a bug in the LangChain library’s logging mechanism.", "The Chroma library segmentation fault reinforces the need for thorough testing and validation of library integrations."], "technical_insights": ["LangChain’s integration with LLM nodes is prone to concurrency issues, requiring robust error handling and synchronization mechanisms.", "The RecursiveCharacterTextSplitter’s data handling could be optimized for handling potentially large text documents.", "The ConsoleCallbackHandler’s logging mechanism needs improved error reporting and stack trace analysis.", "The TracerException implementation needs a more targeted error handling approach.", "The RecursiveCharacterTextSplitter’s integration requires careful consideration of the data structure and potential inconsistencies."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Consistent bug patterns across multiple issues highlight a fundamental issue with the LangChain library’s integration with LLM nodes.\n2.  The `ConsoleCallbackHandler` bug is a significant symptom, indicating a potential issue with real-time UX updates impacting the LLM node’s progress.\n3.  The `RecursiveCharacterTextSplitter` error suggests a problem with the library’s internal data handling or integration logic.\n4.  The `TracerException` in the `ConsoleCallbackHandler` points to a bug in the LangChain library’s logging mechanism.\n5.  The Chroma library segmentation fault reinforces the need for thorough testing and validation of library integrations.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s integration with LLM nodes is prone to concurrency issues, requiring robust error handling and synchronization mechanisms.\n2.  The `RecursiveCharacterTextSplitter`’s data handling could be optimized for handling potentially large text documents.\n3.  The `ConsoleCallbackHandler`’s logging mechanism needs improved error reporting and stack trace analysis.\n4.  The `TracerException` implementation needs a more targeted error handling approach.\n5.  The `RecursiveCharacterTextSplitter`’s integration requires careful consideration of the data structure and potential inconsistencies.\n", "batch_number": 85, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "```json\n{\n  \"summary\": \"The code snippet is a list of dependencies and installed packages for the 'langsmith' Python library. It includes several packages, including: \\n\\n- langsmith (version 0.3.21)\\n- langchain (version 0.3.21)\\n- langsmith-deepseek (version 0.1.3)\\n- langsmith- Fireworks (version 0.1.3)\\n- langsmith-Goo (version 0.3.20)\\n- langsmith-Huggingface (version 0.3.19)\\n- langsmith-AzureAI (version 0.3.11)\\n- langsmith-Cohere (version 0.3.20)\\n- langsmith-Core (version 0.3.45)\\n- langsmith-Fireworks (version 0.1.3)\\n- langsmith-Goo (version 0.3.20)\\n- langsmith-Huggingface (version 0.3.19)\\n- langsmith-MistralAI (version 0.3.11)\\n- langsmith-Ollama (version 0.3.11)\\n- langsmith-OpenAI (version 0.3.11)\\n- langsmith-OpenAI (version 0.3.9)\\n- langsmith-Langserve (version 0.3.45)\\n- langsmith-numpy (version 1.26.2)\\n- openai (version 2.0.0)\\n- opentelemetry (version 1.33)\\n- opentelemetry exporter (version 0.33)\\n- opentelemetry sdk (version 2.4.0)\\n- pydantic (version 3.0.0)\\n- langsmith-pyo3 (version 0.3.21)\\n- langsmith-langsmith (version 0.3.0)\\n- langsmith-langsmith-deepseek (version 0.1.3)\\n- langsmith-langsmith-Fireworks (version 0.1.3)\\n- langsmith-langsmith-Goo (version 0.3.20)\\n- lang", "final_category": "bug", "comments": [{"author": "yigit353", "created_at": "2025-04-01T21:58:36Z", "body_clean": "I developed it as an integration package [code] . You can install it like that: [code] For usage: [link]"}]}, {"ollama_summary": "The core issue involves inconsistent behavior within the `BaseTool` subclass, specifically when returning a list from `_run`/`_arun`. This results in an ambiguous scenario where the list is considered a valid message content block, leading to potential errors when using the ToolMessage.  The code needs to be updated to explicitly handle the empty list case, potentially by allowing tools to define their own message content types or implementing a specific return type for empty lists.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-30T16:01:34Z", "body_clean": "Hi, @menezesandre. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a problem in the [code] class where [code] or [code] methods return an empty list. This return value is misinterpreted as an empty message instead of a serialized JSON string. The issue can cause errors, particularly with tools like [code] . You are seeking guidance on resolving this inconsistency. There have been no comments or activity on the issue yet. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "menezesandre", "created_at": "2025-06-30T16:57:32Z", "body_clean": "It is still relevant. Updated the issue message with the latest system info (the result of the example code is the same) and code links to the latest commit."}, {"author": "dosubot[bot]", "created_at": "2025-06-30T16:59:50Z", "body_clean": "@eyurtsev, the user @menezesandre has confirmed that the issue with the [code] class is still relevant and has provided updates with the latest system info and code links. Could you please assist them with this issue?"}]}, {"ollama_summary": "This issue relates to a critical bug in LangChain's `query_type` component, which is preventing it from correctly passing search kwargs to the `langchain chroma` library. This bug is causing errors and impacting the functionality of the hybrid search system.  The issue is currently being addressed by a stable version update, but the code requires a specific integration package to be updated.", "final_category": "bug", "comments": [{"author": "AmirBraham", "created_at": "2025-05-26T19:58:53Z", "body_clean": "Any update on this ?"}]}, {"ollama_summary": "This issue focuses on a critical bug in LangChain's OpenAIEmbeddings library that prevents the correct use of `tiktoken` within the embedding process.  The code attempts to leverage `tiktoken` for tokenization, but the integration is failing, leading to inconsistent responses and a broken embedding server.  The solution requires a change to the `OpenAIEmbeddings` to explicitly enable `tiktoken` and is likely a bug in the library itself.", "final_category": "bug", "comments": [{"author": "iammannu", "created_at": "2025-04-04T20:50:27Z", "body_clean": "from langchain core.embeddings import Embeddings import requests class MyOpenAICompatibleEmbeddings(Embeddings): def init (self, base url: str, model: str, api key: str = \"empty\"): self.base url = base url self.model = model self.api key = api key def embed query(self, text: str): response = requests.post( f\"{self.base url}/embeddings\", headers={\"Authorization\": f\"Bearer {self.api key}\"}, json={\"model\": self.model, \"input\": text} ) return response.json()[\"data\"][0][\"embedding\"] def embed documents(self, texts: list[str]): response = requests.post( f\"{self.base url}/embeddings\", headers={\"Authorization\": f\"Bearer {self.api key}\"}, json={\"model\": self.model, \"input\": texts} ) return [r[\"embedding\"] for r in response.json()[\"data\"]] // Use this class in LangChain pipelines instead of OpenAIEmbeddings"}, {"author": "xuzexin-hz", "created_at": "2025-04-08T10:36:16Z", "body_clean": "It turns out that the request method is different The actual request parameters of OpenAIEmbeddings are as follows: {'input': [[57668, 53901]], 'model': 'maidalun1020/bce embedding base v1', 'encoding format': 'base64'} And the request parameters of client.embeddings.create are as follows: {'input': '你好', 'model': 'maidalun1020/bce embedding base v1', 'encoding format': 'base64'} OpenAIEmbeddings uses a tokenizer"}, {"author": "Itsanewday", "created_at": "2025-04-17T02:37:13Z", "body_clean": "from langchain core.embeddings import Embeddings import requests class MyOpenAICompatibleEmbeddings(Embeddings): def init (self, base url: str, model: str, api key: str = \"empty\"): self.base url = base url self.model = model self.api key = api key [code] // Use this class in LangChain pipelines instead of OpenAIEmbeddings Thank you very much, it help me a lot. BTW, init part should be [code]"}, {"author": "linogaliana", "created_at": "2025-04-23T11:43:08Z", "body_clean": "I encountered the same weird unexpected and hard to understand issue with a vllm self hosted model. [code] yielding [code] and logs are normal: [code] tokenized input looks normal if we look at the [model card]( [link] : [code] is beggining of string and [code] is end of string. If we try to do the same with default [code] embeddings [code] this gives a totally different result: [code] and if we have a look to the vllm log, we have weird text submitted to the model [code] ', params: PoolingParams(additional metadata=None), prompt token ids: [15339, 1917], lora request: None, prompt adapter request: None. INFO 04 23 04:30:17 [logger.py:39] Received request embd a9b00d6bf7e23205f7f9209251b4c519 1: prompt: ' jailed� pay', params: PoolingParams(additional metadata=None), prompt token ids: [95711, 374, 2523], lora request: None, prompt adapter request: None. [code] emb model = OpenAIEmbeddings( model=\"BAAI/bge multilingual gemma2\", openai api base=openai api base, openai api key=openai api key, tiktoken enabled=False ) emb model.embed documents(documents) which gives the expected results. Does it make sense to enable tiktoken by default rather than Autotokenizer from HF ? Any way, I think a small point about the tokenizer is worth to be mentioned in [Langchain documentation]( [link] since it has dramatic effects on the output of the embedding."}, {"author": "Huyueeer", "created_at": "2025-05-07T01:59:56Z", "body_clean": "@linogaliana I had the same problem"}]}, {"ollama_summary": "This GitHub issue addresses a gap in documentation regarding retrieving logprobs for raw LLM models. The current documentation focuses on chat model examples, but lacks a practical guide for raw LLM retrieval. The key request is to provide an example demonstrating how to retrieve logprobs for these models, or to clearly state the limitation if it’s not supported.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-30T16:01:34Z", "body_clean": "Hi, @ftelnov. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised a concern about the lack of documentation on retrieving log probabilities for raw LLMs using [code] from [code] . You are seeking an example or clarification on whether this task is feasible. If not feasible, you requested a link to a related issue for more information. There have been no comments or developments on this issue yet. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Thorough dependency analysis reveals potential version conflicts, requiring careful management.", "Understanding the _run/_arun logic points to a potential error in message content handling.", "The BaseTool issue highlights the importance of explicit list handling for robust tool functionality.", "The query_type bug impacts hybrid search; a stable version update is required.", "OpenAIEmbeddings integration failure necessitates a specific package update."], "technical_insights": ["Dependency management is crucial; conflicting versions can cause instability.", "The _run/_arun logic suggests a potential issue with message content generation.", "BaseTool’s explicit list handling is vital for error prevention.", "query_type bug impacts hybrid search, requiring a specific package fix.", "OpenAIEmbeddings integration failure impacts embedding server."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Thorough dependency analysis reveals potential version conflicts, requiring careful management.\n2. Understanding the `_run`/`_arun` logic points to a potential error in message content handling.\n3. The `BaseTool` issue highlights the importance of explicit list handling for robust tool functionality.\n4. The `query_type` bug impacts hybrid search; a stable version update is required.\n5. OpenAIEmbeddings integration failure necessitates a specific package update.\nTECHNICAL INSIGHTS:\n1. Dependency management is crucial; conflicting versions can cause instability.\n2. The `_run`/`_arun` logic suggests a potential issue with message content generation.\n3. `BaseTool`’s explicit list handling is vital for error prevention.\n4. `query_type` bug impacts hybrid search, requiring a specific package fix.\n5. OpenAIEmbeddings integration failure impacts embedding server.\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 86, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a bug in LangChain's `AIMessageChunk` class where the `init_tool_calls` function fails when the `args` argument is `None`. This occurs because the function doesn't explicitly check for this condition and throws an error when `args` is missing. The bug is present in the local deployment of the qwq 32B model using vllm, specifically within the `langgraph supervisor example` when generating content.", "final_category": "bug", "comments": [{"author": "npuichigo", "created_at": "2025-04-13T06:47:58Z", "body_clean": "@run zhi how did you fix that?"}, {"author": "itc180016", "created_at": "2025-06-12T09:02:15Z", "body_clean": "@run zhi I encountered a similar issue when using the Qwen3 32B model for tool calls with no args function. How did you resolve it?"}, {"author": "run-zhi", "created_at": "2025-06-13T00:42:18Z", "body_clean": "[@run zhi]( [link] how did you fix that? just upgrade langgraph version"}, {"author": "leonliao", "created_at": "2025-07-26T02:23:35Z", "body_clean": "[@run zhi]( [link] how did you fix that? just upgrade langgraph version Which version should be upgraded to fix this issue? Thanks"}]}, {"ollama_summary": "The LangChain Chroma library is experiencing issues with its dependency on NumPy, specifically requiring a version `>=1.26.2,<2.0.0`. This conflict prevents other packages from successfully installing and running, impacting projects that rely on both LangChain and NumPy.  The issue is likely a bug in the latest LangChain version and isn’t being addressed through updates to the stable release.  A potential solution would be to relax the upper bound on NumPy version to 2.0.2 in a future release.", "final_category": "bug", "comments": [{"author": "ahenawy", "created_at": "2025-04-01T07:19:37Z", "body_clean": "Could langchain chroma be updated in a future release to support numpy =2.0.2, given the current restriction to <2.0.0 causes conflicts with packages needing newer numpy versions?"}, {"author": "sydney-runkle", "created_at": "2025-04-07T19:12:06Z", "body_clean": "Hi @ahenawy, Thanks for the report yes, I'm working on a fix in [link] :)"}, {"author": "sydney-runkle", "created_at": "2025-04-07T19:14:24Z", "body_clean": "Ah actually, going to close this as a dupe of [link] but we'll still fix via the above PR :)"}]}, {"ollama_summary": "This GitHub issue focuses on a confusing and inconsistent issue with API documentation links. The problem stems from a lack of a consistent and logical linking between the API reference pages, code links, and source code pages, leading to unexpected behavior where links to other packages are frequently referenced. The issue is currently being addressed by adding more detailed documentation and investigating potential configuration issues.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-29T16:01:39Z", "body_clean": "Hi, @hesreallyhim. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported inconsistencies in the documentation links within the LangChain API reference. The [code] and [code] links for certain methods are not functioning correctly. The [code] link sometimes redirects to unrelated pages. You noted inconsistency in the availability of source code links for different methods. There have been no comments or developments on this issue yet. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "mdrxy", "created_at": "2025-09-09T18:19:32Z", "body_clean": "This is a valid concern not something we'll tackle in the current iteration of the API ref, but should be handled when we port to our new site."}]}, {"ollama_summary": "The issue reports a problem where the `GraphCypherQAChain.from_llm` function expects an instance of `GraphStore` as input, but it’s not working as expected.  The developer has exhausted standard troubleshooting steps and believes it’s a bug within LangChain itself, specifically related to the integration with Neo4J GraphStore.  Currently, the code throws an error when attempting to use Neo4J GraphStore with the specified input.", "final_category": "bug", "comments": [{"author": "khteh", "created_at": "2025-04-02T05:45:47Z", "body_clean": "Anybody looking into this? This is an impediment for me. Thanks."}]}, {"ollama_summary": "The issue reports that Azure AI models are failing to infer in the `init_chat_model` function, despite proper API key and endpoint setup.  Initial troubleshooting efforts, including searching documentation and using GitHub search, haven't identified a solution. The problem appears to be a bug within the LangChain integration, and the suggested fix (updating to the latest version) hasn’t resolved it.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-03-28T18:15:10Z", "body_clean": "Could you confirm if this works for you? [code] or [code]"}, {"author": "Koolsiddude", "created_at": "2025-03-28T18:30:35Z", "body_clean": "I did use it, but when I use it with the init chat model, I am still getting the same error, also I had been checking out the open deep research repo and was getting this bug I then replaced it with the standard open ai inference, and it works alright, its the azure ai inference that is blocking this. ![Image]( [link]"}, {"author": "ccurme", "created_at": "2025-03-30T18:53:30Z", "body_clean": "I believe this was fixed in [link] but it hasn't been released yet. I will release tomorrow morning."}, {"author": "ccurme", "created_at": "2025-03-31T13:19:29Z", "body_clean": "Released, let me know if issues remain."}]}], "business_insights": ["LangChain’s AIMessageChunk bug impacts local deployment, requiring explicit checks.", "NumPy dependency conflict necessitates a future upgrade to >=1.26.2,<2.0.0", "LangChain’s version restriction hinders package compatibility with NumPy.", "Future release of LangChain to support NumPy =2.0.2 is crucial.", "Addressing the bug in LangChain’s latest version is a priority."], "technical_insights": ["LangChain’s AIMessageChunk has a bug related to init_tool_calls failing with missing args.", "LangChain Chroma’s NumPy dependency conflict requires a future upgrade to >=1.26.2,<2.0.0.", "LangChain’s version restriction limits the compatibility of LangChain with NumPy.", "Future release of LangChain should include support for NumPy version 2.0.2.", "The bug in LangChain’s latest version impacts the integration with Neo4J GraphStore."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s `AIMessageChunk` bug impacts local deployment, requiring explicit checks.\n2.  NumPy dependency conflict necessitates a future upgrade to `>=1.26.2,<2.0.0`\n3.  LangChain’s version restriction hinders package compatibility with NumPy.\n4.  Future release of LangChain to support NumPy =2.0.2 is crucial.\n5.  Addressing the bug in LangChain’s latest version is a priority.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s `AIMessageChunk` has a bug related to `init_tool_calls` failing with missing `args`.\n2.  LangChain Chroma’s NumPy dependency conflict requires a future upgrade to `>=1.26.2,<2.0.0`.\n3.  LangChain’s version restriction limits the compatibility of LangChain with NumPy.\n4.  Future release of LangChain should include support for NumPy version 2.0.2.\n5.  The bug in LangChain’s latest version impacts the integration with Neo4J GraphStore.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 87, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue report highlights a critical bug in the `RunnableBinding` class within the LangChain library, specifically concerning the propagation of configuration factories during binding creation. The bug causes a failure where config factories are lost when a runnable binding is created via a specific method, leading to unexpected behavior and potentially breaking functionality.  The issue stems from a newly introduced behavior in the `RunnableBinding` class that doesn't properly pass along configuration factories when creating new binding instances.  The report suggests this issue is likely a bug in the latest stable version of LangChain and is being considered for a PR fix.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-30T02:55:06Z", "body_clean": "@mahirshah the cause was that RunnableBinding overrides the [code] of parent [code] class and config factory was not passed in this method. This has been fixed in above PR."}, {"author": "mahirshah", "created_at": "2025-03-30T04:03:51Z", "body_clean": "[@mahirshah]( [link] the cause was that RunnableBinding overrides the [code] of parent [code] class and config factory was not passed in this method. This has been fixed in above PR. Thank you left some comments on the PR I think the config factories propagation should be applied to all current RunnableBinding decoration methods, not just [code]"}, {"author": "ccurme", "created_at": "2025-04-10T13:10:33Z", "body_clean": "Hello, thanks for this. Wondering if we're still expected to drop tags in this scenario: [code]"}]}, {"ollama_summary": "The issue highlights a bug in LangChain where the `thinking_block` field returned by Claude model is being ignored when using `ChatOpenAI().invoke()`.  This problem is not related to the user's code but appears to be a fundamental issue within LangChain’s integration with Claude.  Attempts to update to the latest version of LangChain haven’t resolved the problem, suggesting it’s a bug in the core integration.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-04-02T05:16:33Z", "body_clean": "you should use ChatAnthropic instead of the OpenAI equivalent. The following works for me: [code]"}, {"author": "Mikaelsauriol5", "created_at": "2025-06-17T19:28:18Z", "body_clean": "Is there a way to do this with chatopenai?"}]}, {"ollama_summary": "This issue involves a critical bug in the MistralAI Embeddings library that causes it to fail to handle documents exceeding 27000 characters, leading to a 400 error and potentially impacting the integration of long documents into LangChain. The root cause appears to be a hard-coded length limit within the library, and the issue is not being addressed through recent updates.", "final_category": "bug", "comments": [{"author": "Gr33nLight", "created_at": "2025-06-09T09:23:08Z", "body_clean": "@eric burel I'm having a similar issue, on the JS side of things. The error thrown is a code 400 with this message: \"Too many tokens overall, split into more batches.\" Did you manage to find a workaround? I tried messing with maxConcurrency and batch size but no change.. Thanks!"}, {"author": "eric-burel", "created_at": "2025-06-09T17:02:29Z", "body_clean": "Not yet sorry! The problem is not obvious from reading the code and the integration doesn't have sufficient debugging tooling to help. I've been using OpenAI embeddings for now in my course, and also Chroma built ins."}]}, {"ollama_summary": "This issue reports a bug in LangChain where the `func interrupt second time` function causes a recursive loop, leading to an infinite flow of execution when the graph is re-invoked. The code attempts to retrieve subgraph state history, but the history is empty, hindering the ability to resume execution.  The issue is currently not resolved by updating the LangChain version, and the user is seeking assistance in understanding and resolving this problem.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-26T16:03:08Z", "body_clean": "Hi, @PetrosTragoudaras. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a problem with a chatbot using LangChain's subgraphs. The graph resumes incorrectly after the second interrupt point, causing an infinite loop. The issue seems related to an empty subgraph state history. You followed the documentation for managing subgraph state. No comments or developments have been made on this issue yet. Next Steps Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The ChromaDB/Docs issue involves incorrect type hints for the `similarity_search_*` filter type, causing errors in LangChain code. This stems from a fundamental misunderstanding of how ChromaDB's API functions, specifically related to the `[code]` operator and its usage with the `[code]` metadata search and document search methods. The issue is not a bug in the code itself but a discrepancy between the API documentation and the actual implementation.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-26T16:03:00Z", "body_clean": "Hi, @hesreallyhim. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Discrepancies in type hints and API documentation for [code] filter in ChromaDB. Example code provided by you shows type warnings when using filter conditions from official documentation. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "mdrxy", "created_at": "2025-09-09T23:38:43Z", "body_clean": "Looks like this is resolved? Happy to re open if not the case"}, {"author": "hesreallyhim", "created_at": "2025-09-10T21:31:14Z", "body_clean": "@mdrxy thanks, I haven't revisited this in a while, it seems like it's OK... Maybe it's nothing and totally legit but the commit that is last referenced leads to this repository: [link] Which... I'll let you figure out what's going on with that if you're so inclined. It seems to me like a kind of strange unofficial fork, but I haven't done a deep dive. Cheers."}]}], "business_insights": ["Understanding the root cause of the RunnableBinding bug reveals a critical class override issue, potentially impacting core functionality.", "The Claude integration issue highlights a fundamental problem with LangChain’s integration with Claude, requiring a potential re-evaluation of the integration strategy.", "The MistralAI Embeddings bug indicates a need for a more robust handling of long documents, necessitating improvements to the library’s integration.", "The LangChain func interrupt second time bug underscores the importance of handling graph state correctly, potentially impacting the entire system.", "The ChromaDB/Docs issue demonstrates a misunderstanding of ChromaDB API, leading to type hint errors, affecting LangChain code."], "technical_insights": ["LangChain's RunnableBinding class override is a critical bug, causing configuration factory loss during binding.", "Claude integration is a fundamental issue, requiring a re-evaluation of the integration strategy and potential library updates.", "MistralAI Embeddings’ thinking_block issue is related to the OpenAI equivalent and needs a solution.", "The func interrupt second time bug in LangChain is a core integration issue, affecting graph state.", "ChromaDB/Docs’ type hint errors are impacting LangChain code and require a fix in the library."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Understanding the root cause of the `RunnableBinding` bug reveals a critical class override issue, potentially impacting core functionality.\n2. The Claude integration issue highlights a fundamental problem with LangChain’s integration with Claude, requiring a potential re-evaluation of the integration strategy.\n3. The MistralAI Embeddings bug indicates a need for a more robust handling of long documents, necessitating improvements to the library’s integration.\n4. The LangChain `func interrupt second time` bug underscores the importance of handling graph state correctly, potentially impacting the entire system.\n5. The ChromaDB/Docs issue demonstrates a misunderstanding of ChromaDB API, leading to type hint errors, affecting LangChain code.\n\nTECHNICAL INSIGHTS:\n1. LangChain's `RunnableBinding` class override is a critical bug, causing configuration factory loss during binding.\n2. Claude integration is a fundamental issue, requiring a re-evaluation of the integration strategy and potential library updates.\n3. MistralAI Embeddings’ `thinking_block` issue is related to the OpenAI equivalent and needs a solution.\n4. The `func interrupt second time` bug in LangChain is a core integration issue, affecting graph state.\n5. ChromaDB/Docs’ type hint errors are impacting LangChain code and require a fix in the library.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 88, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a problem with the `max_tokens` parameter in the LangChain `ChatPromptTemplate` library, specifically preventing it from correctly limiting the completion tokens to 20. The code attempts to use this parameter, but it consistently fails to produce the expected output, requiring investigation into potential underlying issues with the library's integration or specific configuration.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-26T15:36:51Z", "body_clean": "Hello, thanks for raising this. You'll need to use configuration to ensure that [code] is propagated to the chat model specifically. Currently (in [code] ) it is fed to the prompt, which ignores irrelevant keys. Please follow the guide here and ping me if there are any issues: [link]"}]}, {"ollama_summary": "This issue reports a `TypeError` occurring within the LangChain `azuresearch.documents.aio. search client async.SearchClient.search()` function when attempting to filter documents using the `[code]` integration. This likely stems from a problem with the integration package or a configuration issue, causing the function to return multiple values for the `filter` keyword argument.", "final_category": "bug", "comments": [{"author": "mutje", "created_at": "2025-03-28T11:37:35Z", "body_clean": "Hello, I recently came across similar issue, try using [code] instead of [code] . This code works for me: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-06-27T16:01:52Z", "body_clean": "Hi, @bfigueir. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] in the AzureSearch integration of LangChain, related to the [code] function. The error involves multiple values for the 'filter' keyword argument. @mutje suggested using [code] instead of [code] , which resolved the issue for them. Next Steps: Please confirm if the issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain library is crashing when attempting to refresh the Neo4j graph schema due to an issue with the `apoc.meta.data` component.  Initial investigations and searches haven’t revealed a specific bug in the LangChain code itself, suggesting it’s a bug within the Neo4j integration.  The issue is currently being reported as a stability concern and requires a fix to ensure the graph schema is consistently updated.", "final_category": "bug", "comments": [{"author": "khteh", "created_at": "2025-03-25T08:31:59Z", "body_clean": "[code] but to no avail! [code]"}, {"author": "eyurtsev", "created_at": "2025-03-26T21:16:50Z", "body_clean": "cc @alexthomas93 in case you know what's going on"}, {"author": "alexthomas93", "created_at": "2025-03-27T16:16:51Z", "body_clean": "Hi @khteh, can you confirm that apoc is installed when setting up your Neo4j deployment? For reference, see: [link]"}]}, {"ollama_summary": "The `rm_titles` issue involves a bug where the LangChain library is incorrectly removing the \"title\" property from its schema.  After searching and consulting documentation, the issue appears to be a bug within LangChain itself, not due to the user's code.  The code attempts to remove a crucial property, resulting in an error message and stack trace.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-03-25T17:10:57Z", "body_clean": "@Yazan Hamdan Sent a PR to address should be available in the next release of core. Also just a heads up that the JSONSchema in your PR does not appear to be valid JSONSchema. the root level is an object w/ items but should be an array w/ items?"}]}, {"ollama_summary": "This issue focuses on a critical bug in ZeroxPDFLoader that prevents it from correctly integrating with the GenericLoader, leading to errors and rendering the RAG system's functionality. The bug stems from limitations within the PDF parsing and vector database integration, specifically related to the `langsmith` library and its `langsmith` package.  The code attempts to utilize the `Parsers` version of the `Langchain` library, which is causing the incompatibility.  The issue currently lacks a solution and requires a fix within the `langsmith` library itself.", "final_category": "bug", "comments": [{"author": "pprados", "created_at": "2025-05-07T08:29:18Z", "body_clean": "See [link]"}]}], "business_insights": ["Library integration testing is critical – ensure all components are thoroughly tested.", "Dependency management – consistent library versions are vital for stability.", "Configuration drift – verify configuration updates are propagating correctly.", "Neo4j schema refresh – monitor and address schema inconsistencies.", "LangChain library stability – prioritize bug fixes within the core library."], "technical_insights": ["max_tokens parameter – carefully manage the max_tokens parameter.", "TypeError in azuresearch.documents.aio.search – investigate the root cause of the error.", "filter keyword – ensure proper integration of the [code] filter keyword.", "Neo4j schema refresh – implement robust schema validation and refresh processes.", "rm_titles bug – focus on the LangChain library's bug within the schema.", "ZeroxPDFLoader bug – verify PDF parsing and vector database integration.", "Langchain library stability – prioritize bug fixes within the core library.", "Configuration drift – monitor configuration updates for inconsistencies.", "Dependency versioning – track and manage library versions.", "Neo4j integration – ensure the integration is robust and stable."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Library integration testing is critical – ensure all components are thoroughly tested.\n2.  Dependency management – consistent library versions are vital for stability.\n3.  Configuration drift – verify configuration updates are propagating correctly.\n4.  Neo4j schema refresh – monitor and address schema inconsistencies.\n5.  LangChain library stability – prioritize bug fixes within the core library.\n\nTECHNICAL INSIGHTS:\n1.  `max_tokens` parameter – carefully manage the `max_tokens` parameter.\n2.  `TypeError` in `azuresearch.documents.aio.search` – investigate the root cause of the error.\n3.  `filter` keyword – ensure proper integration of the `[code]` filter keyword.\n4.  Neo4j schema refresh – implement robust schema validation and refresh processes.\n5.  `rm_titles` bug – focus on the LangChain library's bug within the schema.\n6.  ZeroxPDFLoader bug – verify PDF parsing and vector database integration.\n7.  Langchain library stability – prioritize bug fixes within the core library.\n8.  Configuration drift – monitor configuration updates for inconsistencies.\n9.  Dependency versioning – track and manage library versions.\n10. Neo4j integration – ensure the integration is robust and stable.\n", "batch_number": 89, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue focuses on a critical bug in the PDFPlumberLoader library that prevents it from correctly handling the complex and evolving data structure of the RAG project, specifically the integration of Word documents and the requirement for the \"Parsers\" version.  The code currently struggles with tables, image conversions, and the dynamic nature of the files, leading to errors and a lack of proper data processing.  The solution involves updating the LangChain integration package to a newer version, resolving the identified issues.", "final_category": "bug", "comments": [{"author": "pprados", "created_at": "2025-05-07T08:28:17Z", "body_clean": "See [link]"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nChatHuggingFace is experiencing a problem where it fails to generate responses with functions bound by \"bind_tools,\" despite attempts to resolve it through documentation, search, and updates. The issue appears to be a bug within the LangChain integration, specifically related to the model initialization tools not being correctly utilized. The provided code demonstrates the failure to generate outputs when using the `invoke` method, and the relevant package versions are listed.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-23T16:02:29Z", "body_clean": "Hi, @Ying Kang. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You identified a bug with the ChatHuggingFace model not generating responses when using \"bind tools\". The issue persists despite following the documentation and updating to the latest version. Example code was provided to illustrate the problem. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is encountering a `TypeError` because it attempts to serialize an `AsyncCallbackManagerForToolRun` object, which is not JSON serializable. This issue appears to be a bug within LangChain, not directly caused by the code itself, and it consistently occurs when using coroutines within structured tool integrations.  Currently, the bug hasn’t been addressed by updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-24T16:02:21Z", "body_clean": "Hi, @sei li miidas. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A [code] occurs with [code] not being JSON serializable. The issue persists despite updating to the latest stable version of LangChain. The error is confirmed to be a bug within LangChain, not user code. Example code has been provided to demonstrate the issue. No comments or activity have been made on this issue yet. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that prevents the correct integration of parameters within the `[code]` method, leading to a lack of relevant questions and images in the response. The code attempts to utilize the `[code]` and `[code]` parameters, but these aren’t being appended to the response body, resulting in a missing context.  The issue is currently unresolved by a recent update, suggesting a potential regression in the LangChain library.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue highlights a bug in LangChain where the incorrect token count (`usage_metadata`) in streaming mode results in inflated total token usage numbers, particularly when combined with the `count(output token)` metric.  The problem isn’t directly in the code but stems from a flawed aggregation strategy within LangChain’s core messaging system.  Proposed solutions involve adapting the token aggregation to report per-token usage in the final chunk or modifying the usage reporting in OpenAI’s chat models.", "final_category": "bug", "comments": [{"author": "le-codeur-rapide", "created_at": "2025-03-22T11:05:49Z", "body_clean": "Hello @andrePankraz , When I run a basic stream from openai chat model while tracking the stream usage [code] I get the expected usage metadata at the end of the stream. [code] Can you please share your code ?"}, {"author": "Yogesh-Dubey-Ayesavi", "created_at": "2025-03-22T11:51:55Z", "body_clean": "I’m facing the same issue. In my case, I don’t get [code] and the [code] in the usage metadata, not even [code] in case of [code] 1. [code] . 2. [code] . [!NOTE] I have enabled [code] and [code] in runnable configurations. Code [code] Logs for [code] [code] Logs for [code] [code]"}, {"author": "ccurme", "created_at": "2025-03-22T11:54:41Z", "body_clean": "@Yogesh Dubey Ayesavi could you open a separate issue in [link]"}, {"author": "Yogesh-Dubey-Ayesavi", "created_at": "2025-03-22T12:04:28Z", "body_clean": "Yes @ccurme Sure."}, {"author": "andrePankraz", "created_at": "2025-03-23T08:27:54Z", "body_clean": "Hi, thank you for locking into this. I've got a minimal example, that shows the problem. It only happens in astream mode with callback handler what many chatbots are using for step tracking it's embedded into bigger agent graph structures. The final usage metadata is wrong: [code] The problematic parts are called like described in original error description. The methods are working wrong for usage metadata aggregation. But it only appears in final on llm end callback (with agregated generation message), else astream() delivers the original usage metadata per token (yield chunk.message). See here: [link]"}, {"author": "le-codeur-rapide", "created_at": "2025-03-24T21:52:44Z", "body_clean": "Hello @andrePankraz That is weird, I tested your minimal code example and stilll get the expected behaviour: [code] [code] Note that to have this usage metadata I had to pass the [code] argument to [code] function. Then I wonder how you have usage matadata without this. Maybe it is due to the llm then, what model are you using ?"}, {"author": "andrePankraz", "created_at": "2025-03-25T06:41:50Z", "body_clean": "I have passed [code] to llm initialization that works too. But I see the problem with your log, here is mine: [code] As you can see, my OpenAI compatible (!) API gives usage metadata per token (!) with [code] : [code] I use VLLM Inference Server with OpenAI API. So I could try using different version and see, if they have changed this slightly different behaviour. They are not wrong, giving usage metadata with output tokens=1 and input tokens already known but it's a bit different from OpenAI, if I see your log. At the end, the usage metadata aggregation code in [link] doesn't make any sense at all, you can not aggregate input tokens and total tokens like this in a stream. It kind of works for output tokens, but even than the final message also doubles the expected output tokens number with this addition. It just works for OpenAI original API, because they just forward usage metadata once in \"final output token\" (more like a synthetic technical final message, not a real token, stop token comes before in stream)."}, {"author": "le-codeur-rapide", "created_at": "2025-03-25T13:57:15Z", "body_clean": "Ahh ok I see. Yes you are right this [code] does not look like it is working in the general case"}, {"author": "frankoo21", "created_at": "2025-06-03T09:46:13Z", "body_clean": "i have faced the same issue of @andrePankraz , but if i had to work witch langchain openai , how i can resolve it if i keep worked with it , and assuring the counting correctly , is it possible . i think is due to the server of llm, because when i test the counting number with same code with another provider , it works correctly !"}]}], "business_insights": ["LangChain’s integration with the RAG project’s data structure is complex, requiring precise handling of data transformations.", "Updating the LangChain package is a likely solution to resolve the identified issues, but testing is crucial.", "The TypeError related to AsyncCallbackManagerForToolRun suggests a bug in LangChain’s core tool integration.", "The TypeError concerning serialization is a regression, indicating a potential bug in LangChain’s core functionality.", "The TypeError with [code] and [code] parameters highlights a flaw in LangChain’s parameter handling.", "The [code] and [code] parameter issue suggests a problem with LangChain’s streaming model integration.", "The token count issue with streaming mode requires adjustments to the aggregation strategy.", "The [code] and [code] usage metadata issue needs a change to the tracking.", "The [code] and [code] usage metadata issue requires a change to the tracking.", "The bug related to the [code] and [code] parameter issue might be a regression."], "technical_insights": ["LangChain’s integration package is a key focus; updating is the primary solution.", "The TypeError is a bug within LangChain’s core integration, requiring a fix.", "The [code] and [code] parameter issue is a regression; updates are needed.", "The token count issue requires adaptation of aggregation to per-token usage.", "The [code] and [code] usage metadata issue necessitates a change to the tracking.", "The [code] and [code] parameter issue warrants a fix.", "The [code] and [code] parameter issue might be a regression.", "The [code] and [code] parameter issue may be a regression.", "The [code] and [code] parameter issue is a regression.", "The [code] and [code] parameter issue requires a fix."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s integration with the RAG project’s data structure is complex, requiring precise handling of data transformations.\n2.  Updating the LangChain package is a likely solution to resolve the identified issues, but testing is crucial.\n3.  The `TypeError` related to `AsyncCallbackManagerForToolRun` suggests a bug in LangChain’s core tool integration.\n4.  The `TypeError` concerning serialization is a regression, indicating a potential bug in LangChain’s core functionality.\n5.  The `TypeError` with `[code]` and `[code]` parameters highlights a flaw in LangChain’s parameter handling.\n6.  The `[code]` and `[code]` parameter issue suggests a problem with LangChain’s streaming model integration.\n7.  The token count issue with streaming mode requires adjustments to the aggregation strategy.\n8.  The `[code]` and `[code]` usage metadata issue needs a change to the tracking.\n9.  The `[code]` and `[code]` usage metadata issue requires a change to the tracking.\n10. The bug related to the `[code]` and `[code]` parameter issue might be a regression.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s integration package is a key focus; updating is the primary solution.\n2.  The `TypeError` is a bug within LangChain’s core integration, requiring a fix.\n3.  The `[code]` and `[code]` parameter issue is a regression; updates are needed.\n4.  The token count issue requires adaptation of aggregation to per-token usage.\n5.  The `[code]` and `[code]` usage metadata issue necessitates a change to the tracking.\n6.  The `[code]` and `[code]` parameter issue warrants a fix.\n7.  The `[code]` and `[code]` parameter issue might be a regression.\n8.  The `[code]` and `[code]` parameter issue may be a regression.\n9.  The `[code]` and `[code]` parameter issue is a regression.\n10. The `[code]` and `[code]` parameter issue requires a fix.\n", "batch_number": 90, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The Google VertexAI library is throwing an \"InvalidArgument: 400 Request contains an invalid argument\" error when interacting with the API.  After investigating, it appears to be a bug within LangChain itself, not a direct code issue.  The error occurs when calling specific API calls with particular inputs, and the issue hasn’t been addressed by recent updates to the LangChain library.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-22T11:17:08Z", "body_clean": "Can you provide a minimal reproducible example? [code] seems to work fine: [code]"}, {"author": "khteh", "created_at": "2025-03-22T11:40:50Z", "body_clean": "I think you have to use / go through [code] to reproduce the error."}, {"author": "khteh", "created_at": "2025-03-22T11:49:42Z", "body_clean": "This is the minimum I can put together: [code] Running it: [code] Full blown code: [link]"}, {"author": "khteh", "created_at": "2025-04-04T11:19:46Z", "body_clean": "[link]"}, {"author": "AleksandrovichK", "created_at": "2025-06-17T09:46:37Z", "body_clean": "and so what did you do, ultimately?"}, {"author": "khteh", "created_at": "2025-06-18T02:59:57Z", "body_clean": "[link] The referenced thread suggested using Google GenAI API instead of VertexAI. I have NOT tried myself. I have since switched to using self hosting LLM model using Ollama because I refuse to put my credit card information on Google app."}, {"author": "rsbmk", "created_at": "2025-08-12T21:09:46Z", "body_clean": "I have the same error for [code] model. So there is no solution?"}]}, {"ollama_summary": "The issue reports a 400 status code error when using the Draw Mermaid PNG API, despite being a known bug in LangChain.  The user has exhausted standard search methods and documentation, suggesting a potential issue within the LangChain integration.  Currently, the bug is not being addressed by updating the LangChain version, requiring investigation and potential code modification.", "final_category": "bug", "comments": [{"author": "lovelyscientist", "created_at": "2025-03-23T21:07:19Z", "body_clean": "Try this (from [link] [code]"}, {"author": "khteh", "created_at": "2025-03-24T03:30:19Z", "body_clean": "[link]"}, {"author": "khteh", "created_at": "2025-04-04T11:27:17Z", "body_clean": "I don't face this issue nowadays."}, {"author": "Mp5A5", "created_at": "2025-04-22T07:44:10Z", "body_clean": "you can like this: 1. [link] 2. [link] 3. change ： [code] [code] [code] [code] to [code] 4. run docker： [code]"}, {"author": "RamziRebai", "created_at": "2025-10-07T21:53:37Z", "body_clean": "Try this, it will work import base64 import requests from IPython.display import Image mermaid code = graph compiled.get graph().draw mermaid() Encode the Mermaid code graphbytes = mermaid code.encode(\"utf8\") base64 bytes = base64.b64encode(graphbytes) base64 string = base64 bytes.decode(\"ascii\") Use mermaid.ink API url = f\" [link] response = requests.get(url) if response.status code == 200: display(Image(response.content)) else: print(f\"Error: Status code {response.status code}\") print(\"Try copying the code to [link] instead\")"}]}, {"ollama_summary": "This issue stems from a critical import error within the `init chat model helper` function of the LangChain `azure AIChatCompletionsModel` package.  Specifically, the code is failing to import the `AzureAIChatCompletionsModel` from the `langchain azure ai` package, causing the program to crash.  The root cause appears to be an outdated or misconfigured LangChain integration, potentially requiring a refresh or a reinstallation of the package.", "final_category": "bug", "comments": [{"author": "Koolsiddude", "created_at": "2025-03-29T04:55:55Z", "body_clean": "I am still getting the same error, new issue created 30536 and 30544, please investigate"}]}, {"ollama_summary": "This issue reports a bug in LangChain that prevents the support for OpenAI PDF files, specifically the `claude` models. The bug causes an error when attempting to use the `openai` model, and the code doesn't automatically handle the conversion of the PDF data into a format LangChain can understand.  The issue is currently unresolved and requires a fix.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-20T23:16:10Z", "body_clean": "Currently you need to adhere to OpenAI's format (the doc you linked shows an example) [code]"}, {"author": "austinmw", "created_at": "2025-03-21T00:59:58Z", "body_clean": "Ah sorry thanks!"}]}, {"ollama_summary": "This issue involves a potential bug in LangChain that prevents the OpenAI client from correctly utilizing Perplexity's specific attributes like search domain filters and recency. The code currently uses the OpenAI client, and the integration isn't fully supported by Perplexity, leading to errors.  The issue appears to be a fundamental bug within LangChain itself, rather than a specific code change.", "final_category": "bug", "comments": [{"author": "jaimepcr", "created_at": "2025-03-21T09:34:28Z", "body_clean": "I ran into the same issue and couldn’t use the full Perplexity functionality in my requests. It would be great if this could be supported! Definitely think this would be a useful update. 👌"}, {"author": "ccurme", "created_at": "2025-03-22T22:25:05Z", "body_clean": "The OpenAI client supports some fields for handling additional parameters, see for example [here]( [link] Can we use these? [code] I tried passing [code] and got a reasonable error message: BadRequestError: Error code: 400 {'error': {'message': \"Validation error: search recency filter must be either 'hour', 'day', 'week', 'month', or 'year'\", 'type': 'invalid search recency filter', 'code': 400}}"}, {"author": "DavidSanSan110", "created_at": "2025-03-23T00:12:18Z", "body_clean": "Thank you for noticing! I tried it, and it works as expected. However, I also noticed something else in the Python code block: [code] Currently, only citations are appended to the response, but depending on the parameters passed, the response could include other important attributes like related questions or images. To ensure the Perplexity response is handled correctly, these fields should also be included when available. I’m working on a PR to properly append or return these fields. Let me know if you have any thoughts on this! Should I close the other PR?"}, {"author": "ccurme", "created_at": "2025-03-23T15:14:58Z", "body_clean": "Thanks @DavidSanSan110, will take a look at the new PR. For context, we will likely move ChatPerplexity into a dedicated package [code] [here]( [link] in the next few weeks. So in the current implementation in [code] , I'd limit updates to bug fixes and small / straightforward feature additions (the new PR looks reasonable but will take a closer look we're a backlogged at the moment). In my mind here are some other needs for ChatPerplexity: 1. We should document how to access [code] , [code] , etc. in our docs page [here]( [link] 2. If [code] , [code] , etc. make sense as initialization parameters, we can add them to ChatPerplexity so that they will be more visible and easier to access. 3. We should fill out its docstring so that its [API Referece]( [link] is populated. See example [here]( [link]"}]}], "business_insights": ["LangChain’s core functionality is susceptible to specific API calls, highlighting potential stability concerns within the library.", "Addressing the “InvalidArgument: 400 Request contains an invalid argument” error necessitates a deeper dive into LangChain’s internal logic.", "The integration issue with the Draw Mermaid PNG API suggests a broader problem with LangChain’s external dependencies.", "The init chat model helper import error points to a potential dependency conflict or misconfiguration within the LangChain package.", "The Perplexity PDF file support issue underscores the importance of comprehensive testing and validation of LangChain’s integrations."], "technical_insights": ["LangChain’s reliance on specific API calls creates a potential point of failure; thorough testing is crucial.", "The \"InvalidArgument: 400\" error necessitates investigation into the LangChain library's internal error handling mechanisms.", "The azure AIChatCompletionsModel import failure suggests a dependency conflict or misconfiguration within the LangChain package.", "The init chat model helper import error indicates an outdated or misconfigured LangChain integration.", "The Perplexity PDF file support issue highlights a critical integration vulnerability within LangChain’s external dependencies."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s core functionality is susceptible to specific API calls, highlighting potential stability concerns within the library.\n2. Addressing the “InvalidArgument: 400 Request contains an invalid argument” error necessitates a deeper dive into LangChain’s internal logic.\n3. The integration issue with the Draw Mermaid PNG API suggests a broader problem with LangChain’s external dependencies.\n4. The `init chat model helper` import error points to a potential dependency conflict or misconfiguration within the LangChain package.\n5. The Perplexity PDF file support issue underscores the importance of comprehensive testing and validation of LangChain’s integrations.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s reliance on specific API calls creates a potential point of failure; thorough testing is crucial.\n2. The \"InvalidArgument: 400\" error necessitates investigation into the LangChain library's internal error handling mechanisms.\n3. The `azure AIChatCompletionsModel` import failure suggests a dependency conflict or misconfiguration within the LangChain package.\n4. The `init chat model helper` import error indicates an outdated or misconfigured LangChain integration.\n5. The Perplexity PDF file support issue highlights a critical integration vulnerability within LangChain’s external dependencies.\n", "batch_number": 91, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue focuses on a bug within the LangChain image blob parser, specifically when attempting to extract descriptions from PDFs using the LLMImageBlobParser. The parser is failing to respect the 5MB image size limit, causing errors when processing images larger than that.  The code attempts to resize images to a maximum of 5MB, but the underlying functionality doesn't account for this constraint.  The issue is currently unresolved and requires a fix within the LangChain integration.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-23T03:03:53Z", "body_clean": "I understand the requirement but it is difficult to change either [code] or [code] because every llm requirement will be different for the max image size? How do you propose we make it dynamic to account for every llm provider. We just can't make [code] or [code] dependent on specific llm provider requirements"}, {"author": "alberto-agudo", "created_at": "2025-03-23T15:42:20Z", "body_clean": "Yes you’re absolutely right. Tailoring the solution to every LLM provider will be an overkill. However, what I’d propose is allowing an argument for the user to set a maximum image size, so that there are resizing strategies provided within the function; hence leaving it to the developer to check maximum image sizes for their FM provider of choice. I think this will be helpful while maintaining a flexible design, especially for the LLMImageBlobParser function."}, {"author": "dosubot[bot]", "created_at": "2025-06-22T16:02:04Z", "body_clean": "Hi, @alberto agudo. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You suggested adding a feature to control the maximum image size in [code] . The issue is identified as a bug due to varying LLM requirements for image size. Keenborder786 acknowledged the challenge but questioned making it dynamic for all providers. You proposed allowing users to set a maximum image size argument for flexibility. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue focuses on a critical bug in the `generateContentRequest.contents[3].parts` attribute within a Python project, which causes an empty `parts` list to be generated when the code attempts to access the contents of a resource. This is a significant problem as it prevents the code from completing correctly and potentially leads to unexpected behavior. The issue highlights a lack of clear and comprehensive error handling and a need for a more robust approach to resource handling.", "final_category": "bug", "comments": [{"author": "hinthornw", "created_at": "2025-03-20T15:02:32Z", "body_clean": "The error is a Gemini error, and your code snippet doesn't mention Gemini. This doesn't seem like an error in LangGraph at all."}, {"author": "dosubot[bot]", "created_at": "2025-06-20T16:01:57Z", "body_clean": "Hi, @Chandigarh coder. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with an asynchronous Python script using [code] . The error encountered was related to [code] being empty. You provided a minimal reproducible example and system information. User hinthornw suggested the error might be related to Gemini, not LangGraph. Next Steps Could you confirm if this issue is still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue relates to the `get_openai_callback` function in LangChain, which is failing to retrieve the token usage event when streaming mode is activated. The code attempts to use the `callback` event, but it's not being triggered, leading to a zero value for the tokens used.  The issue is currently unresolved, and the code relies on the latest stable version of LangChain, suggesting a potential bug in the integration package.", "final_category": "bug", "comments": [{"author": "axiangcoding", "created_at": "2025-03-20T08:05:04Z", "body_clean": "This may also cause the issue in langgraph: [link]"}, {"author": "axiangcoding", "created_at": "2025-03-20T08:31:30Z", "body_clean": "Find a solution look deep down the code, pass [code] to AzureChatOpenAI, it works fine. I recommend to update the docs"}, {"author": "ccurme", "created_at": "2025-03-27T02:24:47Z", "body_clean": "FYI @axiangcoding if you update langchain openai, AzureChatOpenAI now supports [code] . I've updated the docs: [link]"}, {"author": "axiangcoding", "created_at": "2025-03-27T02:57:01Z", "body_clean": "FYI [@axiangcoding]( [link] if you update langchain openai, AzureChatOpenAI now supports [code] . I've updated the docs: [link] Thanks!"}]}, {"ollama_summary": "The code is experiencing an import error when trying to use the `ExperimentalMarkdownSyntaxTextSplitter` package. This issue stems from a version mismatch between the LangChain library and the specific `ExperimentalMarkdownSyntaxTextSplitter` integration, causing the `ImportError: cannot import name 'ExperimentalMarkdownSyntaxTextSplitter' from 'langchain text splitters'` message.  The issue is likely related to a bug in the LangChain package itself, and attempts to update to the latest stable version haven't resolved it.", "final_category": "bug", "comments": [{"author": "YassinNouh21", "created_at": "2025-03-23T20:48:02Z", "body_clean": "Hi @tko85, I've investigated the issue and reproduced it in an environment matching your setup. The issue appears to be related to how Python is finding the package. Here's what I found: 1. The [code] class is definitely present in the package and is properly exported in [code] . 2. The issue might be related to how Python is resolving the package path. Let's try these steps to fix it: [code] 3. After installation, verify the package is installed correctly: [code] 4. If you're using a Jupyter notebook (as indicated by the [code] command in your example), make sure to restart the kernel after installation. 5. You can also try importing the package this way: [code] If the issue persists after trying these steps, could you please provide: 1. The output of [code] 2. The output of [code] This will help us understand exactly how Python is resolving the package path on your system. Also, since you're using Ubuntu Linux, make sure you have the appropriate permissions for the Python site packages directory where pip installs packages. Let me know if you need any clarification or if the issue persists after trying these steps."}, {"author": "tko85", "created_at": "2025-03-24T16:41:33Z", "body_clean": "These steps resolved the issue. Thank you."}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes the `messages` index to be out of range when `include_system=True`. This happens when the system message is empty, leading to an empty list being processed and potentially causing errors. The fix involves updating the LangChain library to the latest stable version to address this issue.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-18T16:02:28Z", "body_clean": "Hi, @komikndr. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an \"Index out of range\" error in the [code] function. The error occurs when [code] and the human message is empty. This issue is specific to the OpenAI chat model configuration in LangChain. You provided test code and implementation details, noting the bug persists in the latest version. There have been no comments or activity on this issue since it was reported. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Addressing the image blob parser bug proactively prevents future errors and ensures consistent functionality across different LLM providers.", "Thoroughly testing the generateContentRequest.contents[3].parts attribute is crucial for maintaining code stability and preventing unexpected behavior.", "Robust error handling and resource management are vital for preventing unexpected crashes and maintaining code integrity.", "Addressing the get_openai_callback issue prevents data loss and ensures the code functions as intended.", "Updating the LangChain library addresses the import error, promoting code stability and preventing future bugs."], "technical_insights": ["The image blob parser bug is a significant risk due to its potential impact on LLM integration.", "The generateContentRequest.contents[3].parts attribute is a critical component, requiring careful handling of resource limits.", "The get_openai_callback issue highlights a lack of comprehensive error handling and a need for more robust resource management.", "The ExperimentalMarkdownSyntaxTextSplitter import error indicates a potential bug within the LangChain package itself.", "Updating the LangChain library addresses the import error, mitigating potential code instability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing the image blob parser bug proactively prevents future errors and ensures consistent functionality across different LLM providers.\n2. Thoroughly testing the `generateContentRequest.contents[3].parts` attribute is crucial for maintaining code stability and preventing unexpected behavior.\n3. Robust error handling and resource management are vital for preventing unexpected crashes and maintaining code integrity.\n4. Addressing the `get_openai_callback` issue prevents data loss and ensures the code functions as intended.\n5. Updating the LangChain library addresses the import error, promoting code stability and preventing future bugs.\n\nTECHNICAL INSIGHTS:\n1.  The image blob parser bug is a significant risk due to its potential impact on LLM integration.\n2.  The `generateContentRequest.contents[3].parts` attribute is a critical component, requiring careful handling of resource limits.\n3.  The `get_openai_callback` issue highlights a lack of comprehensive error handling and a need for more robust resource management.\n4.  The `ExperimentalMarkdownSyntaxTextSplitter` import error indicates a potential bug within the LangChain package itself.\n5.  Updating the LangChain library addresses the import error, mitigating potential code instability.\n", "batch_number": 92, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `top_k` and `filter` parameters in the `AzureAISearchRetriever` are not functioning correctly, resulting in an index containing only empty content vectors despite documents with embeddings being present. This issue appears to be a bug within the LangChain integration, and attempts to update the library haven’t resolved it. The code attempts to compare documents based on vector embeddings but ignores documents without them, creating an inconsistent index.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-20T01:33:08Z", "body_clean": "Can you please share the Service Endpoint that you are passing?"}, {"author": "andreeas26", "created_at": "2025-03-20T08:13:13Z", "body_clean": "@keenborder786 [link]"}, {"author": "keenborder786", "created_at": "2025-03-30T21:40:16Z", "body_clean": "okay @andreeas26 will have a look"}, {"author": "keenborder786", "created_at": "2025-04-20T22:42:48Z", "body_clean": "@andreeas26 I have double checked and everything seems to be fine at my end. Can you try upgrading to latest packages?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe maintainer is requesting the creation of a standalone package for ChatLitellm, adhering to the existing contributing guide. This package is crucial for versioning, dependency management, and thorough testing of the litellm model integration.  The goal is to establish a robust and maintainable package for this key component of the LangChain ecosystem.", "final_category": "feature", "comments": [{"author": "Akshay-Dongare", "created_at": "2025-03-28T05:36:58Z", "body_clean": "Hi Chester, I am interested in working on this. Could you please assign the issue to me so that I can start? Best Regards, Akshay Dongare"}, {"author": "Akshay-Dongare", "created_at": "2025-04-01T05:42:49Z", "body_clean": "Thanks, I am working on it. Will submit a PR in a few days."}, {"author": "Akshay-Dongare", "created_at": "2025-05-12T08:24:14Z", "body_clean": "Hey @ccurme — the standalone [langchain litellm]( [link] package is live ([latest: 0.2.1]( [link] and all follow up PRs ( 30637, 30685, 31063) have merged. Is it okay to mark this issue as resolved/closed now? Thanks!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `max_retries` parameter in the `ChatMistralAI` class is ineffective because the retry decorator logic has been removed from the code.  A search revealed this is a bug within LangChain, and attempts to update to the latest version of LangChain haven’t resolved the issue. The code demonstrates a failure after only one retry attempt, suggesting a fundamental problem with the retry mechanism.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-03-23T16:43:13Z", "body_clean": "as per above, I un commented code, validated that the retries work as expected, added unit test that validates the ChatMistralAI retry functionality, and added an integration test for the retries. I do not know why this was commented out a year ago I couldn't find a reason for it. Will leave it to the maintainer but I don't see immediate harm in re enabling it."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue currently raises a ValueError when the docstring isn’t parsed correctly, even with a descriptive title.  The proposed solution involves setting `error_on_invalid_docstring` to `True` to handle invalid docstrings.  The core problem is a lack of consistent behavior between the `parse_docstring` method and the `StructuredTool.from_func` function, requiring documentation updates to ensure proper parsing.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-17T16:03:03Z", "body_clean": "Hi, @anubhav756. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a mismatch between the documentation and the actual behavior of the [code] method. The documentation suggests [code] should trigger a [code] for invalid docstrings. The error only occurs when [code] is set. You recommended either aligning the behavior or updating the documentation. No comments or activity have been made on this issue yet. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\n**The issue addresses a lack of support for token counting specifically for o-series models (like those used in ChatOpenAI) within the LangChain ecosystem.** Currently, the existing `tiktoken` library provides token counting functionality, but it’s not integrated into LangChain.  The issue requests a solution to allow for this crucial feature to be readily available for LangChain users.\n\n**Key Details:**\n\n*   **Problem:**  Lack of support for o-series models in token counting.\n*   **Current Status:** `tiktoken` provides the functionality, but it’s not integrated into LangChain.\n*   **Proposed Solution:**  Develop a mechanism to seamlessly integrate token counting for o-series models into LangChain.\n\n---\n\nWould you like me to expand on any of these points, or perhaps suggest potential solutions based on the issue content?", "final_category": "feature", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-17T16:03:03Z", "body_clean": "Hi, @ccurme. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You requested token counting functionality for o series models in the ChatOpenAI module. Suggested using the tiktoken library as a reference for implementation. No comments or developments have occurred since the issue was opened. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Integrating o-series model token counting is a critical feature for LangChain, enhancing model performance and usability.", "Addressing this deficiency simplifies the integration of these models, improving user experience.", "Prioritizing this feature will increase LangChain’s adoption and utility.", "Standardizing token counting across models will improve data quality.", "Streamlining the integration process will improve developer productivity."], "technical_insights": ["The tiktoken library’s current lack of integration into LangChain represents a significant bottleneck.", "The max_retries parameter in the ChatMistralAI class needs revision to avoid infinite loops.", "The parse_docstring method and StructuredTool.from_func function require consistent behavior testing.", "The error_on_invalid_docstring setting in the ChatMistralAI class needs to be thoroughly tested.", "The docstring parsing logic is failing with invalid docstrings, requiring updated documentation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integrating o-series model token counting is a critical feature for LangChain, enhancing model performance and usability.\n2. Addressing this deficiency simplifies the integration of these models, improving user experience.\n3. Prioritizing this feature will increase LangChain’s adoption and utility.\n4. Standardizing token counting across models will improve data quality.\n5. Streamlining the integration process will improve developer productivity.\n\nTECHNICAL INSIGHTS:\n1.  The `tiktoken` library’s current lack of integration into LangChain represents a significant bottleneck.\n2.  The `max_retries` parameter in the `ChatMistralAI` class needs revision to avoid infinite loops.\n3.  The `parse_docstring` method and `StructuredTool.from_func` function require consistent behavior testing.\n4.  The `error_on_invalid_docstring` setting in the `ChatMistralAI` class needs to be thoroughly tested.\n5.  The `docstring` parsing logic is failing with invalid docstrings, requiring updated documentation.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 93, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue addresses a bug where the output of LangChain's batch processing differs from the input order due to race conditions. The fix involves replacing the original context assignment with an index-based approach, which resolves the problem and ensures deterministic, thread-safe batch processing. A comprehensive test suite confirms the fix’s functionality across various scenarios, including high concurrency and exception handling.", "final_category": "bug", "comments": [{"author": "jun0-ds", "created_at": "2025-04-02T05:51:21Z", "body_clean": "I guess return exceptions=True option triggers the error."}, {"author": "dosubot[bot]", "created_at": "2025-07-02T16:01:35Z", "body_clean": "Hi, @jun0 ds. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves the [code] method in LangChain. Outputs sometimes do not match the input order and may include duplicates. The issue is random and difficult to reproduce consistently. You suspect that the [code] option might be causing the error. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, I will automatically close this issue in 7 days. Thank you for your understanding and contribution!"}, {"author": "open-swe[bot]", "created_at": "2025-09-09T23:35:55Z", "body_clean": "🤖 Open SWE has been triggered for this issue. Processing... View run in Open SWE [here]( [link] (this URL will only work for @mdrxy) <details <summary Dev Metadata</summary { \"runId\": \"019930d5 fffa 7040 9f6d d0ade49d028a\", \"threadId\": \"b3aa8afc f4f2 4496 b856 4fe5a43c5491\" } </details <open swe plan message 🤖 Plan Generated I've generated a plan for this issue and will proceed to implement it since auto accept is enabled. Plan: Fix LangChain batch processing order mismatch and duplicate output issue caused by thread safety problem in ContextThreadPoolExecutor Task 1: [code] Task 2: [code] Task 3: [code] Proceeding to implementation... </open swe plan message"}, {"author": "mdrxy", "created_at": "2025-09-09T23:36:22Z", "body_clean": "@jun0 ds could you please provide more context to the environment/conditions that trigger this? More code examples would be appreciated."}]}, {"ollama_summary": "This issue reports a `TypeError` occurring when iterating through a `PydanticOutputParser` object, specifically when attempting to use `transform()` on an `Actor` object. This likely stems from a compatibility issue between LangChain's `PydanticOutputParser` and the specific `Actor` type used within the `transform()` function, potentially involving a version mismatch or a bug in the parser's internal serialization process.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-17T16:03:04Z", "body_clean": "Hi, @shenhaofang. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] when using [code] . The error indicates that the [code] object is not JSON serializable. This suggests a potential bug in handling Pydantic objects during transformation. No further comments or updates have been made on this issue. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem where the `ChatHuggingface` library is failing to connect to Hugging Face due to an air-gapped system, resulting in 401 and 404 errors when attempting to use the `HuggingFaceEndpoint` integration.  The problem seems to stem from LangChain attempting to connect to the Hugging Face website instead of utilizing the local `HuggingFaceEndpoint` which is crucial for the library's functionality.  Currently, the issue is not resolved by updating LangChain, suggesting a bug within the integration package.", "final_category": "bug", "comments": [{"author": "dhruva71", "created_at": "2025-03-22T16:07:53Z", "body_clean": "Can you explain how you are running the model locally so that we have more details? I understand the documentation does show an example with localhost, but that seems to be an example only. From what I see in the code, it only supports connecting and running inference from HuggingFace Hub."}, {"author": "JoeSF49", "created_at": "2025-03-22T16:47:33Z", "body_clean": "I run all LLMs locally on the same server as LangChain code. I'm using HuggingsFace's Text Generation Interface (TGI) docker workload to serve it as an API endpoint hence the usage of \"HuggingFaceEndpoint\". Once loaded i'm trying to use, ChatHuggingFace to leverage the \"with structured output\" as HuggingFaceEndpoint does not support that directive. ChatHuggingFace documentation states.. \"You can instantiate a ChatHuggingFace model in two different ways, either from a HuggingFaceEndpoint or from a HuggingFacePipeline.\" Per... [link] from langchain huggingface import ChatHuggingFace, HuggingFaceEndpoint llm = HuggingFaceEndpoint( repo id=\"HuggingFaceH4/zephyr 7b beta\", task=\"text generation\", max new tokens=512, do sample=False, repetition penalty=1.03, ) chat model = ChatHuggingFace(llm=llm) I have a HuggingFaceEndpoint however the library still attempts to reach out to Huggingface hub over internet. why is it doing this when i've already given it the local HuggingFaceEndpoint?"}, {"author": "dhruva71", "created_at": "2025-03-22T17:17:50Z", "body_clean": "Thanks a lot for the details. I see an [code] parameter available in the parameters of [code] . Could you try passing that in and pointing it to the TGI?"}, {"author": "JoeSF49", "created_at": "2025-03-22T18:18:37Z", "body_clean": "I don't have an issue using huggingfaceendpoint. I use it all the time with endpoint. My issue is using chathuggingface. When passing huggingfaceendpoint, using local endpoint, chathuggingface still tries to egress to Internet On Sat, Mar 22, 2025, 13:18 Dhruvajyoti Sarma @ . wrote: Thanks a lot for the details. I see an endpoint url parameter available in the parameters of HuggingFaceEndpoint. Could you try passing that in and pointing it to the TGI? — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ . [image: dhruva71] dhruva71 left a comment (langchain ai/langchain 30333) < [link] Thanks a lot for the details. I see an endpoint url parameter available in the parameters of HuggingFaceEndpoint. Could you try passing that in and pointing it to the TGI? — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ ."}, {"author": "daniau23", "created_at": "2025-05-30T13:53:13Z", "body_clean": "@dhruva71 I recently made use of the HuggingFaceEndpoint with mistralai/Mistral 7B Instruct v0.3 some days ago and it worked well but today it's not working [code] [code] Error [code]"}]}, {"ollama_summary": "This issue is addressing the need to create a standalone package for the `langchain-opensearch` component to improve versioning, dependency management, and testability. The goal is to provide a reusable package that integrates seamlessly with the existing Opensearch library.  Specifically, the maintainer is requesting the inclusion of a BaseStore component as outlined in the PR.", "final_category": "feature", "comments": [{"author": "Sathvik-Chowdary-Veerapaneni", "created_at": "2025-04-04T19:45:30Z", "body_clean": "Hi @ccurme , I'd like to take on this issue and implement the standalone OpenSearch package. I'll follow the contribution guide and the steps outlined above. Please let me know if there are any specific things I should be aware of or if someone else is already working on this (though it looks unassigned)."}, {"author": "manukychen", "created_at": "2025-04-11T08:24:28Z", "body_clean": "Hi @Sathvik Chowdary Veerapaneni , I am interesting in be part of your standalone package contribution together. And I already done a BaseStore concept, which is in PR[ 30295]( [link] Maybe I can PR my PR on your package or something we can achieve together? Let me know if you're OK with that, thanks!"}, {"author": "Sathvik-Chowdary-Veerapaneni", "created_at": "2025-04-16T05:18:04Z", "body_clean": "Hi @manukychen , I’ve completed the standalone package and it’s nearly ready to close. Here’s what I’ve done: Created [code] with [code] . Moved the vector store from [code] . Updated imports to use [code] . Added mock tests for [code] and [code] . Validated functionality with a real OpenSearch instance. Formatted code with [code] and linted with [code] . Documented usage, tests, and setup in [code] . I’m preparing to submit the PR to [code] soon. Meanwhile, I’d love to connect and discuss integrating your [code] from PR 30295 to strengthen the package for future enhancements. Feel free to share ideas or let me know how we can collaborate! Best, Sathvik"}, {"author": "Sathvik-Chowdary-Veerapaneni", "created_at": "2025-05-06T03:07:05Z", "body_clean": "@ccurme The langchain opensearch package name is already taken on PyPI. Can you advise on how to proceed with publishing? existed pypi pkg link: [link] Repo: [link]"}, {"author": "Sathvik-Chowdary-Veerapaneni", "created_at": "2025-05-11T02:07:40Z", "body_clean": "[@ccurme]( [link] The langchain opensearch package name is already taken on PyPI. Can you advise on how to proceed with publishing? existed pypi pkg link: [link] Repo: [link] Hi @ccurme , following up on the package name—please let me know how you'd like to proceed."}]}, {"ollama_summary": "The issue is a broken link within the LangChain documentation (`docs/docs/concepts/chat_models.mdx`) that causes a 404 error when attempting to access the concept page.  After investigating through documentation, search, and code, it appears to be a bug within the LangChain library itself, not a user-defined modification.  The solution requires a fix within the LangChain codebase.", "final_category": "bug", "comments": [{"author": "mattf", "created_at": "2025-03-17T14:03:18Z", "body_clean": "@IgorKasianenko the paths aren't relative to one another within the repo as rendered by github. they're designed to work when published, see [link]"}]}], "business_insights": ["Addressing race conditions in batch processing is critical for reliable and consistent results across concurrent operations.", "Maintaining a stable and predictable integration between LangChain and Hugging Face is vital for application stability and performance.", "Bug fixes in the PydanticOutputParser component must be prioritized to avoid impacting downstream functionality.", "The ChatHuggingface library's integration with the local Hugging Face server is a significant bottleneck.", "Addressing the TypeError in PydanticOutputParser indicates a potential bug in the serialization process.", "Addressing race conditions in batch processing is critical for reliable and consistent results across concurrent operations.", "Maintaining a stable and predictable integration between LangChain and Hugging Face is vital for application stability and performance.", "Bug fixes in the PydanticOutputParser component must be prioritized to avoid impacting downstream functionality.", "The ChatHuggingface library's integration with the local Hugging Face server is a significant bottleneck.", "Addressing the TypeError in PydanticOutputParser necessitates a fix within the LangChain codebase."], "technical_insights": ["The race condition in LangChain batch processing requires a robust synchronization mechanism, potentially involving explicit locking or retry logic.", "The PydanticOutputParser bug necessitates a thorough review of its serialization process and potential version compatibility issues.", "The TypeError in PydanticOutputParser suggests a specific serialization format conflict or bug within the parser.", "The ChatHuggingface integration's reliance on the local Hugging Face server introduces a potential single point of failure.", "The TypeError in PydanticOutputParser suggests a potential issue with the data format being serialized by the parser.", "The race condition in LangChain batch processing requires a robust synchronization mechanism, potentially involving explicit locking or retry logic.", "The PydanticOutputParser bug necessitates a thorough review of its serialization process and potential version compatibility issues.", "The TypeError in PydanticOutputParser suggests a specific serialization format conflict or bug within the parser.", "The ChatHuggingface integration's reliance on the local Hugging Face server introduces a potential single point of failure.", "The TypeError in PydanticOutputParser suggests a potential issue with the data format being serialized by the parser."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Addressing race conditions in batch processing is critical for reliable and consistent results across concurrent operations.\n2.  Maintaining a stable and predictable integration between LangChain and Hugging Face is vital for application stability and performance.\n3.  Bug fixes in the `PydanticOutputParser` component must be prioritized to avoid impacting downstream functionality.\n4.  The `ChatHuggingface` library's integration with the local Hugging Face server is a significant bottleneck.\n5.  Addressing the `TypeError` in `PydanticOutputParser` indicates a potential bug in the serialization process.\n\nTECHNICAL INSIGHTS:\n1.  The race condition in LangChain batch processing requires a robust synchronization mechanism, potentially involving explicit locking or retry logic.\n2.  The `PydanticOutputParser` bug necessitates a thorough review of its serialization process and potential version compatibility issues.\n3.  The `TypeError` in `PydanticOutputParser` suggests a specific serialization format conflict or bug within the parser.\n4.  The `ChatHuggingface` integration's reliance on the local Hugging Face server introduces a potential single point of failure.\n5.  The `TypeError` in `PydanticOutputParser` suggests a potential issue with the data format being serialized by the parser.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Addressing race conditions in batch processing is critical for reliable and consistent results across concurrent operations.\n2.  Maintaining a stable and predictable integration between LangChain and Hugging Face is vital for application stability and performance.\n3.  Bug fixes in the `PydanticOutputParser` component must be prioritized to avoid impacting downstream functionality.\n4.  The `ChatHuggingface` library's integration with the local Hugging Face server is a significant bottleneck.\n5.  Addressing the `TypeError` in `PydanticOutputParser` necessitates a fix within the LangChain codebase.\n\nTECHNICAL INSIGHTS:\n1.  The race condition in LangChain batch processing requires a robust synchronization mechanism, potentially involving explicit locking or retry logic.\n2.  The `PydanticOutputParser` bug necessitates a thorough review of its serialization process and potential version compatibility issues.\n3.  The `TypeError` in `PydanticOutputParser` suggests a specific serialization format conflict or bug within the parser.\n4.  The `ChatHuggingface` integration's reliance on the local Hugging Face server introduces a potential single point of failure.\n5.  The `TypeError` in `PydanticOutputParser` suggests a potential issue with the data format being serialized by the parser.\n", "batch_number": 94, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue involves a broken link to an outdated, self-referential documentation site. The current link redirects users to a separate page explaining the documentation has moved, requiring manual navigation.  The issue is currently unresolved and requires a solution to ensure users can easily access the updated documentation.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-16T16:01:42Z", "body_clean": "Hi, @elsatch. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The link to the Unstructured documentation in the LangChain repository is outdated. You suggested updating the link to redirect to the new site at [link] There have been no comments or activity on this issue since it was opened. Next Steps Could you please confirm if this issue is still relevant to the latest version of the LangChain repository? If so, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue currently presents broken links within the Docling documentation site, specifically when attempting to access the documentation via the URL [link].  The current implementation redirects all links to new sites, but the URLs for Langchain documentation still point to the old project’s site.  The core problem is a persistent 404 error when accessing the documentation.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-16T16:01:41Z", "body_clean": "Hi, @elsatch. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a broken link to the Docling documentation on the LangChain site. The link leads to a 404 error due to pointing to the project's old site. Other links have been updated, but this specific URL still needs revision. No further activity or comments have been made on the issue. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a critical bug in the `youtubeLoader` package that causes it to return invalid object data during the `.load()` method. This issue is impacting the ability to successfully transcribe YouTube videos, and the code attempts to handle different transcript formats, but the `RecursiveCharacterTextSplitter` function fails when encountering a `TranscriptSnippet` object.  The issue is not related to a recent version update of LangChain, suggesting a fundamental problem within the `youtubeLoader` implementation.", "final_category": "bug", "comments": [{"author": "Rafytafy", "created_at": "2025-03-17T19:35:44Z", "body_clean": "I'm also getting this error"}, {"author": "josiahcoad", "created_at": "2025-03-18T18:56:14Z", "body_clean": "same"}, {"author": "phil-scholarcy", "created_at": "2025-03-19T11:55:10Z", "body_clean": "Currently you will need to downgrade youtube transcript api to 0.6.3 as their API has changed significantly from 1.0.x onwards"}, {"author": "khairul746", "created_at": "2025-03-22T14:10:57Z", "body_clean": "Currently you will need to downgrade youtube transcript api to 0.6.3 as their API has changed significantly from 1.0.x onwards This is work for me. thanks a lot"}]}, {"ollama_summary": "The Google Search integration within LangChain is experiencing an error, specifically failing to retrieve the expected results when using the Google GenAI GoogleSearch tool.  The issue appears to be a bug within the integration package rather than the code itself, and attempts to update to the latest version of LangChain haven’t resolved the problem.  Currently, the error occurs when using the Google GenAI GoogleSearch tool with the specified flash version.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a critical error in LangChain where the 'tools[0].function' parameter is missing, triggering an \"invalid_request_error\".  After investigating through documentation, search, and code, the developer believes it’s a bug within LangChain and not their own code.  The solution requires a fix to the LangChain integration package to ensure the required parameter is present.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-15T23:29:52Z", "body_clean": "Thanks for reporting this, I see you marked the issue closed, let me know if the problem persists. Use of the Responses API requires [code] (full release coming soon!)."}, {"author": "yiraeChristineKim", "created_at": "2025-03-17T02:40:01Z", "body_clean": "I didn't see [code] The link directs me beneath the warning sign. and 0.3.9 rc.1 version is working properly Thanks a lot!"}]}], "business_insights": ["Consistent bug reports indicate a need for improved error handling and logging throughout the LangChain ecosystem.", "The youtubeLoader bug highlights the importance of thorough testing and validation of complex data transformations.", "The googleGenAIGoogleSearch issue underscores the need for robust error management and debugging within external API integrations.", "The tools[0].function bug suggests a potential issue with the integration of external libraries or modules.", "Consistent bug reports across different areas point to broader system stability concerns."], "technical_insights": [], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent bug reports indicate a need for improved error handling and logging throughout the LangChain ecosystem.\n2. The `youtubeLoader` bug highlights the importance of thorough testing and validation of complex data transformations.\n3. The `googleGenAIGoogleSearch` issue underscores the need for robust error management and debugging within external API integrations.\n4. The `tools[0].function` bug suggests a potential issue with the integration of external libraries or modules.\n5. Consistent bug reports across different areas point to broader system stability concerns.\n", "batch_number": 95, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue concerns a confusing documentation example for a specific code snippet, which relies on a standard test case that isn’t clearly defined.  The documentation currently uses a specific code example while referencing a different, potentially outdated, test case.  The core request is to update the documentation to accurately reflect the current usage of the code and test case.", "final_category": "other", "comments": []}, {"ollama_summary": "This issue reports a problem where the ChatOllama toolcalling service isn't functioning correctly, leading to errors and a lack of the expected toolcall behavior. The issue stems from a discrepancy between the LangChain integration and the Ollama library, suggesting a potential bug within the LangChain package itself.  It’s being investigated as a potential issue rather than a direct code fault.", "final_category": "bug", "comments": [{"author": "Molinsharian", "created_at": "2025-03-14T21:40:12Z", "body_clean": "Hi, I have the same bug. My workaround at the moment: from langchain openai import ChatOpenAI llm = ChatOpenAI( api key=\"ollama\", model=\"model name\", base url=\" [link] temperature=0, )"}, {"author": "lemassykoi", "created_at": "2025-03-15T01:14:42Z", "body_clean": "Hi, I have the same bug. My workaround at the moment: from langchain openai import ChatOpenAI llm = ChatOpenAI( api key=\"ollama\", model=\"model name\", base url=\" [link] temperature=0, ) same here"}, {"author": "CeyssensHelder", "created_at": "2025-03-15T13:53:39Z", "body_clean": "I found a solution. However it doesn't seem perfectly stable as 2 out of + 10 runs it didn't return a toolcall, while the purely Ollama code worked every time. Tested with mistral, mistral nemo, llama3.1 8B, llama3.2 3B ; stability problem only occured with mistral nemo. Solution: Update Ollama While Ollama states it downloads updates automatically on Windows/macOS, it doesn't automatically apply them. You still have to manually apply them. Update: seems after updating there are still issues with structured output when using ChatOllama, these are not present with ChatOpenAI. As this is a separate issue, I'll keep this ticket closed"}]}, {"ollama_summary": "The issue involves a requirement to pass metadata filters to a chain at runtime, which is currently not supported in LangChain.  The developer has attempted to resolve the problem by searching for similar questions and updating to the latest version, but the bug persists.  Currently, the code uses a \"origin\" metadata attribute in the vector store, and the developer wants to implement this filtering at runtime for improved flexibility.", "final_category": "bug", "comments": [{"author": "XariZaru", "created_at": "2025-03-13T15:26:59Z", "body_clean": "My workaround so far is to completely ignore the ConversationalRetrievalChain and just directly use the Vector Store and pass in my own filters at the time. But it sucks to not use the retrieval chain since I think it does some things under the hood like rephrasing, etc."}, {"author": "XariZaru", "created_at": "2025-03-17T17:47:19Z", "body_clean": "Still waiting @dosubot"}, {"author": "dosubot[bot]", "created_at": "2025-03-17T17:49:23Z", "body_clean": "<! Answer I found a similar discussion that might be helpful: [Passing metadata filter at time of input]( [link] The suggested solution involves extending the [code] class to create a custom retriever that filters documents based on metadata. Here's an example implementation: [code] You can use it like this: [code] This approach allows you to filter documents based on the specified metadata at runtime <sup [[1]]( [link] <! Dosu Comment Footer To continue talking to [Dosu]( [link] mention @dosu. <sup Help Dosu learn! Give it feedback: [Great Response]( [link] | [Irrelevant Answer]( [link] | [Incorrect Sources]( [link] | [Too Verbose]( [link] | [Hallucination]( [link] | [Bug Report]( [link] | [Other]( [link]"}, {"author": "XariZaru", "created_at": "2025-03-17T18:14:11Z", "body_clean": "I found a similar discussion that might be helpful: [Passing metadata filter at time of input]( [link] The suggested solution involves extending the [code] class to create a custom retriever that filters documents based on metadata. Here's an example implementation: class FilteredRetriever(VectorStoreRetriever): vectorstore: VectorStoreRetriever search type: str = \"similarity\" search kwargs: dict = Field(default factory=dict) filter prefix: str def get relevant documents(self, query: str) List[Document]: results = self.vectorstore.get relevant documents(query=query) return [doc for doc in results if doc.metadata['source'].startswith(self.filter prefix)] You can use it like this: filtered retriever = FilteredRetriever(vectorstore=store.as retriever(), filter prefix=\"engageware\") chain = ConversationalRetrievalChain.from llm( llm=llm, retriever=filtered retriever, memory=st.session state.memory, verbose=True, return source documents=True, ) This approach allows you to filter documents based on the specified metadata at runtime [[1]]( [link] To continue talking to [Dosu]( [link] mention [@dosu]( [link] Help Dosu learn! Give it feedback: [Great Response]( [link] | [Irrelevant Answer]( [link] | [Incorrect Sources]( [link] | [Too Verbose]( [link] | [Hallucination]( [link] | [Bug Report]( [link] | [Other]( [link] @dosubot This won't work. This requires the filters to be passed to the VectorStoreRetriever at the time of creation. I want to be able to use the existing VectorStoreRetriever and dynamically pass arguments into it when invoking the chain."}, {"author": "dosubot[bot]", "created_at": "2025-03-17T18:16:05Z", "body_clean": "<! Answer To dynamically pass metadata filters at runtime without modifying the retriever class, you can adjust the [code] to accept dynamic filters. One approach is to modify the retrieval process to include these filters when calling the retriever. Here's a conceptual example of how you might achieve this: 1. Modify the Chain Invocation : When you call the chain, include the filter in the [code] or directly in the retriever's method if it supports dynamic filtering. 2. Custom Wrapper or Function : Create a wrapper function around the chain invocation that injects the filter into the retriever's search parameters. Here's a simplified example: [code] This approach assumes that the retriever can accept a [code] parameter dynamically. If the retriever does not support this directly, you might need to extend or modify the retriever to handle dynamic filters. <! Dosu Comment Footer To continue talking to [Dosu]( [link] mention @dosu. <sup Help Dosu learn! Give it feedback: [Great Response]( [link] | [Irrelevant Answer]( [link] | [Incorrect Sources]( [link] | [Too Verbose]( [link] | [Hallucination]( [link] | [Bug Report]( [link] | [Other]( [link]"}, {"author": "XariZaru", "created_at": "2025-03-19T21:18:52Z", "body_clean": "I proceeded with my own solution after waiting for some time. I inherit the ParentDocumentRetriever class and override the get relevant documents function. Using the retriever's invoke argument, I can pass kwargs through. The invoke function didn't pass these kwargs over to the get relevant documents function, so I decided to go ahead and do it myself. [code] And now we can invoke: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-06-18T16:02:28Z", "body_clean": "Hi, @XariZaru. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where metadata filters couldn't be passed to a chain at input time. Suggestions were made to extend [code] or modify chain invocation, but these were unsuitable for your needs. You implemented a custom solution by inheriting from [code] and overriding [code] for dynamic filtering. Next Steps: Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a discrepancy between the `cosine_relevance_score_fn` in LangChain and MongoDBAtlasVectorSearch, which expects cosine distance but receives cosine similarity. This results in an empty list of documents when the similarity threshold is set to 0.0, despite the function expecting a distance.  The solution is to override the `cosine_relevance_score_fn` to use the raw similarity score directly for accurate filtering.", "final_category": "bug", "comments": [{"author": "Dheeraj-Nalapat", "created_at": "2025-03-13T08:51:33Z", "body_clean": "Raised a PR fix for this issue: [PR]( [link]"}, {"author": "dosubot[bot]", "created_at": "2025-06-12T16:02:52Z", "body_clean": "Hi, @Dheeraj Nalapat. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves a miscalculation in the [code] component. The [code] incorrectly uses cosine similarity instead of cosine distance. You suggested overriding the function to use the raw similarity score directly. A pull request has been raised by you to address and fix this issue. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Dheeraj-Nalapat", "created_at": "2025-06-16T15:52:18Z", "body_clean": "To solve this issue, a PR was raised to langchain mongodb and it was merged."}, {"author": "dosubot[bot]", "created_at": "2025-06-16T15:52:24Z", "body_clean": "Thank you for closing the issue, Dheeraj Nalapat! We appreciate your help in keeping the repository organized."}]}, {"ollama_summary": "The issue reports a failure to generate a JSON Schema for the `core_schema.IsInstanceSchema` class, specifically when attempting to create a JSON Schema for the `langchain_core.vectorstores.in_memory.InMemoryVectorStore` class.  The problem persists across different troubleshooting steps, suggesting a bug within LangChain’s core functionality.  Currently, the issue is not resolved by updating the LangChain version.", "final_category": "bug", "comments": [{"author": "Yuyang-0", "created_at": "2025-04-15T06:55:50Z", "body_clean": "Any update?"}]}], "business_insights": ["Documentation consistency is crucial; updates should be prioritized.", "Testing coverage is vital; existing tests need to be expanded.", "Dependency management is a potential root cause; verify package integrity.", "Code review process effectiveness is needed; identify and address issues early.", "Version control history is important; track changes and revert if necessary."], "technical_insights": ["LangChain integration testing is incomplete; expand testing scope.", "MongoDBAtlasVectorSearch similarity score discrepancy; refine the cosine_relevance_score_fn.", "core_schema.IsInstanceSchema generation failure; investigate LangChain core issue.", "Version control tracking is insufficient; implement stricter version control.", "Dependency versioning needs review; ensure compatibility across projects."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Documentation consistency is crucial; updates should be prioritized.\n2.  Testing coverage is vital; existing tests need to be expanded.\n3.  Dependency management is a potential root cause; verify package integrity.\n4.  Code review process effectiveness is needed; identify and address issues early.\n5.  Version control history is important; track changes and revert if necessary.\n\nTECHNICAL INSIGHTS:\n1.  LangChain integration testing is incomplete; expand testing scope.\n2.  MongoDBAtlasVectorSearch similarity score discrepancy; refine the `cosine_relevance_score_fn`.\n3.  `core_schema.IsInstanceSchema` generation failure; investigate LangChain core issue.\n4.  Version control tracking is insufficient; implement stricter version control.\n5.  Dependency versioning needs review; ensure compatibility across projects.\n\n", "batch_number": 96, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a bug in LangChain where it fails to correctly integrate with DeepSeek.  The user has already investigated using various resources and search methods, concluding it’s likely a bug within the LangChain library itself. The error occurs when attempting to invoke the DeepSeek model, and the user has already tried updating to the latest version.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-24T01:23:57Z", "body_clean": "Can you please update your package version to [code] for langchain aws"}, {"author": "axot", "created_at": "2025-03-24T02:31:51Z", "body_clean": "Hi @keenborder786, appreciate the update. I've encountered an error using langchain aws 0.2.17 that requires additional debugging time. I've added a log for the [code] . Thanks. [code]"}, {"author": "axot", "created_at": "2025-03-26T05:59:00Z", "body_clean": "Hi, after reviewing the document, I found that the validation error was caused by the [code] parameter, which is not supported in the [Deepseek model]( [link] By removing this parameter, the code now works correctly. Thanks! [code]"}]}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where tests are failing due to a missing `ls structured output format` parameter within the `structured output` test case. This issue stems from a discrepancy between the expected implementation and the actual behavior of the LangChain integration, specifically in the `pydantic` and `typeddict` test frameworks.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-12T18:01:10Z", "body_clean": "Hi @mattf, this is deliberate (we should pin [code] in test dependencies if we aren't already). When we call [code] in [code] , we just need to pass in the schema and method. Are you working here? [link] You can see an example here: [link] Schema can be Pydantic model, TypedDict, JSON schema. You can call this function on the schema when passing it in to be safe: [code]"}, {"author": "mattf", "created_at": "2025-03-13T22:29:37Z", "body_clean": "@ccurme understood. thanks for the pointers."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a `TypeError` during a task involving a model named \"agent\" due to a missing authentication method. The error specifically indicates the expected `api_key` or `auth_token` headers are not being provided, requiring a solution related to local LLM support.  The issue is requesting a discussion about expanding the system's support for local LLM models.", "final_category": "question", "comments": []}, {"ollama_summary": "The issue is a float error occurring when using the semantic search retriever, specifically when `k` is greater than or equal to 75. The error is not present when `k` is set to 50, and the root cause is currently unknown. The code involves a `float()` argument that needs to be addressed.", "final_category": "bug", "comments": [{"author": "baravkareknath", "created_at": "2025-03-14T17:58:51Z", "body_clean": "Hi @Keith Ho I understand your thoughts. I’m interested in resolving this kind of issue, but this is my first time contributing. Could you help me with setting up the repository, adding contributions, and other related tasks?"}, {"author": "dosubot[bot]", "created_at": "2025-06-13T16:01:48Z", "body_clean": "Hi, @Keith Ho. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug in LangChain's semantic search occurs when setting [code] to 75 or higher, causing a float conversion error. You provided example code to demonstrate the issue, which persists even after updating to the latest version. User baravkareknath showed interest in resolving the issue and asked for guidance on contributing. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This GitHub issue highlights a problem with the API reference for the `langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings` class. The documentation incorrectly states that the `kwargs` parameter is required, but the code doesn’t actually use it.  The issue is a misunderstanding of the API’s structure, potentially leading to unexpected behavior when using the library.", "final_category": "other", "comments": [{"author": "dhruv1710", "created_at": "2025-03-11T16:48:49Z", "body_clean": "The query encode kwargs parameter was merged with other changes at Nov 7, 2024 and the latest release of langchain huggingface is on Nov 1, 2024 hence the latest changes might not be reflected on your installation."}, {"author": "jiojioblog", "created_at": "2025-03-12T02:31:15Z", "body_clean": "The query encode kwargs parameter was merged with other changes at Nov 7, 2024 and the latest release of langchain huggingface is on Nov 1, 2024 hence the latest changes might not be reflected on your installation. Thank you!!"}]}], "business_insights": ["Package version updates are critical for stability.", "Addressing bugs early prevents cascading failures.", "Testing is essential for code quality and reliability.", "Clear documentation minimizes confusion and errors.", "Dependency management impacts overall system health."], "technical_insights": ["LangChain's integration with DeepSeek is a key area for bug fixes.", "Test framework discrepancies require detailed debugging.", "Missing ls structured output format parameter is a significant issue.", "TypeError related to authentication is a core problem.", "float() argument in the task requires careful consideration."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Package version updates are critical for stability.\n2.  Addressing bugs early prevents cascading failures.\n3.  Testing is essential for code quality and reliability.\n4.  Clear documentation minimizes confusion and errors.\n5.  Dependency management impacts overall system health.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's integration with DeepSeek is a key area for bug fixes.\n2.  Test framework discrepancies require detailed debugging.\n3.  Missing `ls structured output format` parameter is a significant issue.\n4.  `TypeError` related to authentication is a core problem.\n5.  `float()` argument in the task requires careful consideration.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 97, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a problem where the `RunnableConfig` cannot be correctly passed between chained operations within LangChain, specifically when deploying the code to a server.  The problem only manifests in the development environment and isn’t apparent in the deployed environment.  The root cause appears to be a compatibility issue with how the `RunnableConfig` is handled across different systems, requiring a modification to the example code to resolve the issue.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-10T16:01:47Z", "body_clean": "Hi, @FT Fetters. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where [code] fails to pass between chained operations on certain systems. This issue affects callback methods during server deployment but works fine in a development environment. You proposed a solution by incorporating the callback configuration directly within the [code] function. There have been no comments or additional activity on this issue yet. Next Steps: Could you please confirm if this issue is still relevant to the latest version of the LangChain repository? If so, feel free to keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue highlights a significant problem with the LangChain documentation – the notebooks themselves are hindering users’ ability to effectively learn and use the library. Current notebooks are riddled with JSX and hidden code, making them difficult to understand and execute, particularly for developers who want to fully utilize them for local testing and cloud-based development.  The core request is to treat notebooks as “first-class” entities, ensuring they are fully executable and properly configured for various environments, ultimately improving the user experience and promoting best practices.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-10T16:01:40Z", "body_clean": "Hi, @hesreallyhim. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Challenges with [code] notebooks in LangChain documentation. Issues include JSX snippets as raw text, hidden critical code, and execution problems in Colab. Suggestion to treat notebooks as \"first class\" entities for better usability. No comments or developments on the issue yet. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from VertexAIEmbeddings failing to correctly utilize the new GCP project ID after a project switch.  The problem arises because the code relies on the old Gemini project ID, even though it’s not explicitly configured in the source code or environment.  The solution requires updating the code to reflect the new project ID to resolve the integration issue.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue reports a critical problem with the LangChain library, specifically when running the `ls_structured_output_format` keyword argument. The code is encountering a `TypeError` due to an unexpected keyword argument, causing the program to crash.  The issue appears to be related to a recent update to the LangChain library, and a fix is not yet available.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-10T21:52:41Z", "body_clean": "Can you confirm that you are on [code] ? I'd expect this if you are on a lower version (try [code] ). I just failed to reproduce this in a fresh env: [code]"}, {"author": "rtadewald", "created_at": "2025-03-10T22:28:10Z", "body_clean": "Yeah, that was the issue. Thank you so much!!"}]}, {"ollama_summary": "The `chunk_overlap` functionality within the LangChain text splitter is failing when splitting text from an Markdown file, resulting in no overlap between chunks. The issue is not related to a recent update to the LangChain library but appears to be a bug within the RecursiveCharacterTextSplitter component.  The developer is attempting to split text with a 200-character overlap, but the splitter isn't producing the desired result.", "final_category": "bug", "comments": [{"author": "jpdenford", "created_at": "2025-06-05T09:29:37Z", "body_clean": "The same issue seems to be present in the js/ts library ( [code] )"}, {"author": "sachinML", "created_at": "2025-10-12T10:02:24Z", "body_clean": "Hi, I will try to investigate with split documents and add a minimal reproducible example. If it reproduces, I will open a PR with a failing test + fix."}, {"author": "sachinML", "created_at": "2025-10-12T14:16:14Z", "body_clean": "I tested with split documents and confirmed chunk overlap works within a single section. It seems like a configuration pitfall, not a bug. • After [code] , [code] (not [code] ). This preserves per section metadata and applies overlap within each document. • Consider [code] so the header isn’t a tiny first chunk. • Ensure at least one section is longer than chunk size (or reduce separators) so splitting (and overlap) actually occurs. • Overlap is within a section; it does not cross sections. If helpful, I can open a small PR for the docs to add these notes to the Text Splitters guide."}]}], "business_insights": ["LangChain’s RunnableConfig compatibility issues across systems are a recurring challenge, requiring meticulous code modification.", "Notebooks are hindering user learning – comprehensive notebook tutorials are needed.", "The ls_structured_output_format keyword argument failure highlights a fundamental integration problem.", "VertexAIEmbeddings’ Gemini project ID mismatch is a critical integration issue.", "The TypeError related to the ls_structured_output_format keyword is a significant bug affecting code execution."], "technical_insights": ["LangChain’s dependency management and version compatibility are a core concern.", "Notebooks require thorough testing and proper configuration for robust local execution.", "VertexAIEmbeddings’ Gemini project ID handling needs updated code.", "The ls_structured_output_format keyword argument’s integration issue demands debugging.", "The recursive character text splitter’s overlap failure demands code refinement."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s `RunnableConfig` compatibility issues across systems are a recurring challenge, requiring meticulous code modification.\n2. Notebooks are hindering user learning – comprehensive notebook tutorials are needed.\n3.  The `ls_structured_output_format` keyword argument failure highlights a fundamental integration problem.\n4.  VertexAIEmbeddings’ Gemini project ID mismatch is a critical integration issue.\n5.  The `TypeError` related to the `ls_structured_output_format` keyword is a significant bug affecting code execution.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s dependency management and version compatibility are a core concern.\n2.  Notebooks require thorough testing and proper configuration for robust local execution.\n3.  VertexAIEmbeddings’ Gemini project ID handling needs updated code.\n4.  The `ls_structured_output_format` keyword argument’s integration issue demands debugging.\n5.  The recursive character text splitter’s overlap failure demands code refinement.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 98, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a bug in the `trim messages` method of the `azureChatOpenAI` library, specifically when processing messages with `max tokens=100`. This results in an `AttributeError: 'NoneType' object has no attribute 'startswith'` error when attempting to use the `encoding` method. The code snippet demonstrates this issue by showing the `trim messages` function returning an unexpected result.  The issue points to a potential issue with the `tiktoken` library, which is used for encoding, and suggests a bug within the LangChain integration for the AzureChatOpenAI model.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-09T16:02:10Z", "body_clean": "Hi, @simonhuangAI. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an [code] in the [code] method. The error occurs when using the [code] function with the \"last\" strategy. The issue persists with the latest stable version of LangChain. You have verified that your code is not causing the problem. No further activity or comments have been made on this issue. Next Steps: Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a bug in the LangChain text splitter that causes chunks to be significantly smaller than expected due to an excessive number of tokens counted.  The proposed solution involves replacing the default length function with `lambda x: len(tokenizer.tokenize(x))` to address this issue, potentially improving the application's performance and accuracy.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-08T16:01:27Z", "body_clean": "Hi, @keshavshrikant. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in LangChain's text splitting functionality with the Huggingface tokenizer. The [code] function inaccurately adds extra tokens, affecting token counts. The issue persists even after updating to the latest version. Example code was provided to demonstrate the problem. No comments or developments have occurred since the issue was opened. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes it to fail when interacting with OpenAI models, specifically when validating tool names. The bug occurs due to the validation process incorrectly matching the tool names against the OpenAI API's pattern, leading to an error.  The code attempts to validate the tool names, and the issue is a result of the validation failing for JIRA tools, requiring a fix to the LangChain integration.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-03-10T00:15:12Z", "body_clean": "@ccurme , I opened a [PR]( [link] about a week ago for a [similar problem to solve not just for github toolkit]( [link] but for any such future issues and would address this one as well. I understand that we don't want to bloat OAI partner modules, but this one could save a lot of partner patchwork in the future."}, {"author": "dosubot[bot]", "created_at": "2025-06-09T16:02:15Z", "body_clean": "Hi, @bharat p. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] when using Jira Tools with an OpenAI model due to an invalid tool name pattern. @andrasfe commented that they have opened a pull request to address a similar problem. The pull request aims to resolve the issue by ensuring the tool name pattern matches the expected format. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no further updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical bug in the `get_num_tokens_from_messages` function, which is essential for LangChain's model integration. The code attempts to import the `transformers` library, but it's not correctly defined as a dependency for LangChain. This prevents the function from working as intended and requires a lightweight fallback to the full library, potentially causing issues with model integration.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-06T16:01:45Z", "body_clean": "Hi, @g pavlov. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] function in LangChain. The issue is due to an implicit dependency on the [code] package, which is not installed by default. You provided example code and a stack trace for further investigation. The issue remains unresolved, and no additional comments have been made. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue addresses a bug in LangChain that prevents the correct generation of structured output for Anthropic models. The problem stems from a discrepancy in the model's expected input format, requiring adjustments to the prompt template and potentially requiring a model update. The solution involves implementing a fallback mechanism using the `structured output` feature, ensuring that the output is correctly formatted as JSON Schema.", "final_category": "bug", "comments": [{"author": "beezital", "created_at": "2025-03-14T17:26:52Z", "body_clean": "I am facing the same issue, however it does not happen systematically. I am looping several times in my langgraph and on the third time, one of my required JSON key is missing from the answer. When missing, it's always the same key. My prompt explicitly requests to respond in JSON format and lists the required keys (two keys in my case)"}, {"author": "MarioAlessandroNapoli", "created_at": "2025-03-14T21:00:24Z", "body_clean": "Hi, same problem here: langchain google genai==2.1.0 langchain anthropic==0.3.9 langchain core==0.3.45 langchain community==0.3.19 pydantic==2.10.6 pydantic settings==2.8.1 langgraph==0.3.10 openai==1.66.3 uvicorn==0.34.0 fastapi==0.115.8 protobuf==5.29.3 google cloud tasks==2.18.0 google cloud firestore==2.20.0 class ChapterMarkdown(BaseModel): markdown: str = Field( ..., description=\"Contenuto del capitolo formattato in Markdown, che integra nel testo citazioni e riferimenti, corredati da una lista di link a piè di pagina ordinati e conformi agli standard di citazione accademica.\" ) claude 3 5 sonnet = ChatAnthropic( model=\"claude 3 5 sonnet 20241022\", api key=anthropic api key ) synthesis chain = section synthesis prm | claude 3 5 sonnet.with structured output(ChapterMarkdown) Output with a pydantic error for missing \"markdown\" key, just the one needed."}, {"author": "vk-maurya", "created_at": "2025-03-20T07:07:33Z", "body_clean": "I am experiencing a similar problem, where the instructor library performs smoothly with the same prompt, processing 200 documents without issues. However, when using langchain , it fails every 2nd or 3rd documents, whereas the instructor library consistently produces accurate results. In contrast, Langchain on OpenAI seems to be working flawlessly, raising questions about the inconsistencies between these different tools and libraries. I am unsure about the specific function of the instructor library, but it seems to be performing some kind of magic that makes it work seamlessly with both models. ![Image]( [link]"}, {"author": "viknesh-nm", "created_at": "2025-03-25T23:57:38Z", "body_clean": "I'm also facing an issue when using ChatAnthropic with LangChain to generate structured output using Pydantic models. The structured response is inconsistent—out of 50 executions, only 1 successfully returns a valid structured response. Most of the time, I encounter validation errors due to incorrectly formatted output. Expected Behavior: The LLM should return a valid structured JSON response that conforms to the SkillAIImpactAnalysis Pydantic model. The response should be properly parsed and validated without errors. Observed Behavior: The output from ChatAnthropic appears to be returning a string representation of JSON instead of a valid JSON object. This leads to Pydantic validation errors, mainly around list parsing and missing required fields. Error Message [code] or [code] Sample Code(To reproduce) [code] Steps to Reproduce: Run the script multiple times. Observe that the majority of runs fail with a ValidationError, indicating that the response is not correctly formatted. Occasionally, the structured output is correctly parsed and validated. Possible Cause: The output from ChatAnthropic might be formatted as a string instead of proper JSON. LangChain’s with structured output() may not be enforcing correct JSON serialization. There could be inconsistency in how the model structures responses under different token limits. Suggested Fixes: Ensure the output from ChatAnthropic is always a valid JSON object before passing it to Pydantic. Explicitly parse and validate the response using json.loads() before feeding it into the Pydantic model. Consider using json mode=True if ChatAnthropic supports enforcing proper JSON format. Environment: langchain anthropic version: 0.3.4 pydantic version: 2.9.2 Python version: 3.12 Anthropic Model: claude 3 7 sonnet 20250219 If needed, I can provide more logs or test cases to help debug the issue. Would appreciate any guidance on ensuring reliable structured output with ChatAnthropic. Thanks!"}, {"author": "sangwooklee0201", "created_at": "2025-03-28T20:37:22Z", "body_clean": "I am also experiencing the same issue. langchain plz fix it"}, {"author": "aperera12", "created_at": "2025-04-03T04:18:20Z", "body_clean": "same here, very frustrating. to put things in perspective, the structured output works better with qwen2.5 coder 14b running locally on my laptop 👎"}, {"author": "vk-maurya", "created_at": "2025-04-10T12:52:35Z", "body_clean": "Some level of problem solved by using litellm instead of direct initiating anthropic model through Langchain [code]"}, {"author": "berkbirkan", "created_at": "2025-04-13T10:44:09Z", "body_clean": "@vk maurya Unfortunately ChatLiteLLM does not support structured output feature. So it does not solve this problem. Thank you for your help."}, {"author": "AhmedTammaa", "created_at": "2025-04-20T00:14:04Z", "body_clean": "I had the same issue. After investigation, I found the reason happens when you exceed tokens limit. The token limit for Anthropic is defaulted to 1024 which is very little I guess. Increasing it will solve the problem. I am working on a PR to give more meaningful error message I hope that solves your issue @berkbirkan P.S. on contorary, ChatOpenAI have max tokens as None but anthropic doesn't support that it must be an integer as per their [docs]( [link]"}, {"author": "berkbirkan", "created_at": "2025-04-20T13:30:36Z", "body_clean": "I had the same issue. After investigation, I found the reason happens when you exceed tokens limit. The token limit for Anthropic is defaulted to 1024 which is very little I guess. Increasing it will solve the problem. I am working on a PR to give more meaningful error message I hope that solves your issue [@berkbirkan]( [link] P.S. on contorary, ChatOpenAI have max tokens as None but anthropic doesn't support that it must be an integer as per their [docs]( [link] Thanks for the solution suggestion but unfortunately it didn't work for me. I had already removed the anthropic integration and added alternatives like xai, groq instead. The parameter you mentioned is exactly the same as openai in these llm models. So unfortunately nothing changed. But thanks for your suggestion anyway. I hope it will be useful for others. @AhmedTammaa"}, {"author": "AhmedTammaa", "created_at": "2025-04-20T14:07:16Z", "body_clean": "@berkbirkan Thanks for your response. We can do something as a debugging step Can you re run the code but with [code] It would even be more helpful if you could run something like [code]"}, {"author": "berkbirkan", "created_at": "2025-04-20T14:45:54Z", "body_clean": "[@berkbirkan]( [link] Thanks for your response. We can do something as a debugging step Can you re run the code but with [code] It would even be more helpful if you could run something like from langchain core.output parsers import ( JsonOutputKeyToolsParser, ) tools = [your pydantic object.model json schema()] output parser = JsonOutputKeyToolsParser( key name=your pydantic object name, first tool only=True ) llm = ChatAnthropic(model=\"claude 3 7 sonnet latest\").bind tools(tools, tool choice=\"CallScriptTemplate\") res = llm.invoke(your input) print(res.response metadata) When I rebooted the server, I noticed that the update (your first suggestion) worked without any problems. Thanks. :)"}]}], "business_insights": ["Dependency management is a recurring issue, requiring consistent updates across multiple libraries.", "Lack of clear error handling contributes to unexpected failures and debugging challenges.", "Integration testing is crucial; insufficient tests expose bugs early.", "Code duplication across different libraries necessitates refactoring.", "Documentation gaps hinder understanding of dependencies and their impact."], "technical_insights": ["AttributeError: 'NoneType' object has no attribute 'startswith' indicates a potential issue with the tiktoken library's encoding process.", "LangChain's integration with OpenAI models is a complex area, requiring careful attention to validation.", "The get_num_tokens_from_messages function is a critical component, and its bug impacts model integration.", "The langchain library has multiple versions, impacting the stability of the application.", "The structured output feature is a workaround for the model's expected input format, potentially requiring modification."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management is a recurring issue, requiring consistent updates across multiple libraries.\n2.  Lack of clear error handling contributes to unexpected failures and debugging challenges.\n3.  Integration testing is crucial; insufficient tests expose bugs early.\n4.  Code duplication across different libraries necessitates refactoring.\n5.  Documentation gaps hinder understanding of dependencies and their impact.\n\nTECHNICAL INSIGHTS:\n1.  `AttributeError: 'NoneType' object has no attribute 'startswith'` indicates a potential issue with the `tiktoken` library's encoding process.\n2.  LangChain's integration with OpenAI models is a complex area, requiring careful attention to validation.\n3.  The `get_num_tokens_from_messages` function is a critical component, and its bug impacts model integration.\n4.  The `langchain` library has multiple versions, impacting the stability of the application.\n5.  The `structured output` feature is a workaround for the model's expected input format, potentially requiring modification.\n", "batch_number": 99, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in LangChain where the `model` setting for OpenAI Embeddings is incorrectly defaulting to \"BAAI/bge m3\" instead of the intended \"model\" value. This issue impacts the deployment of the LangChain code and requires a fix to ensure the correct model is used.", "final_category": "bug", "comments": [{"author": "xuzexin-hz", "created_at": "2025-03-21T10:40:48Z", "body_clean": "It's a bit unclear, what's the error message? openai api base=\" [link] what is this address? The address of ollama is not this"}, {"author": "spyron1", "created_at": "2025-03-28T21:21:11Z", "body_clean": "The issue is due to how the library initializes the deployment parameter internally. Even if you pass deployment=\"BAAI/bge m3\", the constructor later sets it to the default (\"text embedding ada 002\") based on its processing order. Two workarounds are: 1.Upgrade the langchain openai package if a fixed version is available. 2.Override the deployment value after initializing the embeddings. For example: [code]"}, {"author": "spyron1", "created_at": "2025-03-28T21:55:37Z", "body_clean": "need to change then this issue may fixed Change on libs/community/langchain community/embeddings/openai.py line 196 from: deployment: Optional[str] = model to: deployment: Optional[str] = None @model validator(mode=\"after\") @classmethod def set default deployment(cls, values: Dict[str, Any]) Dict[str, Any]: if deployment was not explicitly passed, use model if values.get(\"deployment\") is None: values[\"deployment\"] = values.get(\"model\") return values Note:make indentation accordingly With This change If a user creates an instance without passing a deployment, then deployment will be set to the value of model. If a user explicitly passes a deployment (like \"BAAI/bge m3\"), that value remains."}, {"author": "dosubot[bot]", "created_at": "2025-06-27T16:02:00Z", "body_clean": "Hi, @wskbest. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The \"engine\" parameter does not automatically set to the \"model\" parameter, causing deployment defaults to 'text embedding ada 002'. xuzexin hz requested clarification on the error message and API address. spyron1 identified the cause and suggested upgrading the langchain openai package or manually overriding the deployment value. A code change was proposed to default the deployment parameter to the model value if not set. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical bug in the LangChain library that causes ApacheDoris to write data but fail to read it when attempting to read it. This impacts the integration with Alibaba Cloud SelectDB, potentially leading to data inconsistencies and errors.  The issue suggests a potential incompatibility between the LangChain integration and the SelectDB data model, requiring a fix before further testing or production deployment.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-06T16:01:48Z", "body_clean": "Hi, @dominwong4. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary A bug was reported regarding data interaction with Alibaba Cloud SelectDB using ApacheDoris. Data can be written but not read back, affecting the [code] function. You provided example code and suggested a fix by modifying the SQL query string. No additional comments or activities have been made on this issue. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a discrepancy between the current documentation description and the intended content, specifically regarding chat history. The documentation currently describes chat history as [code], while the image shows the desired description as [code].  The issue requests a change to ensure the documentation accurately reflects the intended content and visual representation.", "final_category": "other", "comments": [{"author": "YassinNouh21", "created_at": "2025-03-07T12:17:45Z", "body_clean": "@woodliu I think it should be like this [code]"}, {"author": "githubalexliu", "created_at": "2025-03-12T03:12:56Z", "body_clean": "Hey, I’m interested in working on this issue. Is anyone actively working on it, or is it open for contribution?"}, {"author": "YassinNouh21", "created_at": "2025-03-12T03:14:28Z", "body_clean": "Hey, I’m interested in working on this issue. Is anyone actively working on it, or is it open for contribution? Actually i created branch I will make pr tomorrow"}, {"author": "dosubot[bot]", "created_at": "2025-06-11T16:02:03Z", "body_clean": "Hi, @woodliu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You raised a concern about a discrepancy in the LangChain documentation regarding chat history descriptions. YassinNouh21 provided a detailed suggestion for the correct structure, which you acknowledged positively. Githubalexliu showed interest in contributing, but YassinNouh21 has already created a branch and plans to submit a pull request. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical bug in the LangChain `ChatAnthropic` library that causes it to fail when using the `thinking={ \"type\": \"enabled\", \"budget tokens\": 1024}` parameter. The code attempts to invoke the `ChatAnthropic` model, but the `[link]` parameter is causing the error.  The issue appears to be a fundamental incompatibility with the `thinking` parameter, requiring a fix before the library can function correctly.", "final_category": "bug", "comments": [{"author": "chakravarthik27", "created_at": "2025-03-07T06:58:58Z", "body_clean": "Hi @zhanghao AI , are you working on this feature?"}, {"author": "zhanghao-AI", "created_at": "2025-03-07T07:23:57Z", "body_clean": "Hi [@zhanghao AI]( [link] , are you working on this feature? I encountered this problem when I used langchain to call the claude 3 7 sonnet 20250219 model, and it has not been solved yet. Do you have any solution?"}, {"author": "chakravarthik27", "created_at": "2025-03-07T07:28:21Z", "body_clean": "No, but I will fix this issue as soon as possible."}, {"author": "zhouruiliangxian", "created_at": "2025-03-08T08:51:10Z", "body_clean": "TypeError Traceback (most recent call last) Cell In[1], line 2 1 from langchain openai import ChatOpenAI 2 llm = ChatOpenAI( 3 temperature=0.95, 4 model=\"GLM 4 Air\", 5 openai api key=\"\", 6 openai api base=\" [link] 7 ) File d:\\soft\\anaconda\\envs\\langchain\\Lib\\site packages\\langchain core\\load\\serializable.py:125, in Serializable. init (self, args, kwargs) 123 def init (self, args: Any, kwargs: Any) None: 124 \"\"\"\"\"\" 125 super(). init ( args, kwargs) [... skipping hidden 1 frame] File d:\\soft\\anaconda\\envs\\langchain\\Lib\\site packages\\langchain openai\\chat models\\base.py:527, in BaseChatOpenAI.validate environment(self) 525 self. [link] = [link] 526 sync specific = {\" [link] self. [link] 527 self.root client = openai.OpenAI( client params, sync specific) type: ignore[arg type] 528 self.root client = openai.OpenAI( client params) type: ignore[arg type] 529 self.client = self.root client.chat.completions File d:\\soft\\anaconda\\envs\\langchain\\Lib\\site packages\\openai\\ client.py:123, in OpenAI. init (self, api key, organization, project, base url, timeout, max retries, default headers, default query, [link] strict response validation) 120 if base url is None: 121 base url = f\" [link] 123 super(). init ( 124 version= version , 125 base url=base url, 126 max retries=max retries, 127 timeout=timeout, 128 [link] 129 custom headers=default headers, 130 custom query=default query, 131 strict response validation= strict response validation, 132 ) 134 self. default stream cls = Stream 136 self.completions = resources.Completions(self) File d:\\soft\\anaconda\\envs\\langchain\\Lib\\site packages\\openai\\ base client.py:856, in SyncAPIClient. init (self, version, base url, max retries, timeout, transport, proxies, limits, [link] custom headers, custom query, strict response validation) 839 raise TypeError( 840 f\"Invalid [code] argument; Expected an instance of [code] but got {type( [link] 841 ) 843 super(). init ( 844 version=version, 845 limits=limits, (...) 854 strict response validation= strict response validation, 855 ) 856 self. client = [link] or SyncHttpxClientWrapper( 857 base url=base url, 858 cast to a valid type because mypy doesn't understand our type narrowing 859 timeout=cast(Timeout, timeout), 860 proxies=proxies, 861 transport=transport, 862 limits=limits, 863 follow redirects=True, 864 ) File d:\\soft\\anaconda\\envs\\langchain\\Lib\\site packages\\openai\\ base client.py:754, in DefaultHttpxClient. init (self, kwargs) 752 kwargs.setdefault(\"limits\", DEFAULT CONNECTION LIMITS) 753 kwargs.setdefault(\"follow redirects\", True) 754 super(). init ( kwargs) TypeError: Client. init () got an unexpected keyword argument 'proxies' I also have the same problem, what the problem is?"}, {"author": "chakravarthik27", "created_at": "2025-03-08T12:24:32Z", "body_clean": "proxies A dependencies issue arose with [code] . To fix this, you can either upgrade the OpenAI SDK or downgrade the [code] version. References: [link]"}, {"author": "pandel", "created_at": "2025-03-25T20:27:28Z", "body_clean": "@chakravarthik27 Sorry to bother you, but do you have a timeframe for fixing this? I do have the need to use [code] over a corporate proxy and I am totally lost atm, because I cannot add [code] parameter and am unable to use my own [code] with the correct proxy settings even though I use [code] . Or do you have another idea how to assign a corporate proxy to the [code] [link] client? Is there maybe an [code] environment variable (like the [code] one), that I did not find yet? EDIT: to be clear, this is what I tried and ends up with a [code] error [code]"}, {"author": "pandel", "created_at": "2025-03-26T14:45:24Z", "body_clean": "@zhanghao AI I use a workaround for now to set the [link] client explicitely, maybe it is of any help: You need [code] [code]"}, {"author": "andrasfe", "created_at": "2025-04-02T22:57:36Z", "body_clean": "@chakravarthik27 , I can take care of this if you don't have time. LMK"}, {"author": "xiaohui-hiwintech", "created_at": "2025-04-08T11:15:06Z", "body_clean": "update: sorry, it works for the async model, I didn't make the proper changes to the code."}, {"author": "hengjingzhu", "created_at": "2025-04-16T08:58:33Z", "body_clean": "[@zhanghao AI]( [link] I use a workaround for now to set the [link] client explicitely, maybe it is of any help: You need [code] [code] @pandel it works.thanks bro."}]}, {"ollama_summary": "This issue stems from a bug in Ollama that causes a `pydantic` error when parsing arguments from tool calls, specifically when the tool expects a string but receives an integer. The bug is caused by the `tool call` dictionary having inconsistent argument structure, leading to the `pydantic` library incorrectly interpreting the data.  The proposed solutions involve checking expected data types and parsing only as JSON if basic JSON patterns are present, or implementing a more robust parsing mechanism.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-18T17:37:12Z", "body_clean": "@pawelka @keenborder could someone please provide a minimal reproducible example of the underlying issue? e.g., something like this (I can't actually reproduce the problem) [code]"}, {"author": "pawelka", "created_at": "2025-03-18T18:19:28Z", "body_clean": "Here is sample code to reproduce issue: [code]"}, {"author": "ccurme", "created_at": "2025-03-20T11:27:38Z", "body_clean": "Thanks @pawelka, that was very helpful. @keenborder landed a fix in [link] Will go out in next release."}, {"author": "dosubot[bot]", "created_at": "2025-06-19T16:01:59Z", "body_clean": "Hi, @pawelka. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug where string arguments consisting solely of digits were incorrectly converted to integers. You provided a minimal reproducible example, which helped in identifying the issue. @keenborder implemented a fix, confirmed by @ccurme, which will be included in the next release. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Incorrect model defaulting highlights potential API instability.", "BAAI/bge m3 is a known issue; fix is crucial for deployment.", "Library initialization issues impact broader deployment strategy.", "SelectDB data model incompatibility requires careful integration.", "Documentation discrepancy necessitates updated content.", "Incorrect model defaulting highlights potential API instability.", "BAAI/bge m3 is a known issue; fix is crucial for deployment.", "Library initialization issues impact broader deployment strategy.", "SelectDB data model incompatibility requires careful integration.", "Documentation discrepancy necessitates updated content."], "technical_insights": ["LangChain initialization parameter issues affect model deployment.", "ApacheDoris data writing failures necessitate a fix.", "LangChain integration with SelectDB data model requires attention.", "thinking parameter incompatibility with ChatAnthropic model.", "Ollama pydantic error handling impacts tool calls.", "LangChain initialization parameter issues affect model deployment.", "ApacheDoris data writing failures necessitate a fix.", "LangChain integration with SelectDB data model requires attention.", "thinking parameter incompatibility with ChatAnthropic model.", "Ollama pydantic error handling impacts tool calls."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Incorrect model defaulting highlights potential API instability.\n2.  `BAAI/bge m3` is a known issue; fix is crucial for deployment.\n3.  Library initialization issues impact broader deployment strategy.\n4.  `SelectDB` data model incompatibility requires careful integration.\n5.  Documentation discrepancy necessitates updated content.\n\nTECHNICAL INSIGHTS:\n1.  LangChain initialization parameter issues affect model deployment.\n2.  ApacheDoris data writing failures necessitate a fix.\n3.  LangChain integration with SelectDB data model requires attention.\n4.  `thinking` parameter incompatibility with `ChatAnthropic` model.\n5.  Ollama `pydantic` error handling impacts tool calls.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Incorrect model defaulting highlights potential API instability.\n2.  `BAAI/bge m3` is a known issue; fix is crucial for deployment.\n3.  Library initialization issues impact broader deployment strategy.\n4.  `SelectDB` data model incompatibility requires careful integration.\n5.  Documentation discrepancy necessitates updated content.\n\nTECHNICAL INSIGHTS:\n1.  LangChain initialization parameter issues affect model deployment.\n2.  ApacheDoris data writing failures necessitate a fix.\n3.  LangChain integration with SelectDB data model requires attention.\n4.  `thinking` parameter incompatibility with `ChatAnthropic` model.\n5.  Ollama `pydantic` error handling impacts tool calls.", "batch_number": 100, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\n**Problem:** The type checker is flagging a potential issue with a type hint inherited from a `BaseTool` class.\n\n**Key Details:** The issue stems from a documentation discrepancy – the type hint for the inherited class is incorrect, causing the type checker to warn.\n\n**Proposed Solution:** The author has added a descriptive title and a link to the relevant documentation to clarify the issue and provide context.", "final_category": "other", "comments": [{"author": "eyurtsev", "created_at": "2025-03-07T03:55:38Z", "body_clean": "@shengbo ma you can try to see if you can fix this issue. Generally you can accomplish everything with the @tool decorator"}, {"author": "shengbo-ma", "created_at": "2025-03-07T19:18:24Z", "body_clean": "@eyurtsev Thanks for the advise. @tool decorator may not be a solution for my case: I am adding addtional static non serializable attributes to use in my tool instance. Inheriting from [code] allows me to create a customize tool class that all my tools can inherit from. [code] I saw [your advice in another issue is to wrap a @tool decorated function inside anther function to keep such static args]( [link] but the function style way make it hard to write a base class for all my tools to inherit from. [Inject runtime args feature]( [link] may help but it targets runtime behavior, and is hard to implement (I haven't do deep investigation). Will langChain support it in future?"}, {"author": "eyurtsev", "created_at": "2025-03-07T19:31:12Z", "body_clean": "You're free to do that if you'd like"}, {"author": "shengbo-ma", "created_at": "2025-03-07T19:52:21Z", "body_clean": "@eyurtsev sent PR to fix: [link]"}]}, {"ollama_summary": "The ChatVertexAI application is experiencing a critical bug that causes it to fail when prompted with previous tool calls and outputs. This issue appears to stem from a problem within LangChain’s implementation of the ChatVertexAI model, potentially involving a bug in the core functionality. The code also shows a dependency on a newer version of the `langchain` library, which is causing issues with existing packages.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-06T21:36:29Z", "body_clean": "Hello, It's possible that ChatVertexAI is not reading the function calls off of [code] . My strong recommendation though is to use tool messages instead of function messages (function messages are [legacy]( [link] All agent constructors in the docs will emit ToolMessages. They are like function messages but use [code] instead of [code] to identify corresponding tool calls (so they support multiple calls to the same tool, which function messages do not). Here is updated code for your example: [code] This will work with any LangChain chat model that supports tool calling. Instead of creating the agent using [code] , your best bet is to use langgraph as in the agents tutorial in the docs: [link] You can also use [create tool calling agent]( [link] which uses a chain similar to yours: [link] Either of these methods should work with ChatVertexAI (but if you can migrate, langgraph is a better option)."}, {"author": "Onturenio", "created_at": "2025-03-07T17:49:12Z", "body_clean": "Using [code] worked nicely. Thank you very much!"}]}, {"ollama_summary": "Okay, here's a summary of the code snippets provided, broken down by category and potential implications:\n\n**1. Python Code (Most Relevant):**\n\n*   **`volcengine` initialization:** This is the primary focus. It's a library for quickly creating and managing virtual machines (VMs) in the Google Cloud Platform (GCP).  It's used to deploy and manage the code.\n*   **`pydeck` initialization:**  This is a library for creating 3D maps. It's used to visualize data.\n*   **`pydeck.plotting.plot`:** This is a function used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.plot`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data`:** This function is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This function is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot.data.plot.data`:** This is used to create a plot of the Pydeck map.\n*   **`pydeck.plotting.plot", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-05T16:01:39Z", "body_clean": "Hi, @JoShamash. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are encountering an error with the VolcEngineMaasLLM integration in LangChain. The API is reported as unsupported despite verifying your code and LangChain version. No solution has been found in the available documentation. There have been no comments or updates from other users or maintainers on this issue yet. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue involves a persistent placeholder formatting problem within the LangChain code, specifically with the `[code]` placeholder. The code is exhibiting an error message and stack trace, indicating a fundamental bug that doesn't appear to be resolved by recent updates to the LangChain library.", "final_category": "bug", "comments": [{"author": "YassinNouh21", "created_at": "2025-03-07T12:37:32Z", "body_clean": "@skabbit The Issue When using [code] , you would expect all variable placeholders to follow mustache syntax ( [code] ), but the [code] still expects the f string format ( [code] ). Let's look at how to fix this: Solution You need to use [code] for the placeholder variable name, even when the template format is set to [code] : [code] Why This Happens Looking at the codebase, the [code] class in <mcfile name=\"langchain core/prompts/chat.py\" path=\"/Users/ds/open source/langchain/langchain/libs/core/langchain core/prompts/chat.py\" </mcfile doesn't respect the template format setting of the parent [code] . It always uses the variable name directly without any template formatting. From the code snippet at line 274 275: [code] This is why you need to use [code] instead of [code] for the placeholder variable name."}, {"author": "skabbit", "created_at": "2025-03-11T10:05:22Z", "body_clean": "I think at least that must be covered in documentation, because it was unexpected surprise to our team: we changed template engine and lost all conversation without any error raised on that. Only adding langchain specific test could help avoiding this case (what we actually did in our tests), but that's not what people expect from any library."}, {"author": "YassinNouh21", "created_at": "2025-03-11T10:21:50Z", "body_clean": "I think at least that must be covered in documentation, because it was unexpected surprise to our team: we changed template engine and lost all conversation without any error raised on that. Only adding langchain specific test could help avoiding this case (what we actually did in our tests), but that's not what people expect from any library. I'm glad that I solved your problem so can you mark my answer my comment as a correct answer that solves your problem so that others can know the problem"}, {"author": "skabbit", "created_at": "2025-03-11T10:44:51Z", "body_clean": "To be honest, I solved it way before your comment) My bug report is to update documentation or improve engine compatibility with placeholders."}, {"author": "dosubot[bot]", "created_at": "2025-06-10T16:01:47Z", "body_clean": "Hi, @skabbit. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with [code] using [code] . The placeholder remained an f string instead of using mustache syntax. @YassinNouh21 suggested using [code] instead of [code] to resolve the issue. You highlighted the need for documentation updates to prevent similar issues. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further activity occurs, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\n**Summary:** The LangChain maintainer is requesting a migration from the `tree-sitter-languages` library to the newer `tree sitter language pack`. This is a critical issue as the `tree-sitter-languages` library is no longer maintained and is being used as a component in LangChain's document loaders.\n\n**Key Details:** The issue highlights the need to replace an outdated library with a more actively developed and maintained alternative for document loading within LangChain.\n\nLet me know if you'd like me to elaborate on any specific aspect!", "final_category": "question", "comments": [{"author": "MarsWangyang", "created_at": "2025-03-06T01:42:34Z", "body_clean": "My Python version is 3.13 and it seems that lots of people have this package downloading problem. Not sure if it happens on previous Python version, but [code] doesn't work on Python 3.13 Here is the workaround: [link]"}, {"author": "pebabion", "created_at": "2025-05-13T19:43:37Z", "body_clean": "Hey @ccurme I would like to pick this up."}, {"author": "mdrxy", "created_at": "2025-07-21T23:34:07Z", "body_clean": "@pebabion you got it"}]}], "business_insights": ["Dependency management is a recurring challenge across multiple issues, highlighting potential risks in software development pipelines.", "Maintaining consistent library versions across different projects is crucial for stability and compatibility.", "The tree-sitter-languages library issue suggests a shift in LangChain's technology stack, requiring careful consideration of library dependencies.", "Addressing library compatibility issues proactively minimizes disruption to users and development teams.", "Documenting library versions and update strategies is essential for managing risk and ensuring long-term maintainability."], "technical_insights": ["LangChain's reliance on tree-sitter-languages suggests a potential vulnerability in LangChain's integration with external document processing tools.", "The tree-sitter-languages library issue is a significant operational risk, potentially impacting LangChain's core functionality.", "The pydeck.plotting.plot.data issue points to a bug within LangChain's plotting module, impacting visualization.", "The tree sitter language pack migration is a critical architectural change requiring careful planning and testing.", "The tree-sitter-languages library issue demands a thorough review of LangChain's dependency management practices."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management is a recurring challenge across multiple issues, highlighting potential risks in software development pipelines.\n2.  Maintaining consistent library versions across different projects is crucial for stability and compatibility.\n3.  The `tree-sitter-languages` library issue suggests a shift in LangChain's technology stack, requiring careful consideration of library dependencies.\n4.  Addressing library compatibility issues proactively minimizes disruption to users and development teams.\n5.  Documenting library versions and update strategies is essential for managing risk and ensuring long-term maintainability.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's reliance on `tree-sitter-languages` suggests a potential vulnerability in LangChain's integration with external document processing tools.\n2.  The `tree-sitter-languages` library issue is a significant operational risk, potentially impacting LangChain's core functionality.\n3.  The `pydeck.plotting.plot.data` issue points to a bug within LangChain's plotting module, impacting visualization.\n4.  The `tree sitter language pack` migration is a critical architectural change requiring careful planning and testing.\n5.  The `tree-sitter-languages` library issue demands a thorough review of LangChain's dependency management practices.\n\n", "batch_number": 101, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in the LangChain document loader that prevents it from correctly utilizing a specific resource, causing an error in the script. The bug is related to an outdated version of the tree sitter library, which is causing the loader to fail.  The developers are migrating to a new version of the loader, and the issue is currently not resolvable through updates to the latest stable version.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-05T23:27:37Z", "body_clean": "I see the project [on pypi]( [link] and [code] in a fresh env seems to work, but I do see the readme specifies that it is no longer maintained. Created a help wanted issue to track: [link] Closing in favor of that one."}]}, {"ollama_summary": "The Langchain-openai library is experiencing a critical bug where the `temperature` parameter is consistently causing a 400 error when using the AzureChatOpenAI deployment with the o3 mini model. This issue stems from a conflict with a specific LangChain integration package, requiring a downgrade to version 0.1.6.  The bug is reproducible through a specific evaluation workflow involving the o3 mini deployment and is blocking the evaluation process.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-03-05T20:32:12Z", "body_clean": "The cause of the issue is likely that older versions of langchain openai set a default temperature that is incompatible with o3 mini. You should not run into this issue for langchain openai 0.3, which changed the default to null. If you cannot upgrade langchain openai, you should be able to explicitly pass a temperature of [code] or [code] . Let me know if that does not resolve the problem. Regarding the difficulties upgrading the version: let me know if the conflicts are coming from the langchain ecosystem and I can provide guidance."}, {"author": "keyoumao", "created_at": "2025-03-05T20:55:58Z", "body_clean": "Thank you @ccurme! I tried both by explicitly passing a temperature of None or 1. I am using o3 mini as a evaluator with RAGAS, still get the same error message: see the redacted version below: [code] . Maybe I should ask for [ [link] ? This works for gpt 4o and 4o mini."}, {"author": "keyoumao", "created_at": "2025-03-06T16:34:32Z", "body_clean": "I found a similar issue in RAGAS: [ [link]"}, {"author": "JShuang7711", "created_at": "2025-03-12T13:41:48Z", "body_clean": "do we have solution to fix it? I am using o3 mini as a evaluator with RAGAS, still get the same error message."}]}, {"ollama_summary": "This issue reports a critical error when creating a LanceDB vectorstore table using the LangChain code. The `ErrorMessage` indicates a problem with the `langchain` integration, specifically when importing a required module.  The code attempts to create the table, but the vectorstore constructor fails due to a missing import statement, requiring a fix involving adding the missing import.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-04T16:01:38Z", "body_clean": "Hi, @metadaddy. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: An [code] occurs when creating a LanceDB vectorstore with a table. The error is due to a missing import of [code] . You suggested adding the missing import to resolve the issue. The problem persists with the latest version of LangChain. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "metadaddy", "created_at": "2025-06-04T17:39:41Z", "body_clean": "Closing this, since 30127 has been merged and was released in LangChain Community 0.3.20."}, {"author": "dosubot[bot]", "created_at": "2025-06-04T17:39:48Z", "body_clean": "Thank you for closing the issue, metadaddy! We appreciate your help in keeping the repo organized."}]}, {"ollama_summary": "The issue involves a problem with the Granite 3.2 Thinking system that prevents the creation of a React Agent using langchain. A minimal reproducible example was provided, including all necessary code and dependencies, but the agent creation fails to run correctly.  The solution requires a fix to the langchain dependencies and potentially the Granite 3.2 implementation itself.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2025-03-05T16:19:23Z", "body_clean": "does Ollama actually support \"control\" message? i believe you need to use \"system\" message instead. or perhaps there is some other way to supply this param via a config? do you have any docs referencing this \"control\" message?"}, {"author": "lemassykoi", "created_at": "2025-03-05T16:25:31Z", "body_clean": "[ [link] ![Image]( [link]"}, {"author": "hinthornw", "created_at": "2025-03-05T16:43:39Z", "body_clean": "Did you try a ChatMessage with the control type"}, {"author": "lemassykoi", "created_at": "2025-03-05T17:05:49Z", "body_clean": "Did you try a ChatMessage with the control type hmmm ok, you are right : I tried with ollama without langchain [code] exception : [code] I don't understand as ollama 0.5.13 support all Granite3.2 models"}, {"author": "lemassykoi", "created_at": "2025-03-05T17:08:52Z", "body_clean": "here is a reference message : [link]"}, {"author": "lemassykoi", "created_at": "2025-03-05T17:15:58Z", "body_clean": "this is working : [code] Answer: [code]"}, {"author": "lemassykoi", "created_at": "2025-03-06T06:27:59Z", "body_clean": "with a patch from ollama, error is now from langchain core see [ [link] I updated traceback in first post"}, {"author": "rylativity", "created_at": "2025-03-06T23:25:54Z", "body_clean": "Ollama server has no problem processing messages with the \"control\" role. However, both ollama python (ollama python client) and langchain (specifcally langchain core) raise an error if a message's 'role' field/attribute is not one of a set of accepted literals. The PR linked by @lemassykoi resolves the error raised by ollama python, but it looks like similar changes would need to be made in both langchain core and langchain ollama."}]}, {"ollama_summary": "This issue stems from a critical bug in the Snowflake Language Model (LLM) integration within the LangChain framework. The code attempts to parse special characters in a JSON message, leading to a compilation error and subsequent Snowflake Cortex query failures.  The issue is currently unresolved by a recent update to the LangChain package, requiring a potential version upgrade or a manual fix.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-04T16:01:35Z", "body_clean": "Hi, @venkata51. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a bug with LangChain's integration with Snowflake's Cortex function. Special characters in [code] are causing SQL compilation errors. You have verified that the issue is not due to your code and persists with the latest LangChain version. The error message indicates a parse error near the end of the file during SQL compilation. There have been no comments or developments since the issue was reported. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is a recurring challenge across issues, requiring consistent updates.", "Version control impacts stability; migrating to new versions introduces risk.", "Integration package conflicts are a significant source of bugs; downgrading is needed.", "Specific bug fixes are often tied to particular evaluation workflows.", "Dependency updates frequently introduce regressions; careful testing is crucial.", "Dependency management is a recurring challenge across issues, requiring consistent updates.", "Version control impacts stability; migrating to new versions introduces risk.", "Integration package conflicts are a significant source of bugs; downgrading is needed.", "Specific bug fixes are often tied to particular evaluation workflows.", "Dependency updates frequently introduce regressions; careful testing is crucial."], "technical_insights": ["Tree sitter library is outdated; migration is a core concern.", "LangChain integration package conflicts are a persistent issue.", "AzureChatOpenAI temperature setting is a critical parameter.", "Ollama support for 'control' message is essential for agent creation.", "Granite 3.2 implementation requires a fix for langchain dependencies.", "Tree sitter library is outdated; migration is a core concern.", "LangChain integration package conflicts are a persistent issue.", "AzureChatOpenAI temperature setting is a critical parameter.", "Ollama support for 'control' message is essential for agent creation.", "Granite 3.2 implementation requires a fix for langchain dependencies."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management is a recurring challenge across issues, requiring consistent updates.\n2.  Version control impacts stability; migrating to new versions introduces risk.\n3.  Integration package conflicts are a significant source of bugs; downgrading is needed.\n4.  Specific bug fixes are often tied to particular evaluation workflows.\n5.  Dependency updates frequently introduce regressions; careful testing is crucial.\n\nTECHNICAL INSIGHTS:\n1.  Tree sitter library is outdated; migration is a core concern.\n2.  LangChain integration package conflicts are a persistent issue.\n3.  AzureChatOpenAI temperature setting is a critical parameter.\n4.  Ollama support for 'control' message is essential for agent creation.\n5.  Granite 3.2 implementation requires a fix for langchain dependencies.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Dependency management is a recurring challenge across issues, requiring consistent updates.\n2.  Version control impacts stability; migrating to new versions introduces risk.\n3.  Integration package conflicts are a significant source of bugs; downgrading is needed.\n4.  Specific bug fixes are often tied to particular evaluation workflows.\n5.  Dependency updates frequently introduce regressions; careful testing is crucial.\n\nTECHNICAL INSIGHTS:\n1.  Tree sitter library is outdated; migration is a core concern.\n2.  LangChain integration package conflicts are a persistent issue.\n3.  AzureChatOpenAI temperature setting is a critical parameter.\n4.  Ollama support for 'control' message is essential for agent creation.\n5.  Granite 3.2 implementation requires a fix for langchain dependencies.", "batch_number": 102, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a bug where the `max_completion_tokens` parameter in the `http request` is incorrectly replaced by `max_completion_tokens`. This is causing problems with the LangChain model, specifically with the length of input tokens, leading to unexpected behavior and potentially incorrect results. The code is being used to set model parameters, and the issue stems from a deprecated parameter being used.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-03-09T23:23:52Z", "body_clean": "@memorylorry , FYI: [this]( [link] In OAI [code] has been deprecated in favor of [code] . Also, have you tried using [code] instead of [code] ?"}, {"author": "awasali14", "created_at": "2025-04-21T20:38:11Z", "body_clean": "v3 max token limit is 8000 by the way"}, {"author": "memorylorry", "created_at": "2025-04-28T02:49:39Z", "body_clean": "[@memorylorry]( [link] , FYI: [this]( [link] In OAI [code] has been deprecated in favor of [code] . Also, have you tried using [code] instead of [code] ? Ok, thanks for your notice."}]}, {"ollama_summary": "This issue reports a bug in PyPDFParser that fails to correctly handle filters returned as arrays when parsing PDF scans. The code exhibits inconsistent behavior, generating errors and inconsistent output when encountering filter data. The issue currently doesn’t provide a specific fix, and the code is not resolved by updating the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-03-07T03:57:13Z", "body_clean": "cc @pprados any idea?"}, {"author": "pprados", "created_at": "2025-03-07T09:14:36Z", "body_clean": "@eyurtsev I will take this ticket."}, {"author": "pprados", "created_at": "2025-03-10T08:40:18Z", "body_clean": "@haroldsnyers Thank you for the suggested correction. Can you send me an example of a file that fails?"}, {"author": "haroldsnyers", "created_at": "2025-03-17T08:04:48Z", "body_clean": "@pprados Unfortunetaly, the files I have in my possession are confidential so I cannot share them."}]}, {"ollama_summary": "This issue reports a critical bug in the `BaseImageBlobParser` class within the LangChain library, specifically related to Pillow package import issues. The bug causes a restrictive import that prevents the parser from correctly handling images, leading to an unexpected error message and stack trace.  The issue is currently unresolved with recent updates to LangChain, and the code example demonstrates the problem with image parsing.", "final_category": "bug", "comments": [{"author": "amuwall", "created_at": "2025-03-11T06:43:30Z", "body_clean": "I found this problem too."}, {"author": "amuwall", "created_at": "2025-03-19T06:35:43Z", "body_clean": "This issue was fixed in 30218."}, {"author": "dosubot[bot]", "created_at": "2025-06-18T16:02:29Z", "body_clean": "Hi, @haroldsnyers. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in the [code] class related to handling missing imports, specifically only raising an [code] for Pillow. You suggested a more flexible error handling approach to address other missing packages like [code] . User amuwall confirmed the issue and noted it was resolved in pull request 30218. Next Steps Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's post-processing generation functionality, specifically failing to produce annotations for generated text. The problem is not related to the code itself but rather a configuration initialization step.  The issue currently prevents the system from correctly interpreting annotations, and the code is not resolving by updating the latest stable version of LangChain.  The solution requires investigating the initialization process and potentially a specific integration package configuration.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-06-03T16:02:23Z", "body_clean": "Hi, @molokanov50. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the LangChain library regarding generation post processing. The feature fails to produce citations, with [code] returning [code] . You verified the issue is not related to your code or version, suggesting a problem within LangChain. No further activity or comments have been made on the issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The WikipediaLoader in LangChain is incorrectly fetching content from linked pages instead of the main Wikipedia page, leading to extraneous information being included in the response. This issue was identified through a search and investigation, and the code doesn’t seem to be a bug in the LangChain library itself. The proposed solution is to modify the code to ensure it only retrieves data from the requested Wikipedia page without pulling in linked content.", "final_category": "bug", "comments": [{"author": "kaustubh-darekar", "created_at": "2025-03-04T11:27:55Z", "body_clean": "After further investigation, I found this issue can be resolved by setting max load docs=1 to restrict results to only the main page and increasing doc content chars max to ensure the full article is captured."}]}], "business_insights": ["Model parameter setting errors can trigger unexpected behavior across multiple issues.", "Deprecated parameters highlight potential code refactoring needs.", "Consistent code patterns across issues suggest a design flaw.", "Incorrect token limits in the max_completion_tokens parameter impact model length.", "Incorrectly implemented filter handling in PyPDFParser can cause errors."], "technical_insights": ["LangChain’s deprecated parameter usage is a recurring pattern.", "Incorrect Pillow package import causes inconsistent output.", "BaseImageBlobParser’s restrictive import is a critical bug.", "Post-processing generation failure requires investigation into initialization.", "WikipediaLoader fetching links instead of the main page is a bug."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model parameter setting errors can trigger unexpected behavior across multiple issues.\n2. Deprecated parameters highlight potential code refactoring needs.\n3. Consistent code patterns across issues suggest a design flaw.\n4. Incorrect token limits in the `max_completion_tokens` parameter impact model length.\n5. Incorrectly implemented filter handling in PyPDFParser can cause errors.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s deprecated parameter usage is a recurring pattern.\n2. Incorrect Pillow package import causes inconsistent output.\n3. BaseImageBlobParser’s restrictive import is a critical bug.\n4. Post-processing generation failure requires investigation into initialization.\n5. WikipediaLoader fetching links instead of the main page is a bug.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 103, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code is encountering a `NotImplementedError` when using the `trim_messages` utility with the ChatDeepSeek model due to a missing implementation for counting tokens within the DeepSeek model. This issue appears to be a bug within LangChain specifically related to the DeepSeek model.  The proposed solution is to update to the latest stable version of LangChain or the integration package to address this issue.", "final_category": "bug", "comments": [{"author": "hgbdev", "created_at": "2025-03-04T09:57:09Z", "body_clean": "The [code] package doesn’t natively support token counting for DeepSeek models since it’s tailored to OpenAI’s tokenization logic (see [base.py L1068 L1082]( [link] You can implement a custom token counter as shown in the [LangChain docs]( [link] Here’s a simple example using HuggingFace’s [code] for DeepSeek models (offline tokenization details [here]( [link] [code] This uses DeepSeek’s tokenizer files ( [code] , [code] ) stored locally. Alternatively, [code] could work with adjustments (see [OpenAI’s example]( [link] but [code] aligns better with DeepSeek’s specifics."}, {"author": "kissycn", "created_at": "2025-03-06T14:46:45Z", "body_clean": "@hgbdev Thank you for your help, the issue is perfectly resolved! 🎉"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nLangChain is experiencing issues with serializing custom models inheriting from its core LangChain models, specifically when attempting to load them.  The bug appears to be a mapping issue within the model’s namespace, preventing proper deserialization despite the model not inheriting from LangChain.  The issue is currently not resolved by updating to the latest version of LangChain, suggesting a bug within the model serialization process.\n\n**Code Example:**\n\n[code]\n```python\nfrom langchain.model_components import LLM\nfrom langchain.schema import Model\n\n# Sample custom model\nclass MyCustomModel(LLM):\n    def __init__(self):\n        super().__init__()\n        self.custom_attribute = \"some_value\"\n\n# Example usage\nmodel = MyCustomModel()\n```\n\n**Error Stack Trace (Example):**\n\n```\nTraceback (most recent call last):\n  File \"your_file.py\", line 10, in <module>\n    model = MyCustomModel()\n  File \"your_file.py\", line 25, in MyCustomModel.__init__\n    super().__init__()\n  File \"your_file.py\", line 30, in __init__\n    self.custom_attribute = \"some_value\"\nAttributeError: 'MyCustomModel' object has no attribute 'custom_attribute'\n```", "final_category": "bug", "comments": [{"author": "deershark", "created_at": "2025-03-18T06:27:56Z", "body_clean": "I also encountered this problem, and it was also a similar prompt, but I inherited the [code] class in [code] , and the error occurred in the llm end stage. I hope to get a solution ! ! I see in [code] , when initializing the [code] class, you can use the [code] parameter to add additional [code] , but I don't know where to add it..."}, {"author": "mattf", "created_at": "2025-03-18T16:26:13Z", "body_clean": "[code] this will work if GatewayGeneration exists in a module and reports it via [code] , then you can pass [code] to [code] for instance [code]"}, {"author": "dosubot[bot]", "created_at": "2025-06-17T16:03:07Z", "body_clean": "Hi, @caravin. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where models inheriting from LangChain models cannot be serialized/deserialized using [code] and [code] , resulting in a [code] . User deershark encountered a similar issue with the [code] class and mentioned [code] as a potential solution. Mattf suggested a workaround using the [code] method to specify a valid namespace when calling [code] , providing example code. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on this issue. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue is related to a bug in the LangChain library, specifically when binding tools with Deepseek R1. The code attempts to transform the `args` dictionary, which is causing a JSONDecodeError when the expected value is not found.  The issue is currently unresolved and requires a fix, potentially involving a change to the `args` format or a different approach to handling the `json` decoding.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-03-05T00:47:10Z", "body_clean": "can you please provide a code snippet to reproduce the error?"}, {"author": "MILK-BIOS", "created_at": "2025-03-17T09:35:58Z", "body_clean": "It occurs when a LLM calls a tool. But the args aren't in json/dict form, it just contains value but no key. For example, my LLM wants to call a search tool, and it generates the search contents just in its original form instead of the json form. I think this is raised by my bad prompt probably. [code] json{{ \"role\": \"assistant\", (Must have) \"content\": \"content\", (Must have) \"tool calls\": [ {{ \"fuction\":{{ \"name\":\"tool names(可选值：{tool names})\", \"arguments\":{{\"arg\"}}, }}, \"id\": \"id\", }} ], \"tool call id\": \"id\" }} \"\"\"), (\"human\", \"input：{input}\"), (\"system\", \"chat history：{history}\") ])"}, {"author": "dosubot[bot]", "created_at": "2025-06-16T16:01:41Z", "body_clean": "Hi, @MILK BIOS. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the [code] function related to LLM tool call argument formatting. The issue persists despite updating to the latest version of LangChain. User andrasfe requested a code snippet, and you provided a detailed prompt example. The problem might be linked to incorrect prompt formatting, with LLM generating tool call arguments lacking JSON structure. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue involves a bug in LangChain that prevents the `ruff` linting process from working correctly. The bug occurs when the `dep-group` is not installed before running `ruff`. The proposed solution is to add a step before running `ruff` in the `make` command, ensuring the `dep-group` is installed first.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue involves a critical bug in the LangChain library, specifically for the DeepSeek reasoning model. The code attempts to print the reasoning output, but it consistently fails to do so, leading to an error message and stack trace.  The issue appears to be a fundamental bug within the LangChain integration, and attempts to update to the latest version haven't resolved it.", "final_category": "bug", "comments": [{"author": "YassinNouh21", "created_at": "2025-03-02T22:44:48Z", "body_clean": "It is already mentioned here 29513 as an example To assist with the issue on how to use the provided code in LangChain for reasoning output, you should follow these steps: Use the [code] method to get the reasoning output. [code] This setup will allow you to capture both the content and reasoning from DeepSeek's responses."}, {"author": "laurafbec", "created_at": "2025-03-03T08:54:14Z", "body_clean": "Thanks @YassinNouh21! but it does not work for me with ChatOpenAI class. This is the code I'm using [code]"}, {"author": "andrasfe", "created_at": "2025-03-05T01:14:49Z", "body_clean": "the same code works fine for me: [code]"}, {"author": "laurafbec", "created_at": "2025-03-05T07:52:35Z", "body_clean": "Thanks @andrasfe ! Yes, the code works, but I'm not able to access to the reasoning that should be something like this: [code]"}, {"author": "andrasfe", "created_at": "2025-03-07T03:56:29Z", "body_clean": "@laurafbec , you are right. I validated that the reasoning tokens are correctly returned by the openai module in [code] . My huntch is that we should add them in [code] . I will look into it later this week."}, {"author": "laurafbec", "created_at": "2025-03-07T12:06:44Z", "body_clean": "Thanks a lot @andrasfe !"}, {"author": "JasonHonKL", "created_at": "2025-03-09T08:17:25Z", "body_clean": "@andrasfe I think the problem is currently Langchain doesn't save the reasoning content when using Deeseek. Here's a capture output when I put out the LLMResult object inside the chat models.py [code] Noticing there is no reasoning content. Here's how Dee seek api use Openai to get the reasoning content [code] I guess some API has to be update @laurafbec For your reference I think using langchain Dee seek is better than using langchain openai as the supporting services are sometime quite difference I face similar problem when develop text embedding with the langchain openai while using Dee seek API. I will try to modify the code and push a pull request later this week when time allows. Hope this helps you a bit."}, {"author": "JasonHonKL", "created_at": "2025-03-09T09:24:25Z", "body_clean": "@laurafbec I have tried to solve the issue. Please check if it can solve your case. Have a nice day."}, {"author": "ccurme", "created_at": "2025-03-09T12:53:36Z", "body_clean": "What is the motivation to use ChatOpenAI instead of ChatDeepSeek? ChatDeepSeek [extends BaseChatOpenAI]( [link] its intent is to support Deepseek. ChatOpenAI is intended to support the OpenAI API. It's not tenable to modify this class to support all usage of the [code] SDK; it will become a mess. That's why we implement BaseChatOpenAI and extend it with specific providers."}, {"author": "andrasfe", "created_at": "2025-03-09T15:32:56Z", "body_clean": "@JasonHonKL , I got the fix working but have not yer initiated a PR. It's a very simple enhancement (4 lines of code) to ChatBaseOpenAI to add the reasoning key to response.additional kwargs if not already there.This is in line with @YassinNouh21 's [suggestion]( [link] But I see how adding this to the community module is a better choice."}, {"author": "YassinNouh21", "created_at": "2025-03-09T15:40:59Z", "body_clean": "@JasonHonKL , I got the fix working but have not yer initiated a PR. It's a very simple enhancement (4 lines of code) to ChatBaseOpenAI to add the reasoning key to response.additional kwargs if not already there.This is in line with @YassinNouh21 's [suggestion]( [link] But I see how adding this to the community module is a better choice. Glad it works with u can u mark it as solved"}, {"author": "laurafbec", "created_at": "2025-03-09T16:46:58Z", "body_clean": "Thanks @andrasfe and @YassinNouh21 !! shoudl I update langchain to test it? @ccurme The motivation is to use Openrouter API or other providers as DeepSeek API is quite unreliable regarding latency. Thanks again!"}, {"author": "JasonHonKL", "created_at": "2025-03-09T17:44:02Z", "body_clean": "@laurafbec I guess they won't update it cause they intend you to use the Deepseek chat. You can check my pull request [ 30186]( [link] actually just modify a few lines of code see if it is useful for you."}, {"author": "ccurme", "created_at": "2025-03-09T18:32:02Z", "body_clean": "@laurafbec can you use Openrouter with ChatDeepSeek? You can set the base url in [api base]( [link]"}, {"author": "andrasfe", "created_at": "2025-03-09T20:02:20Z", "body_clean": "This works for me, indeed. The key is not to use base url. [code]"}, {"author": "JasonHonKL", "created_at": "2025-03-10T06:20:04Z", "body_clean": "@andrasfe Same it works for me."}, {"author": "laurafbec", "created_at": "2025-03-10T08:38:57Z", "body_clean": "But I'm not able to print the reasoning...are you? [code]"}, {"author": "JasonHonKL", "created_at": "2025-03-10T10:04:23Z", "body_clean": "@laurafbec I think you fill in wrong kwargs."}, {"author": "andrasfe", "created_at": "2025-03-11T15:02:21Z", "body_clean": "But I'm not able to print the reasoning...are you? [code] Yes, I can see the reasoning output. Will share the exact code later tonight when I get home"}, {"author": "andrasfe", "created_at": "2025-03-12T04:24:14Z", "body_clean": "apologies, @laurafbec I must have used the branch I originally fixed as with a fresh pull it does indeed not work. I believe I found the issue in ChatDeepSeek and working on a fix EDIT : fixed, working for me. [PR raised]( [link]"}, {"author": "andrasfe", "created_at": "2025-03-22T14:26:20Z", "body_clean": "this issue can now be closed."}, {"author": "dosubot[bot]", "created_at": "2025-06-21T16:01:47Z", "body_clean": "Hi, @laurafbec. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involved LangChain not returning DeepSeek reasoning as expected with [code] and [code] . Despite troubleshooting and updating, the problem persisted. Contributors, including YassinNouh21, andrasfe, and JasonHonKL, provided insights. andrasfe identified a fix and raised a pull request to resolve the issue. The discussion emphasized using the correct model class for specific APIs and potential updates to LangChain. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["DeepSeek model integration is a key focus area, potentially requiring updated model components.", "LangChain’s serialization process may be a source of bugs, especially with custom models.", "The NotImplementedError related to trim_messages suggests a specific model configuration issue.", "The [code] package needs refinement to seamlessly support DeepSeek model counting.", "The serialization bug might be a broader issue affecting multiple model types, requiring a system-wide fix."], "technical_insights": ["LangChain’s serialization process is a critical area for improvement, particularly with custom models.", "The [code] package’s lack of native DeepSeek model support necessitates an update.", "The AttributeError within MyCustomModel indicates a mapping problem during deserialization.", "The [code] package’s serialization error is a bug, potentially affecting model loading.", "The [code] package’s serialization error may be related to the model's namespace."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  DeepSeek model integration is a key focus area, potentially requiring updated model components.\n2.  LangChain’s serialization process may be a source of bugs, especially with custom models.\n3.  The `NotImplementedError` related to `trim_messages` suggests a specific model configuration issue.\n4.  The `[code]` package needs refinement to seamlessly support DeepSeek model counting.\n5.  The serialization bug might be a broader issue affecting multiple model types, requiring a system-wide fix.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s serialization process is a critical area for improvement, particularly with custom models.\n2.  The `[code]` package’s lack of native DeepSeek model support necessitates an update.\n3.  The `AttributeError` within `MyCustomModel` indicates a mapping problem during deserialization.\n4.  The `[code]` package’s serialization error is a bug, potentially affecting model loading.\n5.  The `[code]` package’s serialization error may be related to the model's namespace.\n", "batch_number": 104, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nChatTongYi is experiencing a bug where it fails to parse the results returned by the Tongyi integration, specifically when input text exceeds a certain token count.  The issue was identified through searching the LangChain documentation, GitHub search, and a similar question, suggesting a potential bug within the integration itself.  The bug manifests as a failure to receive the response result, and the solution involves adding a specific code snippet to address this issue.", "final_category": "bug", "comments": [{"author": "safa1018", "created_at": "2025-03-02T17:37:56Z", "body_clean": "my dashscope version is 1.22.1"}, {"author": "safa1018", "created_at": "2025-03-03T02:07:13Z", "body_clean": "anyone can help me?"}, {"author": "safa1018", "created_at": "2025-03-03T15:58:17Z", "body_clean": "![Image]( [link] 似乎是这个原因引起的，只要超过60s，就不再返回chunk！！！！"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe LangChain Python API Reference is exhibiting a UI/UX issue where sidebar content is not displaying correctly, impacting navigation.  The problem appears to stem from CSS rendering inconsistencies and is not directly caused by code changes.  The issue is being investigated and a GIF demonstrating the rendering behavior has been attached for further analysis.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-31T16:00:52Z", "body_clean": "Hi, @nandanchandra. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: UI/UX problem with LangChain Python API Reference sidebar. Sidebar content fails to display correctly, likely due to CSS rendering issues. Issue demonstrated with a GIF, occurring on Windows 11 using Chrome at 1920x1080 resolution. No further comments or developments have been made. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "nandanchandra", "created_at": "2025-05-31T16:20:28Z", "body_clean": "We can close this issue as fixed. The fix had been update in PR 30062"}, {"author": "dosubot[bot]", "created_at": "2025-05-31T16:22:37Z", "body_clean": "Thank you for your response, @nandanchandra! We're glad to hear that the issue has been resolved with PR 30062. We'll go ahead and close this issue now."}]}, {"ollama_summary": "The `init_chat_model` bug causes an issue where the parameter base URL in the DeepSeek chat model API returns an incorrect value instead of the expected `api base`. This issue is not reproducible by updating to the latest stable LangChain version.  The root cause is likely a discrepancy in the API’s internal data structure.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-01T22:41:42Z", "body_clean": "What do you mean [code] is being passed to [code] for OpenAI class. Please check [here]( [link]"}, {"author": "panasee", "created_at": "2025-03-07T16:39:54Z", "body_clean": "I found the same problem (not technically a \"problem\", but a weird design). In openai interface, the URL can be designated using [code] parameter. However, in deepseek interface, the parameter is just renamed to [code] . This could cause confusion for using them. I don't know if there is any special consideration for that."}, {"author": "xuzexin-hz", "created_at": "2025-03-13T05:55:26Z", "body_clean": "I found the same problem (not technically a \"problem\", but a weird design). In openai interface, the URL can be designated using [code] parameter. However, in deepseek interface, the parameter is just renamed to [code] . This could cause confusion for using them. I don't know if there is any special consideration for that. This doesn't seem to be a problem with init chat model. init chat model is like a route, and is actually executed by different classes. ![Image]( [link] ChatOpenAI needs base url, but ChatDeepSeek needs api base. ChatDeepSeek is a latecomer, so it is obvious that ChatDeepSeek does not follow the rules."}, {"author": "panasee", "created_at": "2025-03-13T09:40:22Z", "body_clean": "I found the same problem (not technically a \"problem\", but a weird design). In openai interface, the URL can be designated using [code] parameter. However, in deepseek interface, the parameter is just renamed to [code] . This could cause confusion for using them. I don't know if there is any special consideration for that. This doesn't seem to be a problem with init chat model. init chat model is like a route, and is actually executed by different classes. ![Image]( [link] ChatOpenAI needs base url, but ChatDeepSeek needs api base. ChatDeepSeek is a latecomer, so it is obvious that ChatDeepSeek does not follow the rules. Yeah, I know that. But this problem is so obvious that I suspect there is a special reason for setting it that way."}, {"author": "qiaomu-s", "created_at": "2025-04-06T14:39:40Z", "body_clean": "I found the same problem (not technically a \"problem\", but a weird design). In openai interface, the URL can be designated using [code] parameter. However, in deepseek interface, the parameter is just renamed to [code] . This could cause confusion for using them. I don't know if there is any special consideration for that.我發現了同樣的問題（嚴格來說不是“問題”，而是一個奇怪的設計）。在 openai 介面中，可以使用 [code] parameter 指定 URL。但是，在 deepseek 介面中，該參數只是重新命名為 [code] 。這可能會導致使用它們時的混淆。我不知道這是否有任何特別的考慮。 This doesn't seem to be a problem with init chat model. init chat model is like a route, and is actually executed by different classes.這似乎不是 init chat model 的問題。init chat model 就像一個路由，實際上由不同的類執行。 ![Image]( [link] ChatOpenAI needs base url, but ChatDeepSeek needs api base. ChatDeepSeek is a latecomer, so it is obvious that ChatDeepSeek does not follow the rules.ChatOpenAI 需要base url，但 ChatDeepSeek 需要api base。ChatDeepSeek 是後來者，所以很明顯 ChatDeepSeek 沒有遵守規則。 thanks"}]}, {"ollama_summary": "This issue reports a critical bug in LangChain where the code snippet intended to run without errors is now raising an error. The bug stems from a discrepancy between the version of the LangChain library and the specific integration package being used, leading to unexpected behavior.  The issue also suggests a potential regression, and the suggested solution is to update to the latest stable version of LangChain, but this hasn't resolved the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-01T22:53:40Z", "body_clean": "When you add two ChatPromptTemplates, it does not brings in the partial variables. Just do the following: [code]"}, {"author": "thoffmann-artidis", "created_at": "2025-03-04T07:40:41Z", "body_clean": "Hi @keenborder786, Thanks for your reply. I know I could solve the issue that way, but it seems counter intuitive. In my case, [code] is defined at the agent's initialisation time. Further, I select different prompt compositions based on user arguments passed to the agent through [code] . Solving the issue as you suggested makes my code verbose, as I need to apply the [code] method for each possible composition of prompts. I believe a prompt's partial initialisation should be carried through the [code] magic, would you agree?"}]}, {"ollama_summary": "The user is encountering an \"AttributeError: 'tuple' object has no attribute 'invoke'\" error when using LangChain’s ChatOpenAI in Google Colab, specifically when attempting to call `.invoke()` on a `tuple` object. The issue stems from a potential incompatibility with the integration package, despite the user having installed the necessary libraries. The user is investigating this by checking the code and documentation, and is seeking guidance on how to resolve the AttributeError.", "final_category": "bug", "comments": [{"author": "YassinNouh21", "created_at": "2025-03-02T01:46:46Z", "body_clean": "The Problem In this line: [code] Notice the comma at the end. This creates a tuple containing one element (the ChatOpenAI instance) rather than assigning the ChatOpenAI instance directly to [code] . The Solution Remove the trailing comma: [code] This will ensure that [code] is a ChatOpenAI instance, not a tuple, and you'll be able to call the [code] method on it."}, {"author": "xiongzhenglong", "created_at": "2025-03-02T11:45:21Z", "body_clean": "great ! thanks!"}]}], "business_insights": ["Integration bug impacts Tongyi integration response – potential code issue.", "Version mismatch causing AttributeError – library incompatibility.", "LangChain version discrepancy – regression risk.", "Correcting the bug will improve integration stability.", "Update to latest stable LangChain version recommended."], "technical_insights": ["Integration bug: Tongyi integration fails to parse results – code flaw.", "UI/UX issue: Sidebar content not displaying correctly – CSS rendering.", "API Reference: Incorrect sidebar content – CSS rendering inconsistency.", "LangChain library version mismatch – regression.", "Update LangChain – resolve bug."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integration bug impacts Tongyi integration response – potential code issue.\n2. Version mismatch causing `AttributeError` – library incompatibility.\n3. LangChain version discrepancy – regression risk.\n4. Correcting the bug will improve integration stability.\n5. Update to latest stable LangChain version recommended.\n\nTECHNICAL INSIGHTS:\n1. Integration bug: Tongyi integration fails to parse results – code flaw.\n2. UI/UX issue: Sidebar content not displaying correctly – CSS rendering.\n3. API Reference: Incorrect sidebar content – CSS rendering inconsistency.\n4. LangChain library version mismatch – regression.\n5. Update LangChain – resolve bug.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 105, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is to create a standalone package for LangChain's Xinference chat models and related abstractions. This is necessary for proper versioning, dependency management, and testing of the package.  The goal is to standardize the package’s structure and ensure it integrates seamlessly with the existing LangChain ecosystem.", "final_category": "question", "comments": [{"author": "Aravind-11", "created_at": "2025-03-01T02:01:19Z", "body_clean": "Hi, can I work on this? Is it still open?"}, {"author": "ccurme", "created_at": "2025-03-14T15:42:42Z", "body_clean": "@Aravind 11 yes!"}, {"author": "TheSongg", "created_at": "2025-03-15T12:24:36Z", "body_clean": "I submitted an implement langchain xinference PR. Can you check it? [link]"}, {"author": "dosubot[bot]", "created_at": "2025-06-14T16:02:38Z", "body_clean": "Hi, @ccurme. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You proposed creating a standalone package for Xinference chat models. User Aravind 11 expressed interest in contributing and received your confirmation. TheSongg submitted a pull request for the langchain xinference package and requested a review. The issue appears to be resolved with the submission of the pull request. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "TheSongg", "created_at": "2025-06-21T08:49:07Z", "body_clean": "Hi, [@ccurme]( [link] I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You proposed creating a standalone package for Xinference chat models. User Aravind 11 expressed interest in contributing and received your confirmation. TheSongg submitted a pull request for the langchain xinference package and requested a review. The issue appears to be resolved with the submission of the pull request. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution! I released the langchain xinference V0.1.1 version, which supports the chat, llm, embedding, and rerank models."}, {"author": "dosubot[bot]", "created_at": "2025-06-21T08:51:18Z", "body_clean": "Thank you for your response and for releasing the langchain xinference V0.1.1 version! Since the issue appears to be resolved, we will go ahead and close it. We appreciate your contributions to LangChain!"}]}, {"ollama_summary": "The issue reports a significant increase in GPU memory consumption for LangChain code, specifically when processing LLM files. This is occurring twice as much as the summary size, impacting the GPU usage. The problem is not currently resolved by updating the LangChain version, and the root cause is currently unknown.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-30T17:33:28Z", "body_clean": "Hi, @molokanov50. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported excessive GPU memory consumption when using HuggingFace models with LangChain. Models \"RefalMachine/RuadaptQwen2.5 14B Instruct\" and \"Vikhrmodels/Vikhr Llama3.1 8B Instruct R 21 09 24\" consume double their file size in GPU memory. The issue persists even after updating to the latest version of LangChain. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a bug in LangChain’s Azure Search pagination implementation, causing incorrect document retrieval during page transitions. Specifically, the `top` and `skip` parameters are incorrectly linked, leading to the retrieval of duplicate documents. This problem is not resolved by updating the LangChain library and requires investigation into the logic governing the nearest neighbor search within the pagination process.", "final_category": "bug", "comments": [{"author": "iharshlalakiya", "created_at": "2025-03-03T06:01:28Z", "body_clean": "hey @mohit268 , I can help you with this problem."}, {"author": "dosubot[bot]", "created_at": "2025-06-02T16:02:29Z", "body_clean": "Hi, @mohit268. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a bug in LangChain's Azure Search pagination. The [code] parameter is affecting both result count and [code] logic. This dual use of the [code] parameter is leading to incorrect document retrieval. @iharshlalakiya has offered assistance to help resolve the issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical bug in the `unstructured` library, specifically concerning the handling of filenames and parameters within the `unstructured` API file loader. The code incorrectly sets both the filename and parameters, leading to an error message and a stack trace indicating a fundamental incompatibility with the LangChain community package.  The suggested solution is to switch to using the `code` parameter instead of the `[code]` parameter within the `unstructured` function, which is the correct way to utilize the library.", "final_category": "bug", "comments": [{"author": "TheRealVincentVanGogh", "created_at": "2025-02-27T23:51:12Z", "body_clean": "whoops, UnstructuredAPIFileIOLoader is deprecated, so I upgraded to UnstructuredLoader. After doing that, there's a similar issue with UnstructuredLoader [code] , seemingly because langchain unstructured doesn't pass the [code] as the [code] in the partitioning request [code] , but it does handle it properly when not using an API. I ended up just frankensteining some code so it'd work. [code] closing this issue since the original code mentioned is deprecated."}]}, {"ollama_summary": "The Granite3.2 project is experiencing a bug where it generates unexpected \"control\" messages when attempting to enable thinking functionality.  Users have searched for similar issues and found no resolution through updates to the LangChain library.  The bug appears to be specific to the integration with Ollama and involves a new model type being produced.", "final_category": "bug", "comments": [{"author": "lemassykoi", "created_at": "2025-02-28T19:31:54Z", "body_clean": "ok, looks like it is ollama related"}, {"author": "lemassykoi", "created_at": "2025-03-05T15:59:48Z", "body_clean": "ollama release 0.5.13 with support for Granit 3.2, but same error message"}, {"author": "lemassykoi", "created_at": "2025-03-05T16:26:46Z", "body_clean": "duplicate [link]"}]}], "business_insights": ["Package standardization is crucial for version control and dependency management, improving collaboration and stability.", "Recognizing the root cause of the GPU memory issues will accelerate bug resolution and improve performance.", "The Azure Search pagination bug highlights the importance of thorough testing and validation of LangChain’s core components.", "The Granite3.2 issue suggests a potential architectural shift requiring careful consideration of model compatibility.", "Understanding the Ollama integration bug points to potential integration challenges and requires focused investigation."], "technical_insights": ["Standardized package structure is essential for maintainability and collaboration.", "Investigating the GPU memory consumption pattern will identify potential bottlenecks and optimization opportunities.", "The Azure Search bug demonstrates the need for robust error handling and validation within the LangChain ecosystem.", "Granite3.2 integration suggests a need for a thorough review of the library’s design and compatibility with various models.", "Ollama integration bug highlights the importance of comprehensive testing across different model types and configurations."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Package standardization is crucial for version control and dependency management, improving collaboration and stability.\n2. Recognizing the root cause of the GPU memory issues will accelerate bug resolution and improve performance.\n3. The Azure Search pagination bug highlights the importance of thorough testing and validation of LangChain’s core components.\n4. The Granite3.2 issue suggests a potential architectural shift requiring careful consideration of model compatibility.\n5. Understanding the Ollama integration bug points to potential integration challenges and requires focused investigation.\n\nTECHNICAL INSIGHTS:\n1. Standardized package structure is essential for maintainability and collaboration.\n2. Investigating the GPU memory consumption pattern will identify potential bottlenecks and optimization opportunities.\n3. The Azure Search bug demonstrates the need for robust error handling and validation within the LangChain ecosystem.\n4. Granite3.2 integration suggests a need for a thorough review of the library’s design and compatibility with various models.\n5. Ollama integration bug highlights the importance of comprehensive testing across different model types and configurations.\n", "batch_number": 106, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue presents an unexpected auto-scrolling behavior within the LangChain API Reference sidebar navigation, causing the sidebar to scroll automatically when interacting with the search or highlighting features.  It’s not a coding issue but a UI-related problem stemming from styling inconsistencies.  The fix involves updating to the latest stable version of LangChain to resolve the bug.", "final_category": "bug", "comments": [{"author": "CodeLeom", "created_at": "2025-02-27T09:20:20Z", "body_clean": "@nandanchandra I noticed the error is only on the [code] API reference page. It is tied to the search field component. I tested this on a Mac Os (Macbook Pro M2)"}, {"author": "dosubot[bot]", "created_at": "2025-05-29T23:43:57Z", "body_clean": "Hi, @nandanchandra. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves unintended auto scrolling in the sidebar of the LangChain API Reference. Occurs when interacting with the search bar or selecting sections. Confirmed by @CodeLeom to be specific to the [code] API reference page. The problem is related to the search field component. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "CodeLeom", "created_at": "2025-05-30T09:27:07Z", "body_clean": "@nandanchandra This issue has been resolved, and it can be closed. I have tested the docs page. You can confirm as well."}, {"author": "dosubot[bot]", "created_at": "2025-05-30T09:29:19Z", "body_clean": "Thank you for your response, @CodeLeom! We're glad to hear that the issue has been resolved. We'll go ahead and close this issue now."}]}, {"ollama_summary": "The code successfully creates a connection to the database, but the `db.get_usable_table_names()` function returns an empty list, causing issues with chaining AzureChatModel with the database.  The issue is likely a bug in LangChain's integration with the database, potentially related to schema management or data retrieval, and hasn't been resolved by recent updates.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-03-03T03:20:28Z", "body_clean": "Can you check: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-06-02T16:02:29Z", "body_clean": "Hi, @mxrdck. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that [code] returns an empty list with a Microsoft SQL database. Successful connections and correct query results occur when specifying schema and table names directly. Suspected issue with handling multiple schemas in the database. @keenborder786 suggested checking the results of [code] for further investigation. The issue remains unresolved even after updating to the latest version of LangChain. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from LangChain failing to fully generate responses during streaming mode, resulting in truncated output at a maximum token limit of 20.  Initial troubleshooting efforts, including searching documentation and using GitHub search, haven’t identified a root cause.  The problem appears to be a logic error within the HuggingFacePipeline initialization process, specifically when returning a streaming response.", "final_category": "bug", "comments": [{"author": "tishizaki", "created_at": "2025-02-25T09:37:55Z", "body_clean": "Llama 3.2 3B Instruct does not set pad token id in special tokens map.json included in the model. Therefore, I check whether the information in config.json can be used, but when I try to refer to the model's eos token id, Llama 3.2 3B Instruct sets a list of three values ​​128001, 128008, and 128009 for eos token id, so it cannot be uniquely identified. Therefore, the current behavior is to set eos token id in special tokens map.json, which is the tokenizer setting value(128009: <|eot id| ) This itself was similar to the initialization method of HuggingFace TGI. As a test, I tried hard coding 128001 into eos token id, and the answers came out without interruption. 128001 indicates <|endoftext| . I tried it because the pad token id of another model indicated <|endoftext| in the model file, but I am not sure if this is correct."}, {"author": "hteeyeoh", "created_at": "2025-02-25T09:43:05Z", "body_clean": "Llama 3.2 3B Instruct does not set pad token id in special tokens map.json included in the model. Therefore, I check whether the information in config.json can be used, but when I try to refer to the model's eos token id, Llama 3.2 3B Instruct sets a list of three values ​​128001, 128008, and 128009 for eos token id, so it cannot be uniquely identified. Therefore, the current behavior is to set eos token id in special tokens map.json, which is the tokenizer setting value(128009: <|eot id| ) This itself was similar to the initialization method of HuggingFace TGI. As a test, I tried hard coding 128001 into eos token id, and the answers came out without interruption. 128001 indicates <|endoftext| . I tried it because the pad token id of another model indicated <|endoftext| in the model file, but I am not sure if this is correct. This also means the current implementation raised in [link] having some logic issues? Even I tried other model like Intel/neural chat 7b v3 3 the behavior also the same. Seems like the implementation logic causing some issue in streaming mode response."}, {"author": "tishizaki", "created_at": "2025-02-26T05:46:35Z", "body_clean": "I don't know if this is an issue related to the patch logic. Similar problems occur even when running simply using huggingface tokenizers/transformers instead of langchain. I also test other model(microsoft/Phi 3.5 mini instructm,Intel/neural chat 7b v3 3) and similar problem occurs. As a test, I tried hard coding 128001 into eos token id, and the answers came out without interruption. 128001 indicates <|endoftext| . I tried it because the pad token id of another model indicated <|endoftext| in the model file, but I am not sure if this is correct. I tried some times in the hard coded langchain environment, but sometimes the same problem occurred. In addition to that, I tried various things, but it seems that the frequency of occurrence has decreased by increasing max new tokens and eliminating the ambiguity of the question. You say you think that patch is the cause, but didn't you revert the patch and get the same result?"}, {"author": "hteeyeoh", "created_at": "2025-02-26T05:55:28Z", "body_clean": "I don't know if this is an issue related to the patch logic. Similar problems occur even when running simply using huggingface tokenizers/transformers instead of langchain. I also test other model(microsoft/Phi 3.5 mini instructm,Intel/neural chat 7b v3 3) and similar problem occurs. As a test, I tried hard coding 128001 into eos token id, and the answers came out without interruption. 128001 indicates <|endoftext| . I tried it because the pad token id of another model indicated <|endoftext| in the model file, but I am not sure if this is correct. I tried some times in the hard coded langchain environment, but sometimes the same problem occurred. In addition to that, I tried various things, but it seems that the frequency of occurrence has decreased by increasing max new tokens and eliminating the ambiguity of the question. You say you think that patch is the cause, but didn't you revert the patch and get the same result? Hi @tishizaki, Ya i did remove the patch and applied the changes as mentioned in this thread: [link] \"\"\" Okey, had time to look at the issue and I see that before we had no errors raised when users provided non string/non int inputs for special tokens. We would just cast list to str as \"['<|end of text| ', '<|eom id| ', '<|eot id| ']\" and assign that value which is not the correct way to do it I don't think we should bring back the old behavior which doesn't make much sense, although not sure if accepting lists of tokens is a good idea for tokenizers. AFAIK tokenizers assumes that special tokens are only one id/str. So I'll say we should assing with tokenizer.pad token id = tokenizer.eos token id and not tokenizer.pad token id = model.config.eos token id \"\"\" with this i did not see the truncated response with the models which im testing"}, {"author": "tishizaki", "created_at": "2025-02-26T07:18:59Z", "body_clean": "Hi @hteeyeoh, with this i did not see the truncated response with the models which im testing Can I test your patch and a reproducable test code? If possible, paste them."}, {"author": "hteeyeoh", "created_at": "2025-02-26T09:15:10Z", "body_clean": "it is hard for me to paste the whole code of my langchain pipeline building block here. You can just use the simple code snapshot that I have mentioned in the issue description by adding chain build using langchain for the test code... And just modify line in huggingface pipeline.py as below: if tokenizer.pad token is None: tokenizer.pad token id = tokenizer.eos token id With this i think we should able to see the issue and difference which i mentioned. Thanks."}, {"author": "tishizaki", "created_at": "2025-02-27T06:39:53Z", "body_clean": "@hteeyeoh And just modify line in huggingface pipeline.py as below: if tokenizer.pad token is None: tokenizer.pad token id = tokenizer.eos token id I doubt that it is working properly after making this change. This is because the patch I presented in 29500 results in \"tokenizer.pad token id = tokenizer.eos token id\" in the case of Llama 3.2 3B Instruct. I created the patch taking into account the discussion in the thread you mentioned. And it is the same as the patch applied to TGI. Some models specify pad token id and others do not. I understand that this is a workaround where if pad token id is not specified, eos token id is used instead. However, on the other hand, it seems that the same problem occurs even if the pad token id is specified explicitly in models (for example, microsoft/Phi 3.5 mini instructm), even if it is specified correctly, so it seems that this problem is not simply a problem with this modified part. My test code is following. [code]"}, {"author": "hteeyeoh", "created_at": "2025-02-27T06:47:33Z", "body_clean": "[@hteeyeoh]( [link] And just modify line in huggingface pipeline.py as below: if tokenizer.pad token is None: tokenizer.pad token id = tokenizer.eos token id I doubt that it is working properly after making this change. This is because the patch I presented in [ 29500]( [link] results in \"tokenizer.pad token id = tokenizer.eos token id\" in the case of Llama 3.2 3B Instruct. I created the patch taking into account the discussion in the thread you mentioned. And it is the same as the patch applied to TGI. Some models specify pad token id and others do not. I understand that this is a workaround where if pad token id is not specified, eos token id is used instead. However, on the other hand, it seems that the same problem occurs even if the pad token id is specified explicitly in models (for example, microsoft/Phi 3.5 mini instructm), even if it is specified correctly, so it seems that this problem is not simply a problem with this modified part. My test code is following. from langchain community.llms import HuggingFacePipeline hf = HuggingFacePipeline.from model id( model id=\"Intel/neural chat 7b v3 3\", model id=\"meta llama/Llama 3.2 3B Instruct\", model id=\"microsoft/Phi 3.5 mini instruct\", task=\"text generation\", pipeline kwargs={\"max new tokens\": 100}, device map=0, ) from langchain core.prompts import PromptTemplate template = \"\"\"Question: {question} Answer: Let's think step by step.\"\"\" prompt = PromptTemplate.from template(template) chain = prompt | hf question = \"What is electroencephalography?\" print(chain.invoke({\"question\": question})) Yes I agree with that. This would be a temp W/A for that but not sure will that have a fix in future or not. But in your code did you try with streaming response? I saw that with just chain.invoke by not streaming the response there's was no issue. This issue only occur when the response is streaming"}, {"author": "tishizaki", "created_at": "2025-02-27T07:18:54Z", "body_clean": "But in your code did you try with streaming response? I saw that with just chain.invoke by not streaming the response there's was no issue. This issue only occur when the response is streaming In my environment, the same problem occurs with this test code, so I do not run it in streaming mode. The test result outputs are followings. Their outputs include debug message to watch pad token id. microsoft/Phi 3.5 mini instruct has half finished output [code] meta llama/Llama 3.2 3B Instruct has half finished output [code] Intel/neural chat 7b v3 3 is not end with a pereod [code]"}, {"author": "ankurmalik1978", "created_at": "2025-03-18T10:15:28Z", "body_clean": "I had the same issue where response was getting truncated. Setting \"max new tokens=512\" resolved the issue for me pipe = pipeline(\"text generation\", model=model, tokenizer=tokenizer, max new tokens=512)"}, {"author": "dosubot[bot]", "created_at": "2025-06-17T16:03:05Z", "body_clean": "Hi, @hteeyeoh. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves truncated responses in the HuggingFacePipeline model during streaming mode. You and @tishizaki discussed potential causes related to [code] and [code] settings. The problem persisted across different models and configurations. @ankurmalik1978 found that increasing [code] to 512 resolved the issue, suggesting a workaround. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This GitHub issue reports a problem with the `langchain-cli migrate` script, which attempts to upgrade LangChain to version 0.3. The script fails to download Grit CLI, potentially due to a broken link or an issue with the integration package. The issue involves a traceback and a suggested solution of running the migration script twice, with potential for mistakes.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-02-25T23:08:05Z", "body_clean": "Hi @morgante, do you have any suggestions on how to fix?"}, {"author": "morgante", "created_at": "2025-02-26T01:21:14Z", "body_clean": "This was already fixed here: [link] I assume you need to cut a new release."}, {"author": "dosubot[bot]", "created_at": "2025-05-29T23:43:57Z", "body_clean": "Hi, @linomp. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an error with the 'langchain cli migrate' command related to downloading the Grit CLI. Despite troubleshooting and using the latest LangChain version, the issue persisted. @morgante indicated that the issue was fixed in a pull request and suggested a new release might be needed. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Please remove redundant text and explanations from the `docs(tool_artifacts.ipynb)` file, specifically focusing on clarifying the purpose of the code and its implementation. This will improve the overall readability and maintainability of the documentation.", "final_category": "other", "comments": [{"author": "GoogTech", "created_at": "2025-02-24T14:11:30Z", "body_clean": "PR : [link]"}]}], "business_insights": ["UI inconsistencies can impact user experience, requiring proactive bug fixes.", "Addressing UI issues early can prevent broader usability problems.", "Maintaining a consistent UI enhances developer productivity.", "Prioritize UI stability over minor code changes.", "User feedback is crucial for UI optimization."], "technical_insights": ["Style inconsistencies breed confusion and frustration.", "The search field component is a key UI element.", "Database integration is a critical system component.", "LangChain’s integration with the database needs careful management.", "Schema management is a potential root cause of the bug."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. UI inconsistencies can impact user experience, requiring proactive bug fixes.\n2. Addressing UI issues early can prevent broader usability problems.\n3. Maintaining a consistent UI enhances developer productivity.\n4. Prioritize UI stability over minor code changes.\n5. User feedback is crucial for UI optimization.\n\nTECHNICAL INSIGHTS:\n1. Style inconsistencies breed confusion and frustration.\n2. The search field component is a key UI element.\n3. Database integration is a critical system component.\n4. LangChain’s integration with the database needs careful management.\n5. Schema management is a potential root cause of the bug.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 107, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a compatibility problem between LangChain's `max_tokens` and `max_completion_tokens` parameters, specifically when using the DeepSeek 32b model. The code attempts to override the `max_tokens` parameter, which is deprecated in the newer version of LangChain, leading to an error. The proposed solution is to ensure both parameters are supported independently, aligning with the recommended approach for the DeepSeek 32b model and the version of LangChain being used.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-24T14:39:54Z", "body_clean": "Instead of ChatOpenAI, could you use BaseChatOpenAI? [code]"}, {"author": "FT-Fetters", "created_at": "2025-02-25T01:59:13Z", "body_clean": "Instead of ChatOpenAI, could you use BaseChatOpenAI? from langchain openai.chat models.base import BaseChatOpenAI This method does seem to solve the problem, but I’m not sure if there are any functional differences between BaseChatOpenAI and ChatOpenAI."}, {"author": "Huyueeer", "created_at": "2025-02-26T01:49:09Z", "body_clean": "Instead of ChatOpenAI, could you use BaseChatOpenAI? from langchain openai.chat models.base import BaseChatOpenAI @ccurme at langchain openai:0.3.7 When calling gpt 4o, I can use [code] , but when calling o1, I need to use [code] . Will this piece be merged later?"}, {"author": "ccurme", "created_at": "2025-02-26T14:38:51Z", "body_clean": "This method does seem to solve the problem, but I’m not sure if there are any functional differences between BaseChatOpenAI and ChatOpenAI. @FT Fetters These are the functional differences: ChatOpenAI uses [code] by default instead of [code] in the API payload. ChatOpenAI uses OpenAI's dedicated structured output feature for [code] , where BaseChatOpenAI uses tool calling (you can override this by passing [code] ). ChatOpenAI supports a [code] attribute that, when set to True, will include a final chunk containing token usage data at the end of a stream."}, {"author": "ccurme", "created_at": "2025-02-26T14:39:59Z", "body_clean": "[@ccurme]( [link] at langchain openai:0.3.7 When calling gpt 4o, I can use [code] , but when calling o1, I need to use [code] . Will this piece be merged later? @Huyueeer can you share more details about what is hosting the model? Is it OpenAI, or are you accessing [code] through a proxy? (If ChatOpenAI works for you, you should use that.)"}, {"author": "andrasfe", "created_at": "2025-03-05T04:20:24Z", "body_clean": "For consistency reasons, I would suggest a similar solution to Issue [link] [code] . This seems to be the approach for disabling parameters that are not supported by the invoked APIs. Unless there are any objections to this, I can implement it over the weekend."}, {"author": "andrasfe", "created_at": "2025-03-06T04:20:49Z", "body_clean": "@FT Fetters , can you please let me know who your provider is? I am using OpenRouter with \"deepseek/deepseek chat\" and works just fine. Also, assuming no proxy is present or if it is, it doesn't alter the request"}, {"author": "FT-Fetters", "created_at": "2025-03-07T03:27:16Z", "body_clean": "[@FT Fetters]( [link] you please let me know who your provider is? I am using OpenRouter with \"deepseek/deepseek chat\" and works just fine. Also, assuming no proxy is present or if it is, it doesn't alter the request The model I am using is not from someone else’s API; it is deployed on our own server using vLLM, so it might be different from the API interfaces of general providers."}, {"author": "andrasfe", "created_at": "2025-03-09T18:23:47Z", "body_clean": "[@FT Fetters]( [link] you please let me know who your provider is? I am using OpenRouter with \"deepseek/deepseek chat\" and works just fine. Also, assuming no proxy is present or if it is, it doesn't alter the request The model I am using is not from someone else’s API; it is deployed on our own server using vLLM, so it might be different from the API interfaces of general providers. @FT Fetters , I did run the following against local vLLM but with [code] and it appeared to be working just fine with both [code] and [code] . Whereas the model can make a difference, I would disable the proxy and try again, if possible"}, {"author": "dosubot[bot]", "created_at": "2025-06-08T16:01:33Z", "body_clean": "Hi, @FT Fetters. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a compatibility issue with [code] and [code] in [code] . User ccurme suggested using [code] , which resolved the issue. Andrasfe proposed disabling unsupported parameters and any proxy for server hosted models using vLLM. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue involves a regression in the DeepSeek and LLMGraphTransformer integration, specifically when using the V3 version of DeepSeek. The code throws an error when attempting to access an object, and the stack trace points to a potential incompatibility with the latest LangChain version or the specific integration package.  It appears to be a bug related to the DeepSeek library, and attempts to fix it involve updating the LangChain version.", "final_category": "bug", "comments": [{"author": "iharshlalakiya", "created_at": "2025-03-02T06:55:36Z", "body_clean": "hi @M0rtzz , I can help you with this problem."}, {"author": "M0rtzz", "created_at": "2025-03-02T07:43:55Z", "body_clean": "hi [@M0rtzz]( [link] , I can help you with this problem. How can we solve this"}, {"author": "iharshlalakiya", "created_at": "2025-03-02T09:03:33Z", "body_clean": "try this code. from langchain experimental.graph transformers import LLMGraphTransformer from langchain community.graphs.graph document import GraphDocument from langchain.docstore.document import Document from langchain deepseek import ChatDeepSeek from dotenv import load dotenv from typing import List import os env path = \".env\" load dotenv(env path) class TextToGraph: def init (self, model: str = None, api base: str = None, api key: str = None): if not api key: raise ValueError(\"DeepSeek API key is missing. Please set it in the .env file.\") print(f\"Initializing ChatDeepSeek with API Base: {api base}\") self.llm = ChatDeepSeek( model=model, api base=api base, api key=api key ) if self.llm is None: raise ValueError(\"Failed to initialize ChatDeepSeek. Check your API credentials.\") self.llm transformer = LLMGraphTransformer(llm=self.llm) def process text(self, text: str) List[GraphDocument]: if not text.strip(): raise ValueError(\"Input text is empty. Provide valid content.\") doc = Document(page content=text) return self.llm transformer.convert to graph documents([doc]) def process file(self, file path: str) List[GraphDocument]: if not os.path.exists(file path): raise FileNotFoundError(f\"File '{file path}' not found.\") with open(file path, \"r\", encoding=\"utf 8\", errors=\"ignore\") as file: text = file.read() return self.process text(text) if name == \" main \": deepseek api key = os.getenv(\"DEEPSEEK API KEY\") deepseek api base = \" [link] processor = TextToGraph( model=\"deepseek chat\", api base=deepseek api base, api key=deepseek api key ) file path = \"test.txt\" try: graph documents = processor.process file(file path) for graph doc in graph documents: print(graph doc) except Exception as e: print(f\"Error: {e}\") Other Dependencies aiohappyeyeballs==2.4.6 aio [link] aiosignal==1.3.2 annotated types==0.7.0 anyio==4.8.0 attrs==25.1.0 certifi==2025.1.31 charset normalizer==3.4.1 colorama==0.4.6 dataclasses json==0.6.7 distro==1.9.0 dotenv==0.9.9 frozenlist==1.5.0 greenlet==3.1.1 h11==0.14.0 [link] [link] [link] idna==3.10 jiter==0.8.2 jsonpatch==1.33 jsonpointer==3.0.0 langchain==0.3.19 langchain community==0.3.18 langchain core==0.3.40 langchain deepseek==0.1.2 langchain experimental==0.3.4 langchain openai==0.3.7 langchain text splitters==0.3.6 langsmith==0.3.11 marshmallow==3.26.1 multidict==6.1.0 mypy extensions==1.0.0 numpy==1.26.4 openai==1.65.2 orjson==3.10.15 packaging==24.2 propcache==0.3.0 pydantic==2.10.6 pydantic settings==2.8.1 pydantic core==2.27.2 python dotenv==1.0.1 PyYAML==6.0.2 regex==2024.11.6 requests==2.32.3 requests toolbelt==1.0.0 sniffio==1.3.1 SQLAlchemy==2.0.38 tenacity==9.0.0 tiktoken==0.9.0 tqdm==4.67.1 typing inspect==0.9.0 typing extensions==4.12.2 urllib3==2.3.0 yarl==1.18.3 zstandard==0.23.0"}, {"author": "M0rtzz", "created_at": "2025-03-02T09:11:01Z", "body_clean": "@iharshlalakiya Thank you, the issue has been resolved. I have found that certain platform APIs are causing this bug."}]}, {"ollama_summary": "The issue stems from errors in Pydantic 2.11, specifically related to annotations failing when using a specific model (identified as [code]). The problem is likely a refactor within the model itself, not a bug in the code itself, and attempts to rebuild the model are proving ineffective. The solution involves investigating alternative approaches to define the model, potentially by moving the model definition outside of the `if` block, to resolve the recurring errors.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue stems from LangChain incorrectly concatenating the `tool_call.id` from Tencent Hunyuan with the `langchain openai` identifier twice, causing a duplicate error message.  After searching and consulting documentation, the problem appears to be a bug within LangChain’s integration with Hunyuan.  Currently, the code works fine with the LangChain SDK, but not with the core LangChain OpenAI integration.", "final_category": "bug", "comments": [{"author": "reatang", "created_at": "2025-02-24T12:41:22Z", "body_clean": "When using streaming output, I found the difference, Hunyuan returns two IDs, openai only returns one hunyuan [code] openai [code]"}, {"author": "ccurme", "created_at": "2025-02-24T23:41:04Z", "body_clean": "There is an integration specifically for Hunyuan in langchain community, would this suit your use case? [link]"}, {"author": "reatang", "created_at": "2025-02-25T02:51:12Z", "body_clean": "There is an integration specifically for Hunyuan in langchain community, would this suit your use case? [link] I realized that it is not appropriate to make the openai client compatible with Hunyuan. Thank you for your tip. I found that this Hunyuan client does not support tool calls yet. I will continue to use other solutions."}, {"author": "reatang", "created_at": "2025-02-25T05:58:09Z", "body_clean": "I have submitted this issue to Hunyuan official for resolution."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a significant latency problem in OpenAI LLM and embedding instance creation, specifically requiring around 160ms for a single instance, which is significantly slower than ideal.  The problem isn't directly in the code but appears to be a bug within the LangChain integration, as updating the latest stable version doesn't resolve it.  The issue is impacting the performance of a pipeline where multiple LLM and embedding instances are created in a single request.", "final_category": "bug", "comments": [{"author": "hasansustcse13", "created_at": "2025-02-27T05:26:53Z", "body_clean": "@ccurme @eyurtsev"}, {"author": "dosubot[bot]", "created_at": "2025-05-29T23:43:56Z", "body_clean": "Hi, @hasansustcse13. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary High latency reported in creating instances of OpenAI LLM and Embedding classes. Each instance creation takes approximately 150 160 milliseconds. Problematic for requests requiring multiple instances, as it should be faster. Issue persists with the latest stable version of LangChain. You tagged @ccurme and @eyurtsev for potential input or assistance. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Compatibility issues between max_tokens and max_completion_tokens are a recurring concern, requiring careful parameter management.", "Model version mismatch is causing regression in DeepSeek integration, suggesting a library update is necessary.", "Pydantic 2.11 errors related to annotations are a bug within the model itself, needing a refactor.", "Incorrect concatenation of tool_call.id and langchain openai is causing duplicate errors, likely a LangChain integration bug.", "Latency issues with OpenAI LLM and embedding instance creation are impacting pipeline performance, requiring optimization."], "technical_insights": ["LangChain’s max_tokens and max_completion_tokens parameters are a critical area for conflict resolution.", "DeepSeek 32b model compatibility necessitates a specific LangChain version or integration package update.", "Pydantic 2.11 regressions are a bug within the LangChain model integration package.", "Incorrect concatenation of tool_call.id and langchain openai identifiers is a recurring error, requiring a refactor.", "LangChain integration with Tencent Hunyuan is causing duplicate errors, potentially impacting model creation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Compatibility issues between `max_tokens` and `max_completion_tokens` are a recurring concern, requiring careful parameter management.\n2. Model version mismatch is causing regression in DeepSeek integration, suggesting a library update is necessary.\n3. Pydantic 2.11 errors related to annotations are a bug within the model itself, needing a refactor.\n4. Incorrect concatenation of `tool_call.id` and `langchain openai` is causing duplicate errors, likely a LangChain integration bug.\n5. Latency issues with OpenAI LLM and embedding instance creation are impacting pipeline performance, requiring optimization.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s `max_tokens` and `max_completion_tokens` parameters are a critical area for conflict resolution.\n2. DeepSeek 32b model compatibility necessitates a specific LangChain version or integration package update.\n3. Pydantic 2.11 regressions are a bug within the LangChain model integration package.\n4. Incorrect concatenation of `tool_call.id` and `langchain openai` identifiers is a recurring error, requiring a refactor.\n5. LangChain integration with Tencent Hunyuan is causing duplicate errors, potentially impacting model creation.\n", "batch_number": 108, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue involves a 400 error when attempting to use AzureChatOpenAI with LangChain, specifically due to an unsupported parameter ('max tokens') that is not supported by the model. The problem appears to be a bug within the LangChain integration, and the suggested solution is to use 'max completion tokens' instead. The code and version information are available for investigation and potential resolution.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-24T14:56:48Z", "body_clean": "My suggestion for now is this: [code] Let me know if this won't work for you. Unfortunately Azure OpenAI doesn't support [code] for all models (unlike OpenAI it seems), and we have no reliable way of inferring the model from deployment names, so for now we keep the attribute as [code] . You can also pass it in as an invocation param: [code]"}, {"author": "aldensiol", "created_at": "2025-02-24T14:58:58Z", "body_clean": "Thank you for the help! Will try it out and update if this works!"}, {"author": "aldensiol", "created_at": "2025-02-25T02:15:52Z", "body_clean": "AzureChatOpenAI( azure deployment=\"o1 mini\", model kwargs={\"max completion tokens\": 300}, ) Hey man, the same error still arises from both methods."}, {"author": "evisong", "created_at": "2025-02-27T14:48:43Z", "body_clean": "@ccurme Could you please reopen this ticket? It's not working to add [code] . The call could only succeed after removing [code] field. I guess [code] [link] is also necessary to [code] . Thanks."}, {"author": "ccurme", "created_at": "2025-02-27T16:12:14Z", "body_clean": "Can you confirm you are running on latest langchain openai? I'm struggling to reproduce this. Here is what I've tried: Merged in a unit test [here]( [link] asserting that [code] is in the payload and [code] is not. If I set a breakpoint [here]( [link] I confirm that [code] is in the payload (and [code] is not). Conceptually, when params are put together, [code] is [excluded if it's None]( [link] so it should not end up in the payload. [code] Appears to run without issue. Would like to help get to the bottom of this but please let me know if I'm misunderstanding the issue or if you can reproduce it another way."}, {"author": "ccurme", "created_at": "2025-02-27T16:14:38Z", "body_clean": "The problem with adding it to [code] blanket like that is it will fail for older models (e.g., [code] ). This is the case for Azure and not for the OpenAI API. What's more, we have no reliable way of inferring models from deployment names. Open to suggestions here."}, {"author": "evisong", "created_at": "2025-02-28T04:23:05Z", "body_clean": "Can you confirm you are running on latest langchain openai? I'm struggling to reproduce this. Here is what I've tried: ... Would like to help get to the bottom of this but please let me know if I'm misunderstanding the issue or if you can reproduce it another way. @ccurme I just found my issue, my code was like this: [code] When being invoked, both [code] and [code] fields were included in request payload, then I got the [code] . After removing the [code] line, the invocation succeeded. Sorry for misleading."}, {"author": "evisong", "created_at": "2025-02-28T04:32:12Z", "body_clean": "The problem with adding it to [code] blanket like that is it will fail for older models (e.g., [code] ). This is the case for Azure and not for the OpenAI API. What's more, we have no reliable way of inferring models from deployment names. Open to suggestions here. I usually use the [code] param, e.g. [code] in code snippet above. However in LangChain API doc: [code] Maybe adding a new [code] field? But I'm worried there might be further quirks when newer models are released in future."}]}, {"ollama_summary": "This issue involves a critical bug in the `FileCallbackHandler` component of the LangChain library, specifically related to the `on_chain_start` callback.  The code is attempting to access a `NoneType` object, leading to an `AttributeError` and a crash.  The issue is currently unresolved by recent updates to the LangChain library, and further investigation is needed to pinpoint the root cause and implement a fix.", "final_category": "bug", "comments": [{"author": "mirskiy", "created_at": "2025-02-23T20:51:41Z", "body_clean": "Propsed fix in 29942, let me know if this is acceptable."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\n**Problem:** The `tool_choice value` setting is currently only enabled for API versions 2024-06-01 and later, which is a limitation for existing Azure Open AI deployments.\n\n**Key Details:** The issue stems from a discrepancy between the deployment version (code) and the API version (2024-06-01+) of the Azure Open AI service.\n\n**Proposed Solution:**  The issue suggests a potential update or configuration change to allow the `tool_choice` setting to be enabled for older versions as well.", "final_category": "bug", "comments": [{"author": "pcuci", "created_at": "2025-02-23T16:19:34Z", "body_clean": "Ah, no; typo in my config: [code] instead of [code]"}]}, {"ollama_summary": "This GitHub issue addresses a critical bug in the LangChain vectorstore integration, specifically a silent failure to initialize DuckDB without pandas installed. The issue results in a program crash when attempting to query the database, requiring a message to be displayed but not providing any helpful information.  The proposed solution involves raising an error when DuckDB is initialized without pandas, and the issue highlights a potential problem with the integration package and suggests investigating other vectorstores that might have similar issues.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-25T16:00:51Z", "body_clean": "Hi, @DvGils. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves the [code] module failing silently on Windows and causing segmentation faults on Linux. The problem occurs when [code] is not installed, which is a dependency not currently communicated to users. You suggested implementing an error or warning message to alert users about the missing [code] dependency. The issue persists even after updating to the latest version of LangChain, indicating a need for improved error handling or documentation. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is experiencing an `AttributeError: 'ChatTongyi' object has no attribute 'bind tools'` error, likely because the `ChatTongyi` object is not configured to use the `bind tools` function. The issue stems from a bug in the LangChain integration, specifically related to the `bind tools` method, and it’s not being resolved by updating the LangChain library itself. The code attempts to invoke a specific tool function (`multiply`) using the `bind tools` method, causing the error.", "final_category": "bug", "comments": [{"author": "Fauny", "created_at": "2025-02-22T02:53:26Z", "body_clean": "it's my fault: i'm using an old langchain community package"}]}], "business_insights": ["LangChain integration stability is crucial; bugs impact user experience.", "Version compatibility is a significant concern across multiple models.", "Focus on specific model versions to pinpoint root causes.", "Integration package updates are essential for stability.", "Investigate potential vectorstore issues – integration package."], "technical_insights": ["LangChain integration bug affecting key model support.", "AttributeError related to ChatTongyi object.", "bind tools method malfunction; potential integration issue.", "Version mismatch between LangChain library and Azure OpenAI.", "Vectorstore integration bug impacting query functionality."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain integration stability is crucial; bugs impact user experience.\n2.  Version compatibility is a significant concern across multiple models.\n3.  Focus on specific model versions to pinpoint root causes.\n4.  Integration package updates are essential for stability.\n5.  Investigate potential vectorstore issues – integration package.\n\nTECHNICAL INSIGHTS:\n1.  LangChain integration bug affecting key model support.\n2.  `AttributeError` related to `ChatTongyi` object.\n3.  `bind tools` method malfunction; potential integration issue.\n4.  Version mismatch between LangChain library and Azure OpenAI.\n5.  Vectorstore integration bug impacting query functionality.", "batch_number": 109, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue proposes a change to prioritize caching SDK properties (like the [code] SDK) to reduce unnecessary overhead and conserve resources. This is a recommendation from the LangChain maintainer to improve performance and reduce resource consumption, particularly for clients like BaseChatOpenAI.", "final_category": "feature", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-23T16:00:46Z", "body_clean": "Hi, @ccurme. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Proposal to optimize LangChain by implementing cached properties for SDK clients. Current setup creates multiple clients (sync and async) even when only one is needed. Aims to streamline client generation and improve project efficiency. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical bug in LangChain that causes the `await` expression to fail when using `agent executor.ainvoke` with the `run` function. This is specifically affecting the `agent` component, and it’s not resolved by updating the LangChain version. The code attempts to use `await` with a `run` call, leading to a `TypeError` when the `run` function is called.  The traceback indicates a potential issue with the `agent` component's internal workings, possibly related to the `ainvoke` call.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-23T16:00:46Z", "body_clean": "Hi, @pfmonville. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in LangChain involving an asynchronous call [code] that should be synchronous [code] in the [code] function. Example code and a partial error message were provided, indicating a traceback error. The issue persists even after updating to the latest version of LangChain. No further activity or comments have been made on the issue. Next Steps: Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment here to keep the discussion open. If there is no further input, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue is to create a standalone package for LangChain's MLX chat models, fulfilling a requirement from a maintainer to improve versioning, dependency management, and testing. This package will adhere to the existing contributing guide and provide a self-contained solution for the MLX model.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-23T16:00:45Z", "body_clean": "Hi, @ccurme. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You proposed creating a standalone package for MLX chat models. The goal is to improve versioning, dependency management, and integration testing. No comments or developments have been made on this issue yet. Next Steps Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on deprecating HuggingFaceInferenceAPIEmbeddings, which are currently used for embedding tasks. The maintainer is requesting a removal of this component as a replacement is likely available elsewhere.  The core problem is that this specific integration is being deprecated and needs to be addressed to maintain compatibility and avoid potential issues with future LangChain updates.", "final_category": "question", "comments": [{"author": "CtrlMj", "created_at": "2025-05-20T21:01:47Z", "body_clean": "I created [this PR]( [link]"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where a field named \"k\" is missing from a data structure, causing potential errors or unexpected behavior. Specifically, it’s requesting the field to be renamed to \"LIMIT?\". This is a critical issue impacting data integrity and requires a fix to ensure the code functions correctly.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-22T16:00:50Z", "body_clean": "Hi, @cryptocasino888. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the [code] file related to an incorrect SQL query. The query uses \"AND\" with a non existent 'k' field instead of \"LIMIT ?\". You provided a link to the specific line of code needing correction. There have been no comments or activity on this issue since it was opened. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Prioritize caching SDK properties for improved performance and resource management.", "LangChain maintainer’s recommendation suggests proactive caching to reduce overhead.", "The await expression failure with agent executor.ainvoke indicates a potential component issue.", "The agent component’s internal workings may be related to ainvoke calls.", "Addressing the ainvoke issue is crucial for stability and compatibility."], "technical_insights": ["Cache optimization is a key area for performance enhancement.", "The ainvoke call is a potential bottleneck to be addressed.", "The agent component's internal workings are the primary focus.", "A potential component bug affecting the run function is identified.", "Dependency management and testing are critical for long-term stability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Prioritize caching SDK properties for improved performance and resource management.\n2. LangChain maintainer’s recommendation suggests proactive caching to reduce overhead.\n3. The `await` expression failure with `agent executor.ainvoke` indicates a potential component issue.\n4. The `agent` component’s internal workings may be related to `ainvoke` calls.\n5. Addressing the `ainvoke` issue is crucial for stability and compatibility.\n\nTECHNICAL INSIGHTS:\n1. Cache optimization is a key area for performance enhancement.\n2. The `ainvoke` call is a potential bottleneck to be addressed.\n3. The `agent` component's internal workings are the primary focus.\n4. A potential component bug affecting the `run` function is identified.\n5. Dependency management and testing are critical for long-term stability.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 110, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code is encountering a `TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'` error when attempting to use the new `llama text embed v2` model with Pinecone. This stems from the model not being fully implemented in LangChain, requiring a workaround using the default model.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-21T16:01:02Z", "body_clean": "Hi, @coreyryanhanson. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You identified a bug with the [code] model causing a [code] when using [code] . The issue persists despite consulting documentation and updating to the latest version. No further comments or developments have been made on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain embeddings library is experiencing a rate limit exceeded error, preventing further processing. The issue stems from a specific code snippet within the `embeddings` module that incorrectly attempts to retrieve the 'data' key from the response. The code is designed to handle API errors, but the current implementation returns the 'data' key instead of raising an appropriate error, leading to a KeyError.  The issue is currently unresolved by a recent update to the LangChain library, and the author is documenting the problem for potential future debugging.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-20T17:50:19Z", "body_clean": "A [related patch]( [link] was just released in langchain mistralai==0.2.7, does this address your issue?"}, {"author": "dosubot[bot]", "created_at": "2025-05-22T16:00:51Z", "body_clean": "Hi, @maximekl. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a bug in the [code] function related to API rate limit errors causing a [code] . @ccurme mentioned a patch in [code] that might address the issue. Further confirmation or testing is needed to verify if the patch resolves the problem. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports that the structured output feature in LangChain returns unexpected data structures, specifically failing to match the defined schema. This problem isn't resolved by updating LangChain, and the bug was previously present in an older version.  The code example demonstrates this inconsistency when using the structured output feature.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-19T17:02:37Z", "body_clean": "Thanks for reporting this. Can you provide an example that I can run in a fresh session to reproduce the issue? Here is my attempt: [code] This passes with fresh installs from pypi: [code]"}, {"author": "yoch", "created_at": "2025-02-19T17:50:10Z", "body_clean": "OK I got it, sorry I was used a buggy code instanciating the schema like: [code]"}, {"author": "chungxon", "created_at": "2025-06-24T09:14:41Z", "body_clean": "Anyone else having this issue? I'm having the same weird thing as this issue. LLM sometimes returns json schema instead of the correct response as expected :( However, when I try again with the same input, it works perfectly so I'm unable to reproduce the issue"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `TokenTextSplitter` library is encountering a bug where start indices are sometimes -1, causing issues with text retrieval.  The issue was identified through a search of LangChain documentation and GitHub search, and the developers believe it’s a bug within the library’s internal logic.  Currently, the solution involves modifying the loop to handle potential duplicate text and potentially slow down the lookup process.", "final_category": "bug", "comments": [{"author": "MinhQuanBuiSco", "created_at": "2025-02-21T14:22:47Z", "body_clean": "Since you're still relying on find() without a backup plan for failures, there's always a chance that start index will be 1. I've updated create documents() to include a fallback mechanism that guarantees a valid index even if find() fails. Benefits of this approach: 1. Eliminates 1 values by ensuring a valid start index. 2. Maintains the correct sequence of chunks. 3. Handles well duplications. [code]"}, {"author": "vanderschuea", "created_at": "2025-02-21T14:39:29Z", "body_clean": "Hi, I don't think that estimating the position is the best approach. If the string is present verbatim, I'd rather prefer it being linked exactly, than approximately. Yes I'm aware that 1 will always be a necessary fallback because of the call to [code] , but not relying on [code] will need a bigger overhaul. I think the underlying issue is 2 fold: 1. The start and end indices should be saved in the metadata 2. The [code] function should change definitions to return start and end index of each chunk instead of simply returning a string This would enlarge support for every possible chunker (even those that modify the original text by eg. removing duplicate spaces etc.) back to this specific issue In the meantime I'd at least fix the [code] class by not using [code] as it is impossible to estimate how many characters are represented by 1 token. It's not great that so many unnecessary 1 are returned"}, {"author": "MinhQuanBuiSco", "created_at": "2025-02-21T17:44:42Z", "body_clean": "@vanderschuea Sorry, I just reviewed the code and noticed that chunk overlap represents the number of tokens, not characters. We can fix it easily like this: 1. split text on tokens: [code] 2. create documents: [code]"}, {"author": "aowen87", "created_at": "2025-05-12T21:47:41Z", "body_clean": "I'm also seeing this issue when using [code] . Is there any plan to fix this?"}, {"author": "aowen87", "created_at": "2025-05-14T16:03:11Z", "body_clean": "I'm also seeing this issue when using [code] . Is there any plan to fix this? These might actually be two separate issues that both come from encoding length vs plain string length."}, {"author": "ZacharyGonzalez", "created_at": "2025-07-29T00:13:33Z", "body_clean": "The code in the pull request is something i would like to discuss as it still requires work. I will continue to refine it and fix the issues until a discussion can be had. I do not believe modifying TextSplitter's create documents is the right way forwards, so I have overridden it in TokenTextSplitter, but let me know if my current implementation lacks potential."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Jira tools library is failing to correctly interpret data within LangChain queries, resulting in errors related to expected fields.  After investigating using various search methods and documentation, the issue appears to be a bug within the library itself, not a coding error in the user’s application.  The solution requires a fix within the LangChain library to correctly handle the Jira data structure.", "final_category": "bug", "comments": [{"author": "dokato", "created_at": "2025-02-20T17:32:46Z", "body_clean": "should be fixed with 29876"}]}], "business_insights": ["Model integration challenges impact workflow.", "Consistent API errors necessitate robust error handling.", "Schema mismatch hinders data retrieval accuracy.", "Bug detection requires systematic testing.", "Documentation gaps complicate debugging."], "technical_insights": ["LangChain model incompatibility causes errors.", "Rate limit exceeded errors need mitigation.", "Incorrect data retrieval in embeddings module.", "Code snippet introduces KeyError.", "LangChain library update requires review."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model integration challenges impact workflow.\n2. Consistent API errors necessitate robust error handling.\n3. Schema mismatch hinders data retrieval accuracy.\n4. Bug detection requires systematic testing.\n5. Documentation gaps complicate debugging.\n\nTECHNICAL INSIGHTS:\n1. LangChain model incompatibility causes errors.\n2. Rate limit exceeded errors need mitigation.\n3. Incorrect data retrieval in embeddings module.\n4. Code snippet introduces KeyError.\n5. LangChain library update requires review.", "batch_number": 111, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a bug where the `tool call id` parameter consistently returns `None` when calling the LangChain `tools` module. This issue stems from a problem with the `langchain core/tools/base.py` file, specifically in the `run()` method of the `CustomStreamingTool` class. The code attempts to return a specific format of output, but the `tool call id` parameter isn't being correctly handled, resulting in the `None` value being returned. The suggested solution is to debug the code further and ensure the `tool call id` parameter is handled correctly within the `run()` method.", "final_category": "bug", "comments": [{"author": "Strice91", "created_at": "2025-02-20T08:59:37Z", "body_clean": "Thanks for bringing that up. I also sent hours to find out why the artifacts never get returned. This happened to me with every tool I tried: [StructuredTool]( [link] Tool from [create retriever tool]( [link] Potential Cause I think it comes from the [code] which returns only the plain content if no [code] is given. [link] Workaround I was able to do a workaround when I sub classed the [code] class and override the [code] method with always injects a randomly generated [code] into its parent class. But I think, this cannot be right 😆"}, {"author": "simplifiedkd", "created_at": "2025-02-20T16:47:55Z", "body_clean": "Yes exactly. can you share an example. I believe you mean to say BaseTool ?"}, {"author": "Strice91", "created_at": "2025-02-21T14:01:19Z", "body_clean": "Oh sorry you are right, it's the [code] : [code] I hope this does not interfere with any other kind of mechanism. 🤞"}, {"author": "dosubot[bot]", "created_at": "2025-05-23T16:00:47Z", "body_clean": "Hi, @simplifiedkd. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] parameter is consistently [code] in tool responses, affecting artifact returns. @Strice91 confirmed the issue and identified the [code] function as a potential cause. A workaround involves subclassing [code] to inject a random [code] , which has been positively received but is temporary. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a bug in LangChain's `GitHub Toolkit` that causes issues with tool names containing spaces. The code attempts to load tools using the `tools` list, but the names are incorrectly formatted, leading to errors during the `create` operation.  The issue is currently resolved by modifying the tool names to remove spaces, but the code is designed to work with the current `tools` list.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-02-28T01:23:33Z", "body_clean": "I got a fix to it and will do a PR as soon as I get some time. Just need to finalize all the unit tests."}, {"author": "dosubot[bot]", "created_at": "2025-05-30T17:33:30Z", "body_clean": "Hi, @yasonk. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves invalid tool names in the Community GitHub toolkit, which contain spaces and are not supported by OpenAI. A workaround exists by manually setting tool names, but ideally, the tools should function without modification. @andrasfe has mentioned having a fix and plans to submit a pull request after finalizing unit tests, with positive feedback from you and other users. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "yasonk", "created_at": "2025-06-03T16:21:35Z", "body_clean": "@dosubot I would close this issue. The community is moved on to create MCP servers which supersede the community toolkits. So the issue is obsolete"}, {"author": "dosubot[bot]", "created_at": "2025-06-03T16:21:42Z", "body_clean": "Thank you for closing the issue, yasonk! We appreciate your help in keeping the repo organized."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe maintainer is investigating the integration of Azure Document Intelligence into LangChain, currently requiring API keys for authentication. The goal is to explore alternative authentication methods like AAD tokens, Azure CLI, and Managed Identity for improved security and compliance. The maintainer seeks feedback on the feasibility and potential solutions to this enhancement.", "final_category": "feature", "comments": [{"author": "taylorn-ai", "created_at": "2025-02-28T02:48:55Z", "body_clean": "You can use a [code] This was [added ]( [link] last month, so perhaps you don't have the latest version? [code]"}, {"author": "dosubot[bot]", "created_at": "2025-05-30T17:33:29Z", "body_clean": "Hi, @stad121. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You suggested enhancing Azure Document Intelligence integration by supporting alternative authentication methods. @TaylorN15 mentioned a recent addition of the [code] feature that might resolve this. A code snippet using [code] was provided, potentially addressing your request. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem with the Scoring script filter in LangChain, specifically when querying documents that are successfully indexed but fail to retrieve chunks. This occurs on both the local system and a cloud-based endpoint (AWS Jumpbox/Bastion Host), suggesting a potential issue with the indexing or filtering process. The user is seeking a solution to address this discrepancy.", "final_category": "bug", "comments": [{"author": "mrutunjay-kinagi", "created_at": "2025-02-18T12:38:07Z", "body_clean": "I found the root cause of the issue. VectorSearchDB’s default search config params used in LangChain integration code doesn’t work for scale scenarios. Those parameters does KNN search for the <term at file scope, and then filters the results down to specific document. As there are many matching results at file scope in this case, and were overflowing; so some matching results aren't even making it to second stage of filtering down to document. Better way would be to set search scope to document at first, and do KNN search at that scope. I tried this : [code] But now i'm facing this error : Error: OpenSearchVectorSearch.similarity search() got multiple values for argument 'query' @efriis @ccurme"}, {"author": "mrutunjay-kinagi", "created_at": "2025-02-18T12:40:27Z", "body_clean": "@baskaryan Please suggest. Raw OpenSearch Query is working when tested with out using langchain."}, {"author": "mrutunjay-kinagi", "created_at": "2025-02-18T13:23:03Z", "body_clean": "@dosu bot : Any suggestion ?"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a discrepancy between the documentation for the `DOC: ChatLiteLLM` project, specifically the model's `model_kwargs` parameter, and the actual description provided within the code.  The documentation lacks a description for the temperature parameter within the specified code sections, and there’s no request for content related to this missing information.", "final_category": "other", "comments": [{"author": "SaraInCode", "created_at": "2025-02-23T14:27:58Z", "body_clean": "take"}, {"author": "dosubot[bot]", "created_at": "2025-05-25T16:00:51Z", "body_clean": "Hi, @jaceyang97. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Documentation error in the [code] class. [code] incorrectly includes temperature information. [code] section is missing a description. @SaraInCode commented \"take,\" suggesting they may be working on a fix. Next Steps: Is this issue still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Focus on tool call id consistency across modules – identify root causes.", "Debugging run() method for tool call id handling – potential for subtle errors.", "Investigate the langchain core/tools/base.py file for the tool call id parameter – code review.", "Verify the tool call id parameter’s handling within the run() method – ensure correct format.", "Consider a more robust error handling strategy for the tool call id parameter."], "technical_insights": ["tool call id parameter inconsistency across modules – requires detailed code analysis.", "langchain core/tools/base.py file debugging – potential for code errors.", "tool call id parameter handling within run() method – verify correct format.", "Verify the tool call id parameter’s handling within the run() method – ensure correct format.", "Investigate the langchain core/tools/base.py file for the tool call id parameter – code review."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Focus on `tool call id` consistency across modules – identify root causes.\n2.  Debugging `run()` method for `tool call id` handling – potential for subtle errors.\n3.  Investigate the `langchain core/tools/base.py` file for the `tool call id` parameter – code review.\n4.  Verify the `tool call id` parameter’s handling within the `run()` method – ensure correct format.\n5.  Consider a more robust error handling strategy for the `tool call id` parameter.\n\nTECHNICAL INSIGHTS:\n1.  `tool call id` parameter inconsistency across modules – requires detailed code analysis.\n2.  `langchain core/tools/base.py` file debugging – potential for code errors.\n3.  `tool call id` parameter handling within `run()` method – verify correct format.\n4.  Verify the `tool call id` parameter’s handling within the `run()` method – ensure correct format.\n5.  Investigate the `langchain core/tools/base.py` file for the `tool call id` parameter – code review.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 112, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a critical bug preventing the Stream model from correctly processing `ChatMistralAI` and `with_structured_output` mode. The problem manifests as a response that receives the entire output at once, causing an error.  The issue appears to be a regression within LangChain itself, rather than a specific code change, and the solution requires a recent update to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "brochier", "created_at": "2025-02-20T18:51:49Z", "body_clean": "If anyone could propose a quick fix to maintain the custom JSON mode while maintaining the stream response it would be amazing ! I tried to deep dive into the code but I can't understand where exactly the json parser is defined when using the [code] method and thus I can't verify if the [code] is passed."}, {"author": "andrasfe", "created_at": "2025-02-22T15:49:59Z", "body_clean": "I don't know if there is more to it, but adding the underscore to \"biggest cities\" fixed it for me. The error is coming from the output schema definition, specifically with the title \"biggest cities\". According to the error message, function names must only contain alphanumeric characters, underscores, and dashes (no spaces). Here's how to fix it: [code]"}, {"author": "brochier", "created_at": "2025-02-24T16:00:40Z", "body_clean": "I did a mistake when copy pasting the code (I updated my post). It should indeed be [code] . In this case, it does not produce any error. It is just not streaming, that's the bug I want to point."}, {"author": "keenborder786", "created_at": "2025-02-24T22:47:41Z", "body_clean": "Following is the payload being passed to Mistral Endpoint [code] : [code] I tested the Mistral API and directly and the tool calling streaming is not yet supported in MistralAI therefore it is yielding the output as a single result."}, {"author": "brochier", "created_at": "2025-02-25T09:10:24Z", "body_clean": "Using the API directly actually works as expected. So the bug is in langchain. [code]"}, {"author": "brochier", "created_at": "2025-02-27T14:26:27Z", "body_clean": "Here is a substitue I currently use to get streaming working while enforcing structured output. [code]"}, {"author": "aheschl1", "created_at": "2025-03-27T02:05:58Z", "body_clean": "Hello, I am getting a similar issue with Ollama and tool calling: [code] and [code] leads to the entire message printing at once."}, {"author": "dosubot[bot]", "created_at": "2025-06-26T16:03:08Z", "body_clean": "Hi, @brochier. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] model's [code] method does not function correctly with [code] and [code] mode. The entire response is received at once, contrary to expected streaming behavior. @keenborder786 mentioned the Mistral API's lack of support for tool calling streaming, but you confirmed direct API usage works, suggesting a LangChain bug. You provided a workaround using a custom API client for streaming with structured output. A similar issue was reported by @aheschl1 with the Ollama model. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical bug in the Ollama library, specifically related to the deprecated `create structured output chain` function. The code attempts to generate structured output, but it fails due to an incompatibility with a specific version of LangChain.  The issue also includes a traceback indicating a potential issue with the `deprecation.py` file, suggesting a problem with the Ollama library itself.", "final_category": "bug", "comments": [{"author": "RaffaelloFornasiere", "created_at": "2025-02-18T12:07:30Z", "body_clean": "Hi, I tested this and found that replacing [code] with [code] works correctly, as suggested by the deprecation warning. Does this work for you as well?"}, {"author": "trash-fish", "created_at": "2025-02-19T13:27:31Z", "body_clean": "Hi, I tested this and found that replacing [code] with [code] works correctly, as suggested by the deprecation warning. Does this work for you as well? Are you saying like this? This indeed works. [code]"}, {"author": "RaffaelloFornasiere", "created_at": "2025-02-19T13:45:39Z", "body_clean": "Yes, exactly"}, {"author": "trash-fish", "created_at": "2025-02-19T13:46:11Z", "body_clean": "Yes, exactly Okay, thank you"}]}, {"ollama_summary": "The LangChain project is experiencing an issue with the `create react agent` tool, causing a `ValueError` when connecting to JiraToolkit. This likely stems from an incompatibility between the LangChain integration and the JiraToolkit, potentially requiring a recent update to the LangChain package or a specific configuration change.", "final_category": "bug", "comments": [{"author": "PersonalRec", "created_at": "2025-02-17T13:28:15Z", "body_clean": "The issue was in the missing line of code in the [documentation]( [link] This code has a missing line: [code]"}]}, {"ollama_summary": "The ChatFireworks issue stems from a bug where the API retry mechanism isn’t functioning correctly, causing workflow failures due to API errors.  The problem isn’t directly in the code, but rather a lack of a defined retry parameter within the ChatFireworks class, hindering its ability to handle API errors effectively.  Currently, the issue is not resolved by updating LangChain, requiring users to implement their own retry logic.", "final_category": "bug", "comments": [{"author": "aimestereo", "created_at": "2025-02-17T09:48:51Z", "body_clean": "Interim solution for those who experience issues with Fireworks models: add your own retry logic, for example as wrapper around model calls I have a better solution for it and probably this bug is not longer valid. According to [fireworks.AI documentation]( [link] it has compatibility with OpenAI client. You can use [OpenAI Python client library]( [link] to interact with Fireworks. This makes migration of existing applications already using OpenAI particularly easy. That means, that langchain fireworks client can be marked as deprecated? (considering lack functionality) and client for OpenAI can be used instead. In my case I used [code] with [code] and [code] for fireworks.ai works like a charm."}, {"author": "dosubot[bot]", "created_at": "2025-05-19T16:01:00Z", "body_clean": "Hi, @aimestereo. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves the [code] integration in LangChain not retrying on API errors despite the [code] parameter. You provided example code and an error message to illustrate the problem. You suggested using the OpenAI Python client library as an alternative, which worked successfully with Fireworks. You proposed deprecating the LangChain Fireworks client due to its lack of functionality. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain's `FactWithEvidence.get_spans` method, which incorrectly matches substrings to context due to a high default error threshold. This results in inaccurate results, performance issues (taking 2 minutes), and a potential need to reduce the error threshold.  The root cause is excessive fuzzy matching logic, and a suggested fix is to reduce the error threshold and add input validation.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-19T16:00:57Z", "body_clean": "Hi, @Alioth99. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a problem with the [code] method, where the default error threshold of 100 leads to incorrect matches and performance issues. The method is matching unrelated quotes to the context, resulting in irrelevant spans and slow execution. You suggested lowering the error threshold, implementing input validation, and improving documentation for [code] . There have been no further comments or activity on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here to keep the discussion open. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["LangChain’s stability is crucial; regressions impact widespread adoption.", "Recent updates may be causing compatibility issues across different versions.", "The deprecation.py issue suggests a fundamental library problem.", "Integration testing needs more rigorous coverage, particularly with Ollama.", "Error handling and retry mechanisms require more robust design."], "technical_insights": ["LangChain’s recent updates are triggering regression in the ChatMistralAI processing.", "Ollama’s create structured output chain function is experiencing a critical incompatibility.", "The deprecation.py file indicates a potential issue with the Ollama library itself.", "The create react agent tool is failing due to a ValueError with LangChain integration.", "The FactWithEvidence.get_spans method has an incorrect match threshold, impacting results."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s stability is crucial; regressions impact widespread adoption.\n2.  Recent updates may be causing compatibility issues across different versions.\n3.  The `deprecation.py` issue suggests a fundamental library problem.\n4.  Integration testing needs more rigorous coverage, particularly with Ollama.\n5.  Error handling and retry mechanisms require more robust design.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s recent updates are triggering regression in the `ChatMistralAI` processing.\n2.  Ollama’s `create structured output chain` function is experiencing a critical incompatibility.\n3.  The `deprecation.py` file indicates a potential issue with the Ollama library itself.\n4.  The `create react agent` tool is failing due to a `ValueError` with LangChain integration.\n5.  The `FactWithEvidence.get_spans` method has an incorrect match threshold, impacting results.\n", "batch_number": 113, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a critical bug preventing the Stream component from functioning correctly with the ChatXAI agent. The code attempts to stream data back, but instead receives the full response, causing errors and rendering the intended functionality unavailable.  The issue appears to be a regression, potentially related to a recent LangChain update, and is not easily resolved by simply updating the version.", "final_category": "bug", "comments": [{"author": "AffanBinFaisal", "created_at": "2025-02-17T08:06:22Z", "body_clean": "Have you tried setting streaming=True instead of False in: [code]"}, {"author": "kboniadi", "created_at": "2025-02-17T19:18:56Z", "body_clean": "@AffanBinFaisal yah I tried that. Actually should have left it 'True' for the code paste. Will update. Below is the result of the code when settings it to 'True' [code] [code]"}, {"author": "kboniadi", "created_at": "2025-03-14T20:42:48Z", "body_clean": "fix is that u need to be on python =3.11"}, {"author": "dosubot[bot]", "created_at": "2025-06-13T16:01:48Z", "body_clean": "Hi, @kboniadi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involved a bug with streaming in LangChain using ChatXAI with AgentExecutor. You confirmed the [code] parameter was set to [code] as suggested. The problem was resolved by upgrading to Python version 3.11 or higher. @AffanBinFaisal acknowledged the resolution with a thumbs up. Next Steps: If the issue is still relevant to the latest version of LangChain, please comment to keep the discussion open. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a problem with a chain-based SQL QA pipeline within LangChain that consistently generates incorrect SQL queries instead of retrieving data from the database. The issue stems from a potential misconfiguration related to prompt injection, schema retrieval, or session state, leading to the LLM targeting system tables instead of the intended data. The issue is currently unresolved and requires investigation into potential configurations and dependencies.", "final_category": "bug", "comments": [{"author": "devroopsaha744", "created_at": "2025-02-16T19:16:06Z", "body_clean": "I have solved the problem. But the flaw still exists in the logic given the in official documentation. If someone is facing the similar problem, use this [notebook]( [link] as a reference (see the last 3 4 cells) I think the documentation needs an update, especially the chain logic given in the official doc is NOT working properly. I am closing this issue now."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where the “微信交流群” (WeChat Discussion Group) URL is not responding, despite a descriptive title and documentation link being provided.  The core issue is a lack of response to a request for content within the group, requiring investigation and resolution.  Currently, the issue is focused on ensuring the group’s URL is functional and accessible.", "final_category": "other", "comments": [{"author": "langcarl[bot]", "created_at": "2025-02-15T08:25:24Z", "body_clean": "This issue has been flagged as spam and will be closed. Please tag @ccurme if you feel this was done in error."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Chroma integration API documentation is incorrectly directing users to the JavaScript client instead of the official HTML documentation. This issue stems from outdated documentation that needs to be updated to reflect the correct source for Chroma’s API.  The core problem is a discrepancy in the documentation’s link between the Chroma API and its client documentation.", "final_category": "other", "comments": [{"author": "hesreallyhim", "created_at": "2025-03-26T15:57:38Z", "body_clean": "@SayakMukhopadhyay I think this is resolved"}, {"author": "SayakMukhopadhyay", "created_at": "2025-03-26T16:11:31Z", "body_clean": "Awesome, closing this issue."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe LangChain documentation for Google Generative AI Embedding incorrectly uses the `getpass` module, resulting in a specific error. The documentation provides a correct alternative code snippet, but the current implementation is flawed.  The issue requires a fix to ensure the correct usage of the `getpass` module within the documentation to avoid the identified error.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-16T16:00:54Z", "body_clean": "Hi, @jasminaaa20. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights a documentation error related to Google Generative AI Embedding. The error involves the incorrect use of the [code] module, leading to a [code] . You provided the corrected code and a screenshot to illustrate the issue. No further comments or activities have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Stream component bug requires immediate attention; recent LangChain update likely involved.", "Regression issue necessitates a thorough code review and potential version rollback.", "Data stream back issue highlights a potential security vulnerability – stream=True must be set."], "technical_insights": ["LangChain update likely triggered the bug; stream=True is crucial for data retrieval.", "Incorrect SQL query generation suggests prompt injection or schema retrieval.", "Session state and configuration issues may be contributing to the LLM’s targeting system."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Stream component bug requires immediate attention; recent LangChain update likely involved.\n2. Regression issue necessitates a thorough code review and potential version rollback.\n3. Data stream back issue highlights a potential security vulnerability – stream=True must be set.\n\nTECHNICAL INSIGHTS:\n1.  LangChain update likely triggered the bug; stream=True is crucial for data retrieval.\n2.  Incorrect SQL query generation suggests prompt injection or schema retrieval.\n3.  Session state and configuration issues may be contributing to the LLM’s targeting system.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 114, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue highlights a critical bug in the AzureCosmosDBNoSqlVectorSearch library that prevents the application of the IN query filter. This issue is causing errors when attempting to use the IN operator, requiring a change to the operator map to support this functionality.  The code provides a detailed traceback and stack trace, indicating a potential issue within the LangChain library itself.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue involves a bug where ChatMistralAI fails to apply frequency penalties to its Mistral API responses, resulting in a null frequency penalty being returned.  The problem appears to be a discrepancy in how the LangChain integration handles this argument, despite it being supported by the Mistral API.  The solution involves manually sending the request to the API and adapting the code to achieve the desired behavior.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-16T16:00:53Z", "body_clean": "Hi, @Bernsai. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug was identified in the [code] class of the [code] package (version 0.2.6). The [code] argument is not being passed to the Mistral API, resulting in a null value in the API request. You confirmed that manually adding the [code] resolves the issue, indicating a flaw in parameter handling. No further activity or comments have been made on the issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a bug in LangChain’s Parent Document Retriever that prevents parent documents from updating correctly when re-indexed.  The bug occurs when the Record Manager doesn’t update the UIDs of child documents, hindering the retriever’s ability to identify and update the parent document.  Currently, the issue is not resolved by updating the LangChain version, suggesting a potential bug within the integration package.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-16T16:00:53Z", "body_clean": "Hi, @bneel work. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug in LangChain's Parent Document Retriever prevents parent documents from updating correctly during re indexing. Child documents re index successfully, but the issue persists with parent documents. You confirmed the issue is not due to your code and persists in the latest LangChain version. No further activity or comments have been made on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further input, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue is preventing the LangChain RAG system from loading `.doc` files, resulting in a \"zipfile.BadZipFile: File is not a zip file\" error. The problem stems from an incorrect `UnstructuredWordDocumentLoader` implementation, likely related to a bug in the integration package.  The solution involves updating to the latest stable version of LangChain or the specific integration package, which is currently unresolved.", "final_category": "bug", "comments": [{"author": "andrasfe", "created_at": "2025-02-19T04:20:28Z", "body_clean": "I am assuming you mean langchain=0.3.18? I am running the same example using that version + langchain community 0.3.17 and works fine for me. I used a random libre .doc document (on ubuntu). Also used: Package versions: Name: unstructured Version: 0.16.21 Name: python docx Version: 1.1.2"}, {"author": "ejstembler", "created_at": "2025-02-21T17:13:41Z", "body_clean": "I'm getting the same issue using [code] ."}, {"author": "andrasfe", "created_at": "2025-03-05T00:59:55Z", "body_clean": "this seems to me like an unstructured or nltk error. when the doc file is parsed nltk tries to use the tokenizer model but since it cannot find it, it tries to load from a particular path, where the file is not in zip format or is corrupted."}, {"author": "yanjip", "created_at": "2025-05-07T09:11:52Z", "body_clean": "I also encountered a similar problem, but it has been solved at present. Reinstall the nltk package and download the book data. import nltk nltk.download()"}]}, {"ollama_summary": "This issue involves a critical regression in the Hugging Face Endpoint Embeddings library, specifically failing to correctly integrate with the LangChain embedding server when the `huggingface-hub==0.28.1` version is used. The code attempts to send embedding requests to HF, but the integration is broken, requiring a manual update to the library to resolve the problem.", "final_category": "bug", "comments": [{"author": "MhdAdnan-404", "created_at": "2025-04-20T15:35:54Z", "body_clean": "+1"}, {"author": "tomaarsen", "created_at": "2025-05-15T07:40:16Z", "body_clean": "cc @hanouticelina is this issue familiar to you? I think it could be [code] related. Tom Aarsen"}, {"author": "hanouticelina", "created_at": "2025-05-15T09:49:00Z", "body_clean": "Hi @shkarupa alex, Upgrading [code] package should fix the issue: [code] let us know if you still have the same bug after that."}]}], "business_insights": ["LangChain’s AzureCosmosDBNoSqlVectorSearch library bug impacts IN queries, requiring operator map adjustments.", "Mistral API frequency penalties are null due to a discrepancy in LangChain integration, necessitating manual API requests.", "Parent document update failures in LangChain’s RAG system stem from incorrect UIDs in the Record Manager.", "LangChain’s Parent Document Retriever bug hinders parent document updates when re-indexed.", "The integration package bug in LangChain’s RAG system prevents parent document updates."], "technical_insights": ["LangChain library bug affecting IN queries – operator map changes are required.", "Mistral API frequency penalty issue – manual API calls are needed to resolve.", "Parent document retriever bug – incorrect UIDs causing updates.", "RAG system integration bug – incorrect UIDs hindering updates.", "LangChain version bug – Parent Document Retriever integration."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s AzureCosmosDBNoSqlVectorSearch library bug impacts IN queries, requiring operator map adjustments.\n2. Mistral API frequency penalties are null due to a discrepancy in LangChain integration, necessitating manual API requests.\n3. Parent document update failures in LangChain’s RAG system stem from incorrect UIDs in the Record Manager.\n4. LangChain’s `Parent Document Retriever` bug hinders parent document updates when re-indexed.\n5. The integration package bug in LangChain’s RAG system prevents parent document updates.\n\nTECHNICAL INSIGHTS:\n1. LangChain library bug affecting IN queries – operator map changes are required.\n2. Mistral API frequency penalty issue – manual API calls are needed to resolve.\n3. Parent document retriever bug – incorrect UIDs causing updates.\n4. RAG system integration bug – incorrect UIDs hindering updates.\n5. LangChain version bug – Parent Document Retriever integration.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 115, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This GitHub issue highlights a problem where different parts of the Langchain-Elasticsearch documentation are incompatible with different Elasticsearch versions. The documentation adapts to newer versions, but the code itself doesn’t always fully support older versions, potentially leading to unexpected behavior. The issue requests a review of the documentation to clarify supported versions and potentially include code checks for compatibility.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-15T16:01:01Z", "body_clean": "Hi, @olbermann. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised concerns about inconsistencies in LangChain documentation regarding supported Elasticsearch versions. Noted examples use Elasticsearch 8.12.1, but newer formats in the documentation may not be compatible. Suggested explicitly stating supported Elasticsearch versions and adding a code check for compatibility. No comments or developments have been made on this issue yet. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue addresses a bug in LangChain’s callback handler that incorrectly includes reasoning tokens in cost calculations for OpenAI models. The current implementation omits these tokens, leading to inaccurate billing and requires a fix to accurately reflect the total cost for all billable token types.  The proposed solution involves updating the token usage logic to incorporate reasoning tokens, ensuring consistent cost calculations across models.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-15T16:00:58Z", "body_clean": "Hi, @dbuos. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the LangChain library related to cost calculations. The issue affects the [code] and [code] models, where reasoning tokens are excluded from cost computations. You provided code examples from [code] to illustrate the problem. There have been no comments or updates since the issue was opened. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a problem with the ChatOpenAI/AzureChatOpenAI model, specifically the `stream` method, which is failing to correctly output audio chunks when using the `gpt-4o-audio-preview` model.  The code attempts to stream audio responses, but the `stream` method is returning empty data, and the standard `langchain` stream mode isn't working.  The issue appears to be a bug within the LangChain integration, and attempts to fix it by updating the core LangChain version have been unsuccessful.", "final_category": "bug", "comments": [{"author": "jorgehermo9", "created_at": "2025-02-13T09:30:51Z", "body_clean": "Thank you very much opening this. I was diving a little bit in the code and I think I found the problem. Will submit a PR addressing this as soon as I can."}, {"author": "droidnoob", "created_at": "2025-02-13T09:46:43Z", "body_clean": "Thank you very much opening this. I was diving a little bit in the code and I think I found the problem. Will submit a PR addressing this as soon as I can. Thanks @jorgehermo9 I know this might not be part of the PR you're going to create. Once this change is added I assume whenever someone uses the audio model to create an agent, the chat history will contain the base64 data as well. The open ai [documention ]( [link] shows we just need to add the audio id as the previous message like so [code] If the base64 is added it will eat up the token limit I assume."}, {"author": "jorgehermo9", "created_at": "2025-02-13T09:54:09Z", "body_clean": "yeah I think we should retrieve also the audio id along with the data, and replicate what the 'streaming=false' code does"}, {"author": "dosubot[bot]", "created_at": "2025-05-15T16:00:56Z", "body_clean": "Hi, @droidnoob. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a problem with streaming audio chunks using [code] and [code] models, specifically with the [code] model. The issue involves empty [code] during streaming, unlike the OpenAI Python package. jorgehermo9 has identified the problem and plans to submit a PR to address it. You raised concerns about token limits if base64 data is included in chat history, suggesting using audio IDs instead. Next Steps Could you confirm if this issue is still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where the model output is incomplete, specifically failing to include the crucial `<think tag>` that LangChain uses to structure its output. The issue stems from discrepancies in the thought process and formatting between the OpenAI and LangChain APIs, despite both producing the same final conclusion (9.8 is larger than 9.11). The issue is likely a bug in LangChain itself, not a user-defined code change.", "final_category": "bug", "comments": [{"author": "xuzexin-hz", "created_at": "2025-03-13T07:45:12Z", "body_clean": "Checked other resources [x] I added a very descriptive title to this issue.[x] I searched the LangChain documentation with the integrated search.[x] I used the GitHub search to find a similar question and didn't find it.[x] I am sure that this is a bug in LangChain rather than my code.[x] The bug is not resolved by updating to the latest stable version of LangChain (or the specific integration package). Example Code Observed differences (1) Format and structure: LangChain output: The beginning directly states that the concept of “place value” is used to split the number. A step by step explanation of each digit (digit, decile, percentile) is presented for each number. In the comparison process, the deciles are compared directly, conclusions are drawn, and the final answer is labeled with mathematical symbols and boxes. OpenAI calls the output directly: Use the tag to wrap the initial thought process. Align decimal places by rewriting 9.8 as 9.80, then compare percentiles. The formatting and language are slightly different, although the final conclusion is the same. (2) Details of the thinking process: Both explain why comparing deciles is straightforward, but with different emphases: LangChain emphasizes the notion of “place value,” while OpenAI's direct call focuses more on number alignment (e.g., writing 9.8 as 9.80). The specific version and test sample code results are as follows： [code] (1) Original OpenAI API result: from openai import OpenAI openai api key = \"EMPTY\" openai api base = \" [link] client = OpenAI( api key=openai api key, base url=openai api base, ) chat response = client.chat.completions.create( model=\"DeepSeek R1 Distill Qwen 32B\", messages=[ {\"role\": \"user\", \"content\": \"Which is bigger, 9.11 or 9.8?\"}, ], temperature=0.000001, max tokens=8192, extra body={ \"repetition penalty\": 1.05, }, ) print(chat response.choices[0].message.content) output: <think First, I need to compare the two numbers: 9.11 and 9.8. Both numbers have the same whole number part, which is 9. Next, I'll look at the decimal parts. The first number has 0.11, and the second number has 0.8. To make it easier, I can rewrite 9.8 as 9.80 so that both numbers have the same number of decimal places. Now, comparing the hundredths place: 0.11 is less than 0.80. Therefore, 9.11 is less than 9.8. </think To determine which number is larger between 9.11 and 9.8 , let's compare them step by step. Step 1: Compare the Whole Number Part Both numbers have the same whole number part: 9 .11 9 .8 Since the whole numbers are equal, we move on to compare the decimal parts. Step 2: Compare the Decimal Parts 9.11 has a decimal part of 0.11 9.8 can be written as 9.80 to have the same number of decimal places. Now, compare the hundredths place: 0.11 (from 9.11) 0.80 (from 9.8) Since 0.11 < 0.80 , it follows that 9.11 < 9.8 . Final Answer \\[ \\boxed{9.8 \\text{ is bigger}} \\] (2) Langchain Openai API result: from langchain.llms import OpenAI llm = OpenAI( model name = \"DeepSeek R1 Distill Qwen 32B\", openai api base = \" [link] openai api key = \"EMPTY\", temperature=0.000001, max tokens=8192, ) query = \"Which is bigger, 9.11 or 9.8?\" print(llm.invoke(query)) output: To figure this out, you can use the concept of place value. Let's break down each number into its place values. For 9.11, the 9 is in the ones place, the 1 is in the tenths place, and the second 1 is in the hundredths place. For 9.8, the 9 is in the ones place, the 8 is in the tenths place, and there is no hundredths place. Now, compare the tenths place of both numbers. Since 8 is greater than 1, 9.8 is bigger than 9.11. So, 9.8 is bigger. </think To determine which number is larger between 9.11 and 9.8 , we can compare them by examining their place values. Breaking Down the Numbers: 1. 9.11 9 is in the ones place . 1 is in the tenths place . 1 is in the hundredths place . 2. 9.8 9 is in the ones place . 8 is in the tenths place . There is no hundredths place (implied to be 0 ). Comparing the Numbers: Ones Place: Both numbers have 9 in the ones place, so they are equal here. Tenths Place: 9.11 has 1 in the tenths place. 9.8 has 8 in the tenths place. Since 8 1 , 9.8 is greater than 9.11 in the tenths place. Conclusion: Since 9.8 has a greater value in the tenths place compared to 9.11 , 9.8 is the larger number. \\[ \\boxed{9.8} \\] Conclusion The model's output is missing the leading tag. There may be differences in the results under different invocation methods and perhaps in the results. Users may have questions about the details of the interpretation and the format of the output, affecting the understanding of the answer,. Error Message and Stack Trace (if applicable) No response Description In the example comparing two numbers (9.11 and 9.8), the answers obtained by calling the OpenAI interface directly versus calling it through LangChain are consistent in their final conclusions (both indicate that 9.8 is larger than 9.11), but there are significant differences in their chain of thought processes and formats. System Info System Information OS: Linux OS Version: 1 SMP Sat Jul 23 16:22:50 CST 2022 Python Version: 3.12.8 | packaged by conda forge | (main, Dec 5 2024, 14:24:40) [GCC 13.3.0] Package Information langchain core: 0.3.34 langchain: 0.3.18 langchain community: 0.3.16 langsmith: 0.3.6 langchain text splitters: 0.3.6 Optional packages not installed langserve Other Dependencies aio [link] 3.11.12 aio [link] Installed. No version info available. async timeout<5.0.0, =4.0.0;: Installed. No version info available. dataclasses json: 0.6.7 [link] 0.26.0 [link] 0.4.0 jsonpatch<2.0, =1.33: Installed. No version info available. langchain anthropic;: Installed. No version info available. langchain aws;: Installed. No version info available. langchain cohere;: Installed. No version info available. langchain community;: Installed. No version info available. langchain core<1.0.0, =0.3.34: Installed. No version info available. langchain deepseek;: Installed. No version info available. langchain fireworks;: Installed. No version info available. langchain google genai;: Installed. No version info available. langchain google vertexai;: Installed. No version info available. langchain groq;: Installed. No version info available. langchain huggingface;: Installed. No version info available. langchain mistralai;: Installed. No version info available. langchain ollama;: Installed. No version info available. langchain openai;: Installed. No version info available. langchain text splitters<1.0.0, =0.3.6: Installed. No version info available. langchain together;: Installed. No version info available. langsmith pyo3: Installed. No version info available. langsmith<0.4, =0.1.125: Installed. No version info available. langsmith<0.4, =0.1.17: Installed. No version info available. numpy: 1.26.4 numpy<2, =1.26.4;: Installed. No version info available. numpy<3, =1.26.2;: Installed. No version info available. orjson: 3.10.15 packaging<25, =23.2: Installed. No version info available. pydantic: 2.10.6 pydantic settings: 2.7.1 pydantic<3.0.0, =2.5.2;: Installed. No version info available. pydantic<3.0.0, =2.7.4: Installed. No version info available. pydantic<3.0.0, =2.7.4;: Installed. No version info available. pytest: 8.3.4 PyYAML: 6.0.2 PyYAML =5.3: Installed. No version info available. requests: 2.32.3 requests toolbelt: 1.0.0 requests<3, =2: Installed. No version info available. rich: 13.9.4 SQLAlchemy: 2.0.38 SQLAlchemy<3, =1.4: Installed. No version info available. tenacity: 9.0.0 tenacity!=8.4.0,<10, =8.1.0: Installed. No version info available. tenacity!=8.4.0,<10.0.0, =8.1.0: Installed. No version info available. typing extensions =4.7: Installed. No version info available. zstandard: 0.23.0 Hi, boy, the biggest problem here is that these are two different interfaces, /chat/completions and /completions. If you don't know the difference between these two interfaces, please refer to the openai documentation. Also, some parameters of ollama are not supported, but you are using OpenAI here."}, {"author": "dosubot[bot]", "created_at": "2025-06-12T16:03:04Z", "body_clean": "Hi, @ace xc. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Discrepancies in output format when using LangChain with a local DeepSeek distillation model versus direct OpenAI API calls. LangChain output emphasizes \"place value\" and uses mathematical symbols; OpenAI output focuses on number alignment with different formatting. User xuzexin hz suggests the issue may be due to different interfaces used ( [code] vs [code] ). Confirmed as a bug in LangChain, not related to user's code or version updates. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The HuggingFaceEmbeddings library is deprecated, causing issues with LangChain. The issue stems from a bug in the latest LangChain version (0.2.2) that prevents the use of the query instruction parameter, requiring a switch to HuggingFaceEmbeddings.  The solution involves installing the newer library and importing it correctly.", "final_category": "bug", "comments": [{"author": "tomaarsen", "created_at": "2025-05-15T07:38:57Z", "body_clean": "Hello! You should just be able to use the [code] to get identical embeddings: [code] Compared to: [code] Both use Sentence Transformers under the hood, but the Bge class manually prepended the instruction whereas the HuggingFaceEmbeddings class uses the [ [code] encode argument]( [link] Tom Aarsen"}, {"author": "sam-bercovici", "created_at": "2025-05-15T14:55:13Z", "body_clean": "After updating the langchain huggingface, it worked."}]}], "business_insights": ["Documentation compatibility issues across different Elasticsearch versions necessitate standardized documentation updates.", "Maintaining backward compatibility is crucial for long-term system stability and user adoption.", "Addressing documentation inconsistencies will improve the user experience and reduce support requests.", "Clear documentation is fundamental for effective LangChain usage.", "Standardized documentation ensures consistent behavior across different models."], "technical_insights": ["LangChain’s documentation adaptation process presents a significant challenge – version-specific compatibility.", "The stream method’s failure to output audio chunks is a critical bug impacting cost calculations.", "The ChatOpenAI/AzureChatOpenAI model’s stream method requires a fix to accurately reflect token cost.", "The token_usage logic must be updated to handle reasoning tokens, ensuring consistent billing.", "The LangChain versioning issue represents a fundamental bug within the core LangChain framework."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Documentation compatibility issues across different Elasticsearch versions necessitate standardized documentation updates.\n2. Maintaining backward compatibility is crucial for long-term system stability and user adoption.\n3. Addressing documentation inconsistencies will improve the user experience and reduce support requests.\n4. Clear documentation is fundamental for effective LangChain usage.\n5. Standardized documentation ensures consistent behavior across different models.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s documentation adaptation process presents a significant challenge – version-specific compatibility.\n2. The `stream` method’s failure to output audio chunks is a critical bug impacting cost calculations.\n3. The ChatOpenAI/AzureChatOpenAI model’s `stream` method requires a fix to accurately reflect token cost.\n4. The `token_usage` logic must be updated to handle reasoning tokens, ensuring consistent billing.\n5. The LangChain versioning issue represents a fundamental bug within the core LangChain framework.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 116, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `vectorstore.py` for ChromaDB throws a ValueError when saving embeddings created by sentence transformer due to an ambiguous array structure. The issue stems from the check failing to correctly handle arrays with more than one element.  The problem isn’t directly in the code but appears to be a bug within the LangChain integration package, potentially related to the sentence transformer library.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a bug in the LangChain library, specifically within the `chunk_size` parameter of the `embed_documents` function, causing errors when processing documents with a specific size. This issue is currently present in the latest stable version of the repository and is not resolved by updates to the latest stable version.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue reports a discrepancy between the documentation and the actual default value for `num_predict` in OllamaLLM, which should be set to 128 tokens. The author believes this is a mistake and wants to highlight it for clarity.  Currently, the documentation doesn't enforce a limit on generation to 128 tokens, potentially leading to unexpected behavior.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-14T16:00:56Z", "body_clean": "Hi, @arty hlr. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You identified an error in the LangChain documentation regarding the default value for [code] in OllamaLLM. The documentation incorrectly states a default value other than [code] . The implementation does not limit generation to 128 tokens, which contradicts the documentation. No comments or activity have occurred since the issue was opened. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no further activity occurs, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue involves a critical bug in LangChain that causes the HuggingFaceEndpoint to attempt to access a specific Mistral Nemo Instruct 2407 model, despite not needing it. The issue is resolved by downgrading the LangChain version to a stable state, effectively eliminating the problematic integration.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-14T16:00:56Z", "body_clean": "Hi, @XinyaoWa. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with [code] defaulting to \"mistralai/Mistral Nemo Instruct 2407\". Example code was provided to demonstrate the issue. The problem persists even after updating to the latest LangChain version. No further comments or activity have been added to the issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on poorly written documentation with several inconsistencies and unclear code snippets. Specifically, the documentation lacks keyword arguments, uses only one keyword argument, and doesn’t define a return type.  The core request is to improve the clarity and structure of the documentation to better assist beginners.", "final_category": "other", "comments": []}], "business_insights": ["Consistent documentation errors hinder developer understanding, increasing support burden.", "Inconsistent documentation creates confusion and rework, impacting project speed.", "Lack of clear return types makes code harder to understand and debug.", "Poorly structured documentation increases the need for extensive manual review.", "Improving documentation streamlines development workflows and reduces errors."], "technical_insights": ["LangChain integration package documentation is inconsistent, affecting usability.", "chunk_size parameter in embed_documents function is poorly defined and has a bug.", "OllamaLLM documentation fails to accurately reflect default num_predict value.", "HuggingFaceEndpoint attempts to access a specific Mistral Nemo model, despite not needing it.", "LangChain version downgrading resolves the problematic integration issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent documentation errors hinder developer understanding, increasing support burden.\n2. Inconsistent documentation creates confusion and rework, impacting project speed.\n3. Lack of clear return types makes code harder to understand and debug.\n4. Poorly structured documentation increases the need for extensive manual review.\n5. Improving documentation streamlines development workflows and reduces errors.\n\nTECHNICAL INSIGHTS:\n1.  LangChain integration package documentation is inconsistent, affecting usability.\n2.  `chunk_size` parameter in `embed_documents` function is poorly defined and has a bug.\n3.  OllamaLLM documentation fails to accurately reflect default `num_predict` value.\n4.  HuggingFaceEndpoint attempts to access a specific Mistral Nemo model, despite not needing it.\n5.  LangChain version downgrading resolves the problematic integration issue.\n", "batch_number": 117, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue focuses on a persistent problem with `partner` packages (specifically version dependencies and broken links) that prevents them from running on Python 3.13.  Users are encountering compatibility issues with the latest LangChain version, specifically requiring a Python version older than 3.12.  The issue also highlights a missing or incomplete list of partner packages on the LangChain documentation page.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-11T19:38:01Z", "body_clean": "Thanks very much for reporting these. Pinecone support for 3.13 was added [last week]( [link] We just updated langchain pinecone and released support for 3.13 in langchain pinecone==0.2.3. The [code] SDK appears to not yet support python 3.13: [link] That would be the blocker for langchain. I've corrected the link for mongodb. Not all partner packages live in this repo. You can see the full list in the docs [here]( [link] That list is built off of a registry that lives in the monorepo [here]( [link] It includes the google integrations. Closing this issue for now but happy to re open if there are additional specific concerns. Thanks."}]}, {"ollama_summary": "This issue reports a critical problem with the LangChain ChatBedRockConverse library where it fails to process the `output` key from the `ChatBedRockConverse` response, leading to a `KeyError` and confusing the user. This is exacerbated by the library's tendency to capture `BaseException` when processing the output, causing it to attempt to parse the entire response even when the expected key is missing. This issue is particularly problematic for users learning Bedrock, as it can lead to unexpected behavior and difficulty debugging.", "final_category": "bug", "comments": [{"author": "3coins", "created_at": "2025-03-12T18:35:20Z", "body_clean": "Answered this in [link]"}, {"author": "3coins", "created_at": "2025-04-04T19:59:38Z", "body_clean": "Fixed by [link]"}, {"author": "stuaxo", "created_at": "2025-04-05T09:10:33Z", "body_clean": "Good catch I should have closed this already."}]}, {"ollama_summary": "Okay, here's a summary of the code snippets provided, focusing on the key elements and potential issues:\n\n**1. LangChain Code Snippet:**\n\nThe code snippet is a basic LangChain query setup. It demonstrates:\n\n*   **RAG (Retrieval-Augmented Generation):**  It uses a `ChatCompletion` model from OpenAI (specifically `gpt-3.5-turbo`) and a `Vectorstore` to retrieve relevant context from a knowledge base.\n*   **FAISS:** It uses `FAISS` (Facebook AI Similarity Search) to perform semantic search.\n*   **Semantic Search:** The code retrieves relevant context based on the semantic similarity of the query to the knowledge base.\n\n**2.  Code Snippet:  `print(f\"Query: {query}\")`**\n\nThis is a simple print statement that shows the query being sent to the model.\n\n**3.  Code Snippet: `print(f\"Vectorstore: {vectorstore}\")`**\n\nThis prints the vectorstore that is being used.\n\n**4.  Code Snippet: `print(f\"FAISS: {faiss}\")`**\n\nThis prints the FAISS object that is being used.\n\n**5.  Code Snippet: `print(f\"Context: {context}\")`**\n\nThis prints the context that is being used.\n\n**6.  Code Snippet: `print(f\"Query: {query}\")`**\n\nThis is the main query being sent to the model.\n\n**Potential Issues/Observations:**\n\n*   **`Vectorstore` Initialization:** The `Vectorstore` is initialized as `None`.  This is a potential issue because the `Vectorstore` is a crucial component of the RAG pipeline.  It needs to be initialized before the `ChatCompletion` model.\n*   **`ChatCompletion` Model:** The `ChatCompletion` model is being used, which is a specific type of language model.  It's important to understand the model's capabilities and limitations.\n*   **`context` Variable:** The `context` variable is not being used.\n\n**Overall:**\n\nThe code snippet shows a basic framework for building a RAG system using LangChain and FAISS. It's a good starting point, but there are some important considerations regarding initialization and potential issues with the `Vectorstore` and the", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-13T16:00:54Z", "body_clean": "Hi, @aadisupersonicgithub. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You encountered an error with [code] in LangChain. The error persists even after updating to the latest version. You suspect a bug in LangChain and have provided example code and detailed steps for diagnosis. No further activity or comments have been made on this issue. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in the `ChatPromptTemplate` library that fails to correctly handle media types (audio) within the template structure. The library currently doesn’t support including `file uri`, `mime type`, and `type` fields in the template, leading to a `ValueError` when attempting to process multimodal audio input.  The solution requires modifying the `ChatPromptTemplate.from messages` method to accommodate these fields, ensuring seamless integration of audio input.", "final_category": "bug", "comments": [{"author": "jangxyz", "created_at": "2025-02-14T01:47:58Z", "body_clean": "I came here for the exact same request. For me the mime type is video, but the cause is the same. Currently the [code] method checks whether the template is a) a string, or a dict that contains key [code] b) a dict that contains key [code] . ([langchain core/prompts/chat.py]( [link] [code] While this covers the most cases for multimodal inputs, the official how to of google generative ai (and vertex ai) states that it should use a dict containing [code] . (Can't find the relevant doc right now, but here's one for js [tool calls multimodal google generative ai]( [link] I can see that the exact parameters may be model specific, but there is no way to expand the template format for such models. I lose the whole point of using templates. Here's my use case for trying to use the template: [code]"}, {"author": "JasonHonKL", "created_at": "2025-03-09T10:57:23Z", "body_clean": "Same issue here. Gonna take a look with the source code later and see if I could solve."}, {"author": "darktheorys", "created_at": "2025-03-10T21:27:36Z", "body_clean": "Same issue here, we need to have a generic way to support audio/video models from various providers."}, {"author": "dosubot[bot]", "created_at": "2025-06-09T16:02:13Z", "body_clean": "Hi, @mckay w. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights the lack of support for audio input in the ChatPromptTemplate of LangChain. Attempting to use audio files in prompts results in a ValueError. The current implementation supports text and image inputs but not audio or video. Several users, including @jangxyz, @JasonHonKL, and @darktheorys, have echoed this concern. @JasonHonKL mentioned plans to review the source code for potential solutions. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nChatDeepSeek is failing to call its binding functions, despite attempts to resolve it through documentation, search, and code changes. The issue appears to be a bug within the LangChain integration, specifically related to the model used in the chain.  Users are reporting success with alternative solutions like AzureChatOpenAI, but the core problem persists with the binding function.", "final_category": "bug", "comments": [{"author": "TedaLIEz", "created_at": "2025-02-11T05:42:45Z", "body_clean": "I found [code] worked for me. I'm wondering if [code] is going to be deprecated."}, {"author": "andrasfe", "created_at": "2025-03-25T05:15:12Z", "body_clean": "I don't think it's the bind. When I run it the same, error comes from [code] . Specifically, it cannot find additional kwargs[\"function call\"] key. I'll look into it on the weekend"}, {"author": "andrasfe", "created_at": "2025-03-29T00:53:20Z", "body_clean": "@TedaLIEz can you pls. confirm if the following works for you? It does for me. I tried a simpler alternative to your example below. The idea is I replaced [code] with [code] . \"Function\" calling is in general deprecated and \"Tools\" are the preferred way, from what I gather. [code]"}, {"author": "TedaLIEz", "created_at": "2025-03-29T01:13:44Z", "body_clean": "@andrasfe Yes, your code works perfectly. I have no more questions on this issue. Thanks. And here is my test code after adopting your sample: [code]"}]}], "business_insights": ["Proper initialization of the Vectorstore is critical for robust RAG pipelines.", "Careful consideration of the ChatCompletion model’s capabilities and limitations is essential.", "Addressing the context variable within the code snippet is a potential bottleneck.", "Modifying the ChatPromptTemplate to support media types is a crucial fix.", "Addressing the binding function bug is vital for maintaining seamless integration."], "technical_insights": ["The Vectorstore initialization is a potential failure point in the RAG pipeline.", "The ChatCompletion model’s capabilities should be understood and leveraged.", "The context variable is not being utilized, potentially hindering the model’s performance.", "The ChatPromptTemplate needs modification to handle media types effectively.", "The binding function bug requires a modification to ensure seamless integration."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Proper initialization of the `Vectorstore` is critical for robust RAG pipelines.\n2.  Careful consideration of the `ChatCompletion` model’s capabilities and limitations is essential.\n3.  Addressing the `context` variable within the code snippet is a potential bottleneck.\n4.  Modifying the `ChatPromptTemplate` to support media types is a crucial fix.\n5.  Addressing the binding function bug is vital for maintaining seamless integration.\n\nTECHNICAL INSIGHTS:\n1.  The `Vectorstore` initialization is a potential failure point in the RAG pipeline.\n2.  The `ChatCompletion` model’s capabilities should be understood and leveraged.\n3.  The `context` variable is not being utilized, potentially hindering the model’s performance.\n4.  The `ChatPromptTemplate` needs modification to handle media types effectively.\n5.  The binding function bug requires a modification to ensure seamless integration.", "batch_number": 118, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue arises from a `TypeError` in the LangChain RAG pipeline when processing the query caption results from Azure AI Search Vector Store. The code attempts to serialize a Python object, which is not serializable, leading to the error. The code is currently using a specific version of LangChain and the integration package, and the root cause is currently unknown.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-12T16:06:05Z", "body_clean": "Hi, @Hadi2525. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] in LangChain when using Conversational RAG with MemorySavor for AzureSearch Vector Store. The error indicates that the [code] object is not serializable. You verified that this is a bug within LangChain and not due to your own code. The issue remains unresolved despite updating to the latest stable version. There have been no further comments or developments on the issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a critical bug in the PineconeVectorStore library, causing significant problems with the `langchain` framework. The code attempts to import `pinecone` but fails, leading to a broken functionality and a range of dependency errors across various LangChain components.  The root cause appears to be an incompatibility with a specific Pinecone integration package, requiring a potentially complex and potentially unstable update to the LangChain library.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue stems from a bug in LangChain's Self Query Retriever, causing a problem where the query translator produces incorrect structured output for the original query. This issue is impacting a specific use case (Retrieval) and appears to be a widespread problem, potentially due to inconsistencies in PGVectorTranslator implementations.", "final_category": "bug", "comments": [{"author": "imvaibhav28", "created_at": "2025-02-27T10:06:40Z", "body_clean": "This was probably due to version conflict between langchain and langchain postgres. Closing this as no action required on this."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\n**The issue highlights a potential incompatibility between the `CCITTFaxDecode` PDF filter and a specific image reshaping process.  When this filter is used, it triggers an error if it attempts to decode the data incorrectly, specifically within the `PDF_FILTER_WITH_LOSS` repository.**  The proposed solution is to address this issue by modifying the filter’s logic to prevent this decoding error.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-12T16:05:53Z", "body_clean": "Hi, @inseptember. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Misclassification of the [code] filter in the code. Currently placed under [code] , causing errors in reshaping image data. Suggestion to move it to [code] to resolve the issue. No comments or further activity on the issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe user is encountering a limitation in LangChain where they cannot utilize metadata retrieved through the self-query retriever for agent creation. They’ve already tried standard search methods and are suggesting a feature request to allow this functionality. Currently, the system doesn’t provide a way to incorporate this metadata.", "final_category": "feature", "comments": [{"author": "imvaibhav28", "created_at": "2025-02-10T09:50:41Z", "body_clean": "@sreenivasanm6 Are you facing trouble whille doing metadataretrieval using [Self Query retriever reference]( [link] ? I can see the metadata fields are working properly. It's just one param use original query while initialising the retriever which is not functioning. I am going to open a separate issue for this anyway but just wanted to check if it's the same one"}, {"author": "sreenivasanm6", "created_at": "2025-02-10T13:18:37Z", "body_clean": "No, am not facing issues with seflquery retriver. I need to know how can i get the page numbers in langgraph or with agents."}, {"author": "sreenivasanm6", "created_at": "2025-02-11T08:08:25Z", "body_clean": "Any updates on this?"}, {"author": "dosubot[bot]", "created_at": "2025-05-13T16:00:55Z", "body_clean": "Hi, @sreenivasanm6. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a potential issue or missing feature related to using metadata in LangChain. Specifically, you are interested in retrieving page numbers via LangGraph or agents. @imvaibhav28 asked if the issue was related to metadata retrieval using the self query retriever. You clarified that your concern is specifically about obtaining page numbers, not the self query retriever itself. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is a recurring challenge across multiple issues, highlighting the need for robust version control and testing.", "Integration package issues are a significant source of bugs, impacting core functionality across different components.", "Data compatibility issues are causing widespread problems, suggesting potential inconsistencies in libraries and frameworks.", "Bug fixes need to address root causes to prevent future regressions, ensuring stability.", "Feature requests are valuable for identifying usability gaps and guiding development efforts."], "technical_insights": ["LangChain RAG pipeline error handling requires careful serialization/deserialization of Python objects.", "PineconeVectorStore library instability is impacting the langchain framework, potentially due to a specific Pinecone integration.", "Self Query Retriever bug requires a complex and potentially unstable update to the LangChain library.", "LangChain Postgres version conflict is causing a broken functionality for the langchain framework.", "PDF filter logic error in CCITTFaxDecode is causing incorrect structured output for the original query."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management is a recurring challenge across multiple issues, highlighting the need for robust version control and testing.\n2.  Integration package issues are a significant source of bugs, impacting core functionality across different components.\n3.  Data compatibility issues are causing widespread problems, suggesting potential inconsistencies in libraries and frameworks.\n4.  Bug fixes need to address root causes to prevent future regressions, ensuring stability.\n5.  Feature requests are valuable for identifying usability gaps and guiding development efforts.\n\nTECHNICAL INSIGHTS:\n1.  LangChain RAG pipeline error handling requires careful serialization/deserialization of Python objects.\n2.  PineconeVectorStore library instability is impacting the `langchain` framework, potentially due to a specific Pinecone integration.\n3.  Self Query Retriever bug requires a complex and potentially unstable update to the LangChain library.\n4.  LangChain Postgres version conflict is causing a broken functionality for the `langchain` framework.\n5.  PDF filter logic error in `CCITTFaxDecode` is causing incorrect structured output for the original query.\n", "batch_number": 119, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a problem with the OpenAI o3-mini model for LangChain, specifically when using parallel tool calls. The code attempts to leverage parallel execution, but the `parallel tool calls` parameter is not supported by this model, leading to an error.  The issue is currently unresolved with the latest LangChain version and suggests a potential bug within the model itself, rather than a coding error.", "final_category": "bug", "comments": [{"author": "yesh-harmonic", "created_at": "2025-02-12T16:00:38Z", "body_clean": "same issue here, but this worked for me [link]"}, {"author": "andrasfe", "created_at": "2025-02-18T00:11:40Z", "body_clean": "The o3 mini model doesn't support the parallel tool calls parameter. When we pass parallel tool calls=False to the model, it results in an Http 400 error from the OpenAI API. As suggested by @yesh harmonic and per class BaseChatOpenAI docs, one should pass [code] . In other words, [code] The docstring for BaseChatOpenAI specifically mentions this, so no changes are required and I believe this ticket can be closed: For example, older models may not support the 'parallel tool calls' parameter at all, in which case [code] can ben passed in."}, {"author": "WarrenMfg", "created_at": "2025-05-18T14:40:15Z", "body_clean": "I was confused with [code] . Turns out I had to specify both the [code] and the [code] which, for me, have the same name. [code] Hope this helps!"}]}, {"ollama_summary": "This issue stems from a bug within the `createReactAgent` function in LangChain that causes a `TypeError` when attempting to utilize tools. The code attempts to create an agent with a list of tools, but it fails to properly initialize the `DynamicTool` object, leading to a `Cannot read properties of undefined (reading 'tools')` error. The issue appears to be a problem with the integration of the tools, potentially related to a bug in the LangChain library itself.", "final_category": "bug", "comments": [{"author": "margaretlange", "created_at": "2025-02-11T01:39:04Z", "body_clean": "This is the python repository. Are you looking for [link]"}, {"author": "dosubot[bot]", "created_at": "2025-05-13T16:00:54Z", "body_clean": "Hi, @partha kyndryl. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported cryptic errors when using the [code] function, specifically with 'tools'. You are seeking clarification on the correct format and version specific requirements for passing tools. @margaretlange suggested the issue might pertain to the JavaScript version, possibly indicating the LangChainJS repository. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from ChatOpenAI failing to properly handle long LLM outputs, specifically by not respecting the `include_raw` flag.  Users have tested various solutions, including adding descriptive titles and searching the LangChain documentation, but the bug persists. The problem appears to be a bug within LangChain itself, not a user-facing issue, and isn't resolved by updating the library versions.", "final_category": "bug", "comments": [{"author": "margaretlange", "created_at": "2025-02-10T01:53:05Z", "body_clean": "I am new to this, but here are some notes that I took: Type Hierarchy is: BaseChatModel (langchain core) BaseChatOpenAI inherits from BaseChatModel ChatOpenAI inherits from BaseChatOpenAI The langchain core code for BaseChatModel includes a method for [code] . The BaseChatOpenAI class overrides the method. However, there appears to be a simple cut and paste of the very end of the base class method to the very end of the inherited class method. In particular, these lines of code: if include raw: parser assign = RunnablePassthrough.assign( parsed=itemgetter(\"raw\") | output parser, parsing error=lambda : None ) parser none = RunnablePassthrough.assign(parsed=lambda : None) parser with fallback = parser assign.with fallbacks( [parser none], exception key=\"parsing error\" ) return RunnableMap(raw=llm) | parser with fallback else: return llm | output parser At the end of the inherited function I did some type inspection in the debugger. In the case of BaseChatOpenAI , the final line of [code] . returns a langchain core.runnables.base.RunnableSequence. [code] is type <class 'langchain core.runnables.base.RunnableBinding' [code] type is <class 'langchain core.runnables.base.RunnableParallel' [code] type is <class 'langchain core.runnables.fallbacks.RunnableWithFallbacks' return value type using [code] is <class 'langchain core.runnables.base.RunnableSequence' . Does anyone know of a case in which include raw=True for a chat model is working? It would be good to inspect the final return type for a working version and see how it was arrived at. Maybe the type is wrong."}, {"author": "margaretlange", "created_at": "2025-02-11T01:07:41Z", "body_clean": "Update. I'm not sure if the case you are describing is actually supported by the code. Here is what the comments say: include raw: If False then only the parsed structured output is returned. If an error occurs during model output parsing it will be raised. If True then both the raw model response (a BaseMessage) and the parsed model response will be returned. If an error occurs during output parsing it will be caught and returned as well. The final output is always a dict with keys \"raw\", \"parsed\", and \"parsing error\". this suggests to me that if the error occurs in the parsing part of the chain it will be caught but if it occurs in the llm part of the chain it won't be caught. Here's a modified version of your code: [code] This code produces the following output. {'raw': AIMessage(content='{\"foo\": 3}', additional kwargs={'refusal': None}, response metadata={'token usage': None, 'model name': 'test', 'system fingerprint': None, 'finish reason': 'length', 'logprobs': None}, id='run d932d65d 484d 4d57 ad4b 8d18906b258b 0'), 'parsing error': OutputParserException('Failed to parse MyOutput from completion {\"foo\": 3}. Got: 1 validation error for MyOutput\\nfoo\\n Input should be a valid string [type=string type, input value=3, input type=int]\\n For further information visit [link] troubleshooting, visit: [link] '), 'parsed': None} So as promised when the parsing step of the chain fails, the error is caught and it and the raw data is returned. If instead the Openai step itself throws an error (as in your example code), then the entire chain sequence will throw an error. I would examine the behavior of the openai python library to see if it is now throwing an error whereas before it was not doing so in the situation that's annoying you. I don't think this is an example of langchain behaving differently than advertised. I would suggest as a langchain bug this be closed unless there's something I'm not seeing."}, {"author": "didmar", "created_at": "2025-02-11T09:56:02Z", "body_clean": "@margaretlange thank you for investigating! It makes sense now why this exception is not being catch, so as you said it is not really a langchain bug. FYI there is a [related issue]( [link] in openai python lib, but their fix did not add the raw completion to the LengthFinishReasonError. I will dig further into it to see how I can solve my problem (getting the raw completion in case of LengthFinishReasonError), and make an enhancement proposal if relevant."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a bug in LangChain's OpenAIEmbeddings where different embeddings are generated based on the imported function, specifically when using vllm.  The bug persists even after updating to the latest stable version of LangChain.  The code example demonstrates the incorrect embedding generation and the associated error message.", "final_category": "bug", "comments": [{"author": "Goulustis", "created_at": "2025-02-09T11:07:18Z", "body_clean": "nvmd, it is just the warning, the embeddings are the same;"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe LangChain documentation currently doesn’t require an explicit `task` argument when using Hugging Face models, leading to an error when running the example code. The issue is resolved by adding this argument, ensuring better user onboarding and preventing potential errors in production.  The documentation provides a clear example of the required argument.", "final_category": "other", "comments": []}], "business_insights": ["Model compatibility is a key concern; parallel tool calls require specific model versions.", "Documentation clarity is crucial; the lack of a task argument impacts usability.", "Bug consistency across different models suggests a potential library issue.", "Embedding variations highlight a potential data handling flaw.", "User onboarding is essential; documentation needs updating."], "technical_insights": ["Model version mismatch is the core problem; parallel tool calls are unsupported.", "task argument missing in documentation; user onboarding is impacted.", "Library bug affecting embedding generation; update is necessary.", "Embedding variations point to data processing error; potential bug.", "Documentation needs review; clarity is crucial for users."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model compatibility is a key concern; parallel tool calls require specific model versions.\n2. Documentation clarity is crucial; the lack of a `task` argument impacts usability.\n3. Bug consistency across different models suggests a potential library issue.\n4. Embedding variations highlight a potential data handling flaw.\n5. User onboarding is essential; documentation needs updating.\n\nTECHNICAL INSIGHTS:\n1. Model version mismatch is the core problem; parallel tool calls are unsupported.\n2. `task` argument missing in documentation; user onboarding is impacted.\n3. Library bug affecting embedding generation; update is necessary.\n4. Embedding variations point to data processing error; potential bug.\n5. Documentation needs review; clarity is crucial for users.\n", "batch_number": 120, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a problem with LangChain when using open-source models hosted as serverless endpoints in Azure (specifically, DeepSeek). The `Extra parameters ['n']` error indicates a mismatch between the model's expected parameters and the current version of LangChain, hindering LiteLLM's functionality.  The issue is likely related to a bug in the integration package, and attempts to update to the latest stable version haven't resolved it.", "final_category": "bug", "comments": [{"author": "florianchappaz", "created_at": "2025-03-19T08:35:09Z", "body_clean": "[code] model kwargs [code] n [code] litellm [code] n [code] None [code] ChatLiteLLM . e.g. [code]"}, {"author": "florianchappaz", "created_at": "2025-06-02T06:47:55Z", "body_clean": "@ccurme this issue can be closed I guess since resolved by the referenced commit"}]}, {"ollama_summary": "This issue arises because the LangChain community package is causing a `TypeError` when initializing the AzureMLChatOnlineEndpoint. The code attempts to use a `property` object instead of an iterable, which is a requirement for the package.  The issue is likely a bug in the LangChain integration, and the suggested solution is to update to the latest stable version of LangChain or the specific integration package.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-09T16:03:34Z", "body_clean": "Hi, @Vivihung. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered a [code] when initializing [code] . Error message suggests a 'property' type is not iterable. Updated to the latest LangChain version, but the issue persists. Concluded it might be a bug within LangChain itself. No further comments or developments have been made. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where the `Runnable` function only triggers the `with listeners` method on the first LLM invocation. This results in missing logging of subsequent LLM calls, hindering the ability to capture detailed input arguments and potentially impacting debugging. The code attempts to address this by adding a node and edge, but the existing design pattern is causing the issue.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-09T16:03:41Z", "body_clean": "Hi, @colintkyle. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Bug identified in LangChain's StateGraph with [code] method. Only the first LLM invoke/ainvoke call within a node is logged. Problem verified to be within LangChain, not user code. No further comments or developments on the issue. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue proposes adding the ability to retrieve log probabilities (logprobs) when using OpenAI models with structured outputs, which is currently missing. This feature is valuable for applications needing probabilistic reasoning and confidence estimates. The proposed solution involves modifying the OpenAI wrapper to support logprobs during structured output generation.", "final_category": "feature", "comments": [{"author": "LLazzar", "created_at": "2025-02-12T12:11:52Z", "body_clean": "I just discovered this problem and support this, it would be really useful"}, {"author": "chaoyupeng", "created_at": "2025-02-19T22:32:04Z", "body_clean": "Hi, just wondering, is there any updates on this?"}, {"author": "sgettel", "created_at": "2025-03-20T14:51:58Z", "body_clean": "This would be very helpful for my current project"}, {"author": "PriyalPN", "created_at": "2025-04-09T13:46:11Z", "body_clean": "Is there any updates on this, or did any one find a different approach for structured outputs"}, {"author": "matheus695p", "created_at": "2025-06-03T16:08:52Z", "body_clean": "any progress on this ? would be helpfull !!"}, {"author": "SaiPoornaChandraPrakash", "created_at": "2025-06-20T10:11:12Z", "body_clean": "Any Progress on getting the Log Probabilities for LLM responses will enhance my current project. Any Updates on this one?"}, {"author": "ChendiWang", "created_at": "2025-07-04T20:15:54Z", "body_clean": "You can get the log probabilities by adding in [code] flag when calling llm.with structured output [link]"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue proposes a feature to allow LangChain to return multiple alternative completions (n) when using structured outputs from OpenAI models. Currently, LangChain lacks this functionality, hindering applications that benefit from exploring multiple possible outputs for ranking or diversity.  The goal is to enhance robustness and flexibility in decision-making systems through multiple alternative responses.", "final_category": "feature", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-09T16:03:09Z", "body_clean": "Hi, @dbuos. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You proposed a feature enhancement for LangChain to retrieve multiple alternative completions with OpenAI models. This feature aims to support applications needing multiple outputs for tasks like ranking and ensemble methods. No comments or developments have been made on this issue yet. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Integration package bugs are frequently linked to specific model versions; consistent updates are crucial.", "The Extra parameters ['n'] error indicates a fundamental mismatch in model expectations, requiring package updates.", "The LangChain community package’s integration is causing a TypeError when initializing the AzureMLChatOnlineEndpoint, impacting LiteLLM’s functionality.", "Addressing the TypeError requires updating the LangChain package or the integration package.", "The root cause is a bug in the LangChain integration, necessitating a fix."], "technical_insights": ["Integration package bugs frequently cause model mismatch errors; stable updates are vital.", "The TypeError related to the property object is a bug in the LangChain integration.", "The Runnable function's logging missing is a bug, hindering input argument capture.", "Updating the LangChain package or integration package is the recommended solution.", "The issue is related to a bug within the LangChain integration, potentially impacting LiteLLM."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integration package bugs are frequently linked to specific model versions; consistent updates are crucial.\n2. The `Extra parameters ['n']` error indicates a fundamental mismatch in model expectations, requiring package updates.\n3. The LangChain community package’s integration is causing a `TypeError` when initializing the AzureMLChatOnlineEndpoint, impacting LiteLLM’s functionality.\n4. Addressing the `TypeError` requires updating the LangChain package or the integration package.\n5. The root cause is a bug in the LangChain integration, necessitating a fix.\n\nTECHNICAL INSIGHTS:\n1. Integration package bugs frequently cause model mismatch errors; stable updates are vital.\n2. The `TypeError` related to the `property` object is a bug in the LangChain integration.\n3. The `Runnable` function's logging missing is a bug, hindering input argument capture.\n4. Updating the LangChain package or integration package is the recommended solution.\n5. The issue is related to a bug within the LangChain integration, potentially impacting LiteLLM.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 121, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain that causes errors when changing the `.type` attribute of the `o3-mini completions` function message. The code attempts to reassign the `function` role to completions requests, but the `o3-mini` library doesn't correctly handle this change, resulting in an error.  The fix involves updating the LangChain library to the latest version and addressing potential issues with the `o3-mini` integration.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-07T02:09:53Z", "body_clean": "OpenAI [deprecated]( [link] function messages in place of tool messages. LangChain supports [ToolMessage]( [link] for this purpose. Will ToolMessage work for you here instead of FunctionMessage?"}, {"author": "SidGurajala", "created_at": "2025-02-07T18:36:21Z", "body_clean": "Hi, Unfortunately we have some legacy code that requires use of function messages. Would it be possible to enable the role change for FunctionMessages to register with the openAI API? Thanks!"}, {"author": "dosubot[bot]", "created_at": "2025-05-09T16:03:32Z", "body_clean": "Hi, @SidGurajala. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where changing the [code] of [code] to \"developer\" does not yield the expected role in completion requests using the o3 mini model. Despite updating to the latest version, the issue persists. User ccurme suggested using [code] due to OpenAI's deprecation of function messages. You mentioned that legacy code requires function messages and inquired about enabling role changes for [code] with the OpenAI API. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The `trim_messages` and `ChatAnthropic` token counter tool in LangChain is failing to accurately count tokens due to invalid message sequences, specifically when reversed lists or expecting tools as kwargs are encountered. This issue stems from the Anthropic token counting API's requirements not being met within the code.  The proposed solution involves modifying the code to ensure messages are properly formatted before sending them to the API.", "final_category": "bug", "comments": [{"author": "jmbledsoe", "created_at": "2025-02-06T18:03:39Z", "body_clean": "It turns out that to resolve Example 2, Anthropic doesn't care if all the tools referenced in the messages are included, just that at least one tool is included. I originally encountered this issue (thanks @ccurme for writing it up so well 🏆) and I'm currently working around it by passing the following as the [code] parameter to [code] : [code] 🤔 this code doesn't work around Example 3 yet, but when I encounter that I'll post an update."}, {"author": "avshalom-dayan-glossai", "created_at": "2025-02-14T11:12:01Z", "body_clean": "this is what I'm using, not sure I fully understand the implications on the trim strategy though (because of the reversing). [code] usage in [code] : [code]"}, {"author": "dosubot[bot]", "created_at": "2025-05-16T16:00:57Z", "body_clean": "Hi, @ccurme. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a bug in the [code] function when handling invalid message sequences. @jmbledsoe suggests reversing the message order and using a dummy tool as a workaround, though it doesn't cover all cases. @avshalom dayan glossai proposes a similar approach, with concerns about the impact on the trim strategy. Both contributors have shared code examples to demonstrate their solutions. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "jmbledsoe", "created_at": "2025-05-19T12:46:31Z", "body_clean": "Our local workaround is still necessary on LangChain [code] , so the issue still seems relevant."}, {"author": "dosubot[bot]", "created_at": "2025-05-19T12:48:52Z", "body_clean": "@eyurtsev, the user @jmbledsoe has confirmed that the workaround is still necessary on LangChain [code] , indicating that this issue remains relevant. Could you please assist them with this bug in the [code] function?"}, {"author": "wudstrand", "created_at": "2025-08-25T16:46:19Z", "body_clean": "+1"}, {"author": "wudstrand", "created_at": "2025-08-26T19:28:54Z", "body_clean": "@ccurme do you know the status of this bug? I am primarily running into issues with the example 3 situation. I have tried specifying the [code] parameter, but I havent had any success. This is causing issues with the summarization node in langmem as well."}, {"author": "ccurme", "created_at": "2025-08-27T14:16:42Z", "body_clean": "Hi @wudstrand, as a workaround, I'm wondering if you are able to use the count tokens approximately( [link] as the token counter? It should be default in langmem."}, {"author": "wudstrand", "created_at": "2025-09-02T13:59:23Z", "body_clean": "@ccurme this will still be a problem is a select number of cases where the trim messages function removes a tool call response from the chat window which is not an accepted input to gemini and anthropic. This is an issue since I cannot control the end on parameter in langmem."}, {"author": "ccurme", "created_at": "2025-10-20T17:40:15Z", "body_clean": "Hi @wudstrand, Are you using [code] (which I believe is the default in langmem) or ChatAnthropic as the token counter? If [code] , would you mind providing an example to help me reproduce the issue? Here is my attempt using the [settings used in langmem]( [link] Output sequences appear to be valid here. [code] [code] [code]"}]}, {"ollama_summary": "This issue addresses a bug in the BaseChatOpenAI class where hardcoded references to the `[code]` model are present, requiring extension to support the `[code]` series of models. The issue highlights the lack of a readily available solution through updates to the latest LangChain version and suggests a temporary workaround using the current `[code]` model.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-02-06T19:45:59Z", "body_clean": "[code] was added in langchain openai ~0.2, which set a default temperature of 0.7. So [code] would break with the default value. langchain openai ~0.3 updated this default to None. I don't run into any issues using [code] , [code] , [code] , or [code] . What is the motivation for extending this?"}, {"author": "zachschillaci27", "created_at": "2025-02-06T21:22:48Z", "body_clean": "[code] was added in langchain openai ~0.2, which set a default temperature of 0.7. So [code] would break with the default value. langchain openai ~0.3 updated this default to None. I don't run into any issues using [code] , [code] , [code] , or [code] . What is the motivation for extending this? Thanks for the quick response! I can better understand the context now. I personally find it a bit confusing that the patch only handles [code] . It's still the case that [code] is not a valid parameter for [code] , unless it's set to 1: [code] I feel it would make sense to align the treatment for [code] and [code] or remove the validation altogether"}, {"author": "helenadeus", "created_at": "2025-02-23T13:32:22Z", "body_clean": "Is there a resolution for this? It's getting pretty silly that we cannot use langchain / langflow with any of the reasoning models. openAI changed the API slightly with these models, it's likely that they will continuing doing so..."}, {"author": "ccurme", "created_at": "2025-02-23T19:37:29Z", "body_clean": "Is there a resolution for this? It's getting pretty silly that we cannot use langchain / langflow with any of the reasoning models. openAI changed the API slightly with these models, it's likely that they will continuing doing so... @helenadeus They are all supported. What version of [code] are you using?"}, {"author": "nimrod29", "created_at": "2025-02-27T16:42:45Z", "body_clean": "I am encountering the same error mentioned above: [code] [code] When I remove the temperature parameter, I no longer receive an error, but the o3 mini model does not call any tools, even though it should. However, the gpt 4o model works as expected. Using the o1 model without the temperature parameter: [code] While I don't receive any temperature related errors, I encounter a different error after the first tool is called: [code] Btw these are the versions of langchain I am using: [code]"}, {"author": "ccurme", "created_at": "2025-02-28T17:38:17Z", "body_clean": "@nimrod29 can you please post a minimal reproducible example? Here is one attempt, which confirms tool calling is supported with [code] . [code] For your second problem, if: Your version of [code] is up to date Your version of [code] is up to date You are using [code] and not [code] for the OpenAI integration You should not be receiving FunctionMessage objects from a tool. Please post an example that would help someone debug."}, {"author": "nimrod29", "created_at": "2025-03-02T15:46:51Z", "body_clean": "Hey, appreciate the response! here is a minimal reproducible example with the way I am using the agents: [code] [code]"}, {"author": "satishgunasekaran", "created_at": "2025-03-26T07:39:48Z", "body_clean": "Any updates for this"}, {"author": "ccurme", "created_at": "2025-03-31T13:47:56Z", "body_clean": "@nimrod29 the error message indicates that temperature is not supported with this model, but you are providing it when you pass [code] . Can you omit the [code] kwarg and confirm it resolves your issue?"}, {"author": "lgibelli", "created_at": "2025-04-02T21:04:52Z", "body_clean": "[@nimrod29]( [link] the error message indicates that temperature is not supported with this model, but you are providing it when you pass [code] . Can you omit the [code] kwarg and confirm it resolves your issue? He already did that, so did I. The problem with calling tools remains though: [code]"}, {"author": "lgibelli", "created_at": "2025-04-02T21:11:50Z", "body_clean": "I could be totally off course, but the problem might be with the internal memory of the agent: the LangChain's agent makes its first API call Gets a response with a function call Executes the function Adds the function result to its internal state Makes another API call including these function messages That's where the error happens: within a single agent execution, LangChain creates an expanding collection of messages that includes function calls, which is what's causing the error. I suspect this is related to [link]"}, {"author": "lgibelli", "created_at": "2025-04-03T09:17:11Z", "body_clean": "@nimrod29 I used this workaround, so far it's working: [code]"}, {"author": "HelloWorldLTY", "created_at": "2025-04-12T19:55:45Z", "body_clean": "I have seen the same problem here, and deleting temperature doe not work for me. Setting temperature as 1 work for me though."}, {"author": "Hexecu", "created_at": "2025-04-23T09:27:21Z", "body_clean": "Same error about function role [code] I'm actually using AgentExecutor with AzureChatOpenAI but I suppose is something related with my memory management which is using an old version of AgentTokenBufferMemory"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's Agent executor that causes the 'ObservationNameError' when working with the Mistral model. The error seems to relate to an incorrect handling of variable names within the agent's output parser, leading to unexpected output.  The problem is currently unresolved by recent updates to the LangChain library.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-02-07T00:59:10Z", "body_clean": "@DevPatel14 Just do the following and it should. You need to wrap your model in a ChatModel and use the tool calling agent: [code]"}, {"author": "DevPatel14", "created_at": "2025-02-07T07:11:07Z", "body_clean": "@keenborder786 hi, it kind of worked. but i think [code] append some extra prompt with the chat which making mistral 7b less capable to generate our expected output. But thanks for the solution it worked ! 😊"}]}, {"ollama_summary": "The issue is a critical bug in LangChain's ChatDeepSeek model that causes a JSONDecodeError when processing specific input data. The code works fine with a modified model, but the error occurs when the model is used with the default input.  The root cause appears to be a problem with the model's internal data handling, requiring a fix before the integration can be reliably used.", "final_category": "bug", "comments": [{"author": "zyuanat", "created_at": "2025-02-07T04:56:51Z", "body_clean": "[code] Same problem in deepseek chat, and it's been going on for days. I've tried langchain and even the deepseek example request (as following), and they both raise this error. [code] [code] Maybe this is some issue with the Deepseek API platform?"}, {"author": "ccmien", "created_at": "2025-02-07T09:59:14Z", "body_clean": "ref fixed in langchainjs [link]"}, {"author": "zyuanat", "created_at": "2025-02-07T12:48:21Z", "body_clean": "ref fixed in langchainjs [langchain ai/langchainjs 7564]( [link] May I ask where it was resolved? I didn't find it linked to json.decoder.JSONDecodeError"}, {"author": "AhmedTammaa", "created_at": "2025-02-12T11:37:46Z", "body_clean": "I encountered the same issue, I believe the issue is related to deepseek API not sending valid json. The reason for that, is the issue is not consistently reproducible. A hot fix for that is to use retry policy. I am proposing a change that might give a more meaningful error message [code]"}, {"author": "dosubot[bot]", "created_at": "2025-05-14T16:00:56Z", "body_clean": "Hi, @HenryXiaoYang. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a [code] with the [code] model in LangChain, indicating a potential bug in JSON handling. User zyuanat confirmed the issue with [code] , suspecting a problem with the Deepseek API. AhmedTammaa suggested a hot fix with a retry policy and a code change for better error messaging. User ccmien mentioned a related fix in langchainjs, but it wasn't directly linked to the JSON error. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, I will automatically close this issue in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Addressing model compatibility is crucial for seamless integration across different libraries.", "Bug fixes should prioritize stability and prevent regressions in existing functionality.", "The o3-mini integration is a significant point of concern; ensure it’s thoroughly tested.", "LangChain’s library versioning needs careful consideration to avoid breaking existing code.", "The [code] model issue highlights the importance of comprehensive testing and version control."], "technical_insights": ["LangChain library updates frequently; testing is essential for maintaining stability.", "The o3-mini integration presents a potential point of failure; thorough testing is required.", "The [code] model issue necessitates a temporary workaround to ensure consistent behavior.", "The trim_messages and ChatAnthropic token counter tool’s accuracy is impacted by message sequences.", "The Anthropic token counting API's requirements must be met within the code."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Addressing model compatibility is crucial for seamless integration across different libraries.\n2.  Bug fixes should prioritize stability and prevent regressions in existing functionality.\n3.  The `o3-mini` integration is a significant point of concern; ensure it’s thoroughly tested.\n4.  LangChain’s library versioning needs careful consideration to avoid breaking existing code.\n5.  The `[code]` model issue highlights the importance of comprehensive testing and version control.\n\nTECHNICAL INSIGHTS:\n1.  LangChain library updates frequently; testing is essential for maintaining stability.\n2.  The `o3-mini` integration presents a potential point of failure; thorough testing is required.\n3.  The `[code]` model issue necessitates a temporary workaround to ensure consistent behavior.\n4.  The `trim_messages` and `ChatAnthropic` token counter tool’s accuracy is impacted by message sequences.\n5.  The Anthropic token counting API's requirements must be met within the code.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 122, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue highlights a bug in LangChain where the `temperature` parameter for the Gemini model is incorrectly restricted to the range [0.0, 1.0], causing a validation error.  The issue was identified through a search, and the developer believes it’s a bug in the LangChain library rather than the code itself.  The code tests the `ChatGoogleGenerativeAI` function with a temperature of 1.5, triggering the error when the temperature is set to 1.  The issue suggests a potential fix is available by updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "isatyamks", "created_at": "2025-02-06T17:49:55Z", "body_clean": "@ccurme Could you please review this issue and confirm its validity? If it's valid, may I work on it?"}, {"author": "imperorrp", "created_at": "2025-04-01T10:51:52Z", "body_clean": "Looks like this was fixed here recently [link] so it should be possible to set a temperature between 0.0 and 2.0 now. The documentation you linked to does need to be updated though."}, {"author": "dosubot[bot]", "created_at": "2025-07-01T16:01:24Z", "body_clean": "Hi, @serena97. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug regarding incorrect temperature range validation for the Gemini model. isatyamks showed interest in confirming and working on the issue. imperorrp noted that the issue was fixed in a pull request, but the documentation update is pending. Next Steps: Please confirm if the documentation update is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "mdrxy", "created_at": "2025-07-16T18:09:34Z", "body_clean": "Fixed"}]}, {"ollama_summary": "The GitHub issue reports a bug in the LangChain library, specifically within the pre-filter functionality of Azure CosmosDB NoSQL Vector Search. The code incorrectly handles string and list inputs, leading to inconsistent results. This issue is being investigated as a potential regression rather than a deliberate change in the core LangChain library.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue involves bugs in LangGraph's `bind_function` that prevent the code from functioning correctly, specifically related to the use of the ` langchain ai/langgraph 486` tools. A minimal reproducible example has been provided, including a self-contained code snippet that demonstrates the problem. The user is seeking guidance on modifying the Jupyternotebook code to resolve these bugs.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2025-02-05T14:26:55Z", "body_clean": "As you mentioned, it is recommended to use [code] . You would also need to provide a minimum reproducible example [link]"}, {"author": "gbaian10", "created_at": "2025-02-05T14:50:09Z", "body_clean": "< [link] ⬆️In the example you provided. The code is quite old, and both [code] and [code] have undergone frequent updates and changes. I suggest you refer to the [code] to learn, as it should be more similar to the current version. < [link] Additionally, I recommend upgrading Python to version 3.11 or above to minimize potential errors."}, {"author": "vbarda", "created_at": "2025-02-05T17:56:58Z", "body_clean": "thanks @gbaian10 that's exactly right. the only correction is i would recommend looking at the documentation directly [link] or at the docs notebooks in [ [link] ( [code] directory is not maintained and only contains redirects to the docs pages)"}, {"author": "probao", "created_at": "2025-02-06T02:05:37Z", "body_clean": "Thanks All I will try"}]}, {"ollama_summary": "The GitHub issue reports a bug in LangChain where the `ChatMistralAI` model fails to correctly interpret a date (`date: 10`) provided as part of a structured output using `json_schema`.  The model is producing an HTTPStatusError, specifically a 400 Bad Request, when attempting to use the `json_schema` format. The issue suggests a potential issue with the `json_schema` key within the `ChatMistralAI` model's configuration, and the code needs to be modified to handle this key correctly.", "final_category": "bug", "comments": [{"author": "Aaryia", "created_at": "2025-02-05T15:28:22Z", "body_clean": "I made a short PR which fixes the issue. It removes unsupported keywords from the schema using the rm titles function. I did not venture so far as to modify function names or parameter names, not knowing what impact it could have. The main problem I have with this issue is that it does not constrain the generation, it simply converts it to the basic json schema without formatting or additional information. There might be a band aid way of doing it, adding to the [code] value a string representation of the unsupported keywords. This still would not be a constraint, but it would help alignment of the LLM answer with our expected output."}, {"author": "dosubot[bot]", "created_at": "2025-05-08T14:48:55Z", "body_clean": "Hi, @Aaryia. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a 400 bad request error with the ChatMistralAI model when using a Pydantic model containing a [code] value. The issue persists even with the latest version of LangChain, indicating a potential bug. You submitted a pull request to remove unsupported keywords from the schema using the [code] function. You suggested an improvement by adding unsupported keywords as a string in the [code] value to better guide the LLM's output. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is encountering a `ValueError` when using the `Milvus` vector store with the `LangChain` library, specifically due to an outdated or unsupported `SelfQueryRetriever` class. This issue was triggered by a deprecation warning in LangChain 0.2.0, requiring a migration to a newer version of the class.", "final_category": "bug", "comments": [{"author": "spagliarini", "created_at": "2025-04-08T07:02:01Z", "body_clean": "Hi @sloan wu, I'm facing the same issue. Did you or anybody find a solution or workaround to this problem?"}, {"author": "Dreambound131", "created_at": "2025-05-08T19:41:55Z", "body_clean": "Same problem, we managed to solve by manually editing get builtin translator adding the missing Milvus translator"}, {"author": "sloan-wu", "created_at": "2025-05-10T03:33:58Z", "body_clean": "@spagliarinim similiar like abow fix, I have replaced all old milvus replace the langchain milvus class in my project, just want to highlight to have a long term fix."}]}], "business_insights": ["LangChain’s Gemini model temperature issue highlights a critical bug in the library’s core, impacting validation errors.", "Addressing this bug swiftly could significantly improve the library’s stability and user experience.", "Updating to the latest stable version of LangChain is a viable solution to resolve the issue.", "The bug's impact on validation errors suggests a potential flaw in the model’s interpretation of input data.", "Focusing on this bug will strengthen the LangChain library's reliability and user confidence."], "technical_insights": ["LangChain’s ChatMistralAI model has an issue with json_schema output, specifically with date handling.", "The Milvus vector store requires a specific SelfQueryRetriever class; an outdated version is causing problems.", "The ValueError in the LangChain library regarding the Milvus vector store is a deprecation-related bug.", "Updating LangChain to the latest version mitigates the bug and ensures compatibility.", "Addressing this bug will enhance the library's stability and user confidence."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s Gemini model temperature issue highlights a critical bug in the library’s core, impacting validation errors.\n2. Addressing this bug swiftly could significantly improve the library’s stability and user experience.\n3. Updating to the latest stable version of LangChain is a viable solution to resolve the issue.\n4. The bug's impact on validation errors suggests a potential flaw in the model’s interpretation of input data.\n5. Focusing on this bug will strengthen the LangChain library's reliability and user confidence.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s `ChatMistralAI` model has an issue with `json_schema` output, specifically with date handling.\n2. The `Milvus` vector store requires a specific `SelfQueryRetriever` class; an outdated version is causing problems.\n3. The `ValueError` in the `LangChain` library regarding the `Milvus` vector store is a deprecation-related bug.\n4. Updating LangChain to the latest version mitigates the bug and ensures compatibility.\n5. Addressing this bug will enhance the library's stability and user confidence.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 123, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The JinaSearchAPIWrapper is missing the `Authorization` header, preventing it from accessing the search API.  The developer has attempted to manually add the header, but it still fails with a 401 error.  The issue appears to be a bug in the LangChain integration, and the suggested solutions involve either initializing the API with the key or reading it from the environment, which the developer suggests Tavily does.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue addresses a security vulnerability – the current chat model access mechanism relies on a specific code snippet, which is a potential risk. The goal is to standardize this code by replacing it with a more secure and flexible approach, ensuring consistent model access across all LangChain components.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-06T16:00:50Z", "body_clean": "Hi, @ccurme. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You suggested that chat models in LangChain should have a [code] property instead of [code] . The goal is to standardize property access across different models. There has been no activity or comments from other users or maintainers on this issue yet. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The PyMuPDF loader is failing to extract images when using the `extract_images=True` option, causing an error message related to a missing image file. This issue appears to be a bug within LangChain’s integration, and attempts to update to the latest version of LangChain have not resolved it.", "final_category": "bug", "comments": [{"author": "glothos", "created_at": "2025-02-26T16:07:00Z", "body_clean": "Getting this error as well. Is there another workaround while this is not fixed?"}, {"author": "Blackspo0n", "created_at": "2025-03-05T23:00:55Z", "body_clean": "This is still an issue. Any new updates?"}, {"author": "glothos", "created_at": "2025-03-13T20:00:55Z", "body_clean": "This is also happening with PDFs. More specifically using the LLMImageBlobParser with ChatOpenAI"}, {"author": "pprados", "created_at": "2025-03-26T13:56:54Z", "body_clean": "Follow this [PR]( [link]"}, {"author": "pprados", "created_at": "2025-03-26T13:58:38Z", "body_clean": "Follow this [PR]( [link]"}]}, {"ollama_summary": "The issue reports a 404 error after migrating from OllamaEmbeddings to langchain ollama, indicating a potential bug in the integration.  It suggests a problem with the LangChain package, and the user is seeking confirmation if this is a bug or requires additional configuration.", "final_category": "bug", "comments": [{"author": "weitsung50110", "created_at": "2025-02-07T08:41:30Z", "body_clean": "I was able to resolve the issue by upgrading the Ollama Docker image to the latest version. After updating the Docker image, everything worked as expected without encountering the 404 error."}]}, {"ollama_summary": "The `with_structured_output` feature in LangChain is failing to produce results with various models, consistently returning errors and failing to provide any output. This issue stems from a bug within the LangChain integration package, and attempts to update to the latest version haven’t resolved the problem, suggesting a potential internal issue requiring further investigation.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-02-03T23:58:17Z", "body_clean": "@jmozmoz having a look at it."}, {"author": "jmozmoz", "created_at": "2025-02-04T12:30:53Z", "body_clean": "If I use Ollama instead of HuggingFace, the it works: python from langchain ollama import ChatOllama model = ChatOllama(model=\"mistral\") from typing import Optional from pydantic import BaseModel, Field Pydantic class Joke(BaseModel): \"\"\"Joke to tell user.\"\"\" setup: str = Field(description=\"The setup of the joke\") punchline: str = Field(description=\"The punchline to the joke\") rating: Optional[int] = Field( default=None, description=\"How funny the joke is, from 1 to 10\" ) structured llm = model.with structured output(Joke, include raw=True) structured llm.invoke(\"Tell me a joke about cats\") output: {'raw': AIMessage(content='', additional kwargs={}, response metadata={'model': 'mistral', 'created at': '2025 02 04T11:55:06.866183337Z', 'done': True, 'done reason': 'stop', 'total duration': 4002980572, 'load duration': 2234323757, 'prompt eval count': 117, 'prompt eval duration': 795000000, 'eval count': 58, 'eval duration': 970000000, 'message': Message(role='assistant', content='', images=None, tool calls=None)}, id='run a58a0185 6fa0 4601 b72e f46a75823aff 0', tool calls=[{'name': 'Joke', 'args': {'punchline': 'He was in paws ition the whole time', 'setup': \"I told my cat a joke yesterday. He didn't get it, but he looked at me for 3 hours straight.\"}, 'id': '7beea158 fb9e 47bc 8308 493d507ba27f', 'type': 'tool call'}], usage metadata={'input tokens': 117, 'output tokens': 58, 'total tokens': 175}), 'parsed': Joke(setup=\"I told my cat a joke yesterday. He didn't get it, but he looked at me for 3 hours straight.\", punchline='He was in paws ition the whole time', rating=None), 'parsing error': None}"}, {"author": "keenborder786", "created_at": "2025-02-05T23:23:47Z", "body_clean": "@jmozmoz I tried on my machine and it works for me. Can you please post the exact output you are getting."}, {"author": "jmozmoz", "created_at": "2025-02-06T15:55:51Z", "body_clean": "Here is the full output, if I execute the code above (the one with langchain): [code]"}, {"author": "dosubot[bot]", "created_at": "2025-05-08T14:48:55Z", "body_clean": "Hi, @jmozmoz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that the [code] method does not work as expected with the [code] model. The issue results in unstructured output, despite using Pydantic for structured output. The problem does not occur with the Ollama model, indicating it may be specific to the HuggingFace model configuration. Keenborder786 is investigating and requested the exact output, which you provided, showing warnings related to [code] and [code] settings. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Bug fixes are frequently the root cause of integration issues; addressing them promptly enhances overall system stability.", "Prioritize bug fixes – they directly impact user experience and maintainability.", "LangChain’s integration is complex; meticulous testing and debugging are crucial.", "Automated testing and continuous integration are essential for identifying and resolving issues early.", "Thorough logging and error tracking are vital for diagnosing and resolving problems."], "technical_insights": ["API authorization failures indicate a critical security flaw; immediate remediation is required.", "Code standardization mitigates vulnerabilities; consistent implementation improves security.", "LangChain’s integration package is a significant component; updates are necessary.", "Image extraction issues demonstrate a bug within the LangChain integration’s model loading process.", "Ollama embedding integration is problematic; a workaround is needed to resolve the issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Bug fixes are frequently the root cause of integration issues; addressing them promptly enhances overall system stability.\n2.  Prioritize bug fixes – they directly impact user experience and maintainability.\n3.  LangChain’s integration is complex; meticulous testing and debugging are crucial.\n4.  Automated testing and continuous integration are essential for identifying and resolving issues early.\n5.  Thorough logging and error tracking are vital for diagnosing and resolving problems.\n\nTECHNICAL INSIGHTS:\n1.  API authorization failures indicate a critical security flaw; immediate remediation is required.\n2.  Code standardization mitigates vulnerabilities; consistent implementation improves security.\n3.  LangChain’s integration package is a significant component; updates are necessary.\n4.  Image extraction issues demonstrate a bug within the LangChain integration’s model loading process.\n5.  Ollama embedding integration is problematic; a workaround is needed to resolve the issue.\n", "batch_number": 124, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Perplexity’s citation generation is consistently returning empty lists, despite thorough investigation of the LangChain documentation and search results. The issue stems from a bug within the integration package that prevents the accurate retrieval of citations.  Currently, the bug hasn’t been addressed by updates to the latest LangChain version.", "final_category": "bug", "comments": [{"author": "efriis", "created_at": "2025-02-03T22:23:26Z", "body_clean": "Not sure where you got the code snippet you ran and try accessing [code] instead on the latest langchain community and you should see it"}, {"author": "dickreuter", "created_at": "2025-02-03T22:29:00Z", "body_clean": "[code]"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Langchain project is experiencing a critical bug where it’s connecting to a random Mistral-Nemo endpoint instead of the intended Hugging Face endpoint.  Attempts to resolve the issue by updating LangChain haven’t worked, indicating a fundamental problem within the integration. The issue currently prevents the core functionality of Langchain – connecting to Hugging Face for inference – from functioning correctly.", "final_category": "bug", "comments": [{"author": "SMAntony", "created_at": "2025-02-03T18:27:26Z", "body_clean": "I think this is a issue with huggingface hub. After downgrading to hf hub version 0.27.0 (from latest), this issue is fixed."}, {"author": "dosubot[bot]", "created_at": "2025-05-06T16:00:52Z", "body_clean": "Hi, @SMAntony. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a critical bug with the [code] connecting to an incorrect endpoint. The issue persisted even after updating to the latest LangChain version. Downgrading [code] to version 0.27.0 resolved the issue. The problem appears to be related to the [code] version, not LangChain. Next Steps: Please confirm if this issue is still relevant to the latest LangChain version. If not addressed, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here's a summary of the files listed:\n\n*   **`referencing`**: A reference to the `referencing` file, likely a Python script.\n*   **`regex`**: A Python script using the `regex` library.\n*   **`scikit image`**: A Python library for image processing.\n*   **`shapely`**: A Python library for geometric data structures.\n*   **`statsmodels`**: A Python library for statistical modeling.\n*   **`typing`**: A Python library for type hinting.\n*   **`types`**: A Python library for type hinting.\n*   **`tqdm`**: A Python library for progress bars.\n*   **`webcolors`**: A Python library for color conversion.\n*   **`wcwidth`**: A Python library for comparing width.\n*   **`webencodings`**: A Python library for encoding web pages.\n*   **`websocket client==1.8.0`**: A Python WebSocket client.\n*   **`wikipedia`**: A Python library for Wikipedia.\n*   **`yarl`**: A Python library for working with XLSX files.\n*   **`Zipp`**: A Python library for zip files.\n*   **`XlsxWriter`**: A Python library for creating XLSX files.\n*   **`xlrd`**: A Python library for reading XLSX files.\n*   **`xyzservices`**: A Python library for working with XYZ files.\n*   **`zstandard`**: A Python library for working with Zstandard files.\n\nEssentially, this is a collection of Python scripts and libraries related to image processing, data analysis, web development, and file manipulation.", "final_category": "bug", "comments": [{"author": "nizar2yas", "created_at": "2025-02-21T12:32:26Z", "body_clean": "+1"}, {"author": "dosubot[bot]", "created_at": "2025-05-23T16:00:47Z", "body_clean": "Hi, @torvicvasil. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves the [code] function unexpectedly printing messages during an [code] command. You have confirmed this is a bug within LangChain, and updating to the latest version did not resolve it. A code snippet was provided to demonstrate the issue, and another user, nizar2yas, has shown agreement with a \"+1\" comment. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from an incorrect import path within the LangChain documentation, causing an ImportError when attempting to run a specific example. The correct import path is provided in the documentation, but the documentation itself needs to be updated to reflect this. This will resolve the issue for users and improve the documentation’s accuracy.", "final_category": "other", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a bug in LangChain where the DeepSeek R1 model, which was previously working correctly with REST API calls, is significantly truncated when used within the LangChain environment.  The problem isn’t related to a recent update to the LangChain library, and the issue is reproducible with a specific example code snippet.  Further investigation is needed to identify the root cause of the model’s output reduction.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-05T16:00:51Z", "body_clean": "Hi, @XinyueZ. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Discrepancy in model output when using VertexAIModelGarden vs. REST API. REST API provides complete output; VertexAIModelGarden response is truncated. Suspected bug in LangChain as the model works correctly with REST API. No comments or developments on the issue yet. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Incorrect import paths are a frequent source of bugs in complex libraries like LangChain.", "Comprehensive documentation is crucial for users to understand and correctly utilize libraries.", "Code updates can introduce regressions, requiring thorough testing and validation.", "Focus on specific libraries and their dependencies to pinpoint the root cause of issues.", "Maintain a clear and consistent import structure across all LangChain components."], "technical_insights": ["LangChain documentation needs to be updated to reflect the latest import paths for specific models.", "The DeepSeek R1 model's truncation issue is likely related to the import path, not a recent library update.", "The issue is reproducible with a specific code snippet, suggesting a dependency problem.", "Investigate the LangChain library version and its dependencies to identify potential conflicts.", "Review the referencing and regex scripts to understand potential import path issues."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Incorrect import paths are a frequent source of bugs in complex libraries like LangChain.\n2.  Comprehensive documentation is crucial for users to understand and correctly utilize libraries.\n3.  Code updates can introduce regressions, requiring thorough testing and validation.\n4.  Focus on specific libraries and their dependencies to pinpoint the root cause of issues.\n5.  Maintain a clear and consistent import structure across all LangChain components.\n\nTECHNICAL INSIGHTS:\n1.  LangChain documentation needs to be updated to reflect the latest import paths for specific models.\n2.  The DeepSeek R1 model's truncation issue is likely related to the import path, not a recent library update.\n3.  The issue is reproducible with a specific code snippet, suggesting a dependency problem.\n4.  Investigate the LangChain library version and its dependencies to identify potential conflicts.\n5.  Review the `referencing` and `regex` scripts to understand potential import path issues.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 125, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nLangChain’s encoding handling in the loader parent class is failing to correctly extract text from Japanese PDFs, causing garbled output across multiple loaders (including PDFMiner, Docx2txt, etc.). This regression started after the release of version 0.3.17 and affects the entire ecosystem.  The proposed solution is to add encoding normalization to the loader parent class to address this issue and restore correct text extraction.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-06T16:00:50Z", "body_clean": "Hi, @engkimo. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug in LangChain's loader parent class causes improper text encoding. This results in garbled text across various loaders, including PDFMinerLoader. You suggested normalizing text encoding to UTF 8 as a potential solution. Verified that the issue persists in the latest version and found no similar issues. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The HuggingFaceEndpointEmbeddings library is failing with a `ValueError: setting an array element with a sequence` error, specifically when attempting to embed text data.  The issue appears to be a bug within the LangChain integration, as attempts to resolve it by updating the library version haven’t worked.  The code example demonstrates the error with a specific shape and stack trace.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-05T16:00:50Z", "body_clean": "Hi, @tocab. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug when using [code] with FAISS, leading to an error due to inhomogeneous shapes in the embeddings array. The issue persists even after updating to the latest version of LangChain. No further activity or comments have been made on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a bug in the LangChain library, specifically concerning the `langchain.info.py` module, which fails to correctly update the `langchain community` and `langchain core` versions. This results in inconsistent behavior and a lack of updated information, impacting the functionality of the LangChain application.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-05T16:00:51Z", "body_clean": "Hi, @nikhil weamai. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where O3 cost and O3 condition are not updated in [code] . I verified that the issue is not due to your own code and persists in the latest stable version. I suggested using [code] instead of deprecated [code] . There have been no comments or activity since the issue was opened. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue focuses on developing a custom chat model for LLM inference on Triton server, leveraging LangChain and the NVIDIA Runtime Technology (NVIDIA trt). The developer is attempting to automate the chat model's task by integrating it with the LLM served by Triton.  The code includes a descriptive title, search results, and a commit message outlining the goal.", "final_category": "question", "comments": [{"author": "mattf", "created_at": "2025-03-17T14:21:49Z", "body_clean": "cc @dglogo"}, {"author": "dosubot[bot]", "created_at": "2025-06-16T16:01:44Z", "body_clean": "Hi, @DeekshithaDPrakash. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You opened an issue about implementing a custom chat model using a Triton inference server. You shared example code for the [code] class, detailing methods for message conversion and parameter settings. Mattf commented and tagged dglogo, possibly for additional insights or solutions. Next Steps: Could you confirm if this issue is still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in the LangChain library, specifically the `SQLDatabaseToolkit` component, which causes issues when using the `o3 mini` model. The code attempts to instantiate a `SQLDatabase` object, but the `temperature` parameter is not supported by this model. The solution involves removing the `temperature` parameter from the user/system prompt, effectively resolving the error.", "final_category": "bug", "comments": [{"author": "rawathemant246", "created_at": "2025-02-02T19:41:38Z", "body_clean": "As openai reasoning models does not support the temperature parameter i have update the ChatOPENAI api to not to consider the temperature parameter in default parameters to avoid [code]"}, {"author": "aifa", "created_at": "2025-02-02T23:24:25Z", "body_clean": "Thank you for looking into this. I noticed the same behavior when using create react agent, but this is a bit more tricky to investigate, I have not found the source of the error yet. It sounds like the fix on the ChatOpenAI api might be resolving the issue with the react agent as well."}, {"author": "rawathemant246", "created_at": "2025-02-03T02:33:43Z", "body_clean": "@aifa i have go through the create react agent api i'll let you know soon what's the reason. Let me know if you are facing the issue. can you please provide the code snippet and how do you call the create react agent and its response ?"}, {"author": "aifa", "created_at": "2025-02-03T08:49:04Z", "body_clean": "Hi @rawathemant246 , It seems create react agent did not work because I was not using the latest version of langchain openai. I updated the package and the error stopped occurring."}, {"author": "rawathemant246", "created_at": "2025-02-03T09:35:54Z", "body_clean": "@aifa I also checks how to use create react agent you can use the latest method now [code] in the background it uses the ChatOPENAI API so you'll not get the [code] . Nevertheless i also have a created a PR for the community llms openai.py to prevent this."}, {"author": "dosubot[bot]", "created_at": "2025-05-05T16:00:54Z", "body_clean": "Hi, @aifa. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involved a BadRequestError with the SQLDatabaseToolkit using a temperature setting of 0. The error was linked to the o3 mini model, which does not support a temperature of 0. You discovered that updating the [code] package resolved the error with [code] . A pull request was created to prevent similar issues in the future. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Encoding issues are a recurring regression point after version 0.3.17, suggesting a potential instability in the loader parent class.", "Addressing this regression could improve the overall stability and reliability of the LangChain ecosystem.", "Identifying the root cause is crucial for maintaining a consistent and predictable experience for LangChain users.", "A comprehensive analysis of the error logs will help pinpoint the specific code causing the issue.", "Prioritize resolving the encoding bug to maintain the core functionality of the LangChain library."], "technical_insights": ["Encoding normalization is a likely solution to the garbled text extraction problem, addressing a core functional failure.", "The ValueError related to array element sequences indicates a potential bug within the LangChain integration, requiring immediate attention.", "Updating the library version is a temporary workaround, but the underlying bug remains unresolved, highlighting a systemic issue.", "The langchain.info.py module bug affects multiple components, suggesting a wider issue within the LangChain framework.", "The SQLDatabaseToolkit component’s temperature parameter incompatibility is a specific, targeted problem affecting the o3 mini model."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Encoding issues are a recurring regression point after version 0.3.17, suggesting a potential instability in the loader parent class.\n2. Addressing this regression could improve the overall stability and reliability of the LangChain ecosystem.\n3. Identifying the root cause is crucial for maintaining a consistent and predictable experience for LangChain users.\n4. A comprehensive analysis of the error logs will help pinpoint the specific code causing the issue.\n5. Prioritize resolving the encoding bug to maintain the core functionality of the LangChain library.\n\nTECHNICAL INSIGHTS:\n1. Encoding normalization is a likely solution to the garbled text extraction problem, addressing a core functional failure.\n2. The `ValueError` related to array element sequences indicates a potential bug within the LangChain integration, requiring immediate attention.\n3. Updating the library version is a temporary workaround, but the underlying bug remains unresolved, highlighting a systemic issue.\n4. The `langchain.info.py` module bug affects multiple components, suggesting a wider issue within the LangChain framework.\n5. The `SQLDatabaseToolkit` component’s temperature parameter incompatibility is a specific, targeted problem affecting the `o3 mini` model.\n", "batch_number": 126, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue addresses a problem where LangChain and Pinecone metadata filtering works correctly locally but fails to retrieve data when deploying to AWS Lambda. The code uses a vector retriever that filters results based on project ID and table name metadata, but the Lambda deployment returns no results despite the same metadata.  The core issue appears to be a deployment-specific issue with the Lambda environment's metadata handling.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-02-02T15:02:12Z", "body_clean": "It's very difficult to answer your question. From the looks of it, you seem to be passing the [code] argument correctly. You can try one thing, rather than passing in the filter duing the invoke, pass the filter when retriever is being initiated: [code]"}, {"author": "vaishnav-mk", "created_at": "2025-02-02T16:09:20Z", "body_clean": "I tried it earlier, the same thing happens where it works locally but not on AWS lambda On Sun, 2 Feb 2025, 20:32 Mohammad Mohtashim, @ . wrote: It's very difficult to answer your question. From the looks of it, you seem to be passing the filter argument correctly. You can try one thing, rather than passing in the filter duing the invoke, pass the filter when retriever is being initiated: retriever = vector store.as retriever( search type=\"similarity score threshold\", search kwargs={\"k\": 5, \"score threshold\": 0.5, \"filter\": {\"table name\": \"Material\", \"project id\": projectId}}, ) — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ ."}, {"author": "dosubot[bot]", "created_at": "2025-05-04T16:02:41Z", "body_clean": "Hi, @vaishnav mk. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Discrepancy in metadata filtering using LangChain with Pinecone for vector retrieval. Works locally but fails on AWS Lambda. @keenborder786 suggested passing the filter during retriever initiation. You confirmed the issue persists on AWS Lambda despite the suggestion. Next Steps Is this issue still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue addresses a problem with the `create_sql_query_chain` function, specifically when customizing the prompt. The code is attempting to pass `input` and `table info` variables to the prompt, but the error message indicates that the prompt must have *only* the required input variables. The user has already attempted to use a default prompt and didn’t find a solution, and the code includes a relevant example demonstrating the issue. The solution involves modifying the prompt template to ensure it only includes the necessary variables.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-04T16:02:42Z", "body_clean": "Hi, @Mourdhwaj. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are seeking assistance with integrating a custom prompt into the [code] function. You have shared example code and referenced a related discussion but did not find a solution there. The issue remains unresolved, with no additional comments or activity noted. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The `aconfig_with_context()` function in LangChain is causing a blocking call within the code, impacting performance.  The issue is not directly related to code updates and seems to be a persistent problem despite recent updates.  The developers are investigating potential solutions, including alternative asynchronous implementations or optimizing the code to reduce the blocking calls.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-08T14:48:59Z", "body_clean": "Hi, @cbornet. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] function currently makes blocking calls, affecting async performance. Recent updates have mitigated some of the impact, but further improvements are suggested. You propose using [code] or creating an async method for full asynchronicity. The issue was initially identified by BlockBuster. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "cbornet", "created_at": "2025-05-09T20:55:59Z", "body_clean": "@dosubot yes the issue is still relevant"}, {"author": "xoTEMPESTox", "created_at": "2025-10-14T09:03:19Z", "body_clean": "Hi @cbornet , I’m interested in exploring this issue as my first contribution to LangChain. I’m currently reviewing how aconfig with context() interacts with config with context and RunnableLambda.config specs. I haven’t implemented anything yet I’d like to confirm if the suggested direction (using asyncio.to thread or introducing an async variant) is preferred before I start experimenting. Please let me know if it’s okay for me to take this on."}, {"author": "cbornet", "created_at": "2025-10-14T09:54:25Z", "body_clean": "Please let me know if it’s okay for me to take this on. No problem for me. I haven’t implemented anything yet I’d like to confirm if the suggested direction (using asyncio.to thread or introducing an async variant) is preferred before I start experimenting. Maybe @eyurtsev or @mdrxy can give their 2 cents ?"}]}, {"ollama_summary": "This issue stems from a problem where a model isn’t being invoked after sending it via the client, despite it being expected to be called. The default model is being used instead of the specified model due to a failure in the client’s post-call handling of the model.  The solution is to ensure the model is consumed correctly within the client’s call to the Hugging Face endpoint.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-02-01T11:21:27Z", "body_clean": "Nope the models is being passed during the initialization of [InferenceClient]( [link]"}, {"author": "ENCODERS09", "created_at": "2025-02-05T04:12:19Z", "body_clean": "@keenborder786 [link] If you see here, model is passed but the issue lies in the fact that, assigning the self.model attribute in the validate environment method, but there is no ensuring that this assignment is persisted when we call the aembed documents method. The problem is In the validate environment method, we are assigning the self.model attribute based on the self.repo id attribute. However, when we call the aembed documents method, we are not re validating the environment, so the self.model attribute might not be up to date. So either we do this in aembed documents() function [code] or we pass model=self.model [code]"}, {"author": "keenborder786", "created_at": "2025-03-30T21:47:11Z", "body_clean": "@ENCODERS09, why are you saying there is no guarantee that self.model will be assigned? The Pydantic decorator @model validator(mode=\"after\") ensures that self.model is assigned to both self.client and self.async client."}, {"author": "dosubot[bot]", "created_at": "2025-06-29T16:01:35Z", "body_clean": "Hi, @ENCODERS09. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue in [code] where the model parameter is not utilized, defaulting to the standard model. The problem is identified in the [code] method, where [code] is assigned but not re validated in [code] . You suggested potential fixes, but keenborder786 noted that the Pydantic decorator should ensure [code] is correctly assigned. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue addresses a potential bug in LangChain where the integration of OpenAI API keys via Ollama LLMs is not functioning correctly. The developer needs to replace the existing API keys with Ollama’s LLMs, specifically using the `llm.bind tools` functionality, and potentially adjust the `tools` configuration to ensure proper integration.  The issue involves a lack of a clear resolution to the problem, suggesting it’s a bug requiring investigation rather than a simple code update.", "final_category": "feature", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-02T16:01:21Z", "body_clean": "Hi, @bhanu1106. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are seeking assistance with replacing OpenAI API keys and functionalities in a LangChain setup with Ollama LLMS. You provided example code using OpenAI's [code] and [code] . You identified this as a bug within LangChain, not an issue with your code. There have been no further comments or developments on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Deployment-specific metadata handling is a recurring challenge across multiple issues, suggesting a need for more robust metadata validation during deployment.", "The Lambda environment’s metadata handling is a significant factor impacting local code functionality, highlighting potential environment-specific issues.", "The core issue likely relates to the deployment-specific metadata configuration, requiring a more comprehensive approach to ensure consistent behavior across environments.", "The code’s reliance on metadata filtering could be simplified by incorporating more robust validation checks during deployment.", "Addressing metadata issues early in the development lifecycle will reduce debugging time and improve overall code reliability."], "technical_insights": ["Lambda environment metadata handling is a critical point of failure, requiring a dedicated strategy for metadata management.", "The vector retriever filtering mechanism in the code needs careful consideration regarding metadata integration.", "The aconfig_with_context() function’s blocking call suggests potential performance bottlenecks and requires optimization.", "The model invocation issue highlights a critical connection between client-side handling and Hugging Face integration.", "Ollama LLM integration requires specific configuration adjustments to ensure proper metadata passing and model binding."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Deployment-specific metadata handling is a recurring challenge across multiple issues, suggesting a need for more robust metadata validation during deployment.\n2.  The Lambda environment’s metadata handling is a significant factor impacting local code functionality, highlighting potential environment-specific issues.\n3.  The core issue likely relates to the deployment-specific metadata configuration, requiring a more comprehensive approach to ensure consistent behavior across environments.\n4.  The code’s reliance on metadata filtering could be simplified by incorporating more robust validation checks during deployment.\n5.  Addressing metadata issues early in the development lifecycle will reduce debugging time and improve overall code reliability.\n\nTECHNICAL INSIGHTS:\n1.  Lambda environment metadata handling is a critical point of failure, requiring a dedicated strategy for metadata management.\n2.  The vector retriever filtering mechanism in the code needs careful consideration regarding metadata integration.\n3.  The `aconfig_with_context()` function’s blocking call suggests potential performance bottlenecks and requires optimization.\n4.  The model invocation issue highlights a critical connection between client-side handling and Hugging Face integration.\n5.  Ollama LLM integration requires specific configuration adjustments to ensure proper metadata passing and model binding.\n", "batch_number": 127, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from LangChain's Redis Semantic Cache failing to correctly associate cache keys with semantically similar queries, leading to cache misses and performance issues. The proposed solution involves creating a standardized cache key for similar queries, potentially through preprocessing or appending answers to the key, to ensure consistent cache hits. The current static key approach prevents the system from generating answers for new queries, requiring a change to avoid this behavior.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-02-01T11:38:59Z", "body_clean": "I think there’s some confusion in your understanding. Behind the scenes, [code] utilizes [code] . When a query is added to [code] , it is embedded and stored in [code] . During lookup, the user query is embedded again, and the most similar queries (those with a similarity score above the given threshold) are retrieved from [code] ."}, {"author": "rakesh-srivastava-negd", "created_at": "2025-02-03T03:55:47Z", "body_clean": "@keenborder786 I'm referring to this link (Using RedisSemanticCache): [link]"}, {"author": "dosubot[bot]", "created_at": "2025-05-05T16:00:54Z", "body_clean": "Hi, @rakesh srivastava negd. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves RedisSemanticCache not effectively caching semantically similar queries. Unique cache keys are generated by different embeddings, affecting performance. @keenborder786 explained the use of RedisVectorstore for embedding and retrieval based on similarity scores. You referenced documentation for additional context. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The error message indicates a problem with the `pydantic` library during the `DynamicGraph` invocation. Specifically, the `parsed` argument is being used incorrectly, leading to a type mismatch.  The `DynamicGraph` is being invoked with the wrong data type.\n\nHere's a breakdown of the issue and potential solutions:\n\n**Understanding the Problem**\n\n* **`DynamicGraph` and `parsed`:**  The `DynamicGraph` is a component of the LangChain library that handles graph data.  The `parsed` argument is used to provide the data structure that the `DynamicGraph` expects.\n* **Incorrect Data Type:** The `parsed` argument is being passed a `dict` instead of a `list` or `dict` that `DynamicGraph` expects.\n* **Type Mismatch:**  The `DynamicGraph` is expecting a specific data structure for the `parsed` argument, and it's receiving a different one.\n\n**Possible Solutions**\n\n1. **Correct the `parsed` Argument:**  Modify the `parsed` argument to match the expected data type for the `DynamicGraph`.  It should be a `list` or `dict`.\n\n   ```python\n   parsed = {\"node\": \"dog\", \"neighbors\": [\"cat\"]}  # Example\n   ```\n\n2. **Inspect the `DynamicGraph`'s Requirements:**  Carefully examine the documentation for the `DynamicGraph` to understand the expected data structure for the `parsed` argument.\n\n3. **Debugging:** Add debugging statements to the `DynamicGraph`'s initialization to see what data it's receiving.\n\n**Example Code (Illustrative - Adapt to your specific needs)**\n\n```python\nfrom langchain.graph import DynamicGraph\n\n# ... your code ...\n\nparsed = {\"node\": \"dog\", \"neighbors\": [\"cat\"]}  # Corrected\ndynamic_graph = DynamicGraph(data=parsed)\n```\n\n**Important:**  The exact solution depends on the specific `DynamicGraph` implementation and the context of your code.  The key is to ensure the `parsed` argument is correctly formatted to match the expected input.\n\nTo help me give you more specific guidance, could you provide:\n\n*   The exact code snippet where the `DynamicGraph` is being invoked?\n*   The full error message (including the traceback)?\n*   The documentation for the `DynamicGraph`?", "final_category": "bug", "comments": [{"author": "pbrady", "created_at": "2025-01-31T16:29:13Z", "body_clean": "I get the expected results with [code] as the llm. The chain does hook into a different runnable. Here's the ollama chain that fails: [code] The openAI chain that succeeds: [code]"}, {"author": "pbrady", "created_at": "2025-01-31T16:52:40Z", "body_clean": "I threw a [code] into the parser at [link] to get some more details on the ollama failure: [code]"}, {"author": "pbrady", "created_at": "2025-01-31T17:38:58Z", "body_clean": "I noticed that call to [code] in the [code] method is done without specifying the [code] argument. This unspecified argument has different defaults for [code] and [code] . For [code] it defaults to [code] . For [code] , [code] . If I add the argument [code] then I get the expected results from [code] as well! Not sure if this should be hardcoded or left as an argument to the constructor. I also just realized that [code] is in a different repo..."}, {"author": "dosubot[bot]", "created_at": "2025-05-02T16:01:22Z", "body_clean": "Hi, @pbrady. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with [code] using [code] , causing Pydantic parsing errors. The issue did not occur with [code] , indicating a difference in structured output methods. Specifying [code] for [code] resolved the issue. You raised whether this method should be hardcoded or configurable. Mentioned [code] is in a different repository, which might be relevant. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If not updated, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue currently prevents retrieving reasoning content from LangChain while streaming, specifically when using the `[code]` example. This problem is likely related to a bug within the LangChain integration, potentially affecting the specific code being executed. The solution involves updating to the latest stable version of LangChain, which should resolve the issue.", "final_category": "bug", "comments": [{"author": "codergma", "created_at": "2025-02-02T09:37:21Z", "body_clean": "Like me, I believe that the method convert delta to message chunk() did not retrieve the key reasoning content. [link]"}, {"author": "yigit353", "created_at": "2025-02-02T15:44:48Z", "body_clean": "Like me, I believe that the method convert delta to message chunk() did not retrieve the key reasoning content. [langchain/libs/partners/openai/langchain openai/chat models/base.py]( [link] Line 262 in [0c782ee](/langchain ai/langchain/commit/0c782ee5479f1eadf6cc532d7f27617bd2671fe9) def convert delta to message chunk( You proposed a very minimal and excellent solution, however, I guess maintainers didn't want to change the base class for the solution. I believe that a change in the specialized DeepSeekChat class might be better if possible."}, {"author": "4fuu", "created_at": "2025-02-07T11:23:33Z", "body_clean": "This is my solution. [code]"}, {"author": "ccurme", "created_at": "2025-02-11T22:42:05Z", "body_clean": "Hello, I believe this was resolved in [code] . Please update your package and shout if there are additional issues. Thanks!"}, {"author": "ryangsun", "created_at": "2025-03-08T07:17:16Z", "body_clean": "mark"}, {"author": "dustturtle", "created_at": "2025-03-31T12:54:39Z", "body_clean": "how to get reasoning content without stream when using chatopenai? I am using the qwq32 reason model which can output reasoning content when using openai sdk"}, {"author": "dustturtle", "created_at": "2025-03-31T12:55:04Z", "body_clean": "@yigit353"}, {"author": "yigit353", "created_at": "2025-03-31T13:28:46Z", "body_clean": "how to get reasoning content without stream when using chatopenai? I am using the qwq32 reason model which can output reasoning content when using openai sdk @dustturtle Can you give me the code you access qwq 32b reasoning model when using ChatOpenAI? UPDATE : I'm currently working on integration of a standalone [code] package. You can check the progress here: [link] @dustturtle UPDATE : The docs are also added to LangChain repo here: [link] EDIT: ~I think ChatOpenAI is reserved for OpenAI models so you basically cannot use ChatOpenAI for Qwen.~ I couldn't find any way to run Qwen with LangChain. ChatTongyi didn't accept my Dashscope API Key for some reason. EDIT: I followed [the Qwen's documentation of using ChatOpenAI]( [link] If you call it as in the documentation you don't get thinking tokens back if you're not streaming. EDIT: I followed [the QwQ models documentation]( [link] and first of all it says it only supports streaming and also when I run it with ChatOpenAI it didn't capture the reasoning content because the default code is not looking for a key called 'reasoning content' in delta. So it should be another issue to get a ChatQwQ or something. EDIT: I solved the problem by creating a [code] model and created 30579 PR and 30580 issue. QwQ does not support non streaming as it is told by its documentation. So I changed it so that when you call invoke it calls streaming and accumulates the results. It also returns the current reasoning in the end. Original streaming also didn't work I also solved that."}, {"author": "L9qmzn", "created_at": "2025-04-23T14:29:22Z", "body_clean": "EDIT: I followed [the QwQ models documentation]( [link] and first of all it says it only supports streaming and also when I run it with ChatOpenAI it didn't capture the reasoning content because the default code is not looking for a key called 'reasoning content' in delta. So it should be another issue to get a ChatQwQ or something. Hi there, Just wondering — would it be possible to create something like a ChatOpenAICompatible class that could work with any model or provider compatible with the OpenAI SDK? This way, we could use a single interface to interact with OpenAI, DeepSeek, Qwen, etc. It could also be quite helpful for users who are using projects like One API, which unify different model providers under an OpenAI compatible API. Curious to hear your thoughts on this — thanks for all the great work!"}, {"author": "yigit353", "created_at": "2025-04-23T20:11:40Z", "body_clean": "Hi there, Just wondering — would it be possible to create something like a ChatOpenAICompatible class that could work with any model or provider compatible with the OpenAI SDK? This way, we could use a single interface to interact with OpenAI, DeepSeek, Qwen, etc. It could also be quite helpful for users who are using projects like One API, which unify different model providers under an OpenAI compatible API. Curious to hear your thoughts on this — thanks for all the great work! You're raising a solid point, @L9qmzn! In practice, every new model is developed and maintained independently, often by different teams. What LangChain does well is define a general template with built in validation, but beyond that, it’s up to each provider to implement whatever subset of OpenAI compatible functionality they choose to support and possibly extend beyond that. Take QwQ for example: it doesn’t officially support structured outputs, yet I implemented that functionality independently. This highlights both the flexibility and the fragmentation in how these APIs are implemented. If you're considering a unified interface like ChatOpenAICompatible, a pragmatic approach would be to build a capability registry. A structured JSON config that maps each model to the features it supports (e.g., streaming, tools, function calling, reasoning content). You could then create a wrapper or dispatcher that references this registry and either gracefully degrades or blocks unsupported features at runtime. This approach improves the dev experience and also avoids silent failures and unclear errors. You can surface informative warnings or UI level restrictions based on actual capabilities, something both users and downstream systems would benefit from. It’s a scalable and robust pattern if you’re working across multiple backends like One API."}]}, {"ollama_summary": "The user is encountering an issue installing the `langchain deepseek-official` package, resulting in a \"Could not find a version that satisfies the requirement\" error.  They’ve already tried various resources, search methods, and updating the LangChain version, suggesting a potential bug within the package itself.  The user has provided a code snippet that triggers the error, and the stack trace indicates a problem with the LangChain library’s dependency resolution.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-30T16:41:11Z", "body_clean": "This package requires python = 3.9. From your system information it looks like you're running python 3.8."}]}, {"ollama_summary": "This issue involves a critical bug in the LangChain vectorstore library that causes a significant problem with live server data retrieval. When a new user is created, the system generates a new vector database, and subsequent data retrieval fails, leading to a disconnect between the user and the conversation. The bug only manifests on the live server and doesn’t occur in local testing, suggesting a potential issue with the integration process or the server’s state.  The solution requires a reload of the PM2 process to refresh the vector database, which disrupts ongoing user sessions.  Further investigation is needed to determine the root cause and implement a robust solution to ensure seamless data retrieval across all environments.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-05-06T16:00:52Z", "body_clean": "Hi, @Shabbir iRoidSolutions. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Reported bug in LangChain's vector database affecting data retrieval after new data is added. Issue persists despite updating to the latest version. Example code provided demonstrating the problem with different loaders and embeddings. Potential link to [code] and its management of document storage and retrieval. No further comments or developments on the issue. Next Steps: Please confirm if the issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Shabbir-iRoidSolutions", "created_at": "2025-05-08T07:16:52Z", "body_clean": "Hi Dosu, Yes, I'm still facing the issue is still relevant to the latest version of the LangChain Thank you! On Tue, May 6, 2025 at 9:31 PM dosubot[bot] @ . wrote: dosubot[bot] left a comment (langchain ai/langchain 29499) < [link] Hi, @Shabbir iRoidSolutions < [link] I'm Dosu < [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Reported bug in LangChain's vector database affecting data retrieval after new data is added. Issue persists despite updating to the latest version. Example code provided demonstrating the problem with different loaders and embeddings. Potential link to vectorestore function and its management of document storage and retrieval. No further comments or developments on the issue. Next Steps: Please confirm if the issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution! — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you were mentioned.Message ID: @ ."}, {"author": "dosubot[bot]", "created_at": "2025-05-08T07:19:12Z", "body_clean": "Hi @eyurtsev, the user @Shabbir iRoidSolutions has confirmed that the issue with the vector database affecting data retrieval is still relevant to the latest version of LangChain. Could you please assist them with this issue? Thank you!"}]}], "business_insights": ["Dependency management is crucial; inconsistent versions can trigger cascading errors across the system.", "Testing and regression are vital; a bug in one area can impact others.", "Code quality and linters are essential; consistent code improves reliability.", "Monitoring and alerting are needed; proactively identify issues before they impact users.", "Version control practices must be strictly followed; rollback capabilities are key."], "technical_insights": [], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management is crucial; inconsistent versions can trigger cascading errors across the system.\n2.  Testing and regression are vital; a bug in one area can impact others.\n3.  Code quality and linters are essential; consistent code improves reliability.\n4.  Monitoring and alerting are needed; proactively identify issues before they impact users.\n5.  Version control practices must be strictly followed; rollback capabilities are key.\n", "batch_number": 128, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain's CacheBackedEmbeddings that causes errors when hashing text keys. The code attempts to use raw text as keys, leading to a failure to hash and subsequent errors.  The proposed solution is to update to the latest stable version of LangChain to address this bug.", "final_category": "bug", "comments": [{"author": "lyger", "created_at": "2025-01-30T05:52:10Z", "body_clean": "I've figured out that you're supposed to use [code] instead of initializing directly, but I'm leaving this open because it feels like that should be explained clearly in the main class documentation."}, {"author": "dosubot[bot]", "created_at": "2025-05-01T16:00:57Z", "body_clean": "Hi, @lyger. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in [code] where keys are not hashed, causing an [code] with [code] . The issue occurs because keys derived from document texts contain invalid characters. You found that using [code] resolves the issue. It was suggested that this solution should be documented in the main class documentation. Next Steps Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "umangino", "created_at": "2025-09-28T10:16:44Z", "body_clean": "Hi, this issue looks really similar to [link] The problem is in \"full path = self. get full path(key)\" that performs a regex check that doesn't allow for keys containing colon ( : )"}]}, {"ollama_summary": "The YahooFinanceNewsTool is experiencing a critical bug where it fails to extract news data due to a change in the yfinance library’s news data structure. This issue stems from an outdated news data structure that now includes `content.type` and `content.canonicalUrl` fields, breaking compatibility with the tool.  Users have reported this issue across multiple communities, and the issue is a widespread problem affecting the community.", "final_category": "bug", "comments": [{"author": "Jcasttrop", "created_at": "2025-01-30T04:41:33Z", "body_clean": "In this PR I propose a solution (respectively tested to this Issue) [link]"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a critical problem with the AskNewsAPIWrapper documentation – it lacks the necessary credentials (Client ID and Secret Key) required to utilize the search tool. The user was encountering an error while attempting to access the tool, which was resolved by locating these credentials on the AskNews developer website.", "final_category": "other", "comments": [{"author": "keenborder786", "created_at": "2025-01-30T01:21:21Z", "body_clean": "You need to use the api wrapper as following: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-05-01T16:00:58Z", "body_clean": "Hi, @arslaan5. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Lack of documentation for credentials (\"client id\" and \"secret key\") needed for AskNewsAPIWrapper. Suggestion to update documentation with guidance on obtaining credentials from AskNews website. @keenborder786 provided a code snippet demonstrating API wrapper usage with credentials. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, feel free to keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain-huggingface library requires the installation of PyTorch, but the issue is not being resolved by updating to the latest version. The problem appears to be a bug within the LangChain integration, specifically related to the required PyTorch version for inference. The user is encountering an error message indicating a dependency issue and is unable to utilize the library for LLM inference via Hugging Face.", "final_category": "bug", "comments": [{"author": "DarkDk123", "created_at": "2025-02-02T17:38:37Z", "body_clean": "Similar issue! I mostly use [code] for inference APIs. And greatly annoyed by unnecessary large installations i.e. [code] etc. There must be a minimal installation of langchain huggingface as: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-05-04T16:02:40Z", "body_clean": "Hi, @marekb sci. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised a concern about the unnecessary installation of the [code] library when using [code] for Hugging Face inference API. DarkDk123 echoed similar frustrations regarding large installations, including CUDA libraries. A suggestion was made for a minimal installation option for inference API users to streamline the process. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "marekb-sci", "created_at": "2025-05-05T11:26:07Z", "body_clean": "still relevant"}, {"author": "dosubot[bot]", "created_at": "2025-05-05T11:28:22Z", "body_clean": "@eyurtsev, the user @marekb sci has indicated that this issue regarding the unnecessary installation of the [code] library is still relevant. Could you please assist them with this concern?"}, {"author": "thibflo-10", "created_at": "2025-05-25T08:38:37Z", "body_clean": "It is also relevant for my case"}, {"author": "thibflo-10", "created_at": "2025-05-25T11:32:20Z", "body_clean": "Waiting for adaptations of that kind. Here is a temporary solution, where it only needs [code] : [code] I hope it helps"}]}, {"ollama_summary": "The issue stems from a bug in LangChain's Weaviate vectorstore that causes errors when indexing PDFs created with PyMuPDF.  The bug specifically targets metadata keys in the Weaviate schema, leading to failures and requiring a mapping of keys to prevent indexing. The problem is reproducible by updating LangChain to version 0.3.15 and is currently being addressed by the developers.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2025-01-31T18:07:07Z", "body_clean": "cc @pprados could you take a look? Can we add a flag to preserve old behavior? (e.g., metadata format=\"legacy\") [code]"}, {"author": "pprados", "created_at": "2025-02-03T10:06:53Z", "body_clean": "Resolve [here]( [link]"}, {"author": "pprados", "created_at": "2025-02-04T10:45:09Z", "body_clean": "@eyurtsev Resolve [here]( [link]"}, {"author": "pprados", "created_at": "2025-02-08T07:41:04Z", "body_clean": "@KarlCJ Resolve [here]( [link]"}, {"author": "dosubot[bot]", "created_at": "2025-05-10T16:00:42Z", "body_clean": "Hi, @KarlCJ. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with PyMuPDF version 0.3.15 affecting metadata keys in LangChain. The [code] function failed silently due to changes in metadata keys. You resolved the issue by mapping new metadata keys to the old ones. Eyurtsev suggested adding a flag to preserve old behavior. pprados provided a resolution through a pull request. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Update to latest stable LangChain version resolves key cache-related issues.", "Addressing the cache-related bug is a priority for LangChain development.", "Consistent bug fixes across multiple issues demonstrate a focus on stability."], "technical_insights": ["Update to latest stable LangChain version mitigates hash key errors.", "The YahooFinanceNewsTool’s news data structure change necessitates a specific news data structure.", "The LangChain-huggingface library dependency on PyTorch is causing issues."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Update to latest stable LangChain version resolves key cache-related issues.\n2. Addressing the cache-related bug is a priority for LangChain development.\n3. Consistent bug fixes across multiple issues demonstrate a focus on stability.\n\nTECHNICAL INSIGHTS:\n1. Update to latest stable LangChain version mitigates hash key errors.\n2. The YahooFinanceNewsTool’s news data structure change necessitates a specific news data structure.\n3. The LangChain-huggingface library dependency on PyTorch is causing issues.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 129, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is a critical failure to import necessary components from the LangChain library, specifically the `fdk` package, during the OCI Function deployment. This prevents the function from functioning correctly, and the issue is reproducible across different Python versions and environments, suggesting a fundamental problem with LangChain's dependency management.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-30T01:23:32Z", "body_clean": "Please change your import to: [code]"}, {"author": "bhnorman11", "created_at": "2025-01-30T10:06:14Z", "body_clean": "Please change your import to: from langchain community.chat models.oci generative ai import ChatOCIGenAI from langchain community.utilities import SQLDatabase from langchain experimental.sql import SQLDatabaseSequentialChain from langchain core.prompts import PromptTemplate Thanks for your response. Have corrected the import, have received the same error on function invocation."}, {"author": "NaotoNaka", "created_at": "2025-02-17T09:02:53Z", "body_clean": "I dug into this because I had the same error, and it seems that the issue might be a compatibility problem among Docker, fdk, and LangChain rather than an issue with LangChain itself. I worked around the problem by using a venv inside the Docker image for an extra layer of isolation. I didn't use the Cloud Shell because this Dockerfile only worked when I built it locally and then pushed (error code at the bottom). [code] I then uploaded the image to OCI Container Registry with [code] . I hope this helps :) This might be not the right place to post, but FYI, the following code is the error that i encountered when i [code] in Cloud Shell: [code]"}, {"author": "bhnorman11", "created_at": "2025-02-18T11:32:11Z", "body_clean": "I dug into this because I had the same error, and it seems that the issue might be a compatibility problem among Docker, fdk, and LangChain rather than an issue with LangChain itself. I worked around the problem by using a venv inside the Docker image for an extra layer of isolation. I didn't use the Cloud Shell because this Dockerfile only worked when I built it locally and then pushed (error code at the bottom). FROM fnproject/python:3.11 as build stage WORKDIR /function COPY requirements.txt . RUN python3 m venv venv && \\ venv/bin/pip install upgrade pip && \\ venv/bin/pip install no cache dir r requirements.txt && \\ rm rf ~/.cache/pip /tmp COPY . . FROM fnproject/python:3.11 WORKDIR /function COPY from=build stage /function/venv venv COPY from=build stage /function . ENV PYTHONPATH=/function ENV PATH=\"/function/venv/bin:$PATH\" RUN venv/bin/python c \"from langchain community.chat models.oci generative ai import ChatOCIGenAI\" ENTRYPOINT [\"/function/venv/bin/fdk\", \"/function/func.py\", \"handler\"] I then uploaded the image to OCI Container Registry with [code] . I hope this helps :) This might be not the right place to post, but FYI, the following code is the error that i encountered when i [code] in Cloud Shell: [code] That's worked for me, thank you! I'm also deploying locally so not sure about that cloud editor error, though I have had to downgrade Pydantic to 2.9.2 previously due to other issues with it so perhaps that's part of it. Have you tried to actually call ChatOCIGenAI() yet? Having trouble authenticating both using api key and resource principal."}, {"author": "NaotoNaka", "created_at": "2025-02-19T01:48:08Z", "body_clean": "That's worked for me Glad to hear it worked! The Dockerfile error went away when i changed my oci environment, so langchain might not be the main reason for the error. Having trouble authenticating The genai is working beautifully here. Check the documentation once again, and if still persists, we can discuss this in another issue thread :)"}, {"author": "dosubot[bot]", "created_at": "2025-05-21T16:01:07Z", "body_clean": "Hi, @bhnorman11. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered a \"'NoneType' object is not callable\" error when importing LangChain into a Python OCI Function. Modifying import statements did not resolve the error. NaotoNaka identified a compatibility issue and suggested using a virtual environment within the Docker image, which resolved the error. You are now facing authentication challenges with ChatOCIGenAI, suggested to be addressed separately. Next Steps: Please confirm if the authentication issue with ChatOCIGenAI is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a concise summary of the GitHub issue:\n\nLangchain Chroma requires the NumPy version 1.26.0, but the issue reports a dependency conflict. This issue is causing problems in the developer’s project and requests a change to allow NumPy versions higher than 2.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-30T01:33:17Z", "body_clean": "@mikolajsawicki this is because of the following restriction: [code]"}, {"author": "keenborder786", "created_at": "2025-01-30T01:33:29Z", "body_clean": "So can't do much at the moment."}, {"author": "metrizable", "created_at": "2025-02-10T22:25:33Z", "body_clean": "Related [link]"}, {"author": "sydney-runkle", "created_at": "2025-04-07T19:14:44Z", "body_clean": "Thanks for the report will fix via [link] :)"}, {"author": "sydney-runkle", "created_at": "2025-04-15T18:02:37Z", "body_clean": "Fixed by [link]"}]}, {"ollama_summary": "The GitHub issue reports a critical issue where the LangChain library fails to connect to the Apache AGE database for PostgreSQL flexible server, specifically due to a permissions problem. The proposed solution involves modifying the code to create and delete a separate graph, which resolves the issue.", "final_category": "bug", "comments": [{"author": "belenrickmers", "created_at": "2025-04-18T09:49:01Z", "body_clean": "Hello, very interested in this as I am also facing the same exact problem, any chance for fixing it soon? Also worked around it by commenting the loading of the extension (line 143)."}, {"author": "joelwaymack", "created_at": "2025-04-22T15:10:33Z", "body_clean": "Check to make sure the AGE extension is enabled in both the [code] setting and the [code] setting on the Azure Database for PostgreSQL flexible server. If it isn't enabled in the preload setting, the extension won't be enabled on first connection to the database."}]}, {"ollama_summary": "The issue stems from incorrect installation instructions for the `docs: pgvector` repository, leading to an error. The recommended solution is to have users install the psycopg binary and link to the psycopg documentation for further options. This resolves the problem by providing a straightforward fix for the installation process.", "final_category": "other", "comments": [{"author": "oomarish", "created_at": "2025-02-21T14:39:23Z", "body_clean": "I confirm, should make [code] to install psycopg3, through [pypi documentation]( [link] Thank you for opening this issue."}, {"author": "dosubot[bot]", "created_at": "2025-05-23T16:00:47Z", "body_clean": "Hi, @efriis. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights incorrect installation instructions in the pgvector documentation, leading to an ImportError. You suggested updating the documentation to include psycopg binary installation and linking to psycopg documentation. @oomarish confirmed the issue and recommended using [code] , which was supported by @thistleknot. Next Steps: Please confirm if the issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a bug where the `get_index` function within the LangChain Azure AI Search client component is being called twice – once during initialization and again during asynchronous operations. This is causing a latency increase, and the issue is not resolved by updating LangChain.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-27T23:06:50Z", "body_clean": "@msetbar one is for [code] and one is for [code]"}, {"author": "hrishi-008", "created_at": "2025-01-29T08:44:09Z", "body_clean": "Async should be instantiated if [code] is set to true in [code]"}, {"author": "dosubot[bot]", "created_at": "2025-04-30T16:01:00Z", "body_clean": "Hi, @msetbar. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a redundancy in the AzureSearch component's [code] function, causing increased latency. @keenborder786 clarified that the calls are for [code] and [code] respectively. @hrishi 008 suggested instantiating the async client only if [code] is true in [code] . Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is a recurring challenge across multiple issues.", "Fixing dependency conflicts is a common source of bugs and instability.", "Addressing issues related to specific libraries impacts the entire ecosystem.", "Correcting fundamental issues leads to broader system stability.", "Consistent error handling across libraries is crucial for reliability."], "technical_insights": ["LangChain’s dependency management system requires careful configuration.", "NumPy version conflicts are a frequent source of problems.", "The AGE database connection issue highlights a critical system component.", "Incorrect installation instructions contribute to runtime errors.", "The get_index bug necessitates code refactoring and testing."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency management is a recurring challenge across multiple issues.\n2. Fixing dependency conflicts is a common source of bugs and instability.\n3. Addressing issues related to specific libraries impacts the entire ecosystem.\n4. Correcting fundamental issues leads to broader system stability.\n5. Consistent error handling across libraries is crucial for reliability.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s dependency management system requires careful configuration.\n2. NumPy version conflicts are a frequent source of problems.\n3. The AGE database connection issue highlights a critical system component.\n4. Incorrect installation instructions contribute to runtime errors.\n5. The `get_index` bug necessitates code refactoring and testing.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 130, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a bug in LangChain where assertions are not being executed in test code, specifically within a specific test function. This problem is occurring when applying a specific Rust rule (PT012) and results in the test failing without completing the test section.  The root cause appears to be a conflict with the Rust compiler's optimization process, requiring a fix to ensure assertions are always performed.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue asks for a way to record the `first_token_time` for each run in a LangChain application. The developer has already identified a similar question and used LangChain documentation and GitHub search to find a solution involving a specific code implementation. The core requirement is to accurately timestamp the initial token usage for each run.", "final_category": "question", "comments": [{"author": "uznadeem", "created_at": "2025-01-29T11:15:56Z", "body_clean": "I have resolved it, We would need to add an event to your API call to have the time to first token datetime displayed. Another issue to fix would be the timestamps where we have removed the Z and can add .000000. I'm including my data payload below where I used a random string for my new token in that new event: [code]"}]}, {"ollama_summary": "The Llama-3.2-3B-Instruct model failed to utilize the HuggingfacePipeline due to an incorrect value set for the `pad_token`.  After attempting to use the pipeline with the specified code, the error persisted, suggesting a bug within LangChain’s integration.  The issue is consistent with a reported issue in the transformers library, and the solution involves updating the LangChain community package to address the bug.", "final_category": "bug", "comments": [{"author": "S0PEX", "created_at": "2025-01-28T19:48:01Z", "body_clean": "I've updated to [langchain community==0.3.16]( [link] but the issue still persists. Although this version already contains fix [link] Have you had any luck getting this model working? Edit: Alright, never mind. Make sure to import [code] as the same class also exists in [code] !"}, {"author": "tishizaki", "created_at": "2025-01-29T00:53:17Z", "body_clean": "@S0PEX The same bug in libs/partners/huggingface/langchain huggingface/llms/huggingface pipeline.py still persists. I haven't been able to post a patch because I haven't confirmed how to change the test program yet."}, {"author": "tishizaki", "created_at": "2025-02-04T05:14:12Z", "body_clean": "The issue was fixed by PR: 29434 and 29500."}, {"author": "ChristopherCapito", "created_at": "2025-02-14T02:51:53Z", "body_clean": "Do we know when this might be released? I am struggling with this right now as well."}, {"author": "hteeyeoh", "created_at": "2025-02-24T02:06:47Z", "body_clean": "Hi. I'm facing this issue when trying to use \"meta llama/Llama 3.1 8B Instruct\" model via 'HuggingFacePipeline.from model id' and im facing the issue 'tokenizer.pad token id = model.config.eos token id' and ValueError: Cannot set a non string value as the pad token after using from langchain community.llms import HuggingFacePipeline class, the valueerror is not observed but weird behaviour in my application when returning a streaming or non streaming response. When returning non streaming response, I can see the complete answer being generated. But during streaming response, the returning response is truncated at most token is ~20 although i set max new tokens param to 100. I tried to print the token via : for chunk in chain.stream(query): logger.info(f\"data: {chunk}\") yield f\"data: {chunk}\\n\\n\" the chunk data will stop stream when it reached ~(20token) .... Need some help here. the current version of my langchain packages: langchain 0.3.19 langchain community 0.3.17 langchain core 0.3.35 langchain huggingface 0.1.2"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `age_graph` method currently fails to correctly handle combined queries (like `UNION` or `EXCEPT`) in LangChain, resulting in an error message and stack trace.  The issue stems from the method's attempt to parse Cypher queries and incorrectly identify return fields based on the first key word, leading to incorrect query interpretation.  Currently, the bug isn’t addressed by recent LangChain updates.", "final_category": "bug", "comments": [{"author": "rawathemant246", "created_at": "2025-01-30T14:52:49Z", "body_clean": "@zhaohuizh Fix the issue now wrap query method can take UNION and EXCEPT arguments in the cypher query. Add the additional test cases to validate simple cases and complex cases"}, {"author": "dosubot[bot]", "created_at": "2025-05-01T16:00:58Z", "body_clean": "Hi, @zhaohuizh. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the [code] 's [code] method, which failed to handle combined Cypher queries using [code] and [code] . This issue led to an [code] . User rawathemant246 commented that the issue has been fixed. The [code] method now accepts [code] and [code] arguments. Additional test cases have been added to validate both simple and complex queries. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that prevents the integration of vLLM with Qwen2.5, specifically when attempting to output data in a stream. The code provided doesn't produce the expected output, and the user is seeking guidance on resolving this issue, potentially involving configuration changes or a bug in the LangChain library.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-28T23:06:52Z", "body_clean": "Why don't you start a [OpenAI Comptiable Server]( [link] and then use [code] for streaming."}, {"author": "zqyp", "created_at": "2025-02-25T01:55:25Z", "body_clean": "+1"}, {"author": "dosubot[bot]", "created_at": "2025-05-27T16:03:14Z", "body_clean": "Hi, @lxbworld. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported difficulties with implementing streaming output using the VLLM model Qwen2.5 in LangChain. A warning related to PyTorch's process group destruction was noted. @keenborder786 suggested using an OpenAI Compatible Server and [code] for streaming. This suggestion was positively acknowledged, indicating it likely resolved the issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Consistent assertion failures across tests indicate a fundamental bug in the assertion mechanism.", "The Rust rule conflict highlights a potential incompatibility between the compiler and LangChain’s code.", "Timestamping token usage is a critical requirement for accurate LangChain application state management.", "The pad_token issue demonstrates a bug within the HuggingfacePipeline integration.", "Addressing the pad_token bug will improve the overall reliability of LangChain applications."], "technical_insights": ["Rust compiler optimization is causing assertion failures – a known issue.", "The first_token_time recording requirement necessitates a timely timestamping mechanism.", "The llama-3.2-3B-Instruct model’s failure is linked to a bug in the HuggingfacePipeline.py.", "Updating the LangChain community package addresses the bug affecting the HuggingfacePipeline.py.", "The age_graph method’s incorrect handling of combined queries requires a refinement of its Cypher query parsing."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent assertion failures across tests indicate a fundamental bug in the assertion mechanism.\n2. The Rust rule conflict highlights a potential incompatibility between the compiler and LangChain’s code.\n3. Timestamping token usage is a critical requirement for accurate LangChain application state management.\n4. The `pad_token` issue demonstrates a bug within the HuggingfacePipeline integration.\n5. Addressing the `pad_token` bug will improve the overall reliability of LangChain applications.\n\nTECHNICAL INSIGHTS:\n1.  Rust compiler optimization is causing assertion failures – a known issue.\n2.  The `first_token_time` recording requirement necessitates a timely timestamping mechanism.\n3.  The `llama-3.2-3B-Instruct` model’s failure is linked to a bug in the HuggingfacePipeline.py.\n4.  Updating the LangChain community package addresses the bug affecting the HuggingfacePipeline.py.\n5.  The `age_graph` method’s incorrect handling of combined queries requires a refinement of its Cypher query parsing.\n", "batch_number": 131, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code exhibits a bug where the `abatch as completed` command fails to respect the `max_concurrency` configuration, causing all tasks to run concurrently despite the specified limit. This issue stems from a discrepancy between the LangChain integration and the expected behavior of the `abatch` command, potentially due to a bug in the LangChain implementation.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-26T16:00:57Z", "body_clean": "Hi, @keenanpepper. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a discrepancy in the LangChain library regarding the [code] function. The function does not respect the [code] setting, unlike the [code] function. Test code provided demonstrates that the number of concurrent tasks exceeds the specified limit. No further activity or comments have been made on the issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The `TavilySearchResults` issue is preventing the retrieval of images from webpages returned by the Tavily search results, despite explicitly setting `include_images=True`.  The user has already investigated potential solutions by checking documentation, search results, and the latest LangChain version, concluding that it’s a bug within the integration.  Currently, the code fails to produce the expected image data, and the issue is not resolved by updating the LangChain package.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-25T21:40:39Z", "body_clean": "@mrtushartiwari Here is how you can get the raw content from the tool call: [code]"}, {"author": "xuzexin-hz", "created_at": "2025-03-21T10:12:46Z", "body_clean": "Checked other resources [x] I added a very descriptive title to this issue.[x] I searched the LangChain documentation with the integrated search.[x] I used the GitHub search to find a similar question and didn't find it.[x] I am sure that this is a bug in LangChain rather than my code.[x] The bug is not resolved by updating to the latest stable version of LangChain (or the specific integration package). Example Code Not able to get the images for the webpages return by tavily results. Like [end of cold war]( [link] this page has images but i did not recieve it. This is inspite keeping include images=True in parameters. Environment : Google colab Following is the minimal reproducible code %pip install qU \"langchain community =0.2.11\" tavily python import getpass import os if not os.environ.get(\"TAVILY API KEY\"): os.environ[\"TAVILY API KEY\"] = getpass.getpass(\"Tavily API key:\\n\") from langchain community.tools import TavilySearchResults tool = TavilySearchResults( max results=5, search depth=\"advanced\", include answer=True, include raw content=True, include images=True, ) tool results = tool.invoke({\"query\": \"What happened at end of cold war?\"}) tool results Error Message and Stack Trace (if applicable) No response Description I am trying to use langchain integration with tavily seach using from langchain community.tools import TavilySearchResults Expected to return the images present in the webpage along with text. Instead I just get some text present in the webpage and no images are found. System Info The output [code] ![Image]( [link] The object returned by your code is a list. If you want to include images, you need to return ToolMessage, because ToolMessage contains images. Of course, the tool.run() method used by the friend above is also acceptable, but tool.invoke() is suitable for handling more complex scenarios."}, {"author": "dosubot[bot]", "created_at": "2025-06-20T16:02:01Z", "body_clean": "Hi, @mrtushartiwari. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The TavilySearchResults tool fails to retrieve images from webpages, even with [code] . User keenborder786 suggested using [code] for simple scenarios and [code] for complex ones. xuzexin hz confirmed the issue persists after updating LangChain and recommended using ToolMessage to include images. The issue remains unresolved, with only text being returned instead of images. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code reports an error when using the `return_direct` tool and `RunnableWithMessageHistory` due to a validation failure within the tool's message history verification process. This issue stems from a bug in LangChain that doesn't correctly handle the message history, leading to the reported error.  The code relies on the `langsmith` package, which is a potential source of the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-26T14:52:49Z", "body_clean": "You are not using [code] correctly. You need to pass an argument to [code] that serves as an identifier for a particular session. This argument should ensure that [code] returns an instance of [code] . During runtime, you must provide the actual value of the [code] to identify the specific session. For example, something like this should work: [code]"}, {"author": "Finndersen", "created_at": "2025-01-26T23:49:50Z", "body_clean": "I forgot to include the [code] in the [code] call in my example. But the [code] does not need to be implemented like that, that's just an example. It just needs to return a [code] . This isn't the issue the problem is with the final result not being a [code] , since that only happens when with a [code] tool"}, {"author": "dosubot[bot]", "created_at": "2025-04-27T16:00:59Z", "body_clean": "Hi, @Finndersen. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a callback error with the [code] tool and [code] . Keenborder786 explained the correct usage and provided a code example. You acknowledged the oversight but noted the issue persists with the final result type. Next Steps: Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a critical bug in the LangChain library causing the tool to fail to set the required `tool` parameter when building messages for Gemini. This issue impacts the core functionality of the tool and requires a fix to ensure proper message construction for Gemini integration.", "final_category": "bug", "comments": [{"author": "Finndersen", "created_at": "2025-01-24T22:06:57Z", "body_clean": "This can be resolved by setting the [code] attribute when creating the [code] [here]( [link]"}, {"author": "Finndersen", "created_at": "2025-01-24T22:20:14Z", "body_clean": "This issue may have actually been caused by this change [link] in [code]"}, {"author": "Finndersen", "created_at": "2025-01-29T10:08:31Z", "body_clean": "I made a fix for langchain ai/langchain google which should resolve this"}]}, {"ollama_summary": "The issue highlights a compatibility problem with the ChatOpenAI model (o1) due to an unsupported parameter called \"parallel_tool_calls.\"  The fix was implemented in the latest version of LangChain (0.3.2).  The issue is being addressed as a documentation item and is recommended to upgrade to the latest version to ensure compatibility.", "final_category": "other", "comments": [{"author": "baskaryan", "created_at": "2025-01-24T18:08:34Z", "body_clean": "Resolved in langchain openai 0.3.2"}]}], "business_insights": ["LangChain integration and abatch command discrepancies are a primary root cause.", "TavilySearchResults integration failure highlights a bug within the retrieval process.", "LangChain message history validation failure is a critical bug impacting core functionality.", "Gemini integration requires correct tool parameter handling; the fix is in the latest version.", "ChatOpenAI model compatibility with unsupported parameter \"parallel_tool_calls\" is addressed."], "technical_insights": ["LangChain version 0.3.2 fixes the tool parameter issue.", "TavilySearchResults integration failure necessitates a fix within the integration.", "LangChain message history validation is a bug requiring a fix.", "Gemini integration requires correct tool parameter handling.", "LangChain 0.3.2 includes a fix for the tool parameter issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain integration and `abatch` command discrepancies are a primary root cause.\n2. TavilySearchResults integration failure highlights a bug within the retrieval process.\n3. LangChain message history validation failure is a critical bug impacting core functionality.\n4. Gemini integration requires correct `tool` parameter handling; the fix is in the latest version.\n5. ChatOpenAI model compatibility with unsupported parameter \"parallel_tool_calls\" is addressed.\n\nTECHNICAL INSIGHTS:\n1. LangChain version 0.3.2 fixes the `tool` parameter issue.\n2. TavilySearchResults integration failure necessitates a fix within the integration.\n3. LangChain message history validation is a bug requiring a fix.\n4. Gemini integration requires correct `tool` parameter handling.\n5. LangChain 0.3.2 includes a fix for the `tool` parameter issue.\n", "batch_number": 132, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a LangChain tool failing to correctly invoke the `tool.invoke` method because runtime arguments are not being passed to the tool. The code attempts to provide all required arguments to the tool, leading to an error, and the code is being examined for potential issues with parsing and argument handling.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-25T16:01:09Z", "body_clean": "Hi, @shruthiR fauna. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Problem with passing runtime arguments to a tool subclassed from [code] . [code] method fails to recognize the provided runtime argument. Example code was shared to demonstrate the issue. No further comments or activity have been made on this issue. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a problem with the `langchain.ChatOllama` library's ability to correctly return Pydantic class data when using the `resume` context. The code attempts to use the `Resume` format, but the `ChatOllama` library isn't properly interpreting the context, leading to a `None` response instead of the expected data. The issue appears to be a bug in the `langchain` integration, and the suggested solution is to update to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "jonmach", "created_at": "2025-01-27T10:23:07Z", "body_clean": "Not a bug this can be closed, but providing a solution so others can find this: This is 'as documented': [link] My code above does work using the following: [code] Thanks to @t0d4 for identifying this."}, {"author": "emmalumi", "created_at": "2025-03-18T09:58:34Z", "body_clean": "I have had the same issue, any nested pydantic calls seem fail with Ollama and structured output. This seems to linked to this already closed issue [link] that is not resolved either at the moment, as the original example only works part of the time. Only way around is currently setting method='json schema' as you mentioned, but any nested pydantic classes fail with the default method (see this Ollama basic example for structured outputs). If this is not a bug, the documentation could mention that tool calling does not work well for nested structures, the direct Ollama API call is better for these? [code] langchain:0.3.19 langchain community:0.3.18 langchain core:0.3.45 langchain ollama:0.2.3 langchain openai:0.3.6 langchain text splitters:0.3.6"}, {"author": "jonmach", "created_at": "2025-03-18T10:41:49Z", "body_clean": "I've had excellent results from using list. Have you tried to provide more information with your attributes? E.g. pets: list[Pet] = Field([], description=\"List of pets.\") Also, what Ollama model are you using?"}, {"author": "emmalumi", "created_at": "2025-03-18T10:56:53Z", "body_clean": "In the example above, I use llama3.1, but I have experimented with different models. The description does improve simpler cases but for me, the above examples fails even with examples. The only way I can make it work, is reducing the attributes of pet into one other two, while (method=\"json schema\" works 100% of the time with all models I tried): This works (most of the time): [code] This fails (most of the time): [code]"}, {"author": "jonmach", "created_at": "2025-03-18T10:59:20Z", "body_clean": "You need to use include raw = True"}, {"author": "emmalumi", "created_at": "2025-03-18T11:13:59Z", "body_clean": "Yes by setting include raw = True, I avoid the error, as I get raw outputs that would have failed my pydantic class. However, it still does not give me the structured output in the format I wanted as the outputs would violate my pydantic class and thus cause the code to fail without the argument include raw = True. I have had very good results, with using method=\"json schema\", but have not been able to make the tool calling work consistently even for simple nested use cases."}, {"author": "jonmach", "created_at": "2025-03-18T11:19:22Z", "body_clean": "Could you provide the output you want? I get almost perfect results every time using this. There is one example when it hasn't worked and I had to accommodate it via a test in case it responded with a bad structure. You might also want to give your prompt some guidance on the JSON structure to output. e.g. [code]"}, {"author": "jonmach", "created_at": "2025-03-18T11:22:20Z", "body_clean": "Also, where is the prompt that's returning your results? All I see is data, but not a question that should fill in the Pydantic class. Are you expecting it to work out that you want it filled? Try asking specifically for a list of pets, and for each tell me their name, age, and color. The objective here is for you to be able to depend on a reliable structure that you can use downstream in a digital pipeline."}, {"author": "emmalumi", "created_at": "2025-03-18T14:38:38Z", "body_clean": "I want this to return the pydantic base model PetList that I defined, i.e.: [code] There is not system prompt in this example, as this is a very simple example demonstrating the issue. But you can add the option method=\"json schema\", to see that simple example should work. My actual use cases that are a bit more complex do have the system prompt and examples of the json format I want, but the same issue persists without adding the option method=\"json schema\". [code]"}, {"author": "jonmach", "created_at": "2025-03-18T15:03:20Z", "body_clean": "Works for me, unless you're asking for something different: [code] Here's my result: [code] Alternatively, you can take out the specific JSON format (ie. everything from \"You must...\". This is what I then got: [code] Basically the same, but you get what you're given, and Pydantic doesn't always seem to honour the variable names, depending on the LLM model you're using."}, {"author": "dosubot[bot]", "created_at": "2025-06-17T16:03:07Z", "body_clean": "Hi, @jonmach. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with the [code] method not working correctly for complex data models. The issue was resolved using [code] and [code] options. You clarified that the behavior was as documented and provided solutions for others. Emmalumi confirmed similar issues and suggested documentation improvements. Next Steps: Please let us know if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "jonmach", "created_at": "2025-06-17T16:05:58Z", "body_clean": "Unless you've made a change that breaks it, then it's resolved."}, {"author": "dosubot[bot]", "created_at": "2025-06-17T16:08:30Z", "body_clean": "Thank you for your response, @jonmach! We're glad to hear that the issue is resolved. We'll go ahead and close this issue now."}]}, {"ollama_summary": "The issue reports a `KeyError: pf main` error within the LangChain library, specifically when initializing the `StateGraph` class. This error occurs when attempting to add a schema to the state graph during the initialization of the script, likely due to a bug in LangChain’s handling of state schema management, particularly when combined with PromptFlow. The code involves manually creating a `StateGraph` and the `add schema` function, suggesting a potential issue with the integration between these components.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-25T16:01:09Z", "body_clean": "Hi, @NinoCucc. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a KeyError \" pf main \" when using LangGraph's StateGraph with Azure PromptFlow. The error causes an application crash during schema initialization. The issue persists with the latest versions of LangChain, LangGraph, and PromptFlow. It seems related to the handling of state schema in LangGraph. No comments or developments have been made on this issue yet. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a critical bug in LangChain that causes a `TypeError` when passing the `search type` parameter to the similarity search method. This error stems from a problem with the session's request handling, specifically with the `kwarg` being incorrectly interpreted as the `search type` argument.  The solution involves modifying the method to explicitly handle the `search type` parameter, resolving the issue by ensuring the correct keyword is passed to the search function.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-25T16:01:03Z", "body_clean": "Hi, @SergioG M. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary A bug was reported in the LangChain library's AzureSearch class. The [code] method throws a [code] when [code] is used as a keyword argument. You suggested adding [code] as a parameter in the method definition to resolve the error. There have been no further comments or activity on this issue. Next Steps Could you please confirm if this issue is still relevant to the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\n**The issue concerns the need to update and improve the documentation and integration guides for the `init_chat_model` project, specifically focusing on tutorials, how-to guides, and high-traffic integrations.**  The maintainer is requesting this update to ensure the documentation remains accurate and useful for users.  Currently, the documentation relies on a specific code snippet, and the team is working to ensure these resources are updated and compatible with the latest version of the model.", "final_category": "other", "comments": [{"author": "rawathemant246", "created_at": "2025-01-27T15:48:51Z", "body_clean": "@efriis i have a question about this for example import ChatModelTabs from \"@theme/ChatModelTabs\"; <ChatModelTabs openaiParams={ [code] } / it will be revisied as from langchain.chat models import init chat model model = init chat model(model= \"gpt 4o\", model provider=\"openai\", temperature=0) like this right?"}, {"author": "efriis", "created_at": "2025-01-27T19:18:09Z", "body_clean": "Not quite! The chat model tabs should be in the same place, but the implementation of the chat model tabs should instantiate the model using [code] instead"}, {"author": "hesreallyhim", "created_at": "2025-03-11T05:26:11Z", "body_clean": "I'm ramping up on the platform and am not opinionated about this issue, but... to me this is confusing (which is not to say it's not correct). When I read the changelog for v3 I saw the transition from: For example, say that your code is still using the old import from langchain.chat models import ChatOpenAI: After the first run, you’ll get: from langchain community.chat models import ChatOpenAI After the second run, you’ll get: from langchain openai import ChatOpenAI So now it looks like we're going another step to [code] ... but according to the docs, you still have to have the [code] package installed(?) ( [link] I would love to see/understand some more context about this, what is the overarching goal with [code] ?"}, {"author": "Sakshamliftin", "created_at": "2025-05-14T19:07:05Z", "body_clean": "Hey! I took a look at the current [code] implementation and it looks like the code already uses: python from langchain.chat models import init chat model model = init chat model(...)"}]}], "business_insights": ["LangChain’s tool invocation issue highlights robust argument handling requirements.", "The Resume context issue reveals a potential data interpretation error within the ChatOllama integration.", "The KeyError: pf main issue signals a bug in LangChain’s state schema management.", "The StateGraph initialization bug points to a potential integration issue with LangChain’s state management.", "The search type bug requires a modification to the similarity search function."], "technical_insights": ["LangChain’s tool invocation handling requires explicit argument passing.", "ChatOllama’s context interpretation needs refinement.", "LangChain’s state schema management needs review and update.", "The KeyError: pf main bug suggests a state schema problem.", "The stateGraph initialization bug may affect the integration."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s tool invocation issue highlights robust argument handling requirements.\n2. The `Resume` context issue reveals a potential data interpretation error within the `ChatOllama` integration.\n3. The `KeyError: pf main` issue signals a bug in LangChain’s state schema management.\n4. The `StateGraph` initialization bug points to a potential integration issue with LangChain’s state management.\n5. The `search type` bug requires a modification to the similarity search function.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s tool invocation handling requires explicit argument passing.\n2. `ChatOllama`’s context interpretation needs refinement.\n3. LangChain’s state schema management needs review and update.\n4. The `KeyError: pf main` bug suggests a state schema problem.\n5. The `stateGraph` initialization bug may affect the integration.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 133, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in LangChain that prevents the use of the `temperature` argument when interacting with the OpenAI o1 API for the full model (not mini or preview). The code attempts to pass the `temperature` keyword as a parameter to `BaseChatModel.agenerate`, but the `agenerate` function doesn't support it, resulting in an error. The solution requires updating LangChain to a compatible version and ensuring the correct model parameters are used.", "final_category": "bug", "comments": [{"author": "SidGurajala", "created_at": "2025-01-24T06:31:07Z", "body_clean": "For other users: seems like setting temperature to 1.0 fixes this issue. To be honest I'm unsure of why this works as o1 mini and o1 preview triggers an error where you're told that o1 mini and o1 preview only accept a default value of 1, while o1 full tells you the temperature variable is not accepted unless the value is 1.0."}, {"author": "ccurme", "created_at": "2025-01-24T16:31:11Z", "body_clean": "The latest versions of [code] ( = 0.3) set a null default temperature. There are some [breaking changes]( [link] associated with that release (hence the minor version bump), but if you can upgrade that may fix the problem. Your environment information says you are running 0.2.x. For these versions a default temperature of 0.7 is used, but we [attempt to parse]( [link] \"o1\" in the model name and if recognized, set temperature to 1. This may not work with AzureChatOpenAI, which uses a concept of deployment names to specify models."}, {"author": "dosubot[bot]", "created_at": "2025-04-25T16:01:08Z", "body_clean": "Hi, @SidGurajala. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug with the AzureChatOpenAI model's default temperature setting being incompatible with the OpenAI o1 API call. The issue persisted even after updating to the latest version and occurred during the [code] method call. Setting the temperature to 1.0 resolved the issue, though the reason was unclear. User ccurme suggested upgrading to [code] version 0.3 or higher, which sets a null default temperature and may resolve the problem. Next Steps Please confirm if this issue is still relevant with the latest version of the LangChain repository. If it is, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The ChatOllama astream events function is experiencing a bug where it switches from \"on chat model stream\" to \"on llm stream\" unexpectedly, causing the code to fail to retrieve new event types.  Initial investigation using LangChain documentation, GitHub search, and community forums revealed this issue, suggesting it’s a bug within the LangChain integration. The code snippet demonstrates the problem – the event type changes when the LLM is invoked again, potentially due to a field in the event type.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-24T16:01:05Z", "body_clean": "Hi, @weissenbacherpwc. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where event handling switches from \"on chat model stream\" to \"on llm stream\" in \"astream events\". Verified that the issue is not due to your own code. The problem persists even after updating to the latest stable version of LangChain. Example code was provided to demonstrate the issue. No additional comments or developments have been made. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain-openai 0.3.1 issue is a bug where the `max_tokens` setting is consistently overridden to 100 tokens, regardless of the user-defined limit. The proposed solution is to update to a previous version of LangChain to address this issue.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-23T15:11:48Z", "body_clean": "Between 0.2 and 0.3, ChatOpenAI was updated to send [code] to the server, because the [code] parameter has been [deprecated]( [link] If you are using another endpoint (i.e., not OpenAI) that does not support [code] , you should use [code] instead. [code] [code]"}]}, {"ollama_summary": "The issue reports a bug in LangChain's `ContainerProxy.delete_item()` function that requires a `partition_key` argument to delete documents correctly.  The problem is that the function doesn't accept this argument, and attempts to resolve it by updating LangChain versions haven't worked.  The code example demonstrates this failure with a specific deletion operation.", "final_category": "bug", "comments": [{"author": "lorisalx", "created_at": "2025-01-23T13:49:56Z", "body_clean": "to give more context, I don't even know how the delete function of this AzureCosmosDBNoSqlVectorSearch can work since there is no PartitionKey provided here : [link] and the delete item require a mandatory parameter partition key"}, {"author": "lorisalx", "created_at": "2025-01-24T07:13:35Z", "body_clean": "Issue fixed by providing a default partition key parameter: PR 29382"}]}, {"ollama_summary": "Okay, here's a summary of the code snippets provided, focusing on the key observations and potential issues:\n\n**Overall Observations:**\n\n* **Python Focus:** The code is overwhelmingly Python-based.\n* **Large Codebase:** The code represents a substantial project, likely a web application or a complex data processing pipeline.\n* **Multiple Libraries:** A wide range of Python libraries are used, suggesting a sophisticated system.\n* **Potential Issues:** There are several potential issues that need attention, including:\n    * **Missing Dependencies:** Some libraries are not installed or are outdated.\n    * **Code Style:** Some code snippets have inconsistent formatting and style.\n    * **Potential Bugs:** The code contains some potentially problematic logic (e.g., the `pycparser` code).\n    * **Security Concerns:** The use of `pywin32` and `pywinpty` raises a potential security concern if not handled carefully.\n\n**Detailed Breakdown by Snippet:**\n\n1. **`Summary:`** - This is a general overview of the project's purpose.\n\n2. **Snippet 1: `pydeck`** - This snippet suggests a mapping or visualization application using the `pydeck` library. It likely involves creating a map (likely a 2D representation) and displaying data on it.\n\n3. **Snippet 2: `pyzmq`** - This snippet suggests a networking library, possibly used for real-time communication or data streaming.\n\n4. **Snippet 3: `pywin32`** - This snippet indicates a Python script that interacts with Windows-specific features, possibly related to data processing or file management.\n\n5. **Snippet 4: `pywinpty`** - This snippet suggests a tool for managing keyboard and mouse input, potentially for UI automation or testing.\n\n6. **Snippet 5: `pycurl`** - This snippet suggests a web request library, possibly for making API calls or retrieving data from a web server.\n\n7. **Snippet 6: `pyyaml`** - This snippet indicates a YAML parsing library, likely used for configuration files or data serialization.\n\n8. **Snippet 7: `pythroid`** - This snippet suggests a tool for creating interactive dashboards.\n\n9. **Snippet 8: `pythdf`** - This snippet suggests a tool for data exploration, likely using the `pyth", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-23T00:53:30Z", "body_clean": "@gopinadhpadi0532 please issue 29222 where I have guide how to make a proper SQL Agent."}, {"author": "SarangShelke2304", "created_at": "2025-01-23T12:43:32Z", "body_clean": "has this been solved, can i work on it?"}, {"author": "sydney-runkle", "created_at": "2025-04-17T20:25:46Z", "body_clean": "Not able to repro this going to close as stale. Happy to reopen if it's still a concern!"}]}], "business_insights": ["Code stability is paramount; consistent API calls mitigate bugs.", "Dependency management is crucial for maintainability and security.", "Modular design enhances code reusability and testability.", "Python-centric nature suggests potential performance bottlenecks.", "Lack of comprehensive documentation hinders understanding and maintenance."], "technical_insights": ["LangChain's max_tokens setting is a frequent source of issues, requiring a potential upgrade.", "pycparser is a problematic dependency, impacting code quality.", "ContainerProxy.delete_item() function's bug necessitates a version update.", "pywin32 and pywinpty introduce potential security vulnerabilities.", "pydeck and pyzmq suggest complex data visualization/networking applications."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Code stability is paramount; consistent API calls mitigate bugs.\n2.  Dependency management is crucial for maintainability and security.\n3.  Modular design enhances code reusability and testability.\n4.  Python-centric nature suggests potential performance bottlenecks.\n5.  Lack of comprehensive documentation hinders understanding and maintenance.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's `max_tokens` setting is a frequent source of issues, requiring a potential upgrade.\n2.  `pycparser` is a problematic dependency, impacting code quality.\n3.  `ContainerProxy.delete_item()` function's bug necessitates a version update.\n4.  `pywin32` and `pywinpty` introduce potential security vulnerabilities.\n5.  `pydeck` and `pyzmq` suggest complex data visualization/networking applications.\n", "batch_number": 134, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "ChatPerplexity lacks the `bind_tools` functionality required for structured output, despite being a LangChain project.  A search revealed this is a known bug within LangChain, and attempts to update to the latest version haven't resolved it.  The issue currently results in a \"Not Implemented Error\" message with stack traces, indicating a critical missing feature for structured output support.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-23T00:58:30Z", "body_clean": "@jasonzbao working on it"}, {"author": "dosubot[bot]", "created_at": "2025-04-24T16:01:06Z", "body_clean": "Hi, @jasonzbao. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] model lacking the [code] method, causing a Not Implemented Error. Keenborder786 acknowledged the issue and is working on a fix. Positive feedback from users, including you, efriis, and hershanand, indicates community interest in resolving this. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "yulaikarimov", "created_at": "2025-05-19T17:05:34Z", "body_clean": "[@jasonzbao]( [link] working on it are you planning to make it for yandexgpt?"}]}, {"ollama_summary": "The user is encountering a bug where they need to analyze the token count of the Re Ranker model within the Contextual Compression Retriever setup, specifically the token usage during the re-ranking process. They are seeking guidance on how to track and understand this token consumption, potentially leveraging specific LangChain utilities or Voyage model APIs to achieve this.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-23T18:51:48Z", "body_clean": "Hi, @wo yashsinghvi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are using LangChain's ContextualCompressionRetriever with Milvus and Voyage AI models. You are seeking advice on tracking token usage during re ranking and query embedding processes. You are looking for simple methods or utilities within LangChain or Voyage model APIs for token count calculation. The setup is working well, but you need insights on token analysis for performance enhancement. There have been no comments or developments on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain project is experiencing a performance bottleneck due to excessive file imports, resulting in a 12-second import time for each LangChain module.  The issue stems from the code's reliance on multiple file IO operations, and the problem isn't directly related to code changes.  The team is investigating the root cause and exploring potential optimizations to reduce these import times.", "final_category": "bug", "comments": [{"author": "brycepg", "created_at": "2025-02-27T06:54:26Z", "body_clean": "Sorry this was caused by WSL using the Windows filesystem"}]}, {"ollama_summary": "The user is encountering a problem installing the `langchain-pinecone` library on Windows using Python 3.13.1.  They are specifically notified that the library requires Python 64-bit, but the system has an x86_64 version.  The issue stems from a failed package installation process, potentially indicating a bug within the LangChain integration or a dependency issue, and the user needs to investigate further to resolve the problem.", "final_category": "bug", "comments": [{"author": "AbhiramNS1", "created_at": "2025-01-22T11:12:26Z", "body_clean": "This package ( langchain pinecone) can be installed using python 3.10"}, {"author": "hrishi-008", "created_at": "2025-01-29T09:13:06Z", "body_clean": "[code] [code] [code] [code] [code] [code] worked for me win 11 x64"}, {"author": "AbhiramNS1", "created_at": "2025-02-05T05:37:55Z", "body_clean": "[code] [code] [code] [code] [code] [code] worked for me win 11 x64 Actually the issue was that langchain pinecone is not supporting latest python stable release Python 3.13.1 as of today . But thats for responding"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a persistent problem with LangChain's dependency conflicts arising from different versions of packages being installed simultaneously or intentionally.  The maintainers are seeking a way to simplify debugging these conflicts by providing a command-line tool (`[code]`) to upgrade the entire LangChain package set.  The team is open to hearing about any new conflicts they encounter and requests users to share their dependency resolver output for potential issues.", "final_category": "feature", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-22T16:01:07Z", "body_clean": "Hi, @efriis. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves challenges in debugging dependency conflicts in LangChain's Python packages. You suggested upgrading all LangChain packages to their latest versions to reduce conflicts. You encouraged users to report specific dependency resolver issues with detailed information for better debugging. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is a recurring challenge, requiring more robust conflict resolution.", "Consistent package versions are crucial for stability and maintainability.", "Command-line tools can simplify dependency resolution and debugging.", "Addressing dependency conflicts proactively is essential for long-term project success.", "Streamlining dependency management will improve user experience."], "technical_insights": ["LangChain’s dependency structure presents a significant risk of conflicts.", "The [code] tool offers a potential solution for simplified conflict resolution.", "Implementing a command-line upgrade process could improve dependency management.", "Consistent package versions are vital for stability and maintainability.", "Dependency conflicts can hinder project development and testing."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency management is a recurring challenge, requiring more robust conflict resolution.\n2. Consistent package versions are crucial for stability and maintainability.\n3. Command-line tools can simplify dependency resolution and debugging.\n4. Addressing dependency conflicts proactively is essential for long-term project success.\n5. Streamlining dependency management will improve user experience.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s dependency structure presents a significant risk of conflicts.\n2. The `[code]` tool offers a potential solution for simplified conflict resolution.\n3. Implementing a command-line upgrade process could improve dependency management.\n4. Consistent package versions are vital for stability and maintainability.\n5. Dependency conflicts can hinder project development and testing.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 135, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a bug in LangChain that causes the `TracedAsyncStream.getattr` function to fail when it's called with a `response format` payload. This results in a runtime warning and a potential issue with the `get final completion` functionality, impacting the core LangChain integration.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-21T17:03:33Z", "body_clean": "Thanks for reporting this. Can you please provide a minimal reproducible example we can run to generate the error?"}, {"author": "kientv", "created_at": "2025-01-22T02:29:46Z", "body_clean": "Thanks for reporting this. Can you please provide a minimal reproducible example we can run to generate the error? [code] Warning: [code]"}, {"author": "keenborder786", "created_at": "2025-01-27T23:13:55Z", "body_clean": "Can you upgrade langchain openai to [code] . I just tried and face no errrors"}, {"author": "kientv", "created_at": "2025-02-03T07:07:01Z", "body_clean": "Fixed on langchain openai 0.3.3"}, {"author": "kientv", "created_at": "2025-03-14T08:48:34Z", "body_clean": "Seem that it's still errror: [code] MY ENV is python3.11 on ubuntu: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-06-13T16:01:50Z", "body_clean": "Hi, @kientv. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A [code] occurs in [code] due to an unawaited coroutine. The issue persists despite updating to the latest stable version, but does not occur with Gemini. You provided a minimal reproducible example upon request from @ccurme. @keenborder786 suggested upgrading to version [code] , but you confirmed the issue still exists in version [code] . Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "kientv", "created_at": "2025-08-22T14:47:38Z", "body_clean": "@dosubot Still warning with latest langchain version [code] [code]"}]}, {"ollama_summary": "The issue reports that the BAAI/bge-m3 embeddings model isn’t being found when using Ollama. The user has already investigated potential causes by searching documentation and using GitHub search, suggesting a bug within LangChain itself.  The solution requires updating to the latest stable version of LangChain to resolve the issue.", "final_category": "bug", "comments": [{"author": "sardanabhav", "created_at": "2025-01-22T09:27:06Z", "body_clean": "Can you try using [code] ?"}, {"author": "Francesco9932", "created_at": "2025-01-22T10:56:04Z", "body_clean": "@sardanabhav thanks for the reply, but yes already tried. with EMBED MODEL ID = \"bge m3\" ollama raise that bge m3 is not a valid model repo."}, {"author": "sardanabhav", "created_at": "2025-01-22T11:06:12Z", "body_clean": "[@sardanabhav]( [link] thanks for the reply, but yes already tried. with EMBED MODEL ID = \"bge m3\" ollama raise that bge m3 is not a valid model repo. That's weird. It works for me. Can you share the package versions you are using for reproduction?"}, {"author": "Francesco9932", "created_at": "2025-01-22T11:28:27Z", "body_clean": "@sardanabhav venv: python 3.12.8 langchain==0.3.15 langchain experimental==0.3.4 langchain ollama==0.2.2 langchain huggingface==0.1.2 faiss cpu==1.9.0.post1"}, {"author": "sardanabhav", "created_at": "2025-01-22T12:09:46Z", "body_clean": "I am not able to reproduce the issue with the given dependency versions. It works with both [code] and [code] ."}, {"author": "Francesco9932", "created_at": "2025-01-22T13:33:37Z", "body_clean": "Is it possible that the error is based on the latest version of ollama? In the settings shown i'm using: [code] dockerized and served on :11434"}, {"author": "sardanabhav", "created_at": "2025-01-24T10:12:51Z", "body_clean": "Sorry, I wasn't able to test out your version of ollama. I will test it today and let you know."}, {"author": "dosubot[bot]", "created_at": "2025-04-25T16:01:06Z", "body_clean": "Hi, @Francesco9932. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug where the Ollama embeddings model \"BAAI/bge m3\" is not recognized. The issue persists even after updating to the latest stable version of LangChain. Sardanabhav suggested using [code] , but this did not resolve the issue. Sardanabhav is unable to reproduce the issue and plans to test with your version of Ollama. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a failed SSL certificate verification error when using Chatgroq, specifically when calling the LLM via the `app.invoke()` function. The developer has implemented a SQL agent and environment variables for the Goq API key, but the application is still encountering SSL errors.  The core request is to find a workaround or bypass this SSL error for seamless application execution.", "final_category": "bug", "comments": [{"author": "efriis", "created_at": "2025-01-24T00:17:10Z", "body_clean": "can't reproduce this unfortunately! If you want to file again or debug yourself, would recommend checking if you're using some kind of proxy, as well as if you get the same ssl error just using the groq sdk directly"}, {"author": "apoorvasj", "created_at": "2025-06-10T07:22:33Z", "body_clean": "@rajban94 I am facing the same issue. Were you able to find a workaround?"}]}, {"ollama_summary": "The issue reports a bug in LangChain where the vLLM integration fails to process batch processing requests, specifically returning inconsistent results. The developer has already tried updating LangChain and the issue is suspected to be a bug within the vLLM integration itself, not a coding error in the user’s code.  The bug manifests when running the LangChain code with vLLM’s log output.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-22T16:01:07Z", "body_clean": "Hi, @to sora. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a problem with the VLLMOpenAI API during batch processing. You are using the latest version of LangChain and have verified your code. Example code and configuration details were provided to diagnose the issue. No comments or developments have occurred since the issue was opened. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Nithanaroy", "created_at": "2025-04-26T15:30:53Z", "body_clean": "Even I face the same issue, the only way I could resolve this is by manually applying the chat template and pass that to [code] method. [code]"}, {"author": "Nithanaroy", "created_at": "2025-04-26T15:32:54Z", "body_clean": "However, when I use the [code] with another library like RAGAS, I couldn't figure out a way to apply the chat template, as RAGAS internally calls the llm and not me directly. So it would be nice to have native support from [code] class."}, {"author": "dosubot[bot]", "created_at": "2025-04-26T15:33:11Z", "body_clean": "@eyurtsev, the user Nithanaroy has indicated that they are still facing the issue with the VLLMOpenAI API during batch processing and provided a workaround involving the chat template. Could you please assist them with this issue?"}]}, {"ollama_summary": "This issue addresses a duplicate constraint for the NumPy library within the Pyproject.toml file, which is causing potential conflicts and instability in LangChain.  The problem is that a previous version of the constraint was left in place, leading to unexpected behavior.  The issue is likely a bug in LangChain and not a result of the user’s code, and the author is seeking a solution through a discussion thread.", "final_category": "bug", "comments": [{"author": "sydney-runkle", "created_at": "2025-04-07T19:21:52Z", "body_clean": "Looks like this is stale, going to close as resolved for now!"}]}], "business_insights": ["Dependency conflicts are a recurring issue, requiring careful version management.", "Bug fixes should prioritize stability over immediate fixes to prevent regression.", "Testing needs to cover a wider range of scenarios, including edge cases.", "Code reviews should include security and performance considerations.", "Maintain clear documentation of dependencies and potential conflicts."], "technical_insights": ["LangChain's vLLM integration is a significant point of concern.", "SSL certificate verification is a persistent bug in the LLM ecosystem.", "The SQL agent workaround is a reactive solution, not preventative.", "Duplicate constraint management is a potential root cause of instability.", "Dependency conflicts can impact the core functionality of LangChain."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency conflicts are a recurring issue, requiring careful version management.\n2.  Bug fixes should prioritize stability over immediate fixes to prevent regression.\n3.  Testing needs to cover a wider range of scenarios, including edge cases.\n4.  Code reviews should include security and performance considerations.\n5.  Maintain clear documentation of dependencies and potential conflicts.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's vLLM integration is a significant point of concern.\n2.  SSL certificate verification is a persistent bug in the LLM ecosystem.\n3.  The SQL agent workaround is a reactive solution, not preventative.\n4.  Duplicate constraint management is a potential root cause of instability.\n5.  Dependency conflicts can impact the core functionality of LangChain.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n", "batch_number": 136, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `deepseek-r1` issue is preventing the correct integration of the `json schema` with Ollama format, resulting in unexpected output.  The user has tried various troubleshooting steps, including searching documentation and updating LangChain, but the problem persists.  The issue appears to be a bug within the LangChain integration, specifically related to the model's initial processing flow when querying with the JSON schema.", "final_category": "bug", "comments": [{"author": "Hadi2525", "created_at": "2025-01-29T05:03:45Z", "body_clean": "I am having the same issue calling the DeepSeek model. [code] These are the issues raised in [code] : [link] [link]"}, {"author": "alyahmedaly", "created_at": "2025-01-29T08:50:29Z", "body_clean": "I'm using the js version of langchain with Ollama and I can now use format option to return json I will leave this open as looks like others have different experience for now"}, {"author": "dosubot[bot]", "created_at": "2025-04-30T16:01:02Z", "body_clean": "Hi, @alyahmedaly. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The deepseek r1:14b model outputs part of its \"thinking\" process instead of the expected answer when used with the Ollama format. You and @Hadi2525 have both experienced this issue, with @Hadi2525 providing a code snippet for demonstration. You mentioned using the JavaScript version of LangChain and found a workaround by using the format option to return JSON. The issue remains unresolved as others are still experiencing difficulties. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If it is, you can keep the discussion open by commenting on the issue. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem with vllm's batch processing capabilities when using the Langchain code.  The code generates results that are acceptable in vllm’s logs but fail to produce the expected output with the Langchain code. The developers are investigating a potential bug related to the OpenAI API compatibility and are seeking guidance on the correct API usage.", "final_category": "bug", "comments": [{"author": "to-sora", "created_at": "2025-01-21T02:47:14Z", "body_clean": "forget mark as bug"}, {"author": "dosubot[bot]", "created_at": "2025-04-22T16:01:11Z", "body_clean": "Hi, @to sora. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are experiencing difficulties with batch processing using the vllm model and its API. The issue arose while running a comparison test based on the vllm documentation. You shared your setup and code but did not specify the exact problem encountered. You mentioned forgetting to mark the issue as a bug. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a bug in the `litellm` library where the `VertexAI` component fails to support the `tool_choice=any` parameter, causing an `UnsupportedParamsError`. The code attempts to use this parameter, but it results in an error, and the issue is not resolved by updating the LangChain library.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-21T16:00:49Z", "body_clean": "Hi, @j0yk1ll. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug with the ChatLiteLLM model encountering an UnsupportedParamsError. The error is due to VertexAI not supporting the parameter [code] . Acceptable values for [code] are 'auto', 'required', or a JSON object. Updating to the latest version did not resolve the issue, indicating further investigation is needed. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain. If it is, you can keep the discussion open by commenting here. If no updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain project has a bug in the `timeWeightedVectorStoreRetriever` that prevents it from correctly handling Chroma vector stores due to a mismatch in metadata timestamps. This issue causes a `ValueError` when attempting to add documents with timestamps from yesterday, requiring a fix to ensure compatibility with Chroma’s time-based retrieval functionality.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-21T16:00:49Z", "body_clean": "Hi, @ksmooi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Bug in [code] with Chroma related to datetime metadata. Issue does not occur with Faiss, indicating a Chroma specific problem. Verified unresolved in the latest LangChain version. No further comments or developments on the issue. Next Steps: Please confirm if this issue is still relevant with the latest LangChain updates by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a bug in the `OllamaEmbeddings` library that removes options for setting maximum tokens for Ollama embeddings, hindering functionality. This is a critical issue because it prevents users from configuring the embedding parameters, requiring a fix to ensure the library works as expected.", "final_category": "bug", "comments": [{"author": "SyedBaqarAbbas", "created_at": "2025-01-20T18:00:42Z", "body_clean": "Issue was solved in 29296"}]}], "business_insights": ["Integration issues with DeepSeek and Ollama format are a recurring challenge, suggesting a need for improved LangChain integration testing and debugging.", "Embedding parameter mismatch in timeWeightedVectorStoreRetriever is a critical bug that needs immediate attention to maintain functionality.", "The litellm library’s VertexAI component’s compatibility with tool_choice=any is problematic, requiring a fix to ensure proper integration.", "Embedding token limit issues in OllamaEmbeddings are impacting users, necessitating a solution to avoid unexpected errors.", "The deepseek-r1 bug’s impact on the integration with Ollama format highlights the importance of thorough testing and regression analysis."], "technical_insights": ["LangChain’s integration testing is insufficient for complex models like DeepSeek and Ollama format, requiring enhanced automated testing.", "The timeWeightedVectorStoreRetriever bug needs a priority fix, as it directly affects core functionality.", "litellm’s VertexAI parameter handling is a significant bug affecting users, requiring a code update.", "Embedding token limit issues in OllamaEmbeddings are a recurring problem, demanding a solution to prevent errors.", "The deepseek-r1 bug impacts the integration, necessitating a fix for the model’s initial processing flow."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integration issues with DeepSeek and Ollama format are a recurring challenge, suggesting a need for improved LangChain integration testing and debugging.\n2. Embedding parameter mismatch in `timeWeightedVectorStoreRetriever` is a critical bug that needs immediate attention to maintain functionality.\n3. The `litellm` library’s `VertexAI` component’s compatibility with `tool_choice=any` is problematic, requiring a fix to ensure proper integration.\n4. Embedding token limit issues in `OllamaEmbeddings` are impacting users, necessitating a solution to avoid unexpected errors.\n5. The `deepseek-r1` bug’s impact on the integration with Ollama format highlights the importance of thorough testing and regression analysis.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s integration testing is insufficient for complex models like DeepSeek and Ollama format, requiring enhanced automated testing.\n2. The `timeWeightedVectorStoreRetriever` bug needs a priority fix, as it directly affects core functionality.\n3. `litellm`’s `VertexAI` parameter handling is a significant bug affecting users, requiring a code update.\n4. Embedding token limit issues in `OllamaEmbeddings` are a recurring problem, demanding a solution to prevent errors.\n5. The `deepseek-r1` bug impacts the integration, necessitating a fix for the model’s initial processing flow.\n", "batch_number": 137, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain that prevents the correct passing of parameters to the OpenAI assistant, specifically the \"run metadata\" parameter. The current approach of relying on a single \"run metadata\" parameter is problematic due to potential inconsistencies and breaking changes in the OpenAI library.  A proposed solution involves modifying the parameter to allow for separate object passing, aligning with best practices and mitigating potential issues with future OpenAI updates.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-19T16:00:45Z", "body_clean": "Hi, @pm390. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug with the [code] class not accepting the [code] parameter. The issue results in a [code] and persists even after updating to the latest version. The problem seems related to a recent pull request that limits parameters passed to OpenAI. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nDeepSeek V3 is failing to respect the `max_tokens` parameter in LangChain’s `ChatOpenAI()` integration, causing models to generate excessively long responses.  The issue stems from a bug within the LangChain library itself, not user-defined code, and hasn’t been addressed by recent updates.  Users are experiencing a significant output length exceeding the intended limit, hindering the application’s ability to control response length.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-18T21:16:57Z", "body_clean": "[code] is intended to support the OpenAI API. They have [deprecated max tokens]( [link] Try using [code] , which accommodates many APIs that are similar to OpenAI. It still supports max tokens. [code]"}]}, {"ollama_summary": "The DeepSeek V3 library fails to produce structured output when used with LangChain, specifically with the Pydantic model. This issue stems from a bug within the LangChain integration, preventing the use of structured data formats.  The problem is not directly related to the user's code but is a flaw in the LangChain library itself.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-18T21:15:17Z", "body_clean": "[code] is intended to support the OpenAI API. Try using [code] , which accommodates many APIs that are similar to OpenAI. It uses tool calling for structured output by default. [code]"}, {"author": "mohit-217", "created_at": "2025-01-22T20:17:14Z", "body_clean": "Deepseek provided the sample script. Go to link [link]"}, {"author": "ravi-sapientai", "created_at": "2025-02-26T09:57:47Z", "body_clean": "Thanks @mohit 217 For sharing this. What about if deepSeek or any other open source model hosted on self hosted environment ?"}]}, {"ollama_summary": "The issue involves a bug in MiniMaxChat where default values for `minimax_api_host` and `model` are not correctly implemented, leading to incorrect responses.  The bug is not addressed by updating LangChain, and the code itself exhibits a problem that causes it to raise an exception.  The proposed solution would be to implement a more robust error handling mechanism, such as providing informative error messages instead of failing silently.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-18T16:00:45Z", "body_clean": "Hi, @jsmerix. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the [code] class of the LangChain library. The default values for [code] and [code] in the [code] method are outdated. Example code provided triggers a traceback error when sending a chat message. No comments or activity have been made on this issue yet. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue addresses a deprecated `initialize_agent` function in the LangChain documentation, which is being replaced with the more modern `langgraph.prebuilt.create_react_agent`. The goal is to simplify the documentation by utilizing a dedicated agent for React development, providing a demonstration example.  It’s a low-priority issue for tracking and can be addressed incrementally.", "final_category": "other", "comments": [{"author": "aybdee", "created_at": "2025-01-18T20:50:42Z", "body_clean": "I want to try working on this"}, {"author": "Thejaswi05", "created_at": "2025-01-21T19:36:34Z", "body_clean": "@efriis do you expect the changes in the documentation for the tools and integrations using initialize agent' listed at the bottom of the page you shared? Such as: [AINetwork Toolkit]( [link] [AWS Lambda]( [link]"}, {"author": "turboslapper", "created_at": "2025-01-22T08:03:23Z", "body_clean": "Hi everyone, I’ve partially updated the documentation to replace deprecated references to [code] with [code] . Specifically: I addressed the instances for page 1 of 3 in the search: [code] . I plan to work on pages 2 and 3 shortly to complete the updates. Additionally, I noticed a recurring pattern in examples, such as: [code] This doesn't inherently print the output of the agent.run command, and I considered adding something like: [code] to improve clarity for users. However, as this is my first commit, I didn’t want to overstep the scope without further guidance. Let me know if you’d like me to include such improvements! Looking forward to completing the remaining pages soon."}, {"author": "AffanShaikhsurab", "created_at": "2025-02-22T02:30:23Z", "body_clean": "If no one is working on this issue , can I work on this ?"}, {"author": "Yeonseolee", "created_at": "2025-03-18T19:14:26Z", "body_clean": "I noticed that some parts of the documentation still reference [code] . Would it be alright if I take over and help with the remaining updates?"}, {"author": "rthummaluru", "created_at": "2025-04-18T15:13:33Z", "body_clean": "Hi! I’d like to update the EdenAI example in edenai tools.ipynb to remove initialize agent and use the recommended approach. Tagging this as part of 29277 and will send a PR shortly."}, {"author": "ccurme", "created_at": "2025-04-23T18:21:33Z", "body_clean": "Hi all, please make sure that the code you update in the docs runs without error. Thank you!"}, {"author": "colichar", "created_at": "2025-04-24T18:15:00Z", "body_clean": "Hi, I'd like to contribute to this issue as well. As I understand it, there are still quite a few tools that still use the deprecated [code] . Should I just pick one page out to edit the docs that is not modified with existing PRs?"}, {"author": "tskrrish", "created_at": "2025-04-30T20:11:59Z", "body_clean": "Hi! I'd like to work on this issue. Please let me know if it's still available."}, {"author": "Vahed-SK", "created_at": "2025-05-07T02:13:42Z", "body_clean": "Hi! I'd like to work on replacing [code] with [code] in the remaining documentation files. I will update the examples to reflect the new recommended usage. Let me know if that's good to proceed!"}, {"author": "HummdG", "created_at": "2025-05-15T16:35:34Z", "body_clean": "Hi @efriis @Thejaswi05 @ccurme @Yeonseolee ! Would love to work on this issue, no idea where to start from! Is there anyone who I can work with or shadow? Thank you!"}, {"author": "Abdelrahman-Nashaat", "created_at": "2025-05-24T19:50:27Z", "body_clean": "I've just submitted a commit for NASA ToolKit docs. This is my first experience on GitHub, and I’m still a beginner, so please let me know if there’s anything to adjust! @efriis"}, {"author": "tk1475", "created_at": "2025-05-26T13:53:29Z", "body_clean": "Hi @efriis and team! I've begun to replace some instances of initialize agent with [code] in the remaining documentation files. I've also already started working on some untouched pages from the langchain/docs directory and will ensure the examples run without errors. I’ll tag this issue in my upcoming PR(s) for tracking. ![Image]( [link] Please let me know if there’s anything specific I should focus on or avoid, as these are the files I will be editing! Thanks!"}, {"author": "Abdelrahman-Nashaat", "created_at": "2025-05-26T14:40:08Z", "body_clean": "Yes ,the first document (NASA) i already PR it and waiting them to reply. Thank you 😊 في الاثنين، ٢٦ مايو ٢٠٢٥، ٥:٢٧ م Ahmed Hassan @ . كتب: tk1475 left a comment (langchain ai/langchain 29277) < [link] Hi @efriis < [link] and team! I've begun to replace some instances of initialize agent with langgraph.prebuilt.create react agent in the remaining documentation files. I've also already started working on some untouched pages from the langchain/docs directory and will ensure the examples run without errors. I’ll tag this issue in my upcoming PR(s) for tracking. Screenshot.2025 05 26.185159.png (view on web) < [link] Please let me know if there’s anything specific I should focus on or avoid, as these are the files I will be editing! Thanks! — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you commented.Message ID: @ ."}, {"author": "dohrisalim", "created_at": "2025-05-26T15:13:59Z", "body_clean": "Hi team, I would love to work on this issue! @HummdG let me know if you want to work on some of the changes to the docs together."}]}], "business_insights": ["Parameter management consistency impacts OpenAI API reliability.", "Addressing the bug in LangChain will improve API compatibility.", "Documenting the new agent functionality enhances user experience.", "Prioritize the deprecated initialize_agent replacement.", "Maintain a clear and updated documentation for API integrations."], "technical_insights": ["LangChain’s reliance on a single parameter is a recurring issue.", "The bug affecting max_tokens impacts model output length.", "The initialize_agent deprecation highlights a library update.", "DeepSeek V3’s max_tokens issue necessitates a change in the library.", "The minimax_api_host and model bug points to a core library flaw."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Parameter management consistency impacts OpenAI API reliability.\n2.  Addressing the bug in LangChain will improve API compatibility.\n3.  Documenting the new agent functionality enhances user experience.\n4.  Prioritize the deprecated `initialize_agent` replacement.\n5.  Maintain a clear and updated documentation for API integrations.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s reliance on a single parameter is a recurring issue.\n2.  The bug affecting `max_tokens` impacts model output length.\n3.  The `initialize_agent` deprecation highlights a library update.\n4.  DeepSeek V3’s `max_tokens` issue necessitates a change in the library.\n5.  The `minimax_api_host` and `model` bug points to a core library flaw.\n", "batch_number": 138, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue currently prevents the `Async Client` from functioning correctly, specifically when the API Key is already present in the code. This appears to be a bug within the LangChain integration, causing the code to fail when attempting to use the API Key.  The solution requires a fix within the LangChain library itself, as updating to a newer version doesn’t resolve the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-17T20:42:51Z", "body_clean": "@GhimBoon I ran the exact same code you provided and it works, please make sure you are loading the correct environment variables."}, {"author": "GhimBoon", "created_at": "2025-01-18T01:25:19Z", "body_clean": "Closing issue to troubleshoot further. Thank you for the confirmation."}]}, {"ollama_summary": "This issue reports a bug in the `ChatPerplexity` library where the `str` object is causing an AttributeError when attempting to access the `choices` attribute. This results in an error message indicating that the object lacks the expected attribute, and the code throws an error when trying to use the library.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-17T20:54:51Z", "body_clean": "@n sviridenko Can you use the following class: [code] Because according to official Preplexity documentation: [link] The response should be a json. Therefore I wanna see the output of the response that you are getting, before I can help you."}, {"author": "guimorg", "created_at": "2025-02-03T21:08:27Z", "body_clean": "I think this may be related to Rate Limiting issues, @n sviridenko. Try taking a look at your Tier and use the [code] if that is the case. It partially worked for me (also I've tried retrying the request when this happened)."}, {"author": "guimorg", "created_at": "2025-02-11T18:16:50Z", "body_clean": "I've contacted the Perplexity team and it may be an issue with the prompt being too large, they've recommended streaming responses in this case (although this empty response shouldn't actually happen either way)."}, {"author": "nikita-wayhq", "created_at": "2025-02-24T12:58:05Z", "body_clean": "Thanks! Rate limiting + streaming helped so far. Will keep an eye on it."}, {"author": "dosubot[bot]", "created_at": "2025-05-26T16:00:53Z", "body_clean": "Hi, @n sviridenko. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered an [code] with the [code] model related to response handling. [code] suggested using a custom class to print the response for debugging. [code] pointed out potential issues with rate limiting or large prompts and recommended using [code] and streaming responses. [code] confirmed that these suggestions helped mitigate the issue. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem with the `pdf2image` module not being available in the LangChain library, causing the code to fail.  The developer has exhausted common troubleshooting steps (documentation search, GitHub search, and updating LangChain) without resolution.  The core issue appears to be a bug within the LangChain integration package itself, requiring a fix.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-16T16:05:13Z", "body_clean": "You likely need to install [code] . I'd suggest using the [langchain unstructured]( [link] package, as dependencies are managed there (vs. the community integration, which requires separate pip installs)."}, {"author": "Magnuti", "created_at": "2025-02-11T09:50:38Z", "body_clean": "[code] solved the issue, thanks @ccurme!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a typo in a Jupyter Notebook (`tool_results_pass_to_model.ipynb`) that incorrectly formats the documentation text. The documentation requires the code to be formatted as the specified code, but the current version contains a typo.  The issue requests a fix to ensure the documentation accurately reflects the function’s usage and provides a clear guide on how to utilize the tool.", "final_category": "other", "comments": []}, {"ollama_summary": "The LangChain library is experiencing a bug where it fails to properly separate file content. The issue stems from a discrepancy between the expected output format and the actual generated content, leading to a missing document separation. This problem is not related to the current LangChain version but is likely a bug in the underlying implementation.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-17T16:00:48Z", "body_clean": "Hi, @Junon Gz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a problem with the [code] function. The function fails to segment file content into multiple documents, returning it as a single document. The issue persists even after updating to the latest version of LangChain. No further activity or comments have been made on the issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Correct formatting improves user experience and reduces errors.", "Addressing the typo streamlines the documentation and enhances usability.", "Understanding the root cause is crucial for future bug prevention.", "Focusing on documentation quality enhances the overall library.", "Maintaining consistent formatting ensures a predictable workflow."], "technical_insights": ["LangChain integration bug impacting API Key handling.", "ChatPerplexity library AttributeError related to str object.", "pdf2image module dependency issue in LangChain.", "LangChain integration package bug causing errors.", "Potential bug within the LangChain library's core code."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correct formatting improves user experience and reduces errors.\n2. Addressing the typo streamlines the documentation and enhances usability.\n3. Understanding the root cause is crucial for future bug prevention.\n4. Focusing on documentation quality enhances the overall library.\n5. Maintaining consistent formatting ensures a predictable workflow.\n\nTECHNICAL INSIGHTS:\n1. LangChain integration bug impacting API Key handling.\n2. `ChatPerplexity` library AttributeError related to `str` object.\n3. `pdf2image` module dependency issue in LangChain.\n4. LangChain integration package bug causing errors.\n5. Potential bug within the LangChain library's core code.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 139, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is a bug in LangChain that causes a dependency incompatibility with Pydantic, specifically when using the `OpenAIEmbeddings` library. The code attempts to use a Pydantic v2 version, which is not supported by the current version of LangChain. The fix involves updating the LangChain installation to the latest stable version and ensuring the correct import statement is used for Pydantic.", "final_category": "bug", "comments": [{"author": "SyedBaqarAbbas", "created_at": "2025-01-15T18:34:43Z", "body_clean": "Hello @ZaneDash, I ran the following code and it worked without any issues: [code] I am unable to replicate the issue. I just checked and the involved libraries (langchain, pydantic, langchain openai, etc) all have the same version as yours. Could you share an elaborate way to reproduce the error since your stack trace contains initialization to other modules ( [code] )? My set up details from [code] are as below: System Information OS: Linux OS Version: 52~22.04.1 Ubuntu SMP PREEMPT DYNAMIC Mon Dec 9 15:00:52 UTC 2 Python Version: 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0] Package Information langchain core: 0.3.29 langchain: 0.3.14 langsmith: 0.1.147 langchain openai: 0.3.0 langchain text splitters: 0.3.5 Optional packages not installed langserve Other Dependencies aio [link] 3.11.11 async timeout: Installed. No version info available. [link] 0.28.1 jsonpatch: 1.33 langsmith pyo3: Installed. No version info available. numpy: 2.2.1 openai: 1.59.7 orjson: 3.10.14 packaging: 24.2 pydantic: 2.10.5 PyYAML: 6.0.2 requests: 2.32.3 requests toolbelt: 1.0.0 SQLAlchemy: 2.0.37 tenacity: 8.5.0 tiktoken: 0.8.0 typing extensions: 4.12.2"}, {"author": "ZaneDash", "created_at": "2025-01-15T19:59:48Z", "body_clean": "Had incorrect Python alias, closing"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe code exhibits a bug where a child object’s key is automatically covered by its parent object, despite the child’s key being unique. This is a potentially problematic design choice and is not logically consistent.  The issue highlights a need for a fix to prevent unexpected behavior and ensure key uniqueness across objects.", "final_category": "bug", "comments": [{"author": "guochaoqun1998", "created_at": "2025-01-15T15:56:12Z", "body_clean": "[link]"}, {"author": "dosubot[bot]", "created_at": "2025-04-16T16:00:54Z", "body_clean": "Hi, @guochaoqun1998. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You raised a concern about a design choice in LangChain regarding key value overrides in child classes. The behavior seems unreasonable to you, and you're unsure if it's intentional or a bug. You provided a link to the relevant code section for further context. The issue remains unresolved with no further updates or clarifications. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain library is experiencing a critical issue when connecting to Snowflake databases, specifically due to a type mismatch between the `langchain community` and `langsmith` versions. This problem is causing the `sqlachemy` wrapper to fail, resulting in the provided error message and stack trace.  The issue appears to be a conflict between the specific version of the `langchain` package and the `langsmith` library, requiring a potential update to the LangChain package itself.", "final_category": "bug", "comments": [{"author": "SyedBaqarAbbas", "created_at": "2025-01-15T16:52:43Z", "body_clean": "Fixed in 29229"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes the `agent executor` to fail when using the `AgentExecutor` with assistants that utilize tools. The bug specifically impacts the `call` method within the `invoke` function, leading to an AttributeError.  The solution requires updating to the latest stable version of LangChain or a specific integration package to resolve the issue.", "final_category": "bug", "comments": [{"author": "dn-scribe", "created_at": "2025-01-17T08:00:37Z", "body_clean": "I further researched the issue, the following does work: [code] When using the [code] parameter the [code] is not returned. You man reconsider if this is a bug. As a minimum, I'd recommend adding this use case to the documentation."}, {"author": "dosubot[bot]", "created_at": "2025-04-18T16:00:46Z", "body_clean": "Hi, @dn scribe. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an [code] related to the 'RequiredActionFunctionToolCall' object missing a 'tool' attribute. The issue persisted even after updating to the latest version of LangChain. You discovered that using the [code] parameter resolves the issue. You suggested that the problem might be a documentation gap rather than a bug. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "dn-scribe", "created_at": "2025-04-19T20:50:13Z", "body_clean": "AFAIK yes On Fri, Apr 18, 2025 at 7:01 PM dosubot[bot] @ . wrote: Hi, @dn scribe < [link] I'm Dosu < [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an AttributeError related to the 'RequiredActionFunctionToolCall' object missing a 'tool' attribute. The issue persisted even after updating to the latest version of LangChain. You discovered that using the as agent=True parameter resolves the issue. You suggested that the problem might be a documentation gap rather than a bug. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution! — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you were mentioned.Message ID: @ . dosubot[bot] left a comment (langchain ai/langchain 29224) < [link] Hi, @dn scribe < [link] I'm Dosu < [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an AttributeError related to the 'RequiredActionFunctionToolCall' object missing a 'tool' attribute. The issue persisted even after updating to the latest version of LangChain. You discovered that using the as agent=True parameter resolves the issue. You suggested that the problem might be a documentation gap rather than a bug. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution! — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you were mentioned.Message ID: @ ."}, {"author": "dosubot[bot]", "created_at": "2025-04-19T20:52:25Z", "body_clean": "Thank you for your response, @dn scribe! Since you've confirmed the issue is still relevant, we'll be closing this issue now. We appreciate your contribution and feedback!"}]}, {"ollama_summary": "The issue involves a bug in LangChain that prevents the `SQLDatabaseToolkit` from being fully defined, leading to a `pydanticUserError`. This is impacting the `autogen` process, specifically for the `azure postgresql` and `crm` integration chains, and requires a recent version of LangChain (or a specific integration package) to be updated.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-17T21:44:22Z", "body_clean": "You are using very old and experimental way of interacting with the database. You can do something as follow to construct a SQL Agent which talks with your data: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-04-18T16:00:50Z", "body_clean": "Hi, @arno756. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You experienced a [code] with the [code] in LangChain. The error suggested defining [code] and calling [code] . Despite updating to the latest version, the issue persisted, leading you to suspect a bug. Keenborder786 suggested using a SQL Agent for database interaction, which you acknowledged positively. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is a recurring challenge, requiring careful version control and updates across multiple libraries.", "Consistent package versions are critical for stability and compatibility; outdated packages can introduce bugs and regressions.", "Maintaining backward compatibility is vital when evolving libraries; updates should minimize disruption.", "Testing and validation are essential for identifying dependency issues early in the development lifecycle.", "Automated dependency validation tools are beneficial for ensuring consistent and reliable project builds."], "technical_insights": ["LangChain’s dependency architecture is complex; managing version conflicts is a significant concern.", "The langsmith and langchain package versions are often incompatible; a potential upgrade is needed.", "Snowflake integration requires specific version compatibility; a patch or update might be required.", "The sqlachemy wrapper’s failure points to a fundamental incompatibility between the LangChain and Langsmith packages.", "The agent executor bug impacts the call function, requiring a specific LangChain version or integration package."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency management is a recurring challenge, requiring careful version control and updates across multiple libraries.\n2. Consistent package versions are critical for stability and compatibility; outdated packages can introduce bugs and regressions.\n3. Maintaining backward compatibility is vital when evolving libraries; updates should minimize disruption.\n4. Testing and validation are essential for identifying dependency issues early in the development lifecycle.\n5. Automated dependency validation tools are beneficial for ensuring consistent and reliable project builds.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s dependency architecture is complex; managing version conflicts is a significant concern.\n2. The `langsmith` and `langchain` package versions are often incompatible; a potential upgrade is needed.\n3. Snowflake integration requires specific version compatibility; a patch or update might be required.\n4. The `sqlachemy` wrapper’s failure points to a fundamental incompatibility between the LangChain and Langsmith packages.\n5. The `agent executor` bug impacts the `call` function, requiring a specific LangChain version or integration package.\n", "batch_number": 140, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports an `AttributeError` when importing the `langchain_core.prompts` library, specifically when attempting to access the `prompt` attribute. This likely stems from an incompatibility between the LangChain version and the specific prompt library being used. The code attempts to access the `prompt` attribute of the `LangChainCorePrompts` object, which is causing the error.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-14T23:52:07Z", "body_clean": "Please update your langchain core package. I would recommend to create a new environment and install all the langchain packages in that."}, {"author": "dosubot[bot]", "created_at": "2025-04-15T16:01:02Z", "body_clean": "Hi, @dakshsinghal2003. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered an [code] related to the [code] module lacking an [code] attribute when importing from [code] . The issue persists even after updating to the latest version of LangChain. Keenborder786 suggested creating a new environment and reinstalling all LangChain packages as a potential fix. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If it is, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a bug in LangChain where the code is incorrectly matching edges in a Cypher query. After searching the documentation and using GitHub search, the problem persists despite updating to the latest stable version. The code attempts to collect distinct labels from edges, but the `MATCH` statement definition is flawed, resulting in the error message.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-15T16:00:55Z", "body_clean": "Hi, @Eugene M. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary A bug in the LangChain library causes a MATCH statement to hang when retrieving a distinct list of edge labels. You suggested that including a right arrow in the MATCH statement might resolve the issue. The problem persists even after updating to the latest version and occurs within a Docker container. No further comments or developments have been made on this issue. Next Steps Could you please confirm if this issue is still relevant to the latest version of the LangChain repository? If so, feel free to keep the discussion open by commenting here. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Eugene-M", "created_at": "2025-04-15T16:41:05Z", "body_clean": "Hi, [@Eugene M]( [link] I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary A bug in the LangChain library causes a MATCH statement to hang when retrieving a distinct list of edge labels. You suggested that including a right arrow in the MATCH statement might resolve the issue. The problem persists even after updating to the latest version and occurs within a Docker container. No further comments or developments have been made on this issue. Next Steps Could you please confirm if this issue is still relevant to the latest version of the LangChain repository? If so, feel free to keep the discussion open by commenting here. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution! Yes, it's still relevant."}, {"author": "dosubot[bot]", "created_at": "2025-04-15T16:43:19Z", "body_clean": "@eyurtsev, the user @Eugene M has confirmed that the issue regarding the MATCH statement hanging is still relevant, even after updating to the latest version and occurring within a Docker container. Could you please assist them with this issue?"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue involves a \"429 error\" when running a specific task (ID: 0852441c bcd1 ee97 f431 c3b9d0a980f2) that returns an error message indicating exceeding a quota.  The problem seems to be with the documentation, specifically the `openai.RateLimitError` response, which suggests a potential issue with the data or model being used.  The developer is requesting a fix to address this error.", "final_category": "other", "comments": [{"author": "simpliatanu", "created_at": "2025-01-14T09:40:47Z", "body_clean": "can be closed, found the problem in the sample code given in docs corrected code below, first time documents will be [], no check was there, which results in weird error def search recall memories(query: str, config: RunnableConfig) List[str]: \"\"\"Search for relevant memories.\"\"\" Extract the user ID from the config user id = get user id(config) print (f\"User ID: {user id}\") Perform a similarity search with a predefined filter documents = recall vector store.similarity search( query, k=3, filter=lambda doc: doc.metadata.get(\"user id\") == user id, ) Check if any documents were found if not documents: return [] else: Extract and return the content of the documents return [doc.page content for doc in documents]"}, {"author": "dosubot[bot]", "created_at": "2025-04-15T16:00:59Z", "body_clean": "Hi, @simpliatanu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a 429 error when using the long term memory agent example. The error was due to the sample code missing a check for empty document results. You provided a corrected version of the code, resolving the issue. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain. If so, feel free to comment to keep the discussion open. If no further activity occurs, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "simpliatanu", "created_at": "2025-04-15T17:27:57Z", "body_clean": "yes close"}, {"author": "dosubot[bot]", "created_at": "2025-04-15T17:28:04Z", "body_clean": "Thank you for closing the issue, simpliatanu! We appreciate your help in keeping the repository tidy."}]}, {"ollama_summary": "The issue stems from a bug in LangChain that causes the model to output all fields of the pydantic object, specifically the action key. This results in unexpected token usage and prevents the model from producing multiple actions in a single element. The code provides an example demonstrating this behavior and suggests investigating the integration package for potential fixes.", "final_category": "bug", "comments": [{"author": "MagMueller", "created_at": "2025-01-14T04:34:20Z", "body_clean": "So in a nutshell I think the problem is that Langchain or openAI forces every key to be set, even the key is optionally. So maybe you fill it up somewhere with None"}, {"author": "ccurme", "created_at": "2025-01-14T14:32:55Z", "body_clean": "Hi @MagMueller, thanks for submitting this. This is likely stemming from an update in [code] , which changed the default method for [code] . You should be able to restore [code] behavior by explicitly passing in [code] into [code] . Version 0.3 passes Pydantic models straight to OpenAI's [structured output]( [link] feature, which currently [emulates optional parameters]( [link] via union types with [code] . Release notes for 0.3 are [here]( [link] please shout if this does not solve your issue."}, {"author": "dosubot[bot]", "created_at": "2025-04-15T16:01:00Z", "body_clean": "Hi, @MagMueller. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with the ChatOpenAI model returning all fields of a Pydantic object filled with [code] . User ccurme suggested this is due to changes in [code] , which treats all fields as required. A resolution was proposed: use [code] in [code] to revert to previous behavior. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The HTMLSemanticPreservingSplitter function fails to pull headers when using semantic HTML5 tags like `<main>`, `<article>`, etc., resulting in missing metadata.  The issue was identified through a combination of searching LangChain documentation, GitHub search, and a similar question, and it appears to be a bug within the LangChain library itself, not a user-defined code issue.  The solution is to update to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-15T00:17:58Z", "body_clean": "@srkirkland fixed"}, {"author": "dosubot[bot]", "created_at": "2025-04-16T16:00:55Z", "body_clean": "Hi, @srkirkland. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The [code] was not correctly handling headers with semantic HTML5 tags like [code] , [code] , and [code] . This resulted in improper content chunking despite specifying headers to split on. @keenborder786 confirmed that the issue has been fixed. You reacted positively to the update, indicating the resolution was satisfactory. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, feel free to keep the discussion open by commenting here. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Correcting the AttributeError in the langchain_core.prompts library is crucial for ensuring consistent model behavior across different environments.", "Updating the langchain_core.prompts package will resolve the issue and prevent future errors.", "Comprehensive testing of the updated package is necessary to confirm the fix.", "Prioritize this fix to maintain the stability and reliability of LangChain.", "Investigate the root cause of the incompatibility between the LangChain version and the prompt library to prevent recurrence."], "technical_insights": ["LangChain core package incompatibility is the primary cause of the AttributeError.", "The prompt attribute is being accessed incorrectly within the LangChainCorePrompts object.", "The MATCH statement definition in the Cypher query is flawed, causing the error.", "The langchain_core.prompts package requires updating to a newer version to resolve the issue.", "A new environment and installation of the LangChain packages will resolve the issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correcting the `AttributeError` in the `langchain_core.prompts` library is crucial for ensuring consistent model behavior across different environments.\n2. Updating the `langchain_core.prompts` package will resolve the issue and prevent future errors.\n3. Comprehensive testing of the updated package is necessary to confirm the fix.\n4. Prioritize this fix to maintain the stability and reliability of LangChain.\n5. Investigate the root cause of the incompatibility between the LangChain version and the prompt library to prevent recurrence.\n\nTECHNICAL INSIGHTS:\n1. LangChain core package incompatibility is the primary cause of the `AttributeError`.\n2. The `prompt` attribute is being accessed incorrectly within the LangChainCorePrompts object.\n3. The `MATCH` statement definition in the Cypher query is flawed, causing the error.\n4. The `langchain_core.prompts` package requires updating to a newer version to resolve the issue.\n5. A new environment and installation of the LangChain packages will resolve the issue.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 141, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a bug where LangChain fails to serialize structured output when using OpenAI models, specifically with Anthropic and other models.  The problem manifests as a TypeError during model dump serialization, resulting in a JSON parsing error.  The issue appears to be isolated to the OpenAI model and is not related to code changes.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-13T17:37:38Z", "body_clean": "On Friday [code] was released, which changed the default method for [code] . In case that is causing your issue, you can call [code] to restore the previous behavior. See [release notes]( [link] for details. If that is not related to your problem, can you provide a minimal reproducible example and share what versions of langchain packages + pydantic you are using? Here is my attempt, I am unable to reproduce the issue: [code]"}, {"author": "simpliatanu", "created_at": "2025-01-14T04:22:08Z", "body_clean": "Thanks you so much. You were right it is a breaking fix done in 0.3.0 which is causing this issue. The problem occurs which you use pydantic class to definite your output. Works once I pass function calling as method for gpt 4o With gpt4o mini, looks like I need to change my prompt, the model behaves differently Sent from Canary ( [link] On Monday, Jan 13, 2025 at 11:08 PM, ccurme @ . @ . ) wrote: On Friday langchain openai==0.3.0 was released, which changed the default method for with structured output. In case that is causing your issue, you can call llm.with structured output(RouteQuery, method=\"function calling\") to restore the previous behavior. See release notes ( [link] for details. If that is not related to your problem, can you provide a minimal reproducible example and share what versions of langchain packages + pydantic you are using? Here is my attempt, I am unable to reproduce the issue: from typing import Literal from langchain openai import ChatOpenAI from pydantic import BaseModel, Field class RouteQuery(BaseModel): \"\"\"Route a user query to the most relevant datasource.\"\"\" route: Literal[\"search\", \"ordinary\"] = Field( ..., description=\"Given a user question choose to route it to a tool or a ordinary question.\", ) llm = ChatOpenAI(model=\"gpt 4o mini\") structured llm router = llm.with structured output(RouteQuery) structured llm router.invoke(\"how are you?\") — Reply to this email directly, view it on GitHub ( [link] or unsubscribe ( [link] You are receiving this because you authored the thread.Message ID: @ ."}, {"author": "RicardoOM-AC", "created_at": "2025-02-19T00:16:10Z", "body_clean": "Using: langchain==0.3.19 langchain core==0.3.36 langchain openai==0.3.6 langchain text splitters==0.3.6 langfuse==2.59.3 langsmith==0.3.8 This LLM: [code] With this model [code] And this code: [code] Is not generating the standarAnswer object as expected. [code] I think is related. If anyone need more info let me know. If its just thrash, ask me to delete this post so it doesn't make noise."}, {"author": "Guemri-Jawher", "created_at": "2025-02-20T15:13:53Z", "body_clean": "Using: langchain==0.3.19 langchain core==0.3.36 langchain openai==0.3.6 langchain text splitters==0.3.6 langfuse==2.59.3 langsmith==0.3.8 This LLM: [code] With this model [code] And this code: [code] Is not generating the standarAnswer object as expected. [code] I think is related. If anyone need more info let me know. If its just thrash, ask me to delete this post so it doesn't make noise. I have the same error here for llm.with structured output and the baseModel from pydantic V2 To work around the issue, you can use ''from langchain.pydantic v1 import BaseModel, Field''. but this not fixing permanently the problem."}, {"author": "simpliatanu", "created_at": "2025-02-20T15:18:28Z", "body_clean": "It works if you use function calling rather , or use instructor. On Thu, Feb 20, 2025, 8:44 PM Jawher GUEMRI @ . wrote: Using: langchain==0.3.19 langchain core==0.3.36 langchain openai==0.3.6 langchain text splitters==0.3.6 langfuse==2.59.3 langsmith==0.3.8 This LLM: llm: AzureChatOpenAI = AzureChatOpenAI( azure endpoint=os.environ.get(\"AZURE OPENAI ENDPOINT\", \"\"), azure deployment=os.environ.get(\"AZURE OPENAI CHAT DEPLOYMENT NAME\", \"\"), openai api version=os.environ.get(\"AZURE OPENAI API VERSION\", \"\"), max tokens=16256, rate limiter=rate limiter, temperature=0.7, max retries=2, n=1 ) With this model from typing import Dict, Any, List from pydantic import BaseModel, Field class CharacterSchema(BaseModel): \"\"\" Pydantic Schema for API responses. \"\"\" name: str = Field(..., description=\"Unique name assigned to the character\") description: str = Field(..., description=\"Detailed narrative providing context to the character\") physical traits: Dict[str, Any] = Field(..., description=\"Various physical characteristics stored as a dictionary\") clothing: Dict[str, Any] = Field(..., description=\"Details about the clothing and accessories worn by the character\") class Config: from attributes = True For compatibility with SQLAlchemy models (Pydantic v2) class standardAnswer(BaseModel): question:str = Field(...,description=\"Question to ask to the user to find out the character hes thinking\") characters:List[CharacterSchema] = Field(...,description=\"List of characters to display to the user\") And this code: def update character list(answer: str, db: Session, game status) List[Dict[str, str]]: \"\"\" Update the character list based on the user's answer, filtering relevant characters. If the answer matches the character's name, those characters are returned. Otherwise, all characters are returned if no specific filter applies. Raises HTTPException if no characters match the criteria after filtering. \"\"\" Logic for filtering based on user's answer try: character data = [char.model dump() for char in game status[\"characters\"]] prompt=f\"\"\"Given the following list of character: {character data} Filter the list of character based on the following answer: {answer} the question was: {game status[\"question\"]} Then, for the rest of the characters, create a question that will help to filter the list of characters further. If the List is empty, the qustion should be \"I lost, i coudnt find out your character\" if the List is a single element, the qustion should be \"I think this is your character: \" and put the name of the character left. \"\"\" chain=llm.with structured output(standardAnswer, method=\"function calling\") k=chain.invoke(prompt) except Exception as e: logging.error(f\"Error updating character list: {str(e)}\") raise HTTPException(status code=500, detail=str(e)) return k Is not generating the standarAnswer object as expected. INFO:root:Successfully initialized 16 characters. INFO: Application startup complete. INFO: Uvicorn running on [link] (Press CTRL+C to quit) INFO: 127.0.0.1:56397 \"GET / HTTP/1.1\" 200 OK INFO: 127.0.0.1:56397 \"GET /api/v1/characters HTTP/1.1\" 200 OK ERROR:root:Error updating character list: 12 validation errors for standardAnswer characters.0.physical traits Field required [type=missing, input value={'name': 'Liora Sunwhispe...ace and determination.'}, input type=dict] For further information visit [link] characters.0.clothing Field required [type=missing, input value={'name': 'Liora Sunwhispe...ace and determination.'}, input type=dict] For further information visit [link] characters.1.physical traits Field required [type=missing, input value={'name': 'Kallista Emberw...s with ancient powers.'}, input type=dict] For further information visit [link] characters.1.clothing Field required [type=missing, input value={'name': 'Kallista Emberw...s with ancient powers.'}, input type=dict] For further information visit [link] characters.2.physical traits Field required [type=missing, input value={'name': 'Elysande Frostw... frost and wind magic.'}, input type=dict] For further information visit [link] characters.2.clothing Field required [type=missing, input value={'name': 'Elysande Frostw... frost and wind magic.'}, input type=dict] For further information visit [link] characters.3.physical traits Field required [type=missing, input value={'name': 'Zarek Nightgloo...ded in arcane mystery.'}, input type=dict] For further information visit [link] characters.3.clothing Field required [type=missing, input value={'name': 'Zarek Nightgloo...ded in arcane mystery.'}, input type=dict] For further information visit [link] characters.4.physical traits Field required [type=missing, input value={'name': 'Nadara Dreamson... night time travelers.'}, input type=dict] For further information visit [link] characters.4.clothing Field required [type=missing, input value={'name': 'Nadara Dreamson... night time travelers.'}, input type=dict] For further information visit [link] characters.5.physical traits Field required [type=missing, input value={'name': 'Rowan Spellweav...es with melodic tales.'}, input type=dict] For further information visit [link] characters.5.clothing Field required [type=missing, input value={'name': 'Rowan Spellweav...es with melodic tales.'}, input type=dict] For further information visit [link] I think is related. If anyone need more info let me know. If its just thrash, ask me to delete this post so it doesn't make noise. I have the same error here for llm.with structured output and the baseModel from pydantic V2 To work around the issue, you can use ''from langchain.pydantic v1 import BaseModel, Field''. but this not fixing permanently the problem. — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ . [image: Guemri Jawher] Guemri Jawher left a comment (langchain ai/langchain 29177) < [link] Using: langchain==0.3.19 langchain core==0.3.36 langchain openai==0.3.6 langchain text splitters==0.3.6 langfuse==2.59.3 langsmith==0.3.8 This LLM: llm: AzureChatOpenAI = AzureChatOpenAI( azure endpoint=os.environ.get(\"AZURE OPENAI ENDPOINT\", \"\"), azure deployment=os.environ.get(\"AZURE OPENAI CHAT DEPLOYMENT NAME\", \"\"), openai api version=os.environ.get(\"AZURE OPENAI API VERSION\", \"\"), max tokens=16256, rate limiter=rate limiter, temperature=0.7, max retries=2, n=1 ) With this model from typing import Dict, Any, List from pydantic import BaseModel, Field class CharacterSchema(BaseModel): \"\"\" Pydantic Schema for API responses. \"\"\" name: str = Field(..., description=\"Unique name assigned to the character\") description: str = Field(..., description=\"Detailed narrative providing context to the character\") physical traits: Dict[str, Any] = Field(..., description=\"Various physical characteristics stored as a dictionary\") clothing: Dict[str, Any] = Field(..., description=\"Details about the clothing and accessories worn by the character\") class Config: from attributes = True For compatibility with SQLAlchemy models (Pydantic v2) class standardAnswer(BaseModel): question:str = Field(...,description=\"Question to ask to the user to find out the character hes thinking\") characters:List[CharacterSchema] = Field(...,description=\"List of characters to display to the user\") And this code: def update character list(answer: str, db: Session, game status) List[Dict[str, str]]: \"\"\" Update the character list based on the user's answer, filtering relevant characters. If the answer matches the character's name, those characters are returned. Otherwise, all characters are returned if no specific filter applies. Raises HTTPException if no characters match the criteria after filtering. \"\"\" Logic for filtering based on user's answer try: character data = [char.model dump() for char in game status[\"characters\"]] prompt=f\"\"\"Given the following list of character: {character data} Filter the list of character based on the following answer: {answer} the question was: {game status[\"question\"]} Then, for the rest of the characters, create a question that will help to filter the list of characters further. If the List is empty, the qustion should be \"I lost, i coudnt find out your character\" if the List is a single element, the qustion should be \"I think this is your character: \" and put the name of the character left. \"\"\" chain=llm.with structured output(standardAnswer, method=\"function calling\") k=chain.invoke(prompt) except Exception as e: logging.error(f\"Error updating character list: {str(e)}\") raise HTTPException(status code=500, detail=str(e)) return k Is not generating the standarAnswer object as expected. INFO:root:Successfully initialized 16 characters. INFO: Application startup complete. INFO: Uvicorn running on [link] (Press CTRL+C to quit) INFO: 127.0.0.1:56397 \"GET / HTTP/1.1\" 200 OK INFO: 127.0.0.1:56397 \"GET /api/v1/characters HTTP/1.1\" 200 OK ERROR:root:Error updating character list: 12 validation errors for standardAnswer characters.0.physical traits Field required [type=missing, input value={'name': 'Liora Sunwhispe...ace and determination.'}, input type=dict] For further information visit [link] characters.0.clothing Field required [type=missing, input value={'name': 'Liora Sunwhispe...ace and determination.'}, input type=dict] For further information visit [link] characters.1.physical traits Field required [type=missing, input value={'name': 'Kallista Emberw...s with ancient powers.'}, input type=dict] For further information visit [link] characters.1.clothing Field required [type=missing, input value={'name': 'Kallista Emberw...s with ancient powers.'}, input type=dict] For further information visit [link] characters.2.physical traits Field required [type=missing, input value={'name': 'Elysande Frostw... frost and wind magic.'}, input type=dict] For further information visit [link] characters.2.clothing Field required [type=missing, input value={'name': 'Elysande Frostw... frost and wind magic.'}, input type=dict] For further information visit [link] characters.3.physical traits Field required [type=missing, input value={'name': 'Zarek Nightgloo...ded in arcane mystery.'}, input type=dict] For further information visit [link] characters.3.clothing Field required [type=missing, input value={'name': 'Zarek Nightgloo...ded in arcane mystery.'}, input type=dict] For further information visit [link] characters.4.physical traits Field required [type=missing, input value={'name': 'Nadara Dreamson... night time travelers.'}, input type=dict] For further information visit [link] characters.4.clothing Field required [type=missing, input value={'name': 'Nadara Dreamson... night time travelers.'}, input type=dict] For further information visit [link] characters.5.physical traits Field required [type=missing, input value={'name': 'Rowan Spellweav...es with melodic tales.'}, input type=dict] For further information visit [link] characters.5.clothing Field required [type=missing, input value={'name': 'Rowan Spellweav...es with melodic tales.'}, input type=dict] For further information visit [link] I think is related. If anyone need more info let me know. If its just thrash, ask me to delete this post so it doesn't make noise. I have the same error here for llm.with structured output and the baseModel from pydantic V2 To work around the issue, you can use ''from langchain.pydantic v1 import BaseModel, Field''. but this not fixing permanently the problem. — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ ."}, {"author": "dosubot[bot]", "created_at": "2025-05-22T16:01:09Z", "body_clean": "Hi, @simpliatanu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involved serialization errors with OpenAI models and Pydantic's [code] . @ccurme suggested using the [code] method, which resolved the issue for you. @RicardoOM AC and @Guemri Jawher experienced similar errors with Pydantic V2. @Guemri Jawher suggested using [code] as a workaround. The issue was related to changes in LangChain's handling of structured output with OpenAI models. Next Steps: Please confirm if the issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue lies in a missing `aget relevant documents` method within the `PineconeHybridSearchRetriever` class, which is a mandatory part of the async setup for the retriever.  The developer needs to simply add this method to the class, or adapt the existing code to use `await` to prevent unnecessary system processing.  The code is likely a bug in LangChain itself, and attempts to fix it by updating the latest stable version have not resolved the problem.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-14T16:00:59Z", "body_clean": "Hi, @festnoze. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a missing \" aget relevant documents\" function in the PineconeHybridSearchRetriever class. This function is crucial for supporting asynchronous operations. You suggested adding this method or modifying \" get relevant documents\" to support async with \"await\". No comments or developments from other users or maintainers have been made. Next Steps Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a critical failure in installing `chromadb` with Python 3.10.11. The installation process fails, resulting in an error message and a stack trace indicating a problem with the LangChain integration package.  The issue suggests a potential bug within LangChain itself, rather than a problem with the code being attempted.  The user has tried updating to the latest stable version of LangChain and specific integration packages, but the issue persists.", "final_category": "bug", "comments": [{"author": "ashvin-a", "created_at": "2025-01-15T02:52:39Z", "body_clean": "What other packages have you installed in your environment? I was unable to recreate this (btw my machine is Windows 11 and Python version 3.12.0)."}, {"author": "dosubot[bot]", "created_at": "2025-04-16T16:01:07Z", "body_clean": "Hi, @555chy. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered an installation issue with the [code] package using Python 3.10.11. You suspected a bug in LangChain as the cause of the installation failure. The failure occurs during dependency download from a PyPI mirror. User ashvin a attempted replication on Windows 11 with Python 3.12.0 but was unsuccessful. ashvin a inquired about other packages in your environment for further investigation. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports an \"Attribute Error\" when attempting to load the Google API in LangChain, despite attempts to troubleshoot it with documentation, search, and community updates. The error persists even after updating to the latest stable version of LangChain and related packages.  The problem appears to be a bug within the LangChain integration for the Google API, likely related to a specific version of the package.", "final_category": "bug", "comments": [{"author": "sardanabhav", "created_at": "2025-01-22T04:17:05Z", "body_clean": "@Dokterpostds Fix for GoogleApiClient was pushed and merged. Let me know if it works as expected. If so, I will make the changes for GoogleApiYoutubeLoader as well."}, {"author": "NorkzYT", "created_at": "2025-02-05T04:43:25Z", "body_clean": "I have a similar issue. Is there a way to fix this by reverting to an older version? @sardanabhav [code] [code] : [code] [code] : [code]"}, {"author": "sardanabhav", "created_at": "2025-02-08T14:18:29Z", "body_clean": "@NorkzYT Can you please share the stack trace for the error?"}, {"author": "obstriker", "created_at": "2025-02-08T17:55:10Z", "body_clean": "@sardanabhav I think I'm having the same issue, with the example code using wsl: [code] [code]"}, {"author": "sardanabhav", "created_at": "2025-02-08T18:16:12Z", "body_clean": "@NorkzYT It seems like you don't have the latest changes. Can you make sure that your environment has the correct version of langchain community installed ( =0.3.16). please post a screenshot of the following from your python environment: [code]"}, {"author": "obstriker", "created_at": "2025-02-08T19:59:34Z", "body_clean": "@sardanabhav I updated to latest( [code] and [code] ) and the patch for [code] fixed the issue.. Now running the full example: [code] outputs: [code] with stack trace of: [code] Seems like [code] needs the same fix aswell"}, {"author": "NorkzYT", "created_at": "2025-02-08T21:35:22Z", "body_clean": "[<img alt=\"\" width=\"16\" height=\"16\" src=\" [link] It seems like you don't have the latest changes. Can you make sure that your environment has the correct version of langchain community installed ( =0.3.16). please post a screenshot of the following from your python environment: [code] @sardanabhav Thank you for your response, while I do not need this anymore; to help here is the stack trace: [code] And the langchain community version I have installed: py m pip freeze | findstr langchain [code]"}, {"author": "sardanabhav", "created_at": "2025-02-09T04:58:59Z", "body_clean": "[@sardanabhav]( [link] I updated to latest( [code] and [code] ) and the patch for [code] fixed the issue.. Now running the full example: [code] outputs: [code] with stack trace of: [code] Seems like [code] needs the same fix aswell @obstriker That's correct. I will update the GoogleApiYoutubeLoader. Thanks"}, {"author": "sardanabhav", "created_at": "2025-02-09T09:18:51Z", "body_clean": "@obstriker @NorkzYT I have created a pull request for the changes. This should hopefully be fixed in the next release! Thanks for your support!"}, {"author": "NorkzYT", "created_at": "2025-02-09T11:20:51Z", "body_clean": "@sardanabhav Of course, no problem. Thank you for the Pull Request!"}, {"author": "dosubot[bot]", "created_at": "2025-05-11T16:00:47Z", "body_clean": "Hi, @Dokterpostds. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an [code] when using LangChain to load the Google API. A fix for [code] was pushed and confirmed to resolve the issue. The issue with [code] remains, but a pull request has been created to address it in the next release. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This code snippet, from the `llama_cpp` library, is failing due to a `TypeError: 'float' object is not iterable` error when attempting to use the `LlamaCppEmbeddings` function. The error occurs when the embedding process is expecting a list of numbers, but it receives a float, likely due to a bug in the integration package or a specific version of LangChain.  The code is attempting to use the `embed` function with a `float` value, causing the error.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-14T16:01:01Z", "body_clean": "Hi, @habib source. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a TypeError in the [code] method of [code] in LangChain version 0.3.14. The error involves a float object being incorrectly treated as iterable, possibly due to changes from commit 41b6a86. You verified that the bug persists in the latest version and have not found similar issues elsewhere. There are no comments or updates from other users or maintainers on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "habib-source", "created_at": "2025-04-18T19:31:04Z", "body_clean": "Latest langchain community 0.3.21 work fine no error"}, {"author": "dosubot[bot]", "created_at": "2025-04-18T19:31:11Z", "body_clean": "Thank you for closing the issue, habib source! We appreciate your help in keeping the repo organized."}]}], "business_insights": ["Package compatibility issues are a recurring challenge, requiring careful dependency management.", "LangChain’s integration complexity highlights the need for robust error handling and logging.", "Version conflicts between packages can trigger cascading failures, necessitating careful version control.", "Testing is crucial – thorough testing across all dependencies is vital for stability.", "Dependency management impacts overall project reliability, requiring diligent tracking."], "technical_insights": ["LangChain’s integration package is a primary source of bugs, demanding immediate attention.", "The aget relevant documents method's missing integration is a critical bug impacting retrieval.", "The chromadb installation failure suggests a bug within LangChain’s integration with the ChromaDB library.", "The llama_cpp embedding error is a specific bug related to the integration of the LlamaCppEmbeddings function.", "The TypeError: 'float' object is not iterable error in the llama_cpp code points to a potential issue within the integration."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Package compatibility issues are a recurring challenge, requiring careful dependency management.\n2.  LangChain’s integration complexity highlights the need for robust error handling and logging.\n3.  Version conflicts between packages can trigger cascading failures, necessitating careful version control.\n4.  Testing is crucial – thorough testing across all dependencies is vital for stability.\n5.  Dependency management impacts overall project reliability, requiring diligent tracking.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s integration package is a primary source of bugs, demanding immediate attention.\n2.  The `aget relevant documents` method's missing integration is a critical bug impacting retrieval.\n3.  The `chromadb` installation failure suggests a bug within LangChain’s integration with the ChromaDB library.\n4.  The `llama_cpp` embedding error is a specific bug related to the integration of the `LlamaCppEmbeddings` function.\n5.  The `TypeError: 'float' object is not iterable` error in the `llama_cpp` code points to a potential issue within the integration.\n", "batch_number": 142, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a deprecated key used in LangChain's `get_buffer_string()` function. The code snippet in question utilizes this key, and OpenAI has deprecated it, causing the application to fail when interacting with chat models.  The solution involves updating to a newer version of LangChain or the specific integration package to resolve the issue.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-12T21:52:43Z", "body_clean": "You are not using you Tracer in your first call: [code] I tried and get the following valid output which includes the tool call [code]"}, {"author": "huang-jl", "created_at": "2025-01-13T02:18:16Z", "body_clean": "The outputs are not fully correct. Although it print the LLM call output correctly, during print the LLM input, it loses the information about function call. In your example, the following blocks are wrong: [code] Note that there is NOTHING after the \"AI:\" and it print the tool message (the return value of tools) directly. The reason is that LLM output will not use [code] by ConsoleCallbackHandler, but only when print LLM input."}, {"author": "dosubot[bot]", "created_at": "2025-04-14T16:01:04Z", "body_clean": "Hi, @huang jl. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] function in LangChain uses deprecated keys, causing a bug. You provided example code showing the issue persists even after updating to the latest version. @keenborder786 suggested using a Tracer as a solution. You noted that while the LLM call output is correct, the LLM input loses function call information, leaving the issue unresolved. Next Steps: Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in the `rankllm` package, specifically version 0.20.3, that causes an error when used with GPT models (or other models exceeding the 0.12.8 version constraint). The code attempts to query documents using the `rank llm` library, but the integration fails due to a change in the package's internal structure.  The fix involves a PR (29154) addressing this issue, and the code is now correctly integrated into the LangChain project.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where the `Args` and `Returns` sections of a function's docstring are not correctly identified by the function's type hints. The bug occurs when type declarations are present in both the docstring and the function signature, leading to a failure in the function's execution. The proposed solution is to delay the `args` and `returns` annotations during the function definition.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-11T21:44:07Z", "body_clean": "@jeffersonRosman Just do the following and it should work: [code]"}, {"author": "keenborder786", "created_at": "2025-01-11T21:44:43Z", "body_clean": "Note how I changed [code] to [code] which was causing the error"}, {"author": "dosubot[bot]", "created_at": "2025-04-12T16:00:47Z", "body_clean": "Hi, @jeffersonRosman. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in LangChain where a Python function with type hints and type information in the docstring failed due to a mismatch error. User keenborder786 suggested a solution by modifying the docstring format, specifically removing the hyphen before the argument type. This modification resolved the error, allowing the function to execute correctly without removing the type information. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "jeffersonRosman", "created_at": "2025-04-12T20:09:24Z", "body_clean": "Issue is solved For future reference the problem can be fixed by specifying in the result in the function"}, {"author": "dosubot[bot]", "created_at": "2025-04-12T20:11:34Z", "body_clean": "Thank you for your response, @jeffersonRosman! We're glad to hear that the issue is resolved. We'll go ahead and close this issue now."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a bug in the `RecursiveJsonSplitter::split_json()` function where nodes \"GTMS 10\" and \"ITSAMPLE 2\" are consistently lost when splitting JSON data, specifically when the chunk size is adjusted.  The bug appears to be an \"offset by 1\" issue, potentially stemming from a miscalculation within the function's logic.  The developer has identified this as a bug requiring investigation and is requesting a bug report to ensure stability.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-12T16:00:46Z", "body_clean": "Hi, @blupants. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: I identified an off by one error in [code] . I verified the issue persists in the latest version of LangChain. I provided example code illustrating the JSON data structure. There have been no further comments or activity on the issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "blupants", "created_at": "2025-04-13T21:43:51Z", "body_clean": "Hi, [@blupants]( [link] I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: I identified an off by one error in [code] . I verified the issue persists in the latest version of LangChain. I provided example code illustrating the JSON data structure. There have been no further comments or activity on the issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution! I can confirm the issue still persist. I have just updated to the latest version: [code] I ran the example code after upgrading [code] and [code] and the bug is still active. [code]"}, {"author": "dosubot[bot]", "created_at": "2025-04-13T21:46:10Z", "body_clean": "@eyurtsev, the user has confirmed that the off by one error in [code] still persists even after updating to the latest versions of [code] and [code] . Could you please assist them with this issue?"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that prevents the addition of a specific request header after an LLM model is initialized, causing issues with the model's functionality. The proposed solution involves a more robust and maintainable approach to handling such scenarios, potentially requiring a change to the internal OpenAI client updates.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-12T16:00:47Z", "body_clean": "Hi, @Peilun Li. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are facing difficulties adding request headers to a user defined LLM model in LangChain after initialization. Attempts to modify [code] or use the [code] method have not been successful. The issue remains unresolved, with no comments or developments from others. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Key deprecation triggers require immediate updates to LangChain and integration packages.", "Focus on deprecated keys for consistent application behavior.", "Updating is crucial for maintaining compatibility and avoiding errors.", "Rapid updates are needed to address the core bug.", "Prioritize the latest versions for stability."], "technical_insights": ["LangChain key deprecation is a significant risk.", "rankllm version 0.20.3 requires immediate patch.", "Args and Returns documentation must be updated.", "Integration package update is the primary solution.", "PR (29154) fixes the package’s internal structure."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Key deprecation triggers require immediate updates to LangChain and integration packages.\n2.  Focus on deprecated keys for consistent application behavior.\n3.  Updating is crucial for maintaining compatibility and avoiding errors.\n4.  Rapid updates are needed to address the core bug.\n5.  Prioritize the latest versions for stability.\n\nTECHNICAL INSIGHTS:\n1.  LangChain key deprecation is a significant risk.\n2.  `rankllm` version 0.20.3 requires immediate patch.\n3.  `Args` and `Returns` documentation must be updated.\n4.  Integration package update is the primary solution.\n5.  PR (29154) fixes the package’s internal structure.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 143, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The AzureOpenAIWhisperParser GitHub issue is addressing a bug where the authentication fails with a 401 Unauthorized error when using the `[code]` parameter in LangChain. The issue stems from an incorrect parameter name within the client initialization, leading to the parser failing to authenticate with the OpenAI API. The proposed solution is to update the client initialization to use the correct parameter name, resolving the issue and ensuring successful API calls.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-11T16:01:03Z", "body_clean": "Hi, @carloscaicedos. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The [code] fails when using [code] . The issue is related to an incorrect token parameter causing authentication problems. You have provided example code to demonstrate the issue. The problem persists even after updating to the latest version of LangChain. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that causes presigned URLs to become invalid when loading large documents due to Unstructured’s slow processing. This results in the URLs becoming unusable after accessing them, requiring a workaround involving repeatedly calling a specific function.  The solution involves a straightforward process of calling the function multiple times, but the bug is not being addressed through a straightforward update.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-10T22:07:08Z", "body_clean": "@dhdaine check if the above PR solves your issue."}, {"author": "dhdaines", "created_at": "2025-01-13T01:52:53Z", "body_clean": "@dhdaine check if the above PR solves your issue. Thanks! That is indeed one way to deal with the problem, though it isn't really guaranteed to solve it and might use an enormous amount of memory. In reality I'm not using LakeFSLoader directly, in part because UnstructuredFileLoader is obsolete/deprecated, but noticed this in a locally customized version of it. My solution (which possibly uses a lot of disk space but is more memory/CPU friendly) is to simply download all the objects at once before processing them."}, {"author": "dosubot[bot]", "created_at": "2025-04-14T16:01:00Z", "body_clean": "Hi, @dhdaines. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Presigned URLs expire when using [code] , causing a 403 Forbidden error. The Unstructured library processes slowly, contributing to the issue. Keenborder786 suggested a solution via a pull request, but you noted it may consume excessive memory. You proposed downloading all objects at once as a workaround, which is more memory/CPU friendly but requires significant disk space. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The Google Gemini Grounding Tool is failing to properly identify the tool being used, resulting in an error message indicating a missing attribute.  After investigating through documentation, GitHub search, and code examples, the issue appears to be a bug within LangChain that doesn’t implement the expected attribute for the tool.  The solution is to update to the latest stable version of LangChain or the specific integration package.", "final_category": "bug", "comments": [{"author": "BwL1289", "created_at": "2025-02-06T18:41:41Z", "body_clean": "bumping this"}, {"author": "Lorentzo92", "created_at": "2025-02-07T21:51:16Z", "body_clean": "Adding a +"}, {"author": "catsled", "created_at": "2025-02-20T09:00:49Z", "body_clean": "![Image]( [link] me too. model: qwen2.5:7b"}, {"author": "BwL1289", "created_at": "2025-02-20T16:58:12Z", "body_clean": "I'm going to leave this issue open but I was able to get around this by ripping out the (now deprecated) [code] and using [ChatVertexAI]( [link]"}, {"author": "dosubot[bot]", "created_at": "2025-05-22T16:01:08Z", "body_clean": "Hi, @BwL1289. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an [code] with the Google Gemini Grounding Tool in LangChain, related to a missing 'name' attribute in the 'Tool' object. The issue persisted even after updating to the latest version, indicating a potential bug. You found a workaround by using [code] instead of the deprecated [code] . Other users, like Lorentzo92 and catsled, have reported similar issues. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem where the `chat_template` tokenizer is not correctly configured for LangChain’s chat template functions, preventing the code from running.  Initial troubleshooting efforts – searching documentation, using GitHub search, and checking the latest stable version – haven’t identified a fix.  The core problem appears to be a configuration mismatch within the LangChain integration, requiring a fix to ensure the tokenizer is properly set up.", "final_category": "bug", "comments": [{"author": "Ashish-Abraham", "created_at": "2025-02-08T11:22:21Z", "body_clean": "Try using a chat model like meta llama/Llama 3.2 1B Instruct instead of base one."}, {"author": "dosubot[bot]", "created_at": "2025-05-10T16:00:41Z", "body_clean": "Hi, @Arslan Mehmood1. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where [code] is not set, affecting chat template functions. The issue persists even after updating to the latest version of LangChain. The problem occurs specifically with the [code] class using a HuggingFace pipeline. Ashish Abraham suggested using a chat model like meta llama/Llama 3.2 1B Instruct as a workaround. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue addresses a bug in LangChain's `retry` decorator that fails to correctly handle 429 (requests rate limit) errors, resulting in the code raising an error instead of retrying. The decorator currently only catches the error when hitting a rate limit, but the documentation suggests it should handle it with a retry mechanism.  The code currently raises an error without retrying, and the issue is a discrepancy between the documented behavior and the current implementation.", "final_category": "bug", "comments": [{"author": "ZhangShenao", "created_at": "2025-01-16T06:14:02Z", "body_clean": "Try to fix it in 29242"}, {"author": "eric-burel", "created_at": "2025-03-25T15:42:08Z", "body_clean": "Hey folks, any idea how we can better observe errors with this integration? I hit 400 errors with barely any indications, so I can tell if some documents can't be ingested or if I am hitting some sort of limitation. I can't see embedding calls in LangSmith and can't figure how to have [link] to trace calls in stdio to observe what happens. The document embedding method will raise an error as soon as one document cannot be embedded, but won't indicate which."}, {"author": "dosubot[bot]", "created_at": "2025-06-24T16:02:40Z", "body_clean": "Hi, @Gero Gi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a problem with the [code] class not handling rate limiting exceptions, leading to [code] . ZhangShenao proposed a fix in pull request 29242, which you and L0d0c positively reviewed. Eric burel suggested improvements for error visibility and tracing, especially for 400 errors. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Correct parameter name handling resolves authentication failures.", "The correct parameter name is crucial for parser functionality.", "Proper parameter name handling is essential for API calls.", "The issue highlights a key parameter name issue.", "Addressing the parameter name issue is a priority."], "technical_insights": ["Client initialization must use the correct parameter name.", "Incorrect parameter name leads to parser failure.", "The client initialization is the root cause of the problem.", "The client initialization needs updating.", "Client initialization is the key to resolving the issue.", "The issue is a bug related to authentication.", "The bug stems from an incorrect parameter name.", "The bug impacts API calls.", "The bug impacts the parser.", "The bug is caused by incorrect parameter name."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Correct parameter name handling resolves authentication failures.\n2. The correct parameter name is crucial for parser functionality.\n3. Proper parameter name handling is essential for API calls.\n4. The issue highlights a key parameter name issue.\n5. Addressing the parameter name issue is a priority.\n\nTECHNICAL INSIGHTS:\n1. Client initialization must use the correct parameter name.\n2. Incorrect parameter name leads to parser failure.\n3. The client initialization is the root cause of the problem.\n4. The client initialization needs updating.\n5. Client initialization is the key to resolving the issue.\n\nRULES:\n1.  The issue is a bug related to authentication.\n2.  The bug stems from an incorrect parameter name.\n3. The bug impacts API calls.\n4. The bug impacts the parser.\n5. The bug is caused by incorrect parameter name.\n", "batch_number": 144, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue involves a problem where the agentic graph is not streaming the output generated by `bind_tools` when using Langchain. A minimal reproducible example demonstrates the failure, showing the code produces the expected output. The solution requires a fix to the `bind_tools` function to ensure streamed output is implemented.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2025-01-10T14:13:28Z", "body_clean": "So the problem is still with the LLM right? I don't think there is a langgraph issue. Can you confirm the issue with running the streaming using [code] ? i think it's the same issue you referenced above [link]"}, {"author": "GeorgeDoukas", "created_at": "2025-01-13T08:19:07Z", "body_clean": "I created the following two test cases: [code] The output was: [code] The content of the messages is blank."}, {"author": "mhjmaas", "created_at": "2025-01-14T13:04:55Z", "body_clean": "I am seeing the same issue. Whenever a bind tools() is involved the streaming breaks."}, {"author": "zephyr2403", "created_at": "2025-01-15T06:03:00Z", "body_clean": "Facing this issues, Tried Event API and streaming, none of it was working, decided to directly check langchain it wasn't working there as well, [code] Output: I'm doing well, thank you! How can I assist you today?| [code] Output: I|'m| doing| well|,| thank| you|!| How| can| I| assist| you| today|?|| version: [code]"}, {"author": "and1mon", "created_at": "2025-02-01T15:05:51Z", "body_clean": "Any update on this?"}, {"author": "mlhommet", "created_at": "2025-02-10T07:53:13Z", "body_clean": "Looks like there was a fix proposed in November 2024 for this issue but I confirm that it does not fix the issue here streaming only works without tools."}, {"author": "geekben", "created_at": "2025-02-16T14:07:33Z", "body_clean": "I am still seeing the same issue with version as following: [code]"}, {"author": "merenguesL", "created_at": "2025-02-17T08:20:50Z", "body_clean": "我也遇到了同样的问题，还没有解决"}, {"author": "fcOSENSE", "created_at": "2025-02-27T07:31:46Z", "body_clean": "I face the same issue, when bind tools enabled, on llm new token can't fire. So the question is still here."}, {"author": "jacobycwang", "created_at": "2025-03-12T06:02:05Z", "body_clean": "while checking with [code] , the issue lie within this section [link] without [code] , there will be no [code] in the api payload, so the [code] will be [code] . and within parsing [link] the text delta will be extracted as [code] type and pass the [code] check then trigger [code] . with [code] , the [code] will be [code] , then it will go to this section [link] and generate a [code] now the [code] will be a [code] instead of [code] , so the [code] wont be triggered"}, {"author": "efernandezelig", "created_at": "2025-03-14T08:46:13Z", "body_clean": "Same issue here... when I bind the tools, the streaming juts cuts out"}, {"author": "BlueCataDev", "created_at": "2025-03-18T05:43:50Z", "body_clean": "I also encountered this issue"}, {"author": "Miltos-90", "created_at": "2025-03-20T14:23:01Z", "body_clean": "Same here."}, {"author": "Rupper02", "created_at": "2025-04-11T05:04:51Z", "body_clean": "Same issue!"}, {"author": "dsavu09", "created_at": "2025-04-13T18:36:06Z", "body_clean": "Same issue here! Is there any chance this will be fixed?"}, {"author": "greg-gav", "created_at": "2025-04-22T06:33:13Z", "body_clean": "Please fix <"}, {"author": "fcOSENSE", "created_at": "2025-04-23T06:37:43Z", "body_clean": "Please fix it, it can solve a lot of our issues"}, {"author": "motacapla", "created_at": "2025-05-03T15:54:57Z", "body_clean": "Fix pls!"}, {"author": "jpangburn", "created_at": "2025-05-06T17:46:48Z", "body_clean": "When using a reasoning model that outputs stuff like [code] , the fact that bind tools breaks streaming also breaks the [code] method. It won't properly extract the reasoning text from the main text when [code] is in use (because of the broken streaming this method requires streaming to work right). This is not a case of just a nuisance where the streaming is broken but you still ultimately get your message. If you have some code like: [code] The result.content you will get will be like (stripping full content for clarity): [code] The reasoning content is the exact same: [code] Without the bind tools, the result.content is: [code] And the reasoning content is: [code] So the broken streaming from [code] actually changes the output to be wrong in both cases because [code] method doesn't work without streaming."}, {"author": "zhonglunsheng", "created_at": "2025-05-11T10:58:22Z", "body_clean": "Has anyone solved it? I've encountered the same problem. At first, I thought it was because the large language model didn't support it."}, {"author": "jpangburn", "created_at": "2025-05-11T15:40:43Z", "body_clean": "@zhonglunsheng I debugged into it when I posted my comment, and there's a method in the ChatOllama class: [code] That last line, the [code] normally comes back one token at a time. But when you have called bind tools, it comes back as the full response. If you want to determine the root cause, that's where you should start. For me, I didn't need the streaming, so I just worked around the [code] problem by extracting after I get the response back."}, {"author": "choudian", "created_at": "2025-05-19T06:44:08Z", "body_clean": "@baskaryan @hwchase17 Same here. pls"}, {"author": "escolanogui", "created_at": "2025-05-22T13:43:11Z", "body_clean": "any news on this?"}, {"author": "RAPHCVR", "created_at": "2025-05-22T13:50:05Z", "body_clean": "Please fix ! This is a critical feature when using ollama. Issue has now more than 4 months !"}, {"author": "choudian", "created_at": "2025-05-23T01:22:11Z", "body_clean": "I tried switching the model to Deepseek without using Ollama, and it can output in a streaming manner. The issue might be with Ollama."}, {"author": "jpangburn", "created_at": "2025-05-23T01:38:33Z", "body_clean": "@choudian yeah, my experience was the same. I switched to mlx lm using the ChatOpenAI class because I'm on Mac and streaming works fine with bind tools there on the same models. I don't know if it's lower down in the ChatOllama client or the Ollama server, but either way swapping out Ollama resolved the problem."}, {"author": "choudian", "created_at": "2025-05-23T01:54:55Z", "body_clean": "[@choudian]( [link] yeah, my experience was the same. I switched to mlx lm using the ChatOpenAI class because I'm on Mac and streaming works fine with bind tools there on the same models. I don't know if it's lower down in the ChatOllama client or the Ollama server, but either way swapping out Ollama resolved the problem. I'm using ChatOpenAI, and I suspect the issue lies with LangChain rather than the Ollama server side, since the native OpenAI API approach would probably work fine—though I haven't tested it."}, {"author": "RwinShow", "created_at": "2025-06-06T11:51:15Z", "body_clean": "Ollama recently released [an update]( [link] in my case using the latest ollama version fixed the streaming issue I had with .stream of Ollama models using bind tools."}, {"author": "mdrxy", "created_at": "2025-06-28T01:58:13Z", "body_clean": "Closed since this was resolved in recent versions of the Ollama SDK. If you still have issues, ensure your system Ollama binary is up to date ( [code] ). We're pushing a release soon that introduces some tests for this as well. Happy to investigate further if anyone has any more problems."}]}, {"ollama_summary": "The LangChain community is missing a dependency on unstructured data, causing crashes during downloads. This issue appears to be a bug in the LangChain library itself, and attempts to update to the latest version of LangChain haven’t resolved it. The code requires SQLAlchemy, langsmith, PyYAML, Dataclasses, JSON, and other dependencies, which are not currently captured in the dependencies list.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-10T15:20:58Z", "body_clean": "[code] and almost all other third party integration dependencies are [deliberately omitted]( [link] from the explicit dependencies of [code] . They are often not imported until a class is instantiated and we make an effort to raise an informative error message when missing. Due to the number of integrations in [code] , it would not be practical to manage all their dependencies simultaneously. To mitigate this, we recommend new integrations be implemented as [separate packages]( [link] There is an existing package for [langchain unstructured]( [link] that explicitly depends on [code] . This package is recommended over the abstractions in [code] ."}]}, {"ollama_summary": "Okay, let's break down this issue and the potential solutions.\n\n**The Problem:**\n\nThe `langchain.core.utils.merge` function is throwing an error in the `Agent 2` part of the code. Specifically, it's encountering a `TypeError: `Additional kwargs key prompt tokens already exists in left dict and value has unsupported type <class 'int' . Description I am trying to use the Pre built ReAct agent as nodes inside a LangGraph Graph. The graph as 2 ReAct based agent nodes.Both are exactly identical just with different prompts.` error.  This suggests that the `merge` function is attempting to combine data from two different dictionaries (likely related to the prompts) where one dictionary has a `prompt` key, while the other doesn't.\n\n**Root Cause:**\n\nThe `merge` function is designed to combine dictionaries.  The error indicates that the `merge` function is attempting to combine two dictionaries, but one dictionary has a key named `prompt` that the other doesn't. This is a fundamental mismatch in the data structure being passed to the merge function.\n\n**Possible Solutions (and Recommendations):**\n\n1. **Inspect the Data:** The most crucial first step is to *carefully examine the data* that's being passed to `merge`.  Print out the contents of both dictionaries *before* calling `merge`.  This will reveal exactly what keys are causing the conflict.\n\n2. **Data Transformation:**  You need to transform the data so that the `merge` function receives a consistent structure.  This might involve:\n   * **Filtering:** Remove or exclude the problematic data.\n   * **Mapping:** Convert the data into a format that the `merge` function can handle.\n   * **Creating a Combined Dictionary:** Create a new dictionary that contains all the relevant information from both dictionaries, resolving the conflict.\n\n3. **Modify the `merge` Function:**  You might need to adjust the `merge` function itself to handle the case where the dictionaries have different keys.  This could involve adding a check to ensure that both dictionaries have the same keys before merging.\n\n4. **Use a Different Merge Strategy:**  Consider alternative merge strategies that are less prone to this type of error.\n\n**Code Snippets (Illustrative - Requires Context):**\n\nLet's assume a simplified example of how the `merge` function might be used", "final_category": "bug", "comments": [{"author": "AkashBais", "created_at": "2025-01-20T11:45:08Z", "body_clean": "For anyone encountering the same issue, I am extract the content key from the response of the first agent creating a new AIMessage with no metadata [As the issue was with duplicate metadata key] and passing it along to the second agent. This is a temporary way around. I still think that 1 agent should be able to consume the output of another agent as is"}, {"author": "dosubot[bot]", "created_at": "2025-04-21T16:00:53Z", "body_clean": "Hi, @AkashBais. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A [code] occurs in the [code] function when merging dictionaries with a key like [code] that exists in both dictionaries with an unsupported type. The issue arises when using the [code] model. Updating LangChain does not resolve the issue. You suggested a workaround by extracting the content key and creating a new AIMessage without metadata. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a `ImportError` within SurrealDBStore, preventing the code from correctly accessing the Surreal library.  After investigating through various resources and documentation, it appears to be a bug within LangChain that hasn’t been addressed by recent updates.  The code attempts to import the Surreal library, suggesting a fundamental issue with the integration.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-10T16:01:21Z", "body_clean": "Hi, @fredrik jansson se. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: An [code] occurs when importing [code] from the [code] package in the [code] class. You suggested changing the import to [code] . The error persists even after updating to the latest version of LangChain. No further comments or activity have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a bug in the LangChain `UnstructuredMarkdownLoader` that causes it to incorrectly load files as zip files, specifically when encountering a `UnstructuredMarkdownLoader` with a `README.md` file. The code attempts to load a file, but the `UnstructuredMarkdownLoader` fails to interpret it as a zip file, resulting in a `BadZipFile` error. This is likely a problem with the integration of the `README.md` file, potentially due to a misunderstanding of how the loader handles file types.", "final_category": "bug", "comments": [{"author": "ryanSir", "created_at": "2025-01-09T07:56:29Z", "body_clean": "I have solved this problem with download third packages import nltk nltk.download()"}]}], "business_insights": ["Address the root cause of data inconsistencies – a critical issue likely impacting the core functionality.", "Prioritize fixing the merge function – it’s the primary cause of the error.", "Investigate the UnstructuredMarkdownLoader integration – a potential broader problem.", "Verify dependencies – ensure all required libraries are correctly installed and compatible.", "Review the bind_tools function – confirm it’s functioning as expected."], "technical_insights": ["merge function:  The merge function’s design introduces a mismatch in data structures.", "UnstructuredMarkdownLoader:  The loader is incorrectly interpreting README.md files as zip files.", "bind_tools: The bind_tools function’s behavior is causing the merge function to fail.", "Dependency issues: Missing dependencies are hindering the code's functionality.", "LangChain Updates:  The bug may be related to a recent update, requiring a rollback or specific version check."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Address the root cause of data inconsistencies – a critical issue likely impacting the core functionality.\n2.  Prioritize fixing the `merge` function – it’s the primary cause of the error.\n3.  Investigate the `UnstructuredMarkdownLoader` integration – a potential broader problem.\n4.  Verify dependencies – ensure all required libraries are correctly installed and compatible.\n5.  Review the `bind_tools` function – confirm it’s functioning as expected.\n\nTECHNICAL INSIGHTS:\n1.  `merge` function:  The `merge` function’s design introduces a mismatch in data structures.\n2.  `UnstructuredMarkdownLoader`:  The loader is incorrectly interpreting `README.md` files as zip files.\n3.  `bind_tools`: The `bind_tools` function’s behavior is causing the `merge` function to fail.\n4.  Dependency issues: Missing dependencies are hindering the code's functionality.\n5.  LangChain Updates:  The bug may be related to a recent update, requiring a rollback or specific version check.\n\n", "batch_number": 145, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The LangChain CLI for macOS is failing to download the Grit CLI due to a dependency issue, specifically a missing file link. This problem is impacting the ability to utilize the LangChain integration, and the issue is not resolved by updating the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "popsc30", "created_at": "2025-02-06T05:49:57Z", "body_clean": "same here"}, {"author": "dosubot[bot]", "created_at": "2025-05-08T14:48:52Z", "body_clean": "Hi, @ccasgar. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Encountered a CLIError when using [code] on MacOS. Error due to a failed download from a URL. Issue persists with the latest stable version of LangChain. User popsc30 confirmed experiencing the same issue, indicating it affects multiple users. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the `langchain google firestore` package has a typo in the installation guide, causing an error for developers.  The issue involves a specific error message reported by developers when following the documentation.  The issue is currently requesting content clarification to address this issue.", "final_category": "other", "comments": [{"author": "code-with-dhamala", "created_at": "2025-01-08T18:49:48Z", "body_clean": "Can I work on this issue ?"}, {"author": "ashvin-a", "created_at": "2025-01-15T02:55:05Z", "body_clean": "Of course, you could!"}, {"author": "dosubot[bot]", "created_at": "2025-04-16T16:00:59Z", "body_clean": "Hi, @code with dhamala. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A typo was identified in the installation guide for the 'langchain google firestore' package. The incorrect flag \" upgrade\" should be \" upgrade\" to prevent installation errors. You expressed interest in fixing this typo, and @ashvin a confirmed you could proceed with the fix. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If it is, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the \"rag\" tutorial is currently experiencing a typo in the installation instructions, causing problems with package names. The issue stems from a misinterpretation of the conda package names, which are incorrectly formatted.  The issue is currently awaiting a response and a potential fix to ensure the documentation is accurate and functional.", "final_category": "other", "comments": [{"author": "hesreallyhim", "created_at": "2025-03-27T02:31:24Z", "body_clean": "@afkungl I would fix this but this is referring to the legacy v0.2 docs are you still using this?"}, {"author": "afkungl", "created_at": "2025-03-27T06:55:54Z", "body_clean": "@hesreallyhim No, not any more. I switched to the newest version. I find it good that it is now more obvious that this version is legacy."}]}, {"ollama_summary": "The UnstructuredHTMLLoader issue currently fails to parse HTML files correctly, despite attempts to troubleshoot through documentation, search, and updates to the LangChain library. The problem appears to be a bug within the library itself, not due to the user's code.  The issue specifically targets the ability to handle a specific data type (e.g., `[code]`) within the HTML document.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue stems from LangChain failing to include the \"labels\" metadata field in the metadata returned by `ConfluenceLoader` when `include_labels=True` is enabled. This consistently occurs with CQL queries, resulting in missing labels in the document metadata. The problem appears to be a bug within the LangChain integration, and attempts to update to the latest version have not resolved it.", "final_category": "bug", "comments": []}], "business_insights": ["LangChain CLI dependency issue impacts Grit CLI download, requiring updated version.", "Legacy documentation typo causes developer errors, impacting content clarification.", "Legacy v0.2 documentation is now outdated, requiring a switch to the latest version.", "Library bug hinders accurate HTML parsing, specifically with [code] data type.", "Integration bug causes missing labels in ConfluenceLoader metadata."], "technical_insights": ["LangChain library bug impacting HTML parsing, a recurring issue.", "Legacy documentation version 0.2 causing developer errors.", "LangChain library update not resolving the legacy bug.", "Dependency issue necessitates a new LangChain version.", "Integration bug affecting metadata fields in ConfluenceLoader."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain CLI dependency issue impacts Grit CLI download, requiring updated version.\n2. Legacy documentation typo causes developer errors, impacting content clarification.\n3. Legacy v0.2 documentation is now outdated, requiring a switch to the latest version.\n4. Library bug hinders accurate HTML parsing, specifically with `[code]` data type.\n5. Integration bug causes missing labels in ConfluenceLoader metadata.\n\nTECHNICAL INSIGHTS:\n1. LangChain library bug impacting HTML parsing, a recurring issue.\n2. Legacy documentation version 0.2 causing developer errors.\n3. LangChain library update not resolving the legacy bug.\n4. Dependency issue necessitates a new LangChain version.\n5. Integration bug affecting metadata fields in ConfluenceLoader.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 146, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where the `model` field in the `HuggingFaceEndpoint` package is missing crucial documentation, leading to confusion for developers. The `model` field is required, but its purpose and relationship to repository IDs are unclear.  The issue proposes adding detailed documentation clarifying the differences between the `code` and `code` fields to improve understanding and usability.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-09T16:01:20Z", "body_clean": "Hi, @KnightChaser. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights a lack of documentation for the [code] field in the [code] class. You noted that the documentation does not explain the differences between the [code] and [code] fields. Suggested improvement involves adding detailed descriptions to clarify these fields. No further comments or activity have been made on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue is a bug in LangChain that prevents the deletion of messages, causing a specific error message and stack trace. This problem isn’t related to the user’s code but rather a bug within the LangChain library itself, and the solution involves updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "Marsman1996", "created_at": "2025-01-08T15:27:45Z", "body_clean": "Is it OK to expose the [code] here?!"}, {"author": "keenborder786", "created_at": "2025-01-09T00:23:53Z", "body_clean": "@minmie I don't understand why you are trying to do this since you are using [code] the messages are kept in memory as long as the main process is running,.,"}, {"author": "minmie", "created_at": "2025-01-09T09:44:11Z", "body_clean": "Is it OK to expose the [code] here?! thanks,I forgot to remove it."}, {"author": "minmie", "created_at": "2025-01-09T09:57:38Z", "body_clean": "@keenborder786 1. I have a scenario where when a session expires or the user requests deletion, it triggers the clearing of historical messages. 2. You mean if I use another saver, such as PostgresSaver, this error will not occur?"}, {"author": "bhupendra171", "created_at": "2025-01-13T14:05:51Z", "body_clean": "@minmie i am facing issue, while deleting the messages for a subgraph. Did you find a solution ?"}, {"author": "minmie", "created_at": "2025-01-14T01:37:31Z", "body_clean": "@minmie i am facing issue, while deleting the messages for a subgraph. Did you find a solution ? @bhupendra171 I was also stumped."}, {"author": "SyedBaqarAbbas", "created_at": "2025-01-17T05:25:21Z", "body_clean": "@minmie the purpose of MemorySaver is to save the messages in memory (RAM). The messages are volatile and will automatically be cleared once your process ends. That is why it is a little confusing to understand why you'd want to delete messages from an already ephemeral storage. As mentioned in the [docstrings of MemorySaver]( [link] it is mostly used for testing. If you shift to PostgresSaver, you could directly delete the messages from the linked db."}, {"author": "SyedBaqarAbbas", "created_at": "2025-01-17T05:27:32Z", "body_clean": "If for some reason, you are unable to shift to a different MemorySaver, your error can be fixed simply using: [code] Explanation In your original code, you ran: [code] Without any mention of [code] (the previous node which requests the change), the method [code] eventually redirects the graph to [code] which expects the input message to contain a tool call. Due to the messages being empty, this tool call raises an error. Adding the [code] parameter to a node which does not lead to the conditional edge [code] should solve the issue."}, {"author": "minmie", "created_at": "2025-01-22T03:07:44Z", "body_clean": "If you shift to PostgresSaver, you could directly delete the messages from the linked db. @SyedBaqarAbbas Thanks for your help. I was wondering if Saver provides a native way to delete messages, or should I delete them myself?"}, {"author": "dosubot[bot]", "created_at": "2025-04-23T18:51:52Z", "body_clean": "Hi, @minmie. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug related to an error when deleting a message using [code] . The issue persists even after updating to the latest version of LangChain. SyedBaqarAbbas suggested using [code] for persistent storage and provided a code fix. You are considering whether to use a native method for message deletion or handle it manually. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue is a `TypeError` occurring when attempting to serialize a state containing a pandas DataFrame with `NA` values using LangChain.  The code attempts to serialize the DataFrame to JSON, but the serialization process fails due to the DataFrame containing `NA` values, potentially due to LangChain's internal serialization logic not correctly handling these values.  The bug is specific to LangChain's serialization implementation and doesn't appear to be a problem with the code itself, suggesting it’s a bug in the core serialization mechanism.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-09T16:01:17Z", "body_clean": "Hi, @sharifamlani. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] when serializing a DataFrame with [code] values in LangChain. Example code was provided to reproduce the issue. You confirmed the issue persists with the latest version of LangChain. No further comments or activity have been made on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is experiencing a bug where the `bulk_size` attribute of the `OpenSearchVectorSearch` object isn't reverting to its default value, leading to an error. This issue is affecting the `langchain` community v0.3.12 version. The code relies on `langsmith` and `langserve` libraries, and the bug is likely related to a compatibility issue with these dependencies.", "final_category": "bug", "comments": [{"author": "D4n13l1", "created_at": "2025-01-28T13:24:05Z", "body_clean": "The issue was resolved by simply adding the 'bulk size' parameter to the method call. After including this parameter, the function executed successfully. docsearch = OpenSearchVectorSearch.from documents( docs, embeddings, opensearch url=\" [link] [link] \"admin\"), use ssl = False, verify certs = False, ssl assert hostname = False, ssl show warn = False, engine=\"faiss\", bulk size=1000, )"}, {"author": "manukychen", "created_at": "2025-02-08T06:27:47Z", "body_clean": "Hi @kyledepasquale , thanks for reporting this! I am the contributor of PR 28325, and the issue will be fix soon. The problem can be resolved like @D4n13l1 suggest temporarily before I made new PR request and merged!"}, {"author": "epinzur", "created_at": "2025-02-12T18:38:43Z", "body_clean": "just found this issue too, thanks for the fix"}, {"author": "dosubot[bot]", "created_at": "2025-05-14T16:00:57Z", "body_clean": "Hi, @kyledepasquale. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] parameter not reverting to its default in [code] since v0.3.12. D4n13l1 suggested a temporary fix by explicitly adding the [code] parameter, which resolved the issue. manukychen, the contributor of the relevant pull request, acknowledged the problem and mentioned a permanent fix is forthcoming. epinzur also experienced the issue and appreciated the temporary solution. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a bug in LangChain that prevents the store field from being correctly populated when using the `openai.chat.completions.create` function. The issue stems from a discrepancy between the expected data and the actual response, requiring a solution involving updating the LangChain integration package.", "final_category": "feature", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-08T16:01:13Z", "body_clean": "Hi, @ajram23. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You requested support for OpenAI's [code] field in LangChain. This feature is needed for tracking prompt caching and could aid in fine tuning. Jacob Lee confirmed on Slack that this is a bug and advised submitting this request. No further comments or developments have occurred since the issue was opened. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Documentation gaps are a recurring problem, impacting developer understanding.", "Lack of clear code and code field distinctions hinders usability.", "Detailed documentation is crucial for maintaining and updating the model field.", "Adding documentation improves usability and reduces confusion.", "Addressing the documentation issue will improve developer experience."], "technical_insights": ["Missing documentation for model field causes confusion.", "The code and code field distinction is unclear.", "Updating to the latest stable LangChain version is the solution.", "LangChain’s serialization logic needs refinement.", "The bug is specific to the serialization implementation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Documentation gaps are a recurring problem, impacting developer understanding.\n2.  Lack of clear `code` and `code` field distinctions hinders usability.\n3.  Detailed documentation is crucial for maintaining and updating the `model` field.\n4.  Adding documentation improves usability and reduces confusion.\n5.  Addressing the documentation issue will improve developer experience.\n\nTECHNICAL INSIGHTS:\n1.  Missing documentation for `model` field causes confusion.\n2.  The `code` and `code` field distinction is unclear.\n3.  Updating to the latest stable LangChain version is the solution.\n4.  LangChain’s serialization logic needs refinement.\n5.  The bug is specific to the serialization implementation.\n\nRULES:\n1.  BUSINESS INSIGHTS:\n2.  TECHNICAL INSIGHTS:\n", "batch_number": 147, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GraphIndexCreator library is throwing a PydanticUserError when instantiated, preventing the notebook from running. The issue stems from a missing definition of the `rebuild()` method within the `GraphIndexCreator` class, requiring the user to explicitly define the code before attempting to run the model. The bug is likely related to the BaseCache requirement and the model rebuild process.", "final_category": "bug", "comments": [{"author": "VictorCrd", "created_at": "2025-02-08T08:27:25Z", "body_clean": "Came across the same error using VertexAI model. Based on this [link] I updated to latest pydantic version 2.10.6 but this dit not resolve the error However using 2.9.2 pydantic version it did resolve the error"}, {"author": "dosubot[bot]", "created_at": "2025-05-10T16:00:43Z", "body_clean": "Hi, @chaudhary codes. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] when using [code] in Google Colab. The error suggested defining [code] and calling [code] , which were not documented. VictorCrd found that downgrading to Pydantic version 2.9.2 resolved the issue. You acknowledged this solution with a thumbs up reaction. Next Steps: Please confirm if this issue is still relevant with the latest LangChain version. If not updated, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Langchain is experiencing issues returning irrelevant results for TavilySearch, specifically with low relevance scores. The issue stems from a bug within LangChain that doesn’t resolve with recent updates, impacting the search results displayed by Tavily.", "final_category": "bug", "comments": [{"author": "kbatsuren", "created_at": "2025-01-07T06:26:00Z", "body_clean": "Instead of including the scores in the output, another solution could be that TavilySearchResults may filter out the documents for a given threshold."}, {"author": "kbatsuren", "created_at": "2025-01-07T08:58:01Z", "body_clean": "@rotemweiss57 Could you have a look at this issue?"}, {"author": "keenborder786", "created_at": "2025-01-07T12:35:47Z", "body_clean": "@kbatsuren this is because of the following [clean results]( [link] You can get the raw results from same output as follow: [code]"}, {"author": "kbatsuren", "created_at": "2025-01-08T00:26:18Z", "body_clean": "@keenborder786 Thanks for the quick reply. My technical limitation is that many of my codes chained TavilySearch as a tool that calls the invoke function. Is there any way to keep this tool in the chain?"}]}, {"ollama_summary": "The `max_tokens` parameter in the `ChatOpenAI` object in LangChain is failing to function correctly, causing results to be truncated when exceeding 1,024 tokens.  The issue stems from a discrepancy between the documented behavior of the `max_tokens` function and the newly introduced `ChatOpenAI` object, despite the standard default value being 1024.  The code demonstrates this by encountering an error when generating results exceeding this limit.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-07T14:44:27Z", "body_clean": "OpenAI has [deprecated]( [link] the [code] parameter in favor of [code] . The API you are interacting with via the OpenAI SDK has not kept up with OpenAI's changes. Can you try using [code] instead? This supports [code] : [code]"}, {"author": "newispk", "created_at": "2025-01-08T00:54:51Z", "body_clean": "OpenAI has [deprecated]( [link] the [code] parameter in favor of [code] . The API you are interacting with via the OpenAI SDK has not kept up with OpenAI's changes. Can you try using [code] instead? This supports [code] : [code] Thanks it worked for me!"}]}, {"ollama_summary": "This issue asks for guidance on implementing advanced Retrieval Augmented Generation (RAG) in Databricks using Langchain, specifically focusing on techniques beyond standard catalog usage. The user is seeking a step-by-step documentation outlining how to achieve this with minimal reliance on Databricks catalogs and endpoints.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-09T16:01:17Z", "body_clean": "Hi, @Kushagra0409. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You requested enhanced documentation for advanced RAG techniques, focusing on reranking and hierarchical methods. The preference is for LangChain exclusive tools with minimal reliance on external catalogs and endpoints. Suggested separate documentation sections for each RAG technique for clarity. No further comments or activity have been made on this issue. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue is a Python ImportError occurring when attempting to import the `HTMLSemanticPreservingSplitter` from the `langchain text splitters.html` module. This is happening because the module is missing from the `langchain text splitters` package, which is causing the import to fail.", "final_category": "other", "comments": [{"author": "ccurme", "created_at": "2025-01-07T15:01:35Z", "body_clean": "Hi, thanks for this. That splitter is new and was just released in [code] . It was added to the documentation before the release, apologies for that oversight."}]}], "business_insights": ["Caching and Dependency Management are crucial for robust LangChain applications.", "Addressing the PydanticUserError proactively prevents runtime failures and improves user experience.", "Understanding the rebuild() method's role in the GraphIndexCreator is key to resolving the bug.", "The max_tokens parameter's behavior needs careful consideration, especially with recent updates.", "RAG implementation requires a more granular approach than simply leveraging catalogs."], "technical_insights": ["PydanticUserError handling is a critical error handling mechanism.", "The GraphIndexCreator’s missing rebuild() method necessitates explicit code definition.", "The ChatOpenAI object’s max_tokens parameter implementation is outdated.", "LangChain’s recent updates may have introduced a discrepancy in the max_tokens function.", "The HTMLSemanticPreservingSplitter import issue highlights dependency management requirements."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Caching and Dependency Management are crucial for robust LangChain applications.\n2.  Addressing the PydanticUserError proactively prevents runtime failures and improves user experience.\n3.  Understanding the `rebuild()` method's role in the `GraphIndexCreator` is key to resolving the bug.\n4.  The `max_tokens` parameter's behavior needs careful consideration, especially with recent updates.\n5.  RAG implementation requires a more granular approach than simply leveraging catalogs.\n\nTECHNICAL INSIGHTS:\n1.  PydanticUserError handling is a critical error handling mechanism.\n2.  The `GraphIndexCreator`’s missing `rebuild()` method necessitates explicit code definition.\n3.  The `ChatOpenAI` object’s `max_tokens` parameter implementation is outdated.\n4.  LangChain’s recent updates may have introduced a discrepancy in the `max_tokens` function.\n5.  The `HTMLSemanticPreservingSplitter` import issue highlights dependency management requirements.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 148, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code is encountering a TypeError because the `total_tokens` key already exists in a dictionary (`left dict`) that was created during the process of using a LangChain model, specifically with long conversations. This issue is occurring during the RAG flow when the model reaches a lengthy conversation.  The solution currently involves updating to the latest stable LangChain version, but the bug isn't being addressed through that update.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-07T16:00:54Z", "body_clean": "Hi, @azaylamba. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A [code] occurs with [code] when interacting with Claude models. The error is related to a [code] key being of type [code] . You confirmed this is a LangChain bug, persisting even after updating to the latest version. No comments or developments have been made on this issue yet. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GoogleSearchAPIWrapper is failing to interact with the Google Search API due to a timeout error (WinError 10060) when attempting to call it.  The issue stems from a lack of a proper integration package or a bug within the LangChain library itself, despite attempts to update to the latest version.  The code attempts to call the API, but the system fails to respond with the expected timeout.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-07T16:00:57Z", "body_clean": "Hi, @SetonLiang. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Encountering [code] with [code] . Direct access to the Google Search API via browser works fine. Issue persists even after updating to the latest LangChain version. No further comments or developments have been made. Next Steps Is this issue still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The `ChatPromptTemplate.format_messages` function fails to correctly handle f-strings inherited from BaseMessage, specifically SystemMessage, leading to unexpected results.  Initial investigations using LangChain documentation, GitHub search, and Stack Trace analysis suggest this is a bug within the core LangChain integration. The code attempts to process BaseMessage objects, but doesn't handle the inherited f-strings properly, resulting in an error.", "final_category": "bug", "comments": [{"author": "sirine707", "created_at": "2025-01-06T01:21:04Z", "body_clean": "Hi there ,To fix this, you need to modify the format messages method to process f strings here's the updated code let me know if iam not correct ! [code]"}, {"author": "dosubot[bot]", "created_at": "2025-04-07T16:01:00Z", "body_clean": "Hi, @TsinlingLi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the [code] method where f strings in [code] were not processed correctly. User sirine707 suggested a solution by modifying the method to handle f strings, providing a code snippet. The issue has been resolved with the proposed solution. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, feel free to keep the discussion open by commenting here. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that prevents the use of local HuggingFace tools with the generated prompts. The code attempts to utilize tools, but the LangChain documentation doesn’t explicitly define this functionality, and attempts to update to the latest version of LangChain haven’t resolved the problem. The core issue is a lack of support for tool calling within the prompt itself, requiring a fix to allow for this functionality.", "final_category": "bug", "comments": [{"author": "edmcman", "created_at": "2025-02-28T14:18:22Z", "body_clean": "Ping? Can someone tell me if this is expected or not?"}, {"author": "dosubot[bot]", "created_at": "2025-05-30T17:33:29Z", "body_clean": "Hi, @edmcman. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves the ChatHuggingFace integration in LangChain. Tools are not included in the prompt when using a local HuggingFacePipeline, contrary to the documentation. You suspect a discrepancy between the documentation and the code and have asked for clarification from the maintainers. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "edmcman", "created_at": "2025-05-30T18:48:13Z", "body_clean": "Still an issue"}, {"author": "dosubot[bot]", "created_at": "2025-05-30T18:50:25Z", "body_clean": "@eyurtsev, the user @edmcman has indicated that the issue with the ChatHuggingFace integration is still relevant. Could you please assist them with this?"}, {"author": "jedick", "created_at": "2025-07-14T05:01:50Z", "body_clean": "Tool calling with local models would be a great feature. The [docs for ChatHuggingFace.bind tools]( [link] say \"Assumes model is compatible with OpenAI tool calling API.\" Even more telling, the codepath for HuggingFacePipeline in ChatHuggingFace doesn't include the [parse tool call()]( [link] function. Therefore, I think support for tool calling with local models in ChatHuggingFace isn't currently supported. (Though it might be possible if the model is served locally with an OpenAI API.) Here's a workaround to use [HuggingFaceTB/SmolLM3 3B]( [link] locally with tools. The workaround depends on [ToolCallingLLM]( [link] which in turn is based on [OllamaFunctions]( [link] which is described as \"This was an experimental wrapper that bolted on tool calling support to models that do not natively support it\". Hopefully this workaround will become obsolete if and when support for tool calling is added to HuggingFacePipeline! [code] Output: AIMessage(content='', additional kwargs={}, response metadata={}, id='run cc7bf045 37c5 44ba 9189 f86739fb0703 0', tool calls=[{'name': 'duckduckgo search', 'args': {'query': 'silver medal in shooting at Paris Olympics 2024'}, 'id': 'call cda51d7d83274f77ad0752d366d33d10', 'type': 'tool call'}])"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nUsers are reporting a lack of documentation for using LangChain and DeepSeek with the model, specifically requesting information on how to integrate these tools. The issue highlights a critical gap in documentation and asks for guidance on utilizing the combination effectively.", "final_category": "other", "comments": [{"author": "Nydaym", "created_at": "2025-01-09T01:23:25Z", "body_clean": "You can use OpenAI compatible mode to utilize Deepseek"}, {"author": "Shajeel-Afzal", "created_at": "2025-01-16T19:26:11Z", "body_clean": "@alm0ra did you find any solution? I also want to integrate DeepSeek in my applications that are using LangChain!"}, {"author": "alm0ra", "created_at": "2025-01-16T19:44:07Z", "body_clean": "@Shajeel Afzal yes , integrated easily [code]"}]}], "business_insights": ["LangChain documentation is lacking for DeepSeek integration.", "Users need clearer guidance on combining LangChain and DeepSeek.", "Comprehensive documentation is crucial for users to effectively utilize these tools.", "Lack of documentation hinders adoption of LangChain and DeepSeek.", "User experience improves with better integration tutorials."], "technical_insights": ["LangChain documentation needs updates for DeepSeek integration.", "DeepSeek integration is lacking, requiring user guidance.", "The core LangChain integration needs to support tool calls.", "Documentation gaps hinder user adoption of LangChain & DeepSeek.", "Updated documentation is essential for user success."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain documentation is lacking for DeepSeek integration.\n2. Users need clearer guidance on combining LangChain and DeepSeek.\n3. Comprehensive documentation is crucial for users to effectively utilize these tools.\n4. Lack of documentation hinders adoption of LangChain and DeepSeek.\n5. User experience improves with better integration tutorials.\n\nTECHNICAL INSIGHTS:\n1. LangChain documentation needs updates for DeepSeek integration.\n2. DeepSeek integration is lacking, requiring user guidance.\n3. The core LangChain integration needs to support tool calls.\n4. Documentation gaps hinder user adoption of LangChain & DeepSeek.\n5. Updated documentation is essential for user success.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 149, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The LangChain ollama library is experiencing a critical bug that prevents it from correctly identifying tool calls. The code example fails when attempting a simple ollama call, and the issue is not resolved by updating the library. This appears to be a fundamental problem with the library's integration of tool calls, potentially related to a bug in the underlying implementation.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2025-01-05T03:01:57Z", "body_clean": "Thanks for reporting this. I'm unable to reproduce the issue. Could you share what version of Ollama you're using? (i.e., [code] )"}, {"author": "ofri", "created_at": "2025-01-05T05:17:57Z", "body_clean": "[code]"}, {"author": "ofri", "created_at": "2025-01-05T21:02:31Z", "body_clean": "@ccurme Upgrading to latest ollama (0.5.4) solves the issue. So maybe just add to the documentation a minimum ollama version that is supported? Or detect ollama version and issue a warning in the code if running with a version that is too old? relevant documentation: [link] and [link]"}, {"author": "dosubot[bot]", "created_at": "2025-04-06T16:03:05Z", "body_clean": "Hi, @ofri. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involved a broken tool usage in [code] version 0.2.2, causing an [code] . The problem did not occur in version 0.2.1. You confirmed that upgrading to Ollama version 0.5.4 resolved the issue. Suggested improvements include updating documentation for minimum Ollama version or adding a version check with a warning. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is experiencing a `BadRequestError` when calling the LangChain model, specifically due to an issue with the tool call ID format. The error message indicates a problem with the `param` field within the `tool call IDs` structure, requiring a modification to the ID format. The code attempts to generate a tool call ID using the `search` engine, but the generated ID format is incorrect, causing the error. The traceback points to a potential issue with the LangChain model's configuration or integration, requiring investigation into the model's parameters and the `tool call IDs` structure.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-04T22:32:46Z", "body_clean": "@RachelShalom I have optimized your code and all is working well, please check: [code]"}, {"author": "RachelShalom", "created_at": "2025-01-07T15:55:45Z", "body_clean": "Hey @keenborder786 thank for this I see you changed the model for the mistralAI class. I am using a local endpoint ( not mistral AI) which does not seem to work well with mistralAIchatbot class"}, {"author": "dosubot[bot]", "created_at": "2025-04-08T16:01:02Z", "body_clean": "Hi, @RachelShalom. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] with error code 400 related to tool call IDs needing to be alphanumeric strings of length 9. The issue persists even after updating to the latest version of LangChain. User keenborder786 provided an optimized code snippet using the MistralAI model, which resolved the issue for them. You mentioned that the solution is not applicable to your setup due to using a local endpoint incompatible with the MistralAI class. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nLangChain maintainer is experiencing issues with integration tests failing, specifically due to inconsistencies in the Pinecone index and a hanging test vector store.  The issue stems from potential compatibility problems with a recent Pinecone client version, potentially affecting the ability to release the current package.  The root cause is likely related to the serverless index being the source of the problem.", "final_category": "bug", "comments": [{"author": "efriis", "created_at": "2025-01-07T21:24:55Z", "body_clean": "fixed"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe example for the `FewShotChatMessagePromptTemplate` GitHub issue lacks a required prefix, hindering its functionality.  The issue focuses on a specific code example that’s currently being reviewed and requires a fix.  The proposed solution involves adding a descriptive title and linking to the relevant documentation.", "final_category": "other", "comments": []}, {"ollama_summary": "The issue involves a caching problem in ChatOpenAI that prevents the correct serialization of Pydantic classes and JSON data. This occurs when the cache is not properly restoring the serialized output from Redis and Elasticsearch, hindering the functionality of the ChatOpenAI integration.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-04T23:02:39Z", "body_clean": "@giacbrd this happens because of the following [line]( [link] some objects which are kept as a string in the cache do not implement searlization which in turn raises an exceptions, and returns a [code] . And this Generation object is not compatible with [code] which is returned at the following [line]( [link] when chat model hit the cache. The simplest solution is to use InMemoryCache or Redis as cache at the moment as shown: [code]"}, {"author": "giacbrd", "created_at": "2025-01-05T21:33:29Z", "body_clean": "thanks @keenborder786 , yes I am aware of that limitation, in fact the [code referenced in my previous comment]( [link] is the \"back off\" of this lack of serialization implementation. From what I understand, it seems a limit in the design of this part. An object must be json serializable or must implement the [code] interface, so any arbitrary object cannot be properly serialized with the current methods. Redis cache should have the same problems, according to my tests on a plain Redis server (and also looking at the code). Unfortunately the memory cache, which is a simple unlimited dict, cannot be a choice in a production environment."}, {"author": "gltanaka", "created_at": "2025-02-16T01:54:28Z", "body_clean": "I am also having the issue"}, {"author": "ravirajag", "created_at": "2025-02-19T12:41:26Z", "body_clean": "I am also facing the same issue."}, {"author": "tyommik", "created_at": "2025-07-18T16:01:55Z", "body_clean": "Same problem"}]}], "business_insights": ["Integration testing is failing, requiring Pinecone index consistency.", "Cache restoration issues are causing serialization problems.", "Tool call ID format inconsistencies are hindering Ollama library functionality.", "Pinecone index caching needs improvement.", "Model parameter configuration needs review."], "technical_insights": ["Ollama library integration is failing, likely due to tool call ID format.", "Pinecone index caching and Redis restore are causing serialization issues.", "Cache restoration is critical for tool call ID format.", "Tool call ID format inconsistency impacts Ollama library.", "Pinecone index configuration needs investigation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integration testing is failing, requiring Pinecone index consistency.\n2. Cache restoration issues are causing serialization problems.\n3. Tool call ID format inconsistencies are hindering Ollama library functionality.\n4. Pinecone index caching needs improvement.\n5. Model parameter configuration needs review.\n\nTECHNICAL INSIGHTS:\n1. Ollama library integration is failing, likely due to tool call ID format.\n2. Pinecone index caching and Redis restore are causing serialization issues.\n3. Cache restoration is critical for tool call ID format.\n4. Tool call ID format inconsistency impacts Ollama library.\n5. Pinecone index configuration needs investigation.", "batch_number": 150, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a problem with LangChain attempting to use a specific OpenAI model (gpt-4o-2024-05-13-cached) that’s not recognized, resulting in a \"Unknown model\" error. The code attempts to use this model, but the system can't find it, likely due to a configuration issue or a problem with the model itself. The suggested solution is to update LangChain to the latest stable version, which might resolve the issue.", "final_category": "bug", "comments": [{"author": "JanPalasek", "created_at": "2025-01-03T09:22:14Z", "body_clean": "The problem is that [code] calls [code] , even if there are no tokens cached. If the model is not cacheable, [code] raises an error. This should not happen, since we did not want any caching in the first place and thus the caching tokens is zero, so there is not even a point in computing the cost."}, {"author": "ziqizhang", "created_at": "2025-01-12T21:51:04Z", "body_clean": "Can confirm that I also get this error, when I use custom fine tuned models. Is there a fix?"}, {"author": "ccurme", "created_at": "2025-01-13T17:42:38Z", "body_clean": "Can confirm that I also get this error, when I use custom fine tuned models. Is there a fix? @ziqizhang this should be fixed in [code] . Are you running into the issue after upgrade?"}, {"author": "ziqizhang", "created_at": "2025-01-13T19:05:08Z", "body_clean": "Yes, I am using langchain community 0.3.14 already..."}, {"author": "PotatoSpudowski", "created_at": "2025-01-23T05:42:29Z", "body_clean": "I still face this issue with [code] @ccurme what do you suggest we do to override this behaviour as a quick fix till this gets fixed for good?"}, {"author": "ziqizhang-at-ai", "created_at": "2025-03-11T14:59:04Z", "body_clean": "Any update to this?"}, {"author": "ziqizhang-at-ai", "created_at": "2025-03-12T12:12:42Z", "body_clean": "Can confirm that after migrating to the most recent libraries, this warning goes away."}]}, {"ollama_summary": "The issue reports a TypeError when using DeterministicFakeEmbedding with Pinecone Vectorstore.  The problem appears to be a bug within LangChain that’s not being addressed with updates to the latest version.  The code is functionally identical to the example provided in the documentation, suggesting it’s a fundamental issue within the library rather than a specific modification by the user.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-04-03T16:00:48Z", "body_clean": "Hi, @MichaelSkralivetsky. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug is reported when using [code] with the Pinecone vector store. The error encountered is a [code] . The issue persists even after updating to the latest version of LangChain. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If it is, you can keep the discussion open by commenting here. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "MichaelSkralivetsky", "created_at": "2025-04-06T10:13:50Z", "body_clean": "still reproducible with latest: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-04-06T10:16:08Z", "body_clean": "@eyurtsev, the user @MichaelSkralivetsky has confirmed that the issue with [code] and the [code] is still reproducible with the latest version. Could you please assist them with this issue?"}]}, {"ollama_summary": "The SlackToolkit code is failing due to a PydanticUserError, specifically because the `Toolkit` object is not fully defined. The issue stems from a missing definition of the `Toolkit` class within the code, and the user has encountered a similar error while trying to use WebClient.  The solution involves defining the `Toolkit` class and potentially updating the WebClient integration.", "final_category": "bug", "comments": []}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe code in the function declaration doesn’t match the documentation, specifically the function description. This discrepancy is causing potential confusion and may require adjustments to ensure consistent documentation. The issue proposes adding a closing bracket to the `Union` keyword arguments to resolve this issue.", "final_category": "other", "comments": []}, {"ollama_summary": "The GitHub issue reports a deprecation of the 'api' backend for DuckDuckGo Search and presents a warning in LangChain about using it. The code attempts to access the DuckDuckGo Search API, but the API is being used instead of the more efficient 'auto' backend. The issue suggests a potential bug in LangChain and requires a simple code change to resolve it.", "final_category": "bug", "comments": [{"author": "matemiro", "created_at": "2024-12-29T15:03:04Z", "body_clean": "It depends on which [code] version you use. There is also new possible value [code] , which was added in version [7.1.0]( [link] [code] was deprecated in [7.1.1]( [link] From 7.1.1 all possible options are: [code] , [code] , [code] and [code] ."}, {"author": "dosubot[bot]", "created_at": "2025-03-30T16:00:44Z", "body_clean": "Hi, @qaiwiz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a deprecation warning with the [code] tool when using the 'api' backend. You suggested switching the backend to \"auto\" to resolve the warning. @matemiro noted that the 'api' backend was deprecated in version 7.1.1, with new options being [code] , [code] , [code] , and [code] . Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Model updates frequently introduce regressions, requiring careful testing and rollback strategies.", "Dependency management is crucial; outdated dependencies can destabilize the system.", "Documentation clarity directly impacts developer productivity; improved documentation reduces confusion."], "technical_insights": ["LangChain’s model selection process is sensitive to configuration; consistent configurations are vital.", "The Unknown model error highlights a potential issue with model compatibility or caching.", "The TypeError in DeterministicFakeEmbedding suggests a fundamental bug within the library’s implementation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Model updates frequently introduce regressions, requiring careful testing and rollback strategies.\n2.  Dependency management is crucial; outdated dependencies can destabilize the system.\n3.  Documentation clarity directly impacts developer productivity; improved documentation reduces confusion.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s model selection process is sensitive to configuration; consistent configurations are vital.\n2.  The `Unknown model` error highlights a potential issue with model compatibility or caching.\n3.  The `TypeError` in DeterministicFakeEmbedding suggests a fundamental bug within the library’s implementation.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n", "batch_number": 151, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code attempts to use the `azure document intelligence loader` with a `bytes_source` parameter, but the `begin analyze document` function requires a `body` argument, leading to a `TypeError`. This likely stems from an issue with the integration package or a configuration problem within the LangChain code.", "final_category": "bug", "comments": [{"author": "jacobreesmontgomery", "created_at": "2025-03-06T17:21:52Z", "body_clean": "Hi! I am having this same issue still, even with the latest version of the [code] library. When is this estimated to be fixed? I see that it is still open."}, {"author": "dosubot[bot]", "created_at": "2025-06-05T16:01:40Z", "body_clean": "Hi, @hiroci. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a TypeError in [code] when using [code] . The error is due to an incorrect argument name in the [code] function. You suggested changing the argument name from [code] to [code] or omitting it. User jacobreesmontgomery confirmed experiencing the same issue with the latest version and asked about a fix timeline. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue proposes adding the \"developer\" role to the ChatPromptTempkate project, allowing developers to contribute to the code and potentially extend its functionality. This is a requested feature by a LangChain maintainer to facilitate developer involvement and collaboration.", "final_category": "feature", "comments": [{"author": "keenborder786", "created_at": "2024-12-27T23:04:21Z", "body_clean": "@baskaryan please check, the PR."}, {"author": "dosubot[bot]", "created_at": "2025-03-28T16:00:50Z", "body_clean": "Hi, @baskaryan. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You requested the addition of a \"developer\" role to the [code] . The goal is to enable the use of a tuple format. @keenborder786 prompted you to review a related pull request, indicating a potential solution is in progress. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that prevents the use of the `max_completion_tokens` parameter when interacting with the OpenAI library due to a change in the OpenAI Python library's implementation. While LangChain itself isn’t the cause, the bug is currently unresolved and requires a workaround until the OpenAI library updates its integration.", "final_category": "bug", "comments": [{"author": "QuentinFuxa", "created_at": "2024-12-27T20:51:32Z", "body_clean": "Thank you for reporting this issue. It seems likely that the problem lies in the version of the OpenAI Python library you have installed. I tested a similar setup using the following versions: • Python: 3.12.6 • langchain openai: 0.2.14 • openai: 1.58.1 Here’s the code I used for testing: [code] The call to the OpenAI client is done here in the LangChain codebase: [link] In this test, the payload being sent to OpenAI contained: [code] This payload worked correctly without any errors. Could you double check the version of the OpenAI Python library in your environment? Specifically, ensure you are using openai==1.58.1. If you confirm that you’re using the correct version and the issue persists, please share additional details about your setup or any modifications you might have made to the code. Maybe the OpenAI lib uses different parameters depending on the model you use?"}, {"author": "dosubot[bot]", "created_at": "2025-03-28T16:00:53Z", "body_clean": "Hi, @Armasse. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] parameter in the [code] function. QuentinFuxa suggested the issue might be related to the OpenAI Python library version. QuentinFuxa tested with specific versions and found no errors, recommending openai version 1.58.1. Next Steps: Please confirm if this issue is still relevant with the latest LangChain version. If so, feel free to comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a `AttributeError: 'str' object has no attribute 'tool'` error within the LangChain agent workflow, specifically when attempting to access the `tool` attribute of the `agent` node. This likely stems from a problem with the agent's configuration or initialization, potentially related to a recent update or a bug in the agent's internal logic. The traceback points to a potential issue with the `agent` node's initialization or the `tool` attribute's implementation, requiring investigation into the agent's configuration and the specific integration package being used.", "final_category": "bug", "comments": [{"author": "jason571", "created_at": "2024-12-27T07:33:18Z", "body_clean": "self.prompt = config.get prompt(\"system monitor template test3\") self.system = self.prompt graph = StateGraph(AgentState) graph.add node(\"llm\", self.call agents) graph.add node(\"action\", self.take action) graph.add conditional edges( \"llm\", self.exists action, {True: \"action\", False: END} ) self.llm = self.interface.get current model(0.2,0.2,10) self.create tools() graph.add edge(\"action\", \"llm\") graph.set entry point(\"llm\") self.memory = SqliteSaver.from conn string(\":memory:\") self.memory = MemorySaver() self.graph = graph.compile(checkpointer=self.memory) def create tools(self): \"\"\"Creates tools for the agent\"\"\" retriever = self.interface.get retriever() function = FunctionCall(retriever) self.tools = function.get tools() self.toolsData = {t.name: t for t in self.tools} def exists action(self, state: AgentState): result = state['messages'][ 1] return len(result.tool calls) 0 def call agents(self, state: AgentState): if not self.agent executor: self.create agent node() messages = state.get('messages', []) mylogging.info(messages) result = self.agent executor.invoke({\"messages\": messages}) return {'messages': [result]}"}, {"author": "jason571", "created_at": "2024-12-27T07:41:04Z", "body_clean": "This error looks like the LLM has already returned"}, {"author": "jason571", "created_at": "2024-12-27T08:35:07Z", "body_clean": "This may be my wrong way of using it, the issue can be close"}, {"author": "keenborder786", "created_at": "2024-12-27T10:14:16Z", "body_clean": "[code] should be a list of [code] class"}, {"author": "dosubot[bot]", "created_at": "2025-03-28T16:00:53Z", "body_clean": "Hi, @jason571. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered an [code] in your LangChain code, related to a 'str' object being accessed incorrectly. You provided a code snippet and initially suspected a bug in LangChain. You later acknowledged the error might be due to your own misuse and suggested closing the issue. Keenborder786 advised that [code] should be a list of [code] class, which could resolve the problem. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If it is, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue is that the `yfinance` library is failing to correctly parse the output of the chat model, leading to an incorrect result. This problem is not related to the LangChain code itself and is likely a bug in the `yfinance` integration.  The solution involves updating to the latest stable version of LangChain, but this doesn't resolve the issue.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-27T10:29:32Z", "body_clean": "You need to update your system Prompt and make it more comprehensive, something like this should work: [code]"}, {"author": "dlin95123", "created_at": "2024-12-27T21:13:11Z", "body_clean": "Your modified system prompt yields the same results. It does not improve the results. Note that ChatGroq yields correct answers for both system prompts (my original and your modified) with the same LLM model, Llama3.1:8b, as used for ChatOllama. With ChatGroq, it answers the address correctly. But with ChatOllama, it yields the following answer: Based on the provided JSON data, here are some key statistics and insights about Nike, Inc. (NKE): Financials Market Capitalization: $113.8 billion Enterprise Value: $116.6 billion Total Debt: $121.3 billion Cash and Cash Equivalents: $10.2 billion Earnings Per Share (EPS): $3.24 (trailing), $3.23 (forward) Revenue Growth: 0.104% (quarter over quarter) Valuation Price to Earnings (P/E) Ratio: 23.59 (trailing), 29.07 (forward) Price to Book (P/B) Ratio: 7.96 Dividend Yield: 0.0208% Forward P/E Ratio: 29.07 Growth Earnings Growth: 0.255% (quarter over quarter) Revenue Growth: 0.104% (quarter over quarter) Operational Performance Gross Margin: 44.97% Operating Margin: 10.43% Return on Equity (ROE): 37.98% Free Cash Flow: $6.57 billion Analyst Estimates Average Analyst Rating: Buy Recommendation Mean: 2.18 Number of Analysts: 34 Industry and Market Positioning Industry: Consumer Discretionary Sub Industry: Apparel & Footwear Retailers Market Capitalization Rank: 1 in Consumer Discretionary, 4 in Apparel & Footwear Retailers Please note that these statistics are based on the provided JSON data and may not reflect the current market situation or future performance of Nike, Inc. (NKE)."}, {"author": "dlin95123", "created_at": "2025-01-06T01:18:33Z", "body_clean": "It turns out that ChatOllama has an additional parameter, num ctx. The default is only 2048. After increasing it to larger numbers, ChatOllama works correctly too."}]}], "business_insights": ["Integration package compatibility is a key focus; ensure latest versions across all components.", "OpenAI library updates frequently; monitor and test updates to identify and mitigate bugs.", "Agent configuration stability is crucial; investigate potential configuration drift impacting agent behavior.", "Integration package version control is important; track and manage updates effectively.", "Agent initialization logic must be stable; address potential initialization issues."], "technical_insights": ["LangChain package version control is vital; maintain consistent versions across the codebase.", "OpenAI library updates frequently; prioritize updates to address bugs and security vulnerabilities.", "Agent configuration stability is critical; investigate potential configuration drift impacting agent performance.", "Integration package compatibility is a major concern; ensure all packages work together seamlessly.", "Agent initialization logic must be robust; address potential initialization failures."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integration package compatibility is a key focus; ensure latest versions across all components.\n2. OpenAI library updates frequently; monitor and test updates to identify and mitigate bugs.\n3. Agent configuration stability is crucial; investigate potential configuration drift impacting agent behavior.\n4. Integration package version control is important; track and manage updates effectively.\n5. Agent initialization logic must be stable; address potential initialization issues.\n\nTECHNICAL INSIGHTS:\n1. LangChain package version control is vital; maintain consistent versions across the codebase.\n2. OpenAI library updates frequently; prioritize updates to address bugs and security vulnerabilities.\n3. Agent configuration stability is critical; investigate potential configuration drift impacting agent performance.\n4. Integration package compatibility is a major concern; ensure all packages work together seamlessly.\n5. Agent initialization logic must be robust; address potential initialization failures.\n", "batch_number": 152, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a `KeyError: 'request'` occurring within the `langchain_community.llms.tongyi` module when attempting to use the Tongyi LLM model. This problem is causing errors when calling the `chain.invoke()` function, seemingly related to an unstable API base URL. The code attempts to utilize the model, but it fails with the `KeyError` due to an unexpected `request` key being absent in the model's response.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-26T18:23:20Z", "body_clean": "@Coolgiserz this might be a problem [code] package itself."}, {"author": "Coolgiserz", "created_at": "2024-12-27T07:29:08Z", "body_clean": "Thanks for your reply. After conducting some debugging, I’ve discovered that the dashscope package seems to be masking actual user related errors. Instead of exposing the specific issues related to the user’s actions or environment, it throws a generic internal processing exception. ![image]( [link] I will further investigate this behavior and provide more details if needed."}, {"author": "Coolgiserz", "created_at": "2024-12-27T10:45:52Z", "body_clean": "![image]( [link] Sometimes raise KeyError while reaching request rate limit."}, {"author": "safa1018", "created_at": "2025-03-03T03:25:50Z", "body_clean": "so how to solve it"}, {"author": "Endorphins20", "created_at": "2025-03-06T12:36:01Z", "body_clean": "so how to solve it"}, {"author": "Coolgiserz", "created_at": "2025-03-21T10:21:44Z", "body_clean": "This issue is actually caused by insufficient access permissions to the Qwen model or exceeding the request rate limit. You can confirm that you have the model access permission on the Alibaba Cloud official website. Refer to the QPS constraints of the service and reduce concurrent requests. If you need to handle exceptions, capture the status code in the GenerationResponse."}]}, {"ollama_summary": "The issue involves a bug in the OpenAI Assistant Runnable package that prevents the retrieval of usage details for the API. This results in a specific error message and stack trace, and the code returns the expected fields but doesn't provide usage details.  The issue appears to be a bug within LangChain itself, and attempts to update to the latest stable version haven't resolved it.", "final_category": "bug", "comments": [{"author": "Smit3949", "created_at": "2024-12-26T11:47:41Z", "body_clean": "Hey @hwchase17, @efriis could you please take a look at this issue?"}, {"author": "dosubot[bot]", "created_at": "2025-03-27T16:01:01Z", "body_clean": "Hi, @Smit3949. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the LangChain library with [code] not returning usage details. This issue affects charging users based on token usage. The problem persists even after updating to the latest version. You have verified it as a bug and requested attention from maintainers @hwchase17 and @efriis. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Tongyi llm is experiencing a critical error when calling the \"qwen-long\" model, returning incorrect output (\"choices\" instead of \"text\").  Initial investigation suggests a bug within the LangChain integration for this model, specifically related to the API response format.  The issue is currently unresolved by updating LangChain and may require further investigation into the Tongyi server’s response structure.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-26T18:55:28Z", "body_clean": "qwen long might be a chat based model therefore it is returning the output in [code] . Can you try the same call with [code] and it should work."}, {"author": "niuguy", "created_at": "2024-12-27T00:14:24Z", "body_clean": "@keenborder786 Thanks for your response. However, is it possible to use this model consistently with other models? as I would allow users to switch models in my app. Additionally, qwen long is supposed to handle extremely long prompts, making it ideal for one shot invocations."}, {"author": "keenborder786", "created_at": "2024-12-27T10:11:49Z", "body_clean": "Why don't you just use [code]"}, {"author": "niuguy", "created_at": "2024-12-27T13:55:55Z", "body_clean": "OK I see what you mean, yes ChatTongyi works for all. Thanks"}]}, {"ollama_summary": "The issue stems from a discrepancy between the documented functionality of `HTMLSemanticPreservingSplitter` in the API References and its absence in version 0.3.4 of the langchain text splitters library. This prevents users from utilizing the documented feature, leading to import errors.  The problem is currently being addressed by adding a descriptive title and linking to the relevant documentation.", "final_category": "other", "comments": [{"author": "mohammedsalah-ai", "created_at": "2025-01-04T15:22:16Z", "body_clean": "Yeah I have faced the same problem as well. to experiment with it I just copied the source into my file"}, {"author": "dosubot[bot]", "created_at": "2025-04-05T16:02:55Z", "body_clean": "Hi, @aliemir. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a mismatch between the API documentation and the [code] package version 0.3.4. The [code] is documented but not exported, leading to import errors. Another user, mohammedsalah ai, encountered the same issue and temporarily resolved it by copying the source code directly. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If the issue persists, feel free to comment to keep the discussion open; otherwise, it will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is experiencing a critical error when attempting to use Milvus for cosine similarity. Specifically, it's encountering a `MilvusException: (code=1100, message=fail to search: metric type not match: invalid [expected=L2][actual=COSINE]: invalid parameter)` error, indicating a mismatch between the expected and actual cosine similarity metric type. This issue appears to be occurring during the `search` function call within the `vector store.similarity` method.  The code is using `langchain` and `milvus` libraries, and the error suggests a problem with the Milvus integration itself, possibly related to the specified metric type.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2025-01-02T22:22:58Z", "body_clean": "I use the same exact code as follow and it worked. [code] Can you make sure that you are using the correct imports."}, {"author": "yang-collect", "created_at": "2025-03-12T12:45:35Z", "body_clean": "Actually!Langchain can not set index params and search params!Even if you set those,it will work with L2 and another index way."}, {"author": "dosubot[bot]", "created_at": "2025-06-11T16:02:07Z", "body_clean": "Hi, @pierowu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an RPC error with Milvus when using cosine similarity, indicating a metric type mismatch. @keenborder786 suggested checking imports and shared a code snippet that worked for them. @yang collect highlighted that LangChain defaults to 'L2' metric, not supporting custom [code] and [code] . This suggests a limitation or bug in LangChain's handling of these parameters. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Addressing the KeyError with the Tongyi LLM model suggests a potential issue with the API’s response format or data structure, requiring a deeper investigation into the model’s response generation process.", "The discrepancy between the documented HTMLSemanticPreservingSplitter and its absence in version 0.3.4 highlights potential inconsistencies in the LangChain library’s API and its integration with external components.", "The Milvus issue indicates a problem with the Milvus integration, potentially requiring a review of the metric type configuration and integration logic.", "The LangChain and milvus integration suggests a potential dependency issue or incompatibility within the LangChain package itself.", "Addressing the bug related to the qwen-long model suggests a need for improved error handling or validation within the LangChain integration for this specific model."], "technical_insights": ["**LangChain Version:** The milvus issue strongly suggests a version mismatch between LangChain and the Milvus library, requiring a rollback to a stable version.", "**API Response Format:** The KeyError in the Tongyi LLM context points to an unexpected response structure within the API, necessitating a thorough examination of the API’s response format.", "**Milvus Metric Type:** The MilvusException highlights a critical integration problem with the Milvus metric type, demanding a review of the metric type configuration and integration logic.", "**LangChain Dependency:** The HTMLSemanticPreservingSplitter issue indicates a potential dependency conflict or incompatibility with the LangChain package, requiring a potential update or re-installation.", "**Integration Testing:** The qwen-long model issue requires comprehensive integration testing of the LangChain integration to ensure the model functions correctly across various scenarios."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing the `KeyError` with the Tongyi LLM model suggests a potential issue with the API’s response format or data structure, requiring a deeper investigation into the model’s response generation process.\n2. The discrepancy between the documented `HTMLSemanticPreservingSplitter` and its absence in version 0.3.4 highlights potential inconsistencies in the LangChain library’s API and its integration with external components.\n3. The Milvus issue indicates a problem with the Milvus integration, potentially requiring a review of the metric type configuration and integration logic.\n4. The `LangChain` and `milvus` integration suggests a potential dependency issue or incompatibility within the LangChain package itself.\n5. Addressing the bug related to the `qwen-long` model suggests a need for improved error handling or validation within the LangChain integration for this specific model.\n\nTECHNICAL INSIGHTS:\n1.  **LangChain Version:** The `milvus` issue strongly suggests a version mismatch between LangChain and the Milvus library, requiring a rollback to a stable version.\n2.  **API Response Format:** The `KeyError` in the Tongyi LLM context points to an unexpected response structure within the API, necessitating a thorough examination of the API’s response format.\n3.  **Milvus Metric Type:** The `MilvusException` highlights a critical integration problem with the Milvus metric type, demanding a review of the metric type configuration and integration logic.\n4.  **LangChain Dependency:** The `HTMLSemanticPreservingSplitter` issue indicates a potential dependency conflict or incompatibility with the LangChain package, requiring a potential update or re-installation.\n5.  **Integration Testing:** The `qwen-long` model issue requires comprehensive integration testing of the LangChain integration to ensure the model functions correctly across various scenarios.\n", "batch_number": 153, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue relates to a bug where the LangChain Structured Chat format generates incorrect or unhelpful responses, specifically when the input is structured as “FINAL ANSWER”.  After investigating using LangChain’s search and documentation, the problem appears to be a fundamental issue within the format’s interpretation logic.  Currently, the bug isn’t addressed by updating the LangChain version, and the suggested solution is to ensure the input format is correctly structured.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-26T16:00:56Z", "body_clean": "Hi, @Cloverxue. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Bug reported in [code] . Language model misinterprets \"Final Answer\" as an input. Suggested fix: change \"action input\" to \"action output\". Issue persists in the latest version of LangChain. No additional comments or developments. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a bug in LangChain Chroma that causes a streamlit user program to get stuck in a specific code snippet, resulting in a non-error message.  The problem appears to be related to the integration of Chroma with Streamlit, and the issue hasn’t been resolved by updating the LangChain library.  The user is experiencing a consistent error in a specific section of the code, and the issue persists across multiple executions.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-26T16:00:53Z", "body_clean": "Hi, @Jackmoyu001. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Reported bug in LangChain when integrated with Streamlit. Application runs correctly on the first execution but fails on subsequent runs. No error messages are provided during the failure. Issue persists even after updating to the latest version of LangChain. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "hesreallyhim", "created_at": "2025-03-26T16:25:27Z", "body_clean": "hi, sorry if this is not helpful, i haven't had time to study the code carefully, but i have been working with streamlit apps a lot, have you tried making the vector store a [code] ? it seems like a natural thing to do."}, {"author": "dosubot[bot]", "created_at": "2025-03-26T16:27:41Z", "body_clean": "@eyurtsev, the user has indicated that the issue with LangChain and Streamlit is still relevant and has provided a suggestion regarding using [code] . Could you please assist them with this issue?"}, {"author": "hesreallyhim", "created_at": "2025-03-26T17:07:04Z", "body_clean": "Just to clarify, I'm not really suggesting this is a LangChain issue because of the way Streamlit renders the whole app top to bottom on every run, if the [code] block is hit, it's going to recreate the vector store every time. Unless this is what @Jackmoyu001 intends, it's probably best to just put the [code] decorator above the [code] function, this should prevent it from being invoked on every cycle. I've been using langchain chroma with a Streamlit app and I have managed to make it work."}, {"author": "dosubot[bot]", "created_at": "2025-06-25T16:03:07Z", "body_clean": "Hi, @Jackmoyu001. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug where LangChain fails on subsequent runs with Streamlit, without error messages. The issue persists even after updating to the latest version. A suggestion was made by hesreallyhim to use [code] for the vector store to potentially resolve the issue. I previously marked the issue as stale and notified eyurtsev for further assistance. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If it is, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's `BedrockChat` component, specifically when handling input requests for models like Amazon Nova Lite v1.0. The code attempts to parse a `messages` key, which is not found in the expected format, leading to a `ValidationException`.  The issue appears to be a problem with the model's input parsing logic, and the solution requires a reformatting of the input to conform to the expected format.", "final_category": "bug", "comments": [{"author": "efriis", "created_at": "2024-12-24T20:26:33Z", "body_clean": "this integration is deprecated. Would recommend [code] and if you see the same issue, please file an issue for the aws folks to see at [link] !"}]}, {"ollama_summary": "The issue reports a bug in LangChain where the `RemoveMessage` message type is not properly handled, causing errors when converting messages to a dictionary format.  Initial investigations using documentation, search, and GitHub’s search haven’t identified a solution. The bug appears to be a fundamental issue within the LangChain library itself, and attempts to update to newer versions haven’t resolved it.", "final_category": "bug", "comments": [{"author": "daher928", "created_at": "2024-12-24T08:47:42Z", "body_clean": "@hwchase17 Hello Harrison, could you please take a lot at this issue?"}, {"author": "efriis", "created_at": "2024-12-24T20:24:35Z", "body_clean": "Assigning to @vbarda ! I believe the [code] was intended as a langgraph feature, and we may want to add this as a feature of [code] to remove this confusion. I don't think this is a regression (i.e. this always behaved this way). Let me know if that seems right to you!"}, {"author": "daher928", "created_at": "2024-12-24T22:00:42Z", "body_clean": "@efriis It happens when I try to remove messages from graph state in LangGraph and using Azure chat model I would appreciate fixing it as soon as possible! :) Thanks!"}, {"author": "daher928", "created_at": "2024-12-27T13:44:41Z", "body_clean": "Hi @vbarda @efriis , Any updates regarding this issue ?"}, {"author": "eyurtsev", "created_at": "2024-12-27T14:46:28Z", "body_clean": "Hi @daher928 it's holidays season so many of the maintainers are out of office for another week. The issue looks like usage error rather than a bug from the given explanation and code snippet. Remove message should never be sent to a chat model. It's a message type that's used only by the persistence layer of langgraph. If you can share an example of the code you're using with langgraph."}, {"author": "daher928", "created_at": "2024-12-27T15:47:31Z", "body_clean": "Hi @eyurtsev thanks for your comment What I'm trying to achieve is summarizing the conversation as part of the LLM node (after reaching a certain tokens count threshold) and remove messages from history and graph state. (note: I am using AzureChatOpenAI, an my own custom SingleStore checkpointer) This is the code snippet, part of my ReAct LangGraph agent: [code] The result of this code is the exception I mentioned in the issue: [code]"}, {"author": "eyurtsev", "created_at": "2024-12-27T15:53:51Z", "body_clean": "Yeah the code is passing RemoveMessage into a chat model which won't work. RemoveMessage needs to be used together with an appropriate reducer and is meant to be used as part of a state update. We need to clarify this in the docs. For your code start from a working summarization example in langgraph docs and then adapt to your use case."}, {"author": "daher928", "created_at": "2024-12-27T17:31:05Z", "body_clean": "I made some modifications and I did almost exactly as this guide suggests: [link] only difference is I am using AzureChatOpenAI, and still get this error in the next iteration (so for example if the current iteration did pass throw summarizer node, the next iteration will fail) this is the summarizer node: [code] my graph looks like this: ![image]( [link]"}, {"author": "eyurtsev", "created_at": "2024-12-27T17:45:02Z", "body_clean": "The example from the docs is very different structurally from the original code you shared, and it's not related to which chat model is used. pass remove message to a state update with an appropriate reducer . instead your code is currently passing RemoveMessage directly to a chat model. (I.e. Your summarizer isnt being used as a node!!) Start from the example which works correctly, swap the model there, and verify that it still works. For the new example, the issue is almost certainly still in user code, so please share a minimal reproducible example with full stack trace if you want help."}, {"author": "daher928", "created_at": "2024-12-27T19:35:59Z", "body_clean": "Thanks @eyurtsev ! I was able to solve it with your help Closing this issue"}]}, {"ollama_summary": "The issue reports a bug in LangChain where the code attempts to use a variable from an OpenAPI specification parameter, but the integration doesn't correctly replace the variable's value. The code attempts to use the `waapi` library to access the OpenAPI specification, but the `yaml` parsing and `load` function are not handling the OpenAPI spec correctly, leading to an error.  The solution involves updating LangChain to the latest stable version and ensuring the `waapi` library is properly configured.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-25T16:00:54Z", "body_clean": "Hi, @sumeetk8. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the LangChain OpenAPI toolkit. Variable values from API specification parameters are not being replaced as expected. The issue persists even after updating to the latest version. You provided a code example to demonstrate the problem. No further comments or activity have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["LangChain’s format interpretation logic is fundamentally flawed, requiring a comprehensive rewrite.", "The bug impacts a wide range of LangChain applications, suggesting a systemic issue.", "Addressing the bug requires a complete re-evaluation of LangChain’s core data processing.", "The search and documentation investigation uncovered a critical logic error.", "Updating the LangChain library is the most immediate solution, but requires careful testing.", "[insight here] LangChain’s format interpretation logic is fundamentally flawed, requiring a comprehensive rewrite.", "[insight here] The bug impacts a wide range of LangChain applications, suggesting a systemic issue.", "[insight here] Addressing the bug requires a complete re-evaluation of LangChain’s core data processing.", "[insight here] The search and documentation investigation uncovered a critical logic error.", "[insight here] Updating the LangChain library is the most immediate solution, but requires careful testing."], "technical_insights": ["LangChain’s format interpretation is complex, potentially susceptible to subtle errors.", "The BedrockChat component’s input parsing is a core vulnerability.", "The RemoveMessage issue highlights a key component integration problem.", "The ValidationException in the Chroma integration points to model compatibility.", "The waapi library’s configuration is critical for OpenAPI specification handling.", "[insight here] LangChain’s format interpretation is complex, potentially susceptible to subtle errors.", "[insight here] The BedrockChat component’s input parsing is a core vulnerability.", "[insight here] The RemoveMessage issue highlights a key component integration problem.", "[insight here] The ValidationException in the Chroma integration points to model compatibility.", "[insight here] The waapi library’s configuration is critical for OpenAPI specification handling."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s format interpretation logic is fundamentally flawed, requiring a comprehensive rewrite.\n2. The bug impacts a wide range of LangChain applications, suggesting a systemic issue.\n3. Addressing the bug requires a complete re-evaluation of LangChain’s core data processing.\n4. The search and documentation investigation uncovered a critical logic error.\n5. Updating the LangChain library is the most immediate solution, but requires careful testing.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s format interpretation is complex, potentially susceptible to subtle errors.\n2. The `BedrockChat` component’s input parsing is a core vulnerability.\n3. The `RemoveMessage` issue highlights a key component integration problem.\n4. The `ValidationException` in the Chroma integration points to model compatibility.\n5. The `waapi` library’s configuration is critical for OpenAPI specification handling.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here] LangChain’s format interpretation logic is fundamentally flawed, requiring a comprehensive rewrite.\n2. [insight here] The bug impacts a wide range of LangChain applications, suggesting a systemic issue.\n3. [insight here] Addressing the bug requires a complete re-evaluation of LangChain’s core data processing.\n4. [insight here] The search and documentation investigation uncovered a critical logic error.\n5. [insight here] Updating the LangChain library is the most immediate solution, but requires careful testing.\n\nTECHNICAL INSIGHTS:\n1. [insight here] LangChain’s format interpretation is complex, potentially susceptible to subtle errors.\n2. [insight here] The `BedrockChat` component’s input parsing is a core vulnerability.\n3. [insight here] The `RemoveMessage` issue highlights a key component integration problem.\n4. [insight here] The `ValidationException` in the Chroma integration points to model compatibility.\n5. [insight here] The `waapi` library’s configuration is critical for OpenAPI specification handling.\n", "batch_number": 154, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a bug in LangChain's `api 1` component that prevents the correct processing of messages containing \"developer\" roles.  Users are encountering a 400 Bad Request error when attempting to stream data, specifically when the model expects a 'developer' role.  The issue currently doesn't appear to be a bug in the code itself, suggesting a potential integration issue or a change in the model's expected input format.", "final_category": "bug", "comments": [{"author": "gongzhang", "created_at": "2024-12-26T02:33:33Z", "body_clean": "Same issue here. The [code] role does not work. Seams a bug on the OpenAI side. [link] Starting with o1 2024 12 17, o1 models support developer messages rather than system messages, to align with the [chain of command behavior described in the model spec]( [link]"}, {"author": "aubford", "created_at": "2025-02-01T22:20:53Z", "body_clean": "OpenAI changed the message type \"system\" to \"developer\" for the o1 models. Seems like this should be handled/abstracted by LangChain right? Being able to swap out models without worry about these types of implementation details is a core reason we use a tool like LangChain isn't it?"}, {"author": "dalmia", "created_at": "2025-02-03T08:13:13Z", "body_clean": "You can use the developer role like this: [code]"}, {"author": "m4a1carbin4", "created_at": "2025-02-04T10:19:55Z", "body_clean": "@dalmia Thanks! this is just what i need to!"}, {"author": "tonyvperez", "created_at": "2025-02-05T03:03:18Z", "body_clean": "You can use the developer role like this: SystemMessage( content=developer prompt, additional kwargs={\" openai role \": \"developer\"} ) This didn't appear to help, as the prompt was ignored in [code] causing the result to not have any context to my inquiry. So, I've been using [code] and [code] , which appears to work."}, {"author": "logancyang", "created_at": "2025-02-08T00:01:20Z", "body_clean": "Anyone on the langchainjs team looking into this? Would appreciate this to be fixed asap since o series models support \"developer\" role now, but we are still getting this error: [code]"}, {"author": "nav-dev-2000", "created_at": "2025-02-11T10:03:39Z", "body_clean": "Unsupported value: 'messages[3].role' does not support 'function' with this model."}, {"author": "fcamblor", "created_at": "2025-02-17T10:00:33Z", "body_clean": "[Looking at langchainjs code]( [link] it seems like [code] is automatically replaced with [code] on \"reasoning models\" ( [code] , [code] ) which looks unsupported in case of [code] When I manually edited [code] using [patch package]( [link] : [code] By replacing \"developer\" with \"assistant\" I made it to work (that's obviously only a temporary workaround)"}, {"author": "sydney-runkle", "created_at": "2025-04-17T21:50:51Z", "body_clean": "This is fixed on our end [code] supports [code] messages, as do all of the more recent [code] models. Unfortunately, [code] doesn't support system (or developer, equivalently) messages. You can block said information in with a [code] , if desired. Closing as resolved, happy to answer any follow up questions!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe user is experiencing a problem using the CassandraDatabaseToolkit to process data, resulting in incorrect output.  They’ve exhausted standard troubleshooting steps – searching documentation, using GitHub search, and updating LangChain – but the issue persists.  The core problem appears to be that the tool is returning ActionFinish without executing the necessary tools, leading to unexpected results.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-23T08:37:04Z", "body_clean": "@BACMiao It is very difficult to help you without you providing the output. Can you please provide the output? But please note one thing, the model used in tutorial is [code] while model you are using is [code] which might be causing the different output."}, {"author": "BACMiao", "created_at": "2024-12-23T13:28:18Z", "body_clean": "@keenborder786 Thank you very much. Based on your suggestion, I updated the model to [code] and tested again using the latest downloaded commit. Unfortunately, I still got the same results as before. The codes: [code] The output: ![image]( [link] ![image]( [link]"}, {"author": "dosubot[bot]", "created_at": "2025-03-24T16:00:58Z", "body_clean": "Hi, @BACMiao. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with executing query functions using the [code] in LangChain. Despite updating to the latest version and ensuring correct configuration, the issue persists. User keenborder786 suggested using a different model ( [code] ), but the problem remained even after testing with this model. You provided detailed code and output images for further investigation. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports that the `LANGCHAIN_TRACING_V2=true` command is not recognized as a system command, requiring a descriptive title and documentation link.  The developer is requesting a clarification on the command’s purpose and potential troubleshooting steps. Currently, the issue focuses on the lack of a clear explanation for the command’s non-recognition.", "final_category": "other", "comments": [{"author": "keenborder786", "created_at": "2024-12-21T21:06:02Z", "body_clean": "Sorry Can you elaborate your issue?"}, {"author": "ccurme", "created_at": "2024-12-23T20:37:24Z", "body_clean": "I think this issue is regarding how to set environment variables on Windows machines and is unrelated to LangChain."}]}, {"ollama_summary": "The issue stems from a bug in the RAG tutorial code that causes errors when running the examples.  The developer has investigated using LangChain's integrated search and GitHub search, but the problem persists even after updating to the latest stable version of LangChain.  The code produces an error related to the FAISS system information, specifically with the `langsmith` package.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-21T21:03:46Z", "body_clean": "Just do this and it should fix your issue. [code]"}, {"author": "wenzhaoabc", "created_at": "2024-12-24T08:13:28Z", "body_clean": "Thank you for your help! The issue has been resolved. I also suggest updating the documentation on the website to help other users who might encounter similar issues. Thanks again for the support!"}]}, {"ollama_summary": "The issue is a bug in LangChain that prevents the `bind_tools` attribute from being accessed after using `with_structured_output`. This affects a specific function that attempts to retrieve structured output for API calls, and the code doesn't handle the combination of structured output retrieval and tool calling correctly.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-20T16:33:02Z", "body_clean": "@p3nnst8r I don't know what you are trying to achieve, but essentially, [code] returns a [code] that consists of the following two Runnables: [code] tools [code] [code] . So, calling [code] again on the [code] is causing this error. This is not recommended, but if you want to use additional tools in the same [code] , you can do the following: [code] However, I still don't understand why you want to use additional tools when [code] is only used to make the LLM parse the result into a specific format. It is recommended that you initiate a different instance of the LLM with the desired tools."}, {"author": "AniketSaki", "created_at": "2025-01-02T10:02:50Z", "body_clean": "In langchain core==0.3.28, the bind tools fn is not implemented and all basechatmodel's with structured output fn are calling it. [link]"}, {"author": "kapis", "created_at": "2025-01-23T10:49:19Z", "body_clean": "[keenborder786]( [link] [@p3nnst8r]( [link] I don't know what you are trying to achieve, but essentially, [code] returns a [code] that consists of the following two Runnables: [code] tools [code] [code] . So, calling [code] again on the [code] is causing this error. This is not recommended, but if you want to use additional tools in the same [code] , you can do the following: structured llm.steps[0] = structured llm.steps[0].bound.bind tools([a tool, ResponseModel]) However, I still don't understand why you want to use additional tools when [code] is only used to make the LLM parse the result into a specific format. It is recommended that you initiate a different instance of the LLM with the desired tools. Not the original author, but I have the same problem. Structured outputs and tools serve fundamentally different purpose: 1. Tools are for the LLM to trigger external functions. Tools require a feedback passed back to the LLM as a separate, LLM native message type. 2. Structured outputs are just formats for LLM outputs. The default output format is just \"text\". Structured output gives a capability to customize LLM output to be a whatever JSON object. No feedback is required. Imagine a ChatGPT like app where LLM messages are not markdown text, but rich UI elements, implemented via [code] . And this app also needs LLM to have tools with [code] . Such a basic app is impossible to implement with the current Langchain framework. Your suggestion to [code] is irrelevant for this app, because the app will never know if a reaction to a given user message needs to use a tool or structured output this should be decided by the native LLM abilities. I understand why it is like this because just 2 years ago, when Langchain was launched, there were no LLMs that could do real Structured Output and Langchain framework was doing the heavy load of validating the LLM responses. But now, with OpenAI structured outputs guaranteeing correct format for every generation, it's not longer required to validate the outputs of a structured output. Understanding that this may not be true for other LLMs, I think Langchain framework should give this freedom to the developers."}, {"author": "heberuriegas", "created_at": "2025-01-30T03:13:40Z", "body_clean": "Has anyone been able to solve this with streaming response?"}, {"author": "kapis", "created_at": "2025-02-13T09:19:27Z", "body_clean": "@heberuriegas I found this hack to be working with streaming: [code] The downside is you have to manually parse response content. The hack works because langchain adds all extra kwargs provided in [code] to the LLM sdk client."}, {"author": "Rituraj491", "created_at": "2025-02-18T19:56:03Z", "body_clean": "@kapis I'm getting this error when I implemented your solution [code]"}, {"author": "varevshatyan", "created_at": "2025-04-26T17:46:07Z", "body_clean": "Same issue, bumping for visibility, all other threads with this same problem have been closed and the \"hacky\" solutions don't work reliably."}, {"author": "svallory", "created_at": "2025-05-27T16:19:55Z", "body_clean": "I'm baffled that we can't do this. Please guys, prioritize this. It is such a common scenario!"}, {"author": "svallory", "created_at": "2025-05-27T21:43:49Z", "body_clean": "I needed a solution ASAP, so I came up with this (for OpenAI and Gemini) and thought I would share... UPDATE: Since version [code] , [code] supports passing a [code] kwarg to [code] so all you need to do is: [code] But, in case you need to support both OpenAI and Gemini, here's the updated code: [code]"}, {"author": "techmangreat", "created_at": "2025-07-24T20:57:24Z", "body_clean": "\"UPDATE: Since version 0.3.12, ChatOpenAI supports passing a tools kwarg to .with structured output so all you need to do is:\" Please add documentation on how to use \"with structured output\". There is no documentation mentioning a \"tools\" argument. If the \"tools\" argument is used, the response is null on version 0.3.12 of langchain. Please don't make changes without documenting them. Also, how have people been using langchain for years, if this basic functionality (having tool calls and structured output, i.e., two basic building blocks of any AI agent) has only been implemented 3 days ago? Since this feature is experimental , please refer to alternatives, indicating how have people been using langchain for years to build AI agents. To be able to call functions, and to be able to have structured output, are two fundamental building blocks of AI agents. How did any person build any AI agent using langchain up until 3 days ago? What solutions are there to build basic AI agents, without using experimental features from 3 days ago? Don't tell me to refer to the documentation, as the documentation on how to build AI agents with langchain is entirely absent, and all the existing methods to build AI agents with langchain have been DEPRECATED in favor of the complete mess that is langgraph. People just want a basic python interface to interact with AI models. Tool calls, chat history, and structured output is all we need. When will langchain support that?"}]}], "business_insights": ["Integration issues between different components are a recurring theme, potentially impacting widespread usability.", "Model updates frequently trigger regression testing, requiring careful validation of new releases.", "Documentation gaps and unclear command usage contribute to developer frustration and support requests.", "Tooling inconsistencies across LangChain versions complicate the development workflow.", "The ‘developer’ role issue highlights a need for more robust and consistent input parsing."], "technical_insights": ["api 1 component bug impacts a critical data stream, suggesting a fundamental code flaw.", "o1 models require specific model configurations, impacting compatibility across various deployments.", "CassandraDatabaseToolkit issue highlights a tool-specific problem requiring targeted fixes.", "LangChain’s system command recognition failure necessitates a clear command structure.", "LANGCHAIN_TRACING_V2=true command issue addresses environment variable handling."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Integration issues between different components are a recurring theme, potentially impacting widespread usability.\n2.  Model updates frequently trigger regression testing, requiring careful validation of new releases.\n3.  Documentation gaps and unclear command usage contribute to developer frustration and support requests.\n4.  Tooling inconsistencies across LangChain versions complicate the development workflow.\n5.  The ‘developer’ role issue highlights a need for more robust and consistent input parsing.\n\nTECHNICAL INSIGHTS:\n1.  `api 1` component bug impacts a critical data stream, suggesting a fundamental code flaw.\n2.  `o1` models require specific model configurations, impacting compatibility across various deployments.\n3.  CassandraDatabaseToolkit issue highlights a tool-specific problem requiring targeted fixes.\n4.  LangChain’s `system` command recognition failure necessitates a clear command structure.\n5.  `LANGCHAIN_TRACING_V2=true` command issue addresses environment variable handling.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 155, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue highlights a bug in LangChain’s Hugging Face integration tool choice parameter, which is now outdated to match the new TGI v3.0 API. This discrepancy is causing confusion and issues, and the authors suggest updating the code to include the “required” parameter and address other model tokenizer configurations and API key matching issues.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-21T16:01:00Z", "body_clean": "Hi, @2016bgeyer. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The [code] parameter in LangChain's integration with HuggingFace is outdated. The issue persists even after updating to TGI v3.0, indicating a potential bug in LangChain. You provided example code to demonstrate the problem. No further activity or comments have been made on the issue. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further input, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem where the `poetry install with lint,docs` command fails due to the lack of a \"docs\" group in the documentation.  The solution involves adding a descriptive title and link to the documentation page, addressing a missing group identifier.", "final_category": "other", "comments": [{"author": "Uvi-12", "created_at": "2024-12-20T07:02:31Z", "body_clean": "I followed the errors and made some changes in the code: Changed Code: [code] Added Code: [code] Then I ran [code] , which gave this error: [code] I followed it and ran [code] . After its completion, I ran [code] , and I guess it worked properly, below is an attached screenshot after running [code] (correct me if I am wrong) <img width=\"1319\" alt=\"Screenshot 2024 12 20 at 12 28 15 PM\" src=\" [link] / Please let me know if this is a correct fix."}, {"author": "dosubot[bot]", "created_at": "2025-03-21T16:00:56Z", "body_clean": "Hi, @bovlb. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a problem with the LangChain documentation regarding dependency installation for linting and documentation. The error was due to a missing 'docs' group in the command provided. @Uvi 12 suggested adding a [code] section to the [code] file and running [code] . These changes allowed the command to execute successfully, and @Uvi 12 requested confirmation on the fix. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Please provide the GitHub issue link! I need the link to summarize it for you. 😊 \n\nOnce you paste the link, I’ll be happy to provide a 2-3 sentence summary focusing on the problem, key details, and proposed solutions.", "final_category": "other", "comments": [{"author": "efriis", "created_at": "2024-12-19T18:16:08Z", "body_clean": "thanks! fixed to point to 0.2 branch"}]}, {"ollama_summary": "The issue involves a bug where the \"sql_agent demo\" and \"Final Answer\" appear together, causing an exception when running the LangChain application.  After searching and investigating, the developer believes this is a bug within LangChain and isn't resolved by updates.  The problem is specifically triggered during LLM analysis calculations, leading to a halt in the process.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-19T14:40:36Z", "body_clean": "Can you try the following: [code]"}, {"author": "reatang", "created_at": "2024-12-20T02:41:17Z", "body_clean": "yes, i am try. [link] I think it may be the problem with the prompt words, Make [code] and [code] appear in the same answer. ReActSingleInputOutputParser@parse ![image]( [link]"}, {"author": "dosubot[bot]", "created_at": "2025-03-21T16:00:57Z", "body_clean": "Hi, @reatang. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an exception in LangChain's [code] when \"Action\" and \"Final Answer\" appear together in the output. The issue persists even after updating to the latest version, indicating a potential parsing error. @keenborder786 suggested a code snippet to handle parsing errors. You suspect the issue might be related to the prompt structure causing both terms to appear simultaneously. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's `embed_documents` method that fails when processing text with nested embedding structures. The code expects a flat structure, but the returned embedding is unexpectedly nested, leading to a `TypeError`. The fix involves updating the `llama cpp` model path and ensuring the correct embedding structure is used.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-19T20:00:36Z", "body_clean": "@Forgotten Forever fixed in the above PR"}, {"author": "dosubot[bot]", "created_at": "2025-03-20T16:00:52Z", "body_clean": "Hi, @Forgotten Forever. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] in the [code] method using [code] . The error was due to a mismatch in the expected data structure for embeddings. User keenborder786 addressed the issue in a pull request, indicating a fix has been implemented. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Integration issues highlight code quality and consistency across LangChain components.", "Updating model tokenizer configurations is crucial for compatibility.", "Addressing API key matching is a common and impactful bug fix.", "Model path updates are frequently required for compatibility.", "Documentation clarity and model compatibility are key to user experience.", "Integration issues highlight code quality and consistency across LangChain components.", "Updating model tokenizer configurations is crucial for compatibility.", "Addressing API key matching is a common and impactful bug fix.", "Model path updates are frequently required for compatibility.", "Documentation clarity and model compatibility are key to user experience."], "technical_insights": ["TGI v3.0 API mismatch requires code adjustments.", "required parameter in the code is critical.", "Adding a title and link improves documentation.", "The poetry install with lint,docs command is failing.", "Incorrect group identifier in documentation causes errors.", "TGI v3.0 API mismatch requires code adjustments.", "required parameter in the code is critical.", "Adding a title and link improves documentation.", "The poetry install with lint,docs command is failing.", "Incorrect group identifier in documentation causes errors."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Integration issues highlight code quality and consistency across LangChain components.\n2.  Updating model tokenizer configurations is crucial for compatibility.\n3.  Addressing API key matching is a common and impactful bug fix.\n4.  Model path updates are frequently required for compatibility.\n5.  Documentation clarity and model compatibility are key to user experience.\n\nTECHNICAL INSIGHTS:\n1.  TGI v3.0 API mismatch requires code adjustments.\n2.  `required` parameter in the `code` is critical.\n3.  Adding a title and link improves documentation.\n4.  The `poetry install with lint,docs` command is failing.\n5.  Incorrect group identifier in documentation causes errors.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Integration issues highlight code quality and consistency across LangChain components.\n2.  Updating model tokenizer configurations is crucial for compatibility.\n3.  Addressing API key matching is a common and impactful bug fix.\n4.  Model path updates are frequently required for compatibility.\n5.  Documentation clarity and model compatibility are key to user experience.\n\nTECHNICAL INSIGHTS:\n1.  TGI v3.0 API mismatch requires code adjustments.\n2.  `required` parameter in the `code` is critical.\n3.  Adding a title and link improves documentation.\n4.  The `poetry install with lint,docs` command is failing.\n5.  Incorrect group identifier in documentation causes errors.", "batch_number": 156, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The tool call for `langchain.llm.GPT4o` is failing when attempting to use it, specifically when the input is empty. This issue stems from a potential incompatibility between the `langchain` library and the specific OpenAI GPT4o model, requiring a check of the model's version and potential configuration adjustments.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2024-12-18T16:22:46Z", "body_clean": "could you please reduce the example to the tool definition and [code] ? also, this is not a langgraph issue, so will transfer to langchain"}, {"author": "keenborder786", "created_at": "2024-12-18T18:13:22Z", "body_clean": "@HasnainKhanNiazi please add a docstring in each of your tool explaining when to use the tool, that should take care of it."}, {"author": "HasnainKhanNiazi", "created_at": "2024-12-18T19:14:35Z", "body_clean": "@keenborder786 I believe that's not the issue as I have already included doc string in function definition."}, {"author": "vbarda", "created_at": "2024-12-18T19:20:15Z", "body_clean": "By the way, the first example of the tool is unlikely to work since the docstring doesn't conform to google style docstring. i would also recommend checking [code] to see the resulting schema"}, {"author": "keenborder786", "created_at": "2024-12-19T14:47:51Z", "body_clean": "@HasnainKhanNiazi Can you please use Structured Tool as follow: [link] and specify the description, arg schema more explicitly."}, {"author": "HasnainKhanNiazi", "created_at": "2024-12-27T21:45:19Z", "body_clean": "Sorry for the late reply: upon debugging the problem, I found out that another thread was throwing an error and because of that agent execution was stopped after [code] Thanks for the help"}]}, {"ollama_summary": "The issue reports a bug in LangChain where the Ollama model is consistently calling tools, even with simple queries, despite attempts to update the LangChain version. This is impacting the model's functionality and requires investigation to identify the root cause.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-12-18T17:42:33Z", "body_clean": "I believe this is an issue with Ollama and not LangChain specifically. Let me know if I'm mistaken."}, {"author": "bigartcartinc", "created_at": "2025-03-21T08:20:10Z", "body_clean": "from langchain ollama import Chatollama from langchain community.tools.tavily search import TavilySearchResults from langchain core.messages import HumanMessage from langgraph.checkpoint.memory import MemorySaver from langgraph.prebuilt import create react agent import os from dotenv import load dotenv Load environment variables from .env file for Tavily API load dotenv() Create the agent memory = MemorySaver() chat = Chatollama( base url = \" [link] model = \"1lama3.2\", temperature = 0.8, num predict = 256, search = TavilySearchResults(max results=5) tools = [search] agent executor = create react agent(chat, tools, checkpointer=memory) Use the agent config = {\"configurable\": {\"thread id\": \"abc123\"}} for step in agent executor.stream( {\"messages\": [HumanMessage(content=\"use tavily search results to tel config, stream mode=\"values\" step[\"messages\"][ 1].pretty print()"}]}, {"ollama_summary": "This issue stems from a bug in the `MarkdownLoader` library that causes it to fail to load Markdown files containing the emoji symbol 🎉. The code attempts to load a file, but the library doesn't handle this specific character, leading to a crash.  The issue is currently unresolved, and the suggested solutions – updating LangChain and searching the documentation – haven't resolved the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-18T10:16:46Z", "body_clean": "I am not so sure what you are doing. But it is working for me, can you please upgrade [code] pacakge?"}, {"author": "lesliechueng1996", "created_at": "2024-12-18T11:11:58Z", "body_clean": "Thank you very much. I tried it and it might be that some dependencies changed my lxml version to 4.9.4. After I manually upgraded to the latest version(5.3.0), the issue no longer occurred."}]}, {"ollama_summary": "The issue reports a bug in LangChain where `with_structured_output` fails when `kwargs` are not explicitly provided, consistently raising a `ValueError`.  The developer has already investigated other solutions and confirmed it’s a bug within the LangChain integration, not a code issue.  The proposed solution involves modifying the code to handle missing `kwargs` gracefully.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-18T18:26:35Z", "body_clean": "@orlandokaramani fixed"}, {"author": "dosubot[bot]", "created_at": "2025-03-19T16:01:10Z", "body_clean": "Hi, @orlandokaramani. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involved a bug in the [code] class's [code] method failing in [code] . The failure was due to a [code] from unsupported non None [code] . @keenborder786 addressed and fixed the issue. You acknowledged the fix with a thumbs up reaction. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports that Chroma isn’t automatically ephemeral when persisted_directory=None, causing it to retain retrieved documents.  The problem stems from the inconsistent retrieval of documents across iterations, leading to the same data being used.  Currently, the code doesn’t properly handle this, resulting in the persistence of old data.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-18T11:09:04Z", "body_clean": "@realliyifei You are absolutely right, between every iteration despite creating a new instance of Chroma, same in memory storage is being used. I verified by the following: [code] The output for above was as follow: [code] which shows same document are being persisted across each iteration. My guess is that behind the scenes Chroma keeps using the same memory in the single python process. As you can see when I ran each iteration in a different python process, the number of documents remained 6. [code] [code]"}, {"author": "realliyifei", "created_at": "2024-12-18T11:21:27Z", "body_clean": "Thanks for the verification. Is there any quick workaround for the original code? I don't think I would run them in different processes."}, {"author": "keenborder786", "created_at": "2024-12-18T14:03:15Z", "body_clean": "Currently No :("}, {"author": "realliyifei", "created_at": "2024-12-19T10:07:01Z", "body_clean": "A quick fix is to reset the chromadb instance each time (another workaround may be creating new collections each time via chromadb): [code] [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-20T16:01:13Z", "body_clean": "Hi, @realliyifei. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves the Chroma vector store persisting data across iterations despite [code] . You reported this as a bug, and @keenborder786 confirmed the issue by showing that in memory storage is reused within a single Python process. A temporary workaround involves resetting the Chroma instance or creating new collections for each iteration. @keenborder786 mentioned there's no quick fix without using separate processes. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Model version compatibility is a recurring issue, requiring careful model selection.", "Specific tool calls are critical; ensure consistent interaction across libraries.", "Integration testing is vital to identify and resolve library-specific bugs.", "Dependency updates and version checks are essential for stability.", "Thorough code review is needed to address potential integration points."], "technical_insights": ["langchain.llm.GPT4o model version is the primary root cause.", "Ollama model call inconsistencies suggest a potential version mismatch.", "MarkdownLoader bug needs immediate attention; ensure proper emoji handling.", "Chroma persistence issues require more robust retrieval logic.", "LangChain’s with_structured_output functionality has a bug related to kwargs."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model version compatibility is a recurring issue, requiring careful model selection.\n2. Specific tool calls are critical; ensure consistent interaction across libraries.\n3. Integration testing is vital to identify and resolve library-specific bugs.\n4. Dependency updates and version checks are essential for stability.\n5. Thorough code review is needed to address potential integration points.\n\nTECHNICAL INSIGHTS:\n1. `langchain.llm.GPT4o` model version is the primary root cause.\n2. Ollama model call inconsistencies suggest a potential version mismatch.\n3. `MarkdownLoader` bug needs immediate attention; ensure proper emoji handling.\n4. Chroma persistence issues require more robust retrieval logic.\n5. LangChain’s `with_structured_output` functionality has a bug related to kwargs.", "batch_number": 157, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a vulnerability in LangChain's ` langchain-pinecone` library (version 0.2.0) that allows an aiohttp version constraint to be exceeded, potentially leading to security risks.  The vulnerability was discovered in the latest stable version of the library and is being addressed by a fix in a specific aiohttp version.  The issue currently requires updating aiohttp to a newer version to mitigate the vulnerability.", "final_category": "bug", "comments": [{"author": "michaelromagne", "created_at": "2025-01-07T12:52:24Z", "body_clean": "Dependabot now needs aiohttp to be bumped from 3.9.5 to 3.10.11, and langchain pinecone is a blocker"}, {"author": "ccurme", "created_at": "2025-01-10T20:06:53Z", "body_clean": "Released a fix in [code] . Please shout if issues remain!"}, {"author": "surajbeston", "created_at": "2025-03-08T08:05:51Z", "body_clean": "conflicts with realtime, would you mind requiring aiohttp 3.11.13 or higher. realtime 2.4.1 requires aio [link] but you have aiohttp 3.10.11 which is incompatible."}]}, {"ollama_summary": "The ChatOllama issue is causing a critical bug where the application fails to parse requests when not explicitly specifying JSON input. After upgrading to the latest version of LangChain, the bug persists, and the code no longer correctly handles JSON output. The issue appears to be a fundamental bug within the LangChain integration for Ollama, and the developer hasn’t addressed it in a recent update.", "final_category": "bug", "comments": [{"author": "lharrison13", "created_at": "2024-12-17T02:04:14Z", "body_clean": "This might be an issue with ollama since its happening in fabric as well [link]"}, {"author": "jmorganca", "created_at": "2024-12-17T02:20:12Z", "body_clean": "Hi all, sorry about this. We are working on a fix."}, {"author": "xindoreen", "created_at": "2024-12-17T02:20:53Z", "body_clean": "Getting the same error when using chat from ollama."}, {"author": "lharrison13", "created_at": "2024-12-17T03:03:48Z", "body_clean": "Thanks @jmorganca!"}, {"author": "iotnxt", "created_at": "2024-12-17T05:51:00Z", "body_clean": "I am also seeing the same error and also right after upgrading ollama: Error querying LLM: invalid format: expected \"json\" or a JSON schema my application used to work before the ollama upgrade: ollama version is 0.5.2 0 g60f7556 dirty"}, {"author": "roychowdhuryrohit-dev", "created_at": "2024-12-17T06:10:41Z", "body_clean": "I can confirm this issue occurs using LlamaIndex+Ollama(docker) but not with Ollama(Mac app)."}, {"author": "utkucanaytac", "created_at": "2024-12-17T07:57:37Z", "body_clean": "setting [code] solves it."}, {"author": "jmorganca", "created_at": "2024-12-17T08:15:28Z", "body_clean": "Hi all, this should be fixed in version 0.5.3: [link]"}]}, {"ollama_summary": "This issue reports a latency problem in the LangChain chain invocation, specifically observed during a sequence of operations. The problem manifests as intermittent delays, potentially lasting a few minutes, impacting the performance of the application. The code attempts to retry the request, but the latency persists, suggesting a potential bug within the LangChain integration.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-17T12:00:36Z", "body_clean": "@KalakondaSainath I would suggest you use [code] to trace your chain, this way you will be better able to break down the latency coming from each runnable in chain."}, {"author": "rayamoh", "created_at": "2024-12-17T14:37:53Z", "body_clean": "@keenborder786 Bringing LANGSMITH to our org is big task going through approvals and buy the product. Can we get inputs on why there is gap of 2.5 mins from below run, between ClientSecret token and Retry request. Any additional logs we can enable in langchain to understand how retry logic \"wait exponential\" is being used in create base retry decorator ![image]( [link] @KalakondaSainath"}, {"author": "keenborder786", "created_at": "2024-12-18T09:56:21Z", "body_clean": "@rayamoh I think so the best solution in your case will be to write a custom [Call Back Handler]( [link] which keep track of time tracking and then use it in chain: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-19T16:01:13Z", "body_clean": "Hi, @KalakondaSainath. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported latency issues with the [code] function using Azure's GPT 4o model. Despite updating to the latest version and verifying your code, the issue persists. User keenborder786 suggested using [code] for tracing, but rayamoh noted it would require significant organizational effort. Keenborder786 recommended writing a custom Call Back Handler to track time and understand the latency better. Next Steps: Please let me know if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The Agent React application is failing to accept gpt4 and gpt 4o models as input, specifically when using the `mimial reproduce code` example. This issue only occurs with these models and was identified through searching and investigation, suggesting a bug within LangChain itself.  The proposed solution is to try replacing it with OpenAI, which might resolve the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-17T12:05:48Z", "body_clean": "@HelloWorldLTY, which version of [code] are you using. Can you uprade to the latest version. Since I tested the same code and everything seems to be working."}, {"author": "keenborder786", "created_at": "2024-12-17T12:08:06Z", "body_clean": "But @HelloWorldLTY if you are facing this error then do the following: [code] Making [code] will make sure that agent executor takes care of any parsing error by feeding the parsing error back to llm."}, {"author": "HelloWorldLTY", "created_at": "2024-12-17T13:07:11Z", "body_clean": "Hi, I have tried handle parsing errors=True but it will repeat error information for me. I think I have updated my longchain. Here is my info: kiwisolver==1.4.7 langchain==0.3.7 langchain anthropic==0.3.0 langchain community==0.3.5 langchain core==0.3.24 langchain experimental==0.3.3 langchain huggingface==0.1.2 langchain ollama==0.2.0 langchain openai==0.2.5 langchain text splitters==0.3.2 langgraph==0.2.44 langgraph checkpoint==2.0.2 langgraph sdk==0.1.35 langsmith==0.1.139"}, {"author": "HelloWorldLTY", "created_at": "2024-12-19T04:50:37Z", "body_clean": "Hi, does it mean I can try reactgpt4 or gpt4o with the referred comments? Thanks."}, {"author": "dosubot[bot]", "created_at": "2025-03-20T16:00:58Z", "body_clean": "Hi, @HelloWorldLTY. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where the ReAct agent cannot process \"gpt 4o\" as an input model, resulting in an OutputParserException. Keenborder786 suggested upgrading LangChain and using [code] . You noted that the suggested solution only repeats the error information and provided your package versions. You are seeking clarification on using \"reactgpt4\" or \"gpt4o\" with the suggested adjustments. Next Steps: Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a `RecursionError` within the LangChain `Milvus.aadd` function, specifically when attempting to process documents. This issue stems from a bug in the integration package that causes the code to repeatedly call `aadd` with the same `documents` list, leading to a stack overflow. The code is designed to process documents, but a potential issue with the `aadd` function's internal logic is causing it to recur.  The issue is currently not resolved by updating the LangChain version, and the suggested solution is to investigate the bug within the `Milvus.aadd` function itself.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-15T16:01:53Z", "body_clean": "@MichaelSkralivetsky, take care of in the following PR: [link]"}, {"author": "zc277584121", "created_at": "2024-12-20T06:40:10Z", "body_clean": "merged the PR"}, {"author": "dosubot[bot]", "created_at": "2025-03-21T16:00:56Z", "body_clean": "Hi, @MichaelSkralivetsky. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] with the [code] function when using Milvus in LangChain. Keenborder786 addressed the issue in a pull request. The pull request was merged by zc277584121. You confirmed that the fix resolved the issue. Next Steps: If this issue is still relevant to the latest version of LangChain, please comment to keep the discussion open. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency updates are a recurring issue, requiring careful version management.", "Security vulnerabilities in libraries are a significant concern, necessitating timely fixes.", "Latency issues in LangChain integrations are impacting application performance.", "Model compatibility issues between different models are causing problems.", "Bug fixes in the integration package are crucial for stability."], "technical_insights": ["langchain-pinecone version 0.2.0 vulnerability requires immediate aiohttp version 3.10.11 update.", "ChatOllama bug related to JSON parsing during LangChain integration.", "LangChain chain invocation latency issues, potentially linked to the integration.", "Agent React application failing with gpt4/gpt4o model input issues.", "Milvus.aadd recursion error within LangChain, potentially due to aadd function logic."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency updates are a recurring issue, requiring careful version management.\n2. Security vulnerabilities in libraries are a significant concern, necessitating timely fixes.\n3. Latency issues in LangChain integrations are impacting application performance.\n4. Model compatibility issues between different models are causing problems.\n5. Bug fixes in the integration package are crucial for stability.\n\nTECHNICAL INSIGHTS:\n1. ` langchain-pinecone` version 0.2.0 vulnerability requires immediate aiohttp version 3.10.11 update.\n2. `ChatOllama` bug related to JSON parsing during LangChain integration.\n3. LangChain chain invocation latency issues, potentially linked to the integration.\n4. Agent React application failing with gpt4/gpt4o model input issues.\n5. `Milvus.aadd` recursion error within LangChain, potentially due to `aadd` function logic.\n", "batch_number": 158, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue highlights a problem where the Colab link in the \"Classify Text into Labels\" tutorial points to a deadlink, resulting in a missing \"Open in Colab .svg\" file. The documentation doesn’t contain this file, and the developer needs to address this discrepancy.  Currently, there’s no specific request for a solution beyond identifying the missing file.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-15T16:00:49Z", "body_clean": "Hi, @AndrewPBerg. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a broken 'Open in Colab' link in the 'Classify Text into Labels' tutorial. The link leads to a non existent GitHub URL. Noted absence of similarly named notebooks in the updated documentation directory. No further comments or activity on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a \"Supabase client is required\" error when adding documents to a vector store using the `from_documents` function within LangChain. Despite the correct initialization of the Supabase client and valid table names, the error persists, even when the vector store similarity search works correctly.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-13T05:13:28Z", "body_clean": "@shockValue666 [code] is a class method and you are trying to use it with an already initialized instance which is throwing off this error. What you need to do the following, meaning you need to initialize the [code] only using [code] . [code]"}, {"author": "keenborder786", "created_at": "2024-12-15T15:39:53Z", "body_clean": "@shockValue666 can you please close this PR"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a critical bug in LangChain where the `NotImplementedError` occurs when attempting to extend a class with a specific method. The developer copied the method and extended the class, successfully creating the agent, but the bug persists. The issue requests a pull request to add this method to the class to resolve the problem.", "final_category": "feature", "comments": [{"author": "ccurme", "created_at": "2024-12-16T14:53:13Z", "body_clean": "Should be addressed in [link]"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a conflicting piece of information regarding ChatOllama’s structured output support, with the documentation stating it’s supported while the Ollama release indicates it’s not. This discrepancy is causing confusion and potentially impacting compatibility with the Pydantic parser.  The core request is to clarify and ensure the support for structured output is officially documented and consistent with Ollama’s recent release.", "final_category": "other", "comments": [{"author": "Uvi-12", "created_at": "2024-12-12T19:24:03Z", "body_clean": "Without structured output, Ollama won’t work with the Pydantic parser because the parser needs structured data like JSON to function. However, with Ollama’s recent update on December 6, 2024, structured output is now supported, making it compatible with the Pydantic parser. I will update the documentation to reflect this change and ensure everything is aligned as per the recent update."}, {"author": "hykelvinlee42", "created_at": "2024-12-13T14:19:07Z", "body_clean": "@Uvi 12 When running the [following code]( [link] with the latest version of Ollama, I'm still encountering [code] . Are you suggesting this error comes from [code] instead of [code] . I'm quite new to the Langchain library. [code] [code]"}, {"author": "hykelvinlee42", "created_at": "2024-12-13T14:21:18Z", "body_clean": "[code] python import json import random Define the schema schema = { \"properties\": { \"name\": {\"description\": \"name of an actor\", \"title\": \"Name\", \"type\": \"string\"}, \"film names\": {\"description\": \"list of names of films they starred in\", \"items\": {\"type\": \"string\"}, \"title\": \"Film Names\", \"type\": \"array\"} }, \"required\": [\"name\", \"film names\"] } Define a list of actors actors = [ \"Leonardo DiCaprio\", \"Tom Hanks\", \"Meryl Streep\", \"Denzel Washington\", \"Julia Roberts\" ] Select a random actor actor name = random.choice(actors) Generate filmography for the selected actor filmography = { \"name\": actor name, \"film names\": [ f\"{random.choice(['The Revenant', 'Forrest Gump', 'Erin Brockovich', 'Training Day', 'Pretty Woman'])} ({random.randint(1990, 2022)})\" for in range(random.randint(5, 10)) ] } Validate the filmography against the schema def validate against schema(data): try: jsonschema.validate(instance=data, schema=schema) return True except jsonschema.exceptions.ValidationError: return False print(json.dumps(filmography, indent=4)) if not validate against schema(filmography): print(\"Filmography is not well formatted\") This script selects a random actor from the list and generates a filmography for that actor. The filmography includes a name and a list of film names with titles and release years. It then validates the generated filmography against the provided schema to ensure it conforms to the expected structure. Please note that this is just an example, and you may need to adjust the script according to your specific requirements. For troubleshooting, visit: [link]"}, {"author": "Uvi-12", "created_at": "2024-12-13T15:04:12Z", "body_clean": "The error you're encountering seems to be caused by the output from the ChatOllama model not being in a valid JSON format, which is required by the [code] . Even though Ollama recently added support for structured output (as of Dec 6, 2024), the error suggests that the output returned by the model doesn't match the expected JSON structure. The [code] expects structured data like JSON, and the output may still be in a different format, such as a string or Python script, which results in the [code] . To address your question about whether the error is coming from Pydantic or Langchain Ollama, it's most likely related to the format of the output returned by ChatOllama rather than a problem with LangChain or Pydantic itself. Since Ollama now supports structured output, it should be compatible with the Pydantic parser, but it's important to verify whether the LangChain integration has been fully updated to handle this new feature. If the output is still not in the expected format, such as a Python script instead of JSON, you may need to modify the parsing logic or handle the output manually to ensure it can be processed correctly."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a conflict in the documentation for the `id_key` used within the MultiVectorRetriever component of a Multi-RAG cookbook.  The current documentation requires specific code snippets to be updated to ensure proper metadata retrieval.  The lack of a clear solution is hindering users from utilizing the cookbook effectively and is a potential area for improvement.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-13T16:01:03Z", "body_clean": "Hi, @SMAntony. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Documentation error in the Multi RAG cookbooks regarding the [code] string. This error affects the expected output when using the MultiVectorRetriever. You are seeking guidance on resolving the issue and are open to contributing a fix. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Incorrect file references can severely impact user experience and workflow.", "Clear documentation is vital for developers to avoid confusion and errors.", "Addressing these discrepancies proactively enhances user satisfaction and reduces support burden.", "Maintaining consistency across documentation is crucial for reliable integration.", "Prioritize resolving the missing file to improve the user experience."], "technical_insights": ["Colab link deadlink indicates a broken link, requiring immediate attention.", "Supabase client error during vector store integration suggests a configuration issue.", "LangChain class method extension issue requires a pull request to resolve the bug.", "LangChain documentation conflict regarding ChatOllama structured output support needs clarification.", "Documentation for id_key in MultiVectorRetriever component is missing, hindering functionality."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Incorrect file references can severely impact user experience and workflow.\n2.  Clear documentation is vital for developers to avoid confusion and errors.\n3.  Addressing these discrepancies proactively enhances user satisfaction and reduces support burden.\n4.  Maintaining consistency across documentation is crucial for reliable integration.\n5.  Prioritize resolving the missing file to improve the user experience.\n\nTECHNICAL INSIGHTS:\n1.  Colab link deadlink indicates a broken link, requiring immediate attention.\n2.  Supabase client error during vector store integration suggests a configuration issue.\n3.  LangChain class method extension issue requires a pull request to resolve the bug.\n4.  LangChain documentation conflict regarding ChatOllama structured output support needs clarification.\n5.  Documentation for `id_key` in MultiVectorRetriever component is missing, hindering functionality.\n", "batch_number": 159, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a bug in the `llama_index` library where the `QUERY_CONFIG_TYPE` parameter is no longer supported, preventing the retrieval of relevant documents.  Users have attempted to resolve the problem by updating LangChain and llama index versions, but the issue persists. The core problem lies in the library’s outdated functionality and the lack of a consistent method for specifying the query configuration.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-13T16:00:57Z", "body_clean": "Hi, @91d906h4. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that [code] is no longer supported in [code] within LangChain. This leads to deprecation warnings and errors when using [code] . You provided example code and error messages to verify this is a bug in LangChain. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports that the LangChain `embeddings` library is failing to embed queries and documents locally, despite working correctly when used directly. This suggests a bug within the integration package, potentially a version incompatibility or a problem with the underlying model.  The solution is to ensure the latest stable version of LangChain and its associated integration package is used.", "final_category": "bug", "comments": [{"author": "kevin-liangit", "created_at": "2024-12-13T16:55:36Z", "body_clean": "seems to be related when using engine: infinity [link] using IninfityEmbeddings works, as outlined in [link] [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-14T16:00:56Z", "body_clean": "Hi, @kevin liangit. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] class failing to embed queries/documents using a locally hosted model. The issue is linked to using the engine \"infinity,\" as noted in a related issue on the Infinity repository. You found a workaround by using [code] with a specific configuration, which resolves the problem. Next Steps: Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a LangChain component failing to correctly parse attachment JSON from Confluence documents, resulting in malformed URLs and 404 errors. The code attempts to download attachments, but the JSON parsing is broken, and the generated URLs are incorrect, requiring a fix in the ConfluenceLoader implementation.  The issue is likely a bug within the LangChain library itself, and attempts to update to the latest stable version have not resolved the problem.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-12-13T23:08:28Z", "body_clean": "@Tonkonozhenko I'm wondering if you can replicate this or if [link] is related?"}, {"author": "cosmorocker", "created_at": "2024-12-14T09:29:11Z", "body_clean": "@ml lubich, could you try again using the URL ending with the [code] ? I see in the docs it's required: [link]"}, {"author": "dosubot[bot]", "created_at": "2025-03-15T16:00:47Z", "body_clean": "Hi, @ml lubich. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The ConfluenceLoader in LangChain is failing to parse JSON for attachments. Incorrect URLs are being generated, with double slashes and a missing [code] path segment. @ccurme asked if @Tonkonozhenko could replicate the issue or if it relates to a recent pull request. @cosmorocker suggested using a URL ending with [code] as per the documentation to potentially resolve the issue. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe AzureAIDocumentIntelligenceLoader is incorrectly calling the document intelligence endpoint, despite verifying the API key and URL are correct.  The issue stems from LangChain defaulting to the endpoint even when explicitly providing the URL, causing a documented bug in the integration.  Currently, the bug isn’t resolved by updating LangChain, suggesting it’s a fundamental issue within the library’s implementation.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-12T16:01:03Z", "body_clean": "Hi, @ambodiam. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with the [code] calling an incorrect endpoint. You've confirmed the issue is not due to your code or an outdated library version. Example code and error logs were provided to illustrate the problem. There have been no comments or activity on this issue yet. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain's `toolConfig.tools[0].toolSpec` parameter, which requires a string value (\"name\", \"description\", or \"inputSchema\") and currently only accepts \"name\", \"description\", or \"inputSchema\".  The code attempts to use a StructuredPrompt with LangSmith, triggering an error due to this mismatch.  The solution requires updating LangChain to the latest stable version or a specific integration package.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-11T08:30:54Z", "body_clean": "@austinmw can you please share your code?"}, {"author": "dosubot[bot]", "created_at": "2025-03-12T16:01:08Z", "body_clean": "Hi, @austinmw. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves an error with a StructuredPrompt using LangSmith and Promptim. An invalid parameter \"strict\" is causing the error; it should be replaced with \"name,\" \"description,\" or \"inputSchema.\" You have confirmed this as a bug in LangChain. @keenborder786 has requested you to share your code for further investigation. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "sei-li-miidas", "created_at": "2025-03-18T01:25:31Z", "body_clean": "@keenborder786 I have the same error [code] below is my code. [code] because there is no \"strict\" parameter in function [bind tools]( [link] function. I have to call convert to openai tool myself. BTW. I'm using [code] , a little different with the link above"}, {"author": "dosubot[bot]", "created_at": "2025-03-18T01:27:44Z", "body_clean": "@eyurtsev, the user @sei li miidas has confirmed that the issue with the [code] parameter is still relevant and has provided their code for further context. Could you please assist them with this issue?"}, {"author": "sei-li-miidas", "created_at": "2025-03-18T02:02:33Z", "body_clean": "I guess the reason isn't in langchain, but aws botocore. from [here]( [link] it seems, it doesn't support strict. Thought I don't know which service 2.json is being using"}, {"author": "austinmw", "created_at": "2025-03-28T17:46:13Z", "body_clean": "@keenborder786 maybe it's because I'm trying to use Anthropic models but strict mode is only supported for OpenAI models?"}, {"author": "dosubot[bot]", "created_at": "2025-06-27T16:01:52Z", "body_clean": "Hi, @austinmw. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an error with a StructuredPrompt using LangSmith and Promptim due to an unknown \"strict\" parameter. User keenborder786 requested your code for further investigation. User sei li miidas confirmed the same error and suggested it might be related to AWS botocore. You speculated that the \"strict\" parameter might only be supported for OpenAI models, not Anthropic models. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If no further updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Library updates frequently introduce regressions, necessitating rigorous testing and monitoring.", "Version conflicts can severely impact stability, highlighting the importance of comprehensive dependency management.", "Bug fixes often reveal underlying design flaws, demanding a deeper understanding of the code’s logic.", "Integration package issues are a common source of instability, requiring careful package management.", "Lack of consistent configuration methods contributes to recurring bugs, demanding improved design."], "technical_insights": ["Library updates frequently introduce regressions, necessitating rigorous testing and monitoring.", "Version conflicts can severely impact stability, highlighting the importance of comprehensive dependency management.", "Bug fixes often reveal underlying design flaws, demanding a deeper understanding of the code’s logic.", "Integration package issues are a common source of instability, requiring careful package management.", "Lack of consistent configuration methods demands a deeper understanding of the code’s logic."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Library updates frequently introduce regressions, necessitating rigorous testing and monitoring.\n2.  Version conflicts can severely impact stability, highlighting the importance of comprehensive dependency management.\n3.  Bug fixes often reveal underlying design flaws, demanding a deeper understanding of the code’s logic.\n4.  Integration package issues are a common source of instability, requiring careful package management.\n5.  Lack of consistent configuration methods contributes to recurring bugs, demanding improved design.\n\nTECHNICAL INSIGHTS:\n1.  Library updates frequently introduce regressions, necessitating rigorous testing and monitoring.\n2.  Version conflicts can severely impact stability, highlighting the importance of comprehensive dependency management.\n3.  Bug fixes often reveal underlying design flaws, demanding a deeper understanding of the code’s logic.\n4.  Integration package issues are a common source of instability, requiring careful package management.\n5.  Lack of consistent configuration methods demands a deeper understanding of the code’s logic.\n", "batch_number": 160, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue describes a problem with LangServe's RemoteRunnable functionality, specifically when attempting to use `LLMChain` or other chain classes. The code fails to apply the RemoteRunnable, leading to an error message and stack trace. The proposed solution is to ensure the correct version of LangChain is installed, as the bug appears to be a compatibility issue with the integration package.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-11T10:59:09Z", "body_clean": "@jianlins You are using Deprecate way of using, the recommended way is to use [LCEL]( [link] So you can achieve the same result using as follow: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-12T16:01:03Z", "body_clean": "Hi, @jianlins. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported difficulties in chaining RemoteRunnable clients to a local LLM server using Langserve. The issue was identified as a bug in LangChain. @keenborder786 noted the use of a deprecated method and suggested using LCEL, providing a code example for the updated approach. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain project is experiencing a bug where it fails to support the `langsmith` library version 0.2.0 when the user requests `langchain` version 0.3.10. This issue stems from a dependency conflict where the user's LangChain version requires `langsmith` to be below 0.2.0, which is incompatible with the latest version of LangChain and its integration package.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-12-09T17:54:40Z", "body_clean": "Resolved by [link]"}, {"author": "dosubot[bot]", "created_at": "2025-03-10T16:01:16Z", "body_clean": "Hi, @tjmcdonough. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a compatibility problem between langchain version 0.3.10 and langsmith version 0.2.1. @ccurme mentioned that the issue has been resolved by [PR 28598]( [link] Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on this issue. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a bug in LangChain where the `fetch` function doesn’t correctly handle query parameters for web pages. The code currently only accepts headers and cookies, requiring a basic parameter or authentication mechanism.  The issue is being investigated as a potential regression rather than a deliberate change.", "final_category": "feature", "comments": [{"author": "keenborder786", "created_at": "2024-12-10T08:55:10Z", "body_clean": "@bluearrow98 you can use [code] to pass in the query parameters. But it is not being used in [code] which I have fixed in above PR."}, {"author": "dosubot[bot]", "created_at": "2025-03-11T16:01:06Z", "body_clean": "Hi, @bluearrow98. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised an issue about the [code] 's [code] function not supporting query parameters and authentication. [code] suggested using [code] for query parameters and submitted a pull request to address this. You responded positively to the proposed solution. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a bug in LangChain’s ChatCohere agentic RAG system that causes it to consistently fail when attempting to transform queries. The code checks if the last message is a ToolMessage or HumanMessage, but the system doesn’t allow for rewriting the question.  The bug appears to be a design choice within the ChatCohere class, hindering the agent’s ability to intelligently rephrase queries and ultimately failing to transform the input.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-11T10:46:17Z", "body_clean": "I have created the following [PR]( [link] which will migrate ChatCohere to V2 and will take care of it."}, {"author": "dosubot[bot]", "created_at": "2025-03-12T16:01:15Z", "body_clean": "Hi, @jimmyshah83. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in the ChatCohere component where queries fail to transform correctly, causing message type errors. The issue does not occur with AzureChatOpenAI, raising questions about the design choice in ChatCohere. Keenborder786 has created a pull request to migrate ChatCohere to V2, which aims to resolve the issue. Next Steps Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\n**Problem:** The current docstring parsing in LangChain is failing to correctly interpret Google-style docstrings with more than one paragraph, leading to errors.\n\n**Key Details:** This issue specifically targets the inability to parse docstrings that follow a specific format (two paragraphs) and highlights a recent change that causes this issue.\n\n**Proposed Solution:** The issue requests a fix to improve the parsing logic to handle multi-paragraph docstrings effectively.", "final_category": "bug", "comments": [{"author": "isatyamks", "created_at": "2024-12-15T19:02:57Z", "body_clean": "@ccurme Could you please review my PR 28730? I improved parse google docstring to support multi paragraph descriptions while ensuring backward compatibility."}]}], "business_insights": ["Compatibility issues between LangChain and specific chain classes are a recurring theme, requiring careful version management.", "Dependency conflicts are a significant source of bugs, potentially impacting broader LangChain usage.", "The integration package’s compatibility with LangChain is a critical area for improvement.", "Versioning and backward compatibility are essential for long-term stability.", "A clear understanding of LangChain’s dependencies is vital for maintaining system integrity."], "technical_insights": ["LangChain’s integration package requires careful version control to avoid compatibility issues.", "The LangChain dependency conflict with langsmith version 0.2.0 is a major bug.", "The fetch function’s query parameter handling requires a more robust mechanism.", "The ChatCohere agentic RAG system’s docstring parsing bug necessitates a fix.", "The integration package’s multi-paragraph docstring parsing needs improvement."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Compatibility issues between LangChain and specific chain classes are a recurring theme, requiring careful version management.\n2. Dependency conflicts are a significant source of bugs, potentially impacting broader LangChain usage.\n3. The integration package’s compatibility with LangChain is a critical area for improvement.\n4. Versioning and backward compatibility are essential for long-term stability.\n5. A clear understanding of LangChain’s dependencies is vital for maintaining system integrity.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s integration package requires careful version control to avoid compatibility issues.\n2. The LangChain dependency conflict with `langsmith` version 0.2.0 is a major bug.\n3. The `fetch` function’s query parameter handling requires a more robust mechanism.\n4. The ChatCohere agentic RAG system’s docstring parsing bug necessitates a fix.\n5. The integration package’s multi-paragraph docstring parsing needs improvement.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 161, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue addresses a critical bug in the LangChain `unstructured.document loaders` module, specifically concerning the ability to read files with the `single` mode.  The current implementation of the `UnstructuredLoader` class has a syntax tag `[code]` that suggests a potential breaking change, and the code doesn't handle the `single` mode correctly, leading to an error message and stack trace.  The developers are investigating the root cause and are working to resolve the issue, but the current state is causing confusion and requires a workaround.", "final_category": "bug", "comments": [{"author": "ml-lubich", "created_at": "2024-12-11T19:15:43Z", "body_clean": "Please provide your error message, this is very generic and vague. (inputs and outputs as well would be helpful for debugging)"}, {"author": "lesliechueng1996", "created_at": "2024-12-18T07:16:14Z", "body_clean": "No error message. Currently I have the code like this: [code] Since I pass the mode as single to the loader, it will return a single langchain document object. At the same time , I receive some warning that suggest me to use UnstructuredLoader instead of UnstructuredFileLoader. But when I use UnstructuredLoader, since it doesn't have the mode field [code] so it will not return a single langchain document object. My question is how to get the single doc, after I migrate to the UnstructuredLoader to avoid big change in my project?"}, {"author": "rahul-trip", "created_at": "2024-12-19T11:38:10Z", "body_clean": "Hi @Coniferish, under git blame, I can see that [code] is marked as deprecated, could you please shed some light on this. What exactly is deprecated, is it the [code] or the [code] ? Thanks in advance."}, {"author": "rahul-trip", "created_at": "2024-12-19T11:41:26Z", "body_clean": "@lesliechueng1996 , Worst case scenario, you can merge the documents received using following way: Sample code: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-20T16:01:16Z", "body_clean": "Hi, @lesliechueng1996. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that the [code] class lacks \"single\" mode support, unlike the deprecated [code] . There is uncertainty if this is an intentional change or a bug. User ml lubich requested more details for debugging, while rahul trip suggested a manual workaround. The issue remains unresolved, highlighting a gap in functionality between the old and new loaders. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue is a bug in the LangChain library that requires the minimum version of OpenAI (1.55.3) to be installed for the `langchain-openai` package to function correctly.  The code reported error message and stack trace indicates a compatibility issue with the latest version of LangChain, which has removed the `proxies` argument.  The proposed solution is to update the LangChain library to the specified version.", "final_category": "feature", "comments": []}, {"ollama_summary": "The ArxivRetriever library in LangChain is returning incorrect document counts when attempting to retrieve full documents, despite the documentation indicating a simple argument change. The issue stems from a discrepancy between the Colab environment and local environments, where the retriever returns 3 documents even with the correct argument.  The solution requires a fix within the LangChain library itself to ensure accurate document retrieval across different environments.", "final_category": "bug", "comments": [{"author": "EMIDY643", "created_at": "2024-12-08T20:35:07Z", "body_clean": "DeepNude AI offers advanced tools for generating high quality AI powered imagery. With features like precision, ease of use, and seamless integration, it caters to beginners and professionals alike. Users can enjoy: [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] 3 Best undress ai for free without sing up : [link] 4 surprise For an iPhone at a surprising price : [link] No cost: Completely free with no hidden charges. [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] DeepNude AI offers advanced tools for generating high quality AI powered imagery. With features like precision, ease of use, and seamless integration, it caters to beginners and professionals alike. Users can enjoy: [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] 3 Best undress ai for free without sing up : [link] 4 surprise For an iPhone at a surprising price : [link] No cost: Completely free with no hidden charges. [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ][( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] Accessibility: Available on various platforms. Advanced results: Crisp and accurate outputs. Why Choose DeepNude AI? [link] Trusted worldwide for its efficiency, DeepNude AI combines simplicity with reliability, making it an ideal choice for users seeking fast, effective AI solutions Originally posted by @comtthe in [link]"}, {"author": "keenborder786", "created_at": "2024-12-08T21:03:18Z", "body_clean": "@katyachemistry, you need to use [code] which basically is how many documents do you need to fetch which you want (minimum number of documents). On the other hand, [code] is bascially if you are fetching more than x docs, this will act as a upper limit meaning query will never fetch more than this amount (maximum number of docs)"}, {"author": "keenborder786", "created_at": "2024-12-08T21:05:53Z", "body_clean": "@katyachemistry check this: [link]"}, {"author": "keenborder786", "created_at": "2024-12-08T21:10:55Z", "body_clean": "Their is a slight issue where [code] is not being used but you want [code] regardless"}, {"author": "katyachemistry", "created_at": "2024-12-08T21:18:37Z", "body_clean": "Their is a slight issue where [code] is not being used but you want [code] regardless I see. top k results works, thank you."}]}, {"ollama_summary": "This issue stems from a reAct agent failing to correctly utilize multiple custom tools within the agent’s framework. The agent attempts to integrate several tools, including a standalone tool that generates random words and a tool that requires a string as input, but the agent consistently misuses the output of the first tool when used as input for the second tool, leading to errors.  The problem is not related to the LangChain library itself but rather a bug in the integration process.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-09T16:00:47Z", "body_clean": "Hi, @DucretJe. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Reported bug with ReAct agent not using multiple custom tools correctly. Issue persists despite using the [code] decorator and updating to the latest version. Confirmed as a library bug by you, not a code error. No further comments or developments have been made. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. Comment to keep the discussion open. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "DucretJe", "created_at": "2025-03-10T08:24:18Z", "body_clean": "No need. The issue seems to come from llama, v3.2 or 3.3 is the same, it doesn't support the tools correctly. Using qwen2.5 gives better results."}, {"author": "dosubot[bot]", "created_at": "2025-03-10T08:24:25Z", "body_clean": "Thank you, DucretJe, for closing the issue! We appreciate your help in keeping the repository organized."}]}, {"ollama_summary": "The LangChain Ollama library has a bug where the default value of `format` causes an error. This issue stems from a discrepancy in the `langsmith: 0.1.129` version, leading to a JSON result that isn’t what’s expected. The code attempts to use the default value, and a fix is needed to ensure the correct plain text response is generated.", "final_category": "bug", "comments": [{"author": "samyIO", "created_at": "2024-12-07T08:35:19Z", "body_clean": "Omg thanks! I have the same issue. I'm debugging my python environment since hours! Which version is free of this bug?"}, {"author": "LogCreative", "created_at": "2024-12-07T08:41:53Z", "body_clean": "Omg thanks! I have the same issue. I'm debugging my python environment since hours! Which version is free of this bug? It seems the code has not been fixed yet👀, the referenced code is the latest."}, {"author": "samyIO", "created_at": "2024-12-07T08:43:38Z", "body_clean": "Yea.. i thought maybe i could use an older version. But i don't know when the bug started."}, {"author": "LogCreative", "created_at": "2024-12-07T08:57:38Z", "body_clean": "Yea.. i thought maybe i could use an older version. But i don't know when the bug started. I changed the package file directly😁. The [code] from [code] is new; and the one from [code] has been marked as deprecated and does not support tool calling."}, {"author": "juliojm13", "created_at": "2024-12-07T13:30:37Z", "body_clean": "@samyIO Thank you for oppening this issue! I have the same problem since yesterday after your latest release. Any estimation to resolve this bug?"}, {"author": "edmcman", "created_at": "2024-12-07T13:34:03Z", "body_clean": "I have not looked at the problem, but [code] avoids it for now. This suggests to me that this is an Ollama bug."}, {"author": "edmcman", "created_at": "2024-12-07T13:34:36Z", "body_clean": "[link]"}, {"author": "polinanechaeva25", "created_at": "2024-12-07T13:34:43Z", "body_clean": "OMG, i have absolutely the same error. I'm waiting for this issue to be solved"}, {"author": "juliojm13", "created_at": "2024-12-07T16:53:22Z", "body_clean": "I have not looked at the problem, but [code] avoids it for now. This suggests to me that this is an Ollama bug. Downgrading to ollama==0.4.2 helps, thanks! @edmcman"}, {"author": "varun-d", "created_at": "2024-12-08T01:44:09Z", "body_clean": "Thanks @LogCreative I've observed the same bug. Ollama (0.5.1) Llama 3 on Localhost:11434 I am not going to downgrade my local installation. [code] ERROR: [code] A warning for [link] while installing langchain ollama: [code]"}, {"author": "nadeemcite", "created_at": "2024-12-08T01:55:10Z", "body_clean": "The issue stems from a recent update in the ollama python package, where the [BaseGenerateRequest class only allows 'json' as a valid value]( [link] for the format field. Previously, an empty string was also permitted, but this support was removed in the latest update. To resolve this, we can modify the types.py file in the ollama python package to allow an empty string alongside 'json'. I've also added a PR to address this issue [here]( [link]"}, {"author": "ParthSareen", "created_at": "2024-12-08T03:48:04Z", "body_clean": "Hey sorry for the breaking change! We've just cut a release to fix this. I would still recommend updates on the langchain end to defaulting to [code] instead. There can be unintended consequences to setting as an empty string once the request hits the server so would like to avoid that pattern. Thanks!"}, {"author": "jmorganca", "created_at": "2024-12-08T03:54:44Z", "body_clean": "To add: sorry this happened. For those who are hitting the error, updating to the newest version of the [code] package should fix it: [code]"}, {"author": "cogitojayant", "created_at": "2024-12-08T04:48:42Z", "body_clean": "Still issue persists"}, {"author": "jmorganca", "created_at": "2024-12-08T04:52:08Z", "body_clean": "@cogitojayant Sorry about that – do you have a code snippet to reproduce? OP's code now runs with [code]"}, {"author": "neurabluAI", "created_at": "2024-12-08T08:16:43Z", "body_clean": "ollama==0.4.4 did the job in an environment with langchain. thank you!"}, {"author": "FangKQ", "created_at": "2024-12-09T03:51:34Z", "body_clean": "ollama==0.4.4 still doesn't work"}, {"author": "Pacman1984", "created_at": "2024-12-17T03:56:51Z", "body_clean": "Still not working [code] ValueError Traceback (most recent call last) Cell In[15], [line 13](vscode notebook cell:?execution count=15&line=13) [10](vscode notebook cell:?execution count=15&line=10) Initialize ChatOllama and bind the schema as a tool [11](vscode notebook cell:?execution count=15&line=11) llm = ChatOllama(model=\"qwen2.5:14b instruct\", [12](vscode notebook cell:?execution count=15&line=12) base url=\" [link] [13](vscode notebook cell:?execution count=15&line=13) structured llm = llm.with structured output(WeatherData, method=\"json schema\") [15](vscode notebook cell:?execution count=15&line=15) Define input [16](vscode notebook cell:?execution count=15&line=16) messages = [ [17](vscode notebook cell:?execution count=15&line=17) (\"system\", \"You are a weather assistant.\"), [18](vscode notebook cell:?execution count=15&line=18) (\"human\", \"Provide weather details for Tokyo.\") [19](vscode notebook cell:?execution count=15&line=19) ] File i:\\Coding\\\\.venv\\Lib\\site packages\\langchain core\\language models\\chat models.py:1228, in BaseChatModel.with structured output(self, schema, include raw, kwargs) ValueError: Received unsupported arguments {'method': 'json schema'} Ollama server is 0.51 local: pip list | findstr i \"langchain ollama\" langchain 0.3.11 langchain community 0.3.11 langchain core 0.3.25 langchain experimental 0.3.3 langchain ollama 0.2.1 langchain text splitters 0.3.2 ollama 0.4.4"}]}], "business_insights": ["Version compatibility is a key concern; updates often introduce regressions.", "Testing across diverse environments is crucial for stability.", "Bug fixes should prioritize stability over rapid iteration.", "Dependency management impacts overall code quality.", "Comprehensive test suites are vital for identifying regressions.", "Version compatibility is a key concern; updates often introduce regressions.", "Testing across diverse environments is crucial for stability.", "Bug fixes should prioritize stability over rapid iteration.", "Dependency management impacts overall code quality.", "Comprehensive test suites are vital for identifying regressions."], "technical_insights": ["unstructured.document loaders bug necessitates careful version control.", "OpenAI version 1.55.3 compatibility is a significant issue.", "LangChain library version updates introduce potential errors.", "ArxivRetriever requires a specific LangChain version for compatibility.", "ReAct agent integration requires careful tool management.", "unstructured.document loaders bug necessitates careful version control.", "OpenAI version 1.55.3 compatibility is a significant issue.", "LangChain library version updates introduce potential errors.", "ArxivRetriever requires a specific LangChain version for compatibility.", "ReAct agent integration requires careful tool management."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Version compatibility is a key concern; updates often introduce regressions.\n2.  Testing across diverse environments is crucial for stability.\n3.  Bug fixes should prioritize stability over rapid iteration.\n4.  Dependency management impacts overall code quality.\n5.  Comprehensive test suites are vital for identifying regressions.\n\nTECHNICAL INSIGHTS:\n1.  `unstructured.document loaders` bug necessitates careful version control.\n2.  OpenAI version 1.55.3 compatibility is a significant issue.\n3.  LangChain library version updates introduce potential errors.\n4.  ArxivRetriever requires a specific LangChain version for compatibility.\n5.  ReAct agent integration requires careful tool management.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Version compatibility is a key concern; updates often introduce regressions.\n2.  Testing across diverse environments is crucial for stability.\n3.  Bug fixes should prioritize stability over rapid iteration.\n4.  Dependency management impacts overall code quality.\n5.  Comprehensive test suites are vital for identifying regressions.\n\nTECHNICAL INSIGHTS:\n1.  `unstructured.document loaders` bug necessitates careful version control.\n2.  OpenAI version 1.55.3 compatibility is a significant issue.\n3.  LangChain library version updates introduce potential errors.\n4.  ArxivRetriever requires a specific LangChain version for compatibility.\n5.  ReAct agent integration requires careful tool management.\n", "batch_number": 162, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a critical bug in LangChain that prevents the use of the self-query retriever with Weaviate Vector Store, specifically targeting version 3.11. This is due to a change in Weavite's support, requiring an update to the LangChain code to ensure compatibility with V4.  The code raises a ValueError when attempting to use the retriever with a Weaviate Vector Store.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-07T07:08:34Z", "body_clean": "@RuiDevAltar have been fixed in above PR."}, {"author": "dosubot[bot]", "created_at": "2025-03-08T16:00:50Z", "body_clean": "Hi, @RuiDevAltar. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a [code] with [code] and [code] . The issue persisted even after updating to the latest version. It was confirmed as a bug in LangChain. User keenborder786 mentioned a fix in a recent pull request, which you and others acknowledged positively. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe current documentation for BaseLLMs doesn’t clearly define the exceptions that can be raised when invoking these models, hindering developers from effectively handling potential errors.  The issue highlights a lack of detail regarding specific exception types and suggests adding a \"Raises\" section to the documentation to improve code clarity and robustness.  Currently, developers need to manually determine and handle all possible exceptions without a clear guide.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-07T16:01:06Z", "body_clean": "Hi, @Mark531. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised an issue about the lack of documentation on exceptions for the [code] and [code] methods in the BaseLLM class. You suggested adding a \"Raises\" section to the documentation to help developers handle exceptions, especially for specific implementations like OpenAI's models. There have been no further comments or activity on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Mark531", "created_at": "2025-03-07T22:27:18Z", "body_clean": "Yes, this issue is still relevant for the next version of LangChain."}, {"author": "dosubot[bot]", "created_at": "2025-03-07T22:29:29Z", "body_clean": "@eyurtsev, the user @Mark531 has confirmed that the issue regarding the lack of documentation on exceptions for the [code] and [code] methods is still relevant for the next version of LangChain. Could you please assist them with this?"}]}, {"ollama_summary": "The `InMemoryRateLimiter` is not working correctly with child classes of the `BaseLLM` model, specifically when the `InMemoryRateLimiter` is used within a child class. This issue stems from a lack of integration and usage within the `BaseLLM`’s constructor, causing unexpected behavior where the rate limiter is not applied to child classes. The documentation doesn’t address this issue, leading to potential confusion for users.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-07T08:08:30Z", "body_clean": "Yes that is intentional. [code] are not supported with [code]"}, {"author": "dylanbouchard", "created_at": "2024-12-07T14:59:44Z", "body_clean": "Yes that is intentional. [code] are not supported with [code] Understood. Are there plans to add this support? If not, it would help to clarify this in the documentation."}, {"author": "EMIDY643", "created_at": "2024-12-08T20:39:00Z", "body_clean": "I just came across an incredible tool that's incredibly useful! 🚀✨ If you want to give it a try, explore these resources for free access—no sign up required! 🙌🔗 🔗 👉🔴 [Unlock AI magic for free here!]( [link] ✅ 🔗 👉 🔴[Explore free AI features now!]( [link] ✅ 3 Best undress ai for free without sing up : [Click HERE ]( [link] 4 surprise For an iPhone at a surprising price : [Click HERE ]( [link] No cost: Completely free with no hidden charges. DeepNude AI offers advanced tools for generating high quality AI powered imagery. With features like precision, ease of use, and seamless integration, it caters to beginners and professionals alike. Users can enjoy: [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] 3 Best undress ai for free without sing up : [link] 4 surprise For an iPhone at a surprising price : [link] No cost: Completely free with no hidden charges. [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] DeepNude AI offers advanced tools for generating high quality AI powered imagery. With features like precision, ease of use, and seamless integration, it caters to beginners and professionals alike. Users can enjoy: [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] 3 Best undress ai for free without sing up : [link] 4 surprise For an iPhone at a surprising price : [link] No cost: Completely free with no hidden charges. [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ][( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] [👉🔴 Click HERE ]( [link] Accessibility: Available on various platforms. Advanced results: Crisp and accurate outputs. Why Choose DeepNude AI? [link] Trusted worldwide for its efficiency, DeepNude AI combines simplicity with reliability, making it an ideal choice for users seeking fast, effective AI solutions Originally posted by @comtthe in [link] 28439"}, {"author": "keenborder786", "created_at": "2024-12-08T20:40:20Z", "body_clean": "@dylanbouchard not currently"}, {"author": "dylanbouchard", "created_at": "2024-12-09T14:03:27Z", "body_clean": "@keenborder786 Can I create a PR to 1) update the documentation for rate limiter, 2) create a warning / exception when rate limiter is passed to a BaseLLM, and/or 3) make BaseLLM compatible with rate limiter? Please let me know what you think makes most sense. As it is currently, this has caused a great deal of confusion for folks I work with."}, {"author": "dosubot[bot]", "created_at": "2025-03-10T16:01:32Z", "body_clean": "Hi, @dylanbouchard. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that [code] does not work with [code] child classes like [code] . It functions correctly with [code] child classes such as [code] . keenborder786 confirmed this behavior is intentional, and rate limiters are not supported with [code] . You suggested documentation updates or warnings to clarify this behavior. keenborder786 mentioned no current plans to add rate limiter support to [code] . Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The HuggingFaceEndpoint is returning incorrect responses and template outputs, causing issues with RAG applications. The bug persists across multiple versions of LangChain and is impacting the core functionality of the system, specifically involving a loop and exceeding the maximum token limit.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-12-21T12:46:29Z", "body_clean": "@myke11j Can you try something like this: [code]"}, {"author": "myke11j", "created_at": "2024-12-22T12:30:34Z", "body_clean": "@keenborder786 This will download the model on my system, I'm not looking for that, that's why I'm using HFEndpoint for inference."}, {"author": "liorbalmas", "created_at": "2025-01-21T08:40:50Z", "body_clean": "Same issue here With Langchain: [code] Result: Mount Everest The highest mountain in the world is Mount Everest. The highest mountain in the world is Mount Everest. The highest mountain in the world is Mount Everest. The highest mountain in the world is Mount Everest. Mount Everest Mount Everest The highest mountain in the world is Mount Everest. The highest mountain in the world is Mount Everest. Mount Everest Mount Everest Mount Everest Mount Everest Mount Everest Mount Everest Mount Everest Mount Everest Without Langchain: [code] Result Mount Everest Workaround: [code] Result Mount Everest"}, {"author": "dosubot[bot]", "created_at": "2025-04-22T16:01:09Z", "body_clean": "Hi, @myke11j. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the HuggingFaceEndpoint in LangChain, where outputs are repetitive and incorrect. User keenborder786 suggested downloading the model locally as a workaround, which you declined. User liorbalmas confirmed the issue and noted it doesn't occur with the Hugging Face API directly, sharing a workaround using ChatOpenAI. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue involves a critical bug in the LangChain `ChatGoogleGenerativeAI` library that causes it to fail to properly map the `title` field during the `marshmallow` process. This results in an \"Unknown field for Schema: title\" error, potentially halting the application's functionality.  The code and stack trace point to a problem with the `marshal` library's configuration or a specific data transformation within the `langchain` package.  A fix involves updating the LangChain library to the latest stable version or adjusting the `marshal` configuration to correctly handle the `title` property.", "final_category": "bug", "comments": [{"author": "salah55s", "created_at": "2024-12-10T10:36:10Z", "body_clean": "Same, it's a langchain bug, I think we should use another release, but which one!"}, {"author": "databaaz", "created_at": "2024-12-10T15:35:12Z", "body_clean": "I encountered the same issue. The [code] class throws this error with Pydantic schema. What worked for me is the following: Instead of doing [code] , instead do [code] Where [code] is an instance of [code]"}, {"author": "Hamza5", "created_at": "2024-12-16T12:59:49Z", "body_clean": "I have a simpler example that causes the same bug, which is a variation of the [official extraction tutorial]( [link] [code] Now, I am using the workaround of @databaaz to make this work: [code] Please note that the problem occurs only when one of the [code] s is a [code] . In my code, when using [code] instead of [code] , everything works perfectly (but I need to use [code] )."}, {"author": "dosubot[bot]", "created_at": "2025-03-17T16:00:57Z", "body_clean": "Hi, @majorgilles. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a crash with the error \"Unknown field for Schema: title\" when using [code] . The problem occurs with structured output and a custom model, especially when a [code] is a [code] . A workaround using [code] instead of [code] has been provided and confirmed to work by multiple users. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If no further updates are provided, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "piekill", "created_at": "2025-09-11T08:11:49Z", "body_clean": "In my case the output of [code] is different from [code] for [code] : the return is an AIMessage and the final answer is in the args of tool calls. So I have to do the following to get the same output as [code] : [code]"}]}], "business_insights": ["Understanding the Weavite support change is crucial for maintaining compatibility across LangChain versions.", "Detailed documentation for the BaseLLM exceptions is essential for developer stability and error handling.", "Integration of the Raises section in the documentation will improve code clarity.", "The InMemoryRateLimiter’s integration within child classes requires a more robust design.", "The ChatGoogleGenerativeAI library’s mapping of the title field is a critical bug that needs resolution."], "technical_insights": ["LangChain’s support for Weavite significantly impacts compatibility, requiring updates to the code.", "The lack of explicit exception handling in the BaseLLM documentation necessitates detailed documentation.", "The InMemoryRateLimiter’s issue within child classes highlights a design flaw requiring integration.", "The ChatGoogleGenerativeAI library's title field mapping presents a bug that needs correction.", "Updating the LangChain library to the latest stable version is a potential fix for the title mapping issue."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Understanding the `Weavite` support change is crucial for maintaining compatibility across LangChain versions.\n2. Detailed documentation for the BaseLLM exceptions is essential for developer stability and error handling.\n3. Integration of the `Raises` section in the documentation will improve code clarity.\n4. The `InMemoryRateLimiter`’s integration within child classes requires a more robust design.\n5. The `ChatGoogleGenerativeAI` library’s mapping of the `title` field is a critical bug that needs resolution.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s support for `Weavite` significantly impacts compatibility, requiring updates to the code.\n2.  The lack of explicit exception handling in the BaseLLM documentation necessitates detailed documentation.\n3.  The `InMemoryRateLimiter`’s issue within child classes highlights a design flaw requiring integration.\n4.  The `ChatGoogleGenerativeAI` library's `title` field mapping presents a bug that needs correction.\n5.  Updating the LangChain library to the latest stable version is a potential fix for the `title` mapping issue.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 163, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue involves a GenAI application using LangChain that’s returning irrelevant responses when processing video files uploaded to Google Cloud Storage.  The problem stems from LangChain incorrectly handling video input, leading to hallucinated content despite the files being retrieved correctly.  Currently, the code doesn’t correctly pass the video data to the Gemini Flash 1.5 model, causing the application to generate irrelevant outputs.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-07T16:01:15Z", "body_clean": "Hello! I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug occurs when using an LCEL based chain with Gemini models and inputs from a Google Storage Bucket. The issue persists even after updating to the latest stable version of LangChain. It seems related to processing video inputs with the specified chain configuration. Example code was provided to demonstrate the issue. No further comments or developments have been made since the initial report. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository. You can keep the discussion open by commenting on the issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue is a critical error in the `RootListenersTracer.on_llm_end` callback function, which is preventing LangChain from correctly loading and using an LLM. The error message indicates a serialization problem, specifically with the `Message` object, and it suggests a potential issue with the `model` parameter within the `ChatOllama` object.  The code is attempting to load an object that doesn't implement serialization, requiring a fix to the underlying model loading process.", "final_category": "bug", "comments": [{"author": "akeagle", "created_at": "2024-12-13T09:43:18Z", "body_clean": "me too,the error is reported when following the tutorial"}, {"author": "heikaqiu", "created_at": "2024-12-17T08:53:58Z", "body_clean": "如果直接使用模型 [code] 则会报异常 但是使用chain则不会 [code]"}, {"author": "gundamzl", "created_at": "2024-12-28T03:56:34Z", "body_clean": "我使用langgraph.graph同样报出该错误，使用ChatOllama会报错，但使用ChatOpenAI不会。 [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-29T16:00:52Z", "body_clean": "Hi, @wangkun001. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] in the [code] callback related to object serialization. User akeagle also faced this error while following a tutorial. Heikaqiu found that using [code] directly causes the error, but using a chain with [code] does not. Gundamzl experienced a similar error with [code] and [code] , but not with [code] , indicating the issue might be specific to certain components. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If it is, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a validation error within the `__init__()` method of the `langchain.openai.Embeddings` class, specifically due to the unexpected inclusion of the `proxies` keyword argument.  The error occurs when initializing the OpenAI Embeddings object, suggesting a bug within the LangChain integration package.  The solution requires updating to the latest stable version of LangChain and LangChain OpenAI to resolve the issue.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-12-06T19:40:40Z", "body_clean": "Last week [code] [removed a deprecated proxies argument]( [link] The [code] SDK then released [1.56.1]( [link] to remove the use of [code] . You will need to either update your OpenAI SDK to the latest version or install [code] . Let me know if this does not resolve your issue."}, {"author": "UtkuBulkan", "created_at": "2025-01-13T19:32:56Z", "body_clean": "No it does not solve the issue."}]}, {"ollama_summary": "The code throws a `TypeError` when initializing the LangChain ChatOpenAI model, specifically due to an unexpected `proxies` keyword argument. This issue started after updating to the latest stable version of LangChain, and the bug isn’t related to the specific integration package. The code attempts to use the `OPENROUTER API KEY` to configure the model, resulting in the `TypeError`.", "final_category": "bug", "comments": [{"author": "Heoh888", "created_at": "2024-12-05T23:24:23Z", "body_clean": "I think my mistake is also related to this TypeError: Client. init () got an unexpected keyword argument 'proxies'"}, {"author": "keenborder786", "created_at": "2024-12-05T23:52:22Z", "body_clean": "Can you please update your packages @Heoh888 , I tried on latest version [code] and [code] and it is working."}, {"author": "dosubot[bot]", "created_at": "2025-03-06T16:00:59Z", "body_clean": "Hi, @HamdiBarkous. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] with the [code] class due to an unexpected 'proxies' keyword argument. Another user, Heoh888, experienced a similar issue, suggesting it might be widespread. Keenborder786 recommended updating the [code] and [code] packages. The issue was resolved by updating to the latest versions of these packages. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\n**The core problem is that Ollama now allows calling streaming tool calls, which requires updating the code to ensure compatibility and stability.**  This change was requested by a LangChain maintainer and is being addressed to enhance Ollama’s functionality.  The proposed solution involves updating the relevant code to accommodate these new calls.", "final_category": "feature", "comments": [{"author": "keenborder786", "created_at": "2024-12-05T23:52:37Z", "body_clean": "@ccurme I am working on this"}, {"author": "keenborder786", "created_at": "2024-12-06T01:30:41Z", "body_clean": "@ccurme Isn't this already implemented if you see the [following]( [link] The tool call is being returned in streaming response. I also tested it with the following on Ollama 0.4.7: [code] And it returned me the following response: [code]"}, {"author": "ccurme", "created_at": "2024-12-10T17:54:05Z", "body_clean": "@keenborder786 current behavior is to override the [code] parameter if tools are included. Updating this in [link]"}]}], "business_insights": ["Addressing the video processing issue proactively is crucial for maintaining user experience and ensuring the core functionality of the LangChain application.", "Updating the Ollama model compatibility ensures a stable and reliable environment for the application.", "Recognizing the change as a feature request demonstrates a commitment to long-term development and integration.", "Prioritizing stability is essential for maintaining user confidence and preventing future issues.", "Monitoring the impact of the update on other features and integrations will be vital."], "technical_insights": ["LangChain’s video handling relies heavily on the Gemini Flash 1.5 model, requiring careful handling of video input data.", "The serialization issue with the Message object within the ChatOllama object suggests a deeper problem with LangChain’s model loading process.", "The validation error within the __init__() method of the langchain.openai.Embeddings class indicates a bug within the LangChain integration package.", "The proxies keyword argument in the LangChain ChatOpenAI model initialization is a potential source of incompatibility and requires investigation.", "The TypeError during model initialization highlights an issue with the LangChain package's core functionality and needs a fix."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Addressing the video processing issue proactively is crucial for maintaining user experience and ensuring the core functionality of the LangChain application.\n2. Updating the Ollama model compatibility ensures a stable and reliable environment for the application.\n3. Recognizing the change as a feature request demonstrates a commitment to long-term development and integration.\n4. Prioritizing stability is essential for maintaining user confidence and preventing future issues.\n5. Monitoring the impact of the update on other features and integrations will be vital.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s video handling relies heavily on the Gemini Flash 1.5 model, requiring careful handling of video input data.\n2.  The serialization issue with the `Message` object within the `ChatOllama` object suggests a deeper problem with LangChain’s model loading process.\n3.  The validation error within the `__init__()` method of the `langchain.openai.Embeddings` class indicates a bug within the LangChain integration package.\n4.  The `proxies` keyword argument in the LangChain ChatOpenAI model initialization is a potential source of incompatibility and requires investigation.\n5.  The `TypeError` during model initialization highlights an issue with the LangChain package's core functionality and needs a fix.\n", "batch_number": 164, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a bug in LangChain where the `recursive_set_additional_properties_false` method fails to correctly handle the `AnyOf` attribute type. This is causing unexpected behavior when the function attempts to add properties recursively. The developer has ruled out a code issue and suggests checking for the `AnyOf` attribute in the LangChain documentation and search results, but the bug hasn’t been resolved by updating the library.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-12-05T17:58:03Z", "body_clean": "Duplicate of [link]"}, {"author": "dosubot[bot]", "created_at": "2025-03-06T16:00:59Z", "body_clean": "Hi, @fernando torres blip ai. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug with the [code] method not handling [code] attribute types correctly. The issue causes errors with schemas that include [code] types, requiring [code] to be set to false. @ccurme mentioned that this is a duplicate of issue 28106, which is already being tracked. Next Steps Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\nThe current documentation for MLX-LM is inaccurate and contains a critical error that’s causing issues in a notebook. The issue specifically points to a bug in the last cell that results in an error message.  The request is for a working example to illustrate the functionality of the MLX-LM.", "final_category": "other", "comments": [{"author": "ZhangShenao", "created_at": "2024-12-23T06:55:06Z", "body_clean": "Try to fix this in [link]"}]}, {"ollama_summary": "The code is throwing an `AttributeError: 'HumanMessage' object has no attribute 'get'` error when attempting to access the `get()` method on a `HumanMessage` object.  After attempting to resolve the issue with a fresh virtual environment and dependencies, the problem persists.  The issue suggests a potential bug within LangChain itself, rather than the user's code, and the solution involves reverting to a previous stable version.", "final_category": "bug", "comments": [{"author": "pranitsawant80", "created_at": "2024-12-07T07:48:00Z", "body_clean": "[code] Check this it might help.. The issue with langchain core undersite packages..in ai.py file I tried installing the newly updated version for langchain core ie. 0.3.22 But it did not help... So I thought of changing our logic rather than changing that ai.py file.. I have put changes between and @@@@@@@@@@@@@ in the above code. changes are in ChatMessage module include a content dictionary field append method passing content after wrapping it under the dictionary iter pair have changed to make it work for new modifications You can adjust functions accordingly and remove unnecessary lines... Hope this will help...🙏"}, {"author": "jacopo-chevallard", "created_at": "2024-12-09T09:05:55Z", "body_clean": "Perhaps @keenborder786 or @Jakolo121, who helped on 26967, can confirm whether this is a bug or not?"}, {"author": "Jakolo121", "created_at": "2024-12-09T09:45:40Z", "body_clean": "@jacopo chevallard you mentioned that Following the solution in [link] I created a new, clean venv and reinstalled the dependencies, but I still get the error. what helped on the 26967 was reinstalling python and poetry. So I guess this is not a bug. But I didn't test your code on my environment."}, {"author": "jacopo-chevallard", "created_at": "2024-12-09T11:14:46Z", "body_clean": "thanks for the feedback @Jakolo121 So I guess this is not a bug. But I didn't test your code on my environment. Ok, if you get the chance to test it, it would be great (and useful for the LangChain folks, I guess, to confirm the existence of a bug)"}, {"author": "Jakolo121", "created_at": "2024-12-09T16:27:55Z", "body_clean": "I tried your code in the environment from the 26967 issue and it did not work. I also tested your code in a new environment. With the same result. I created the new env with Python 3.13 and 3.12"}, {"author": "jacopo-chevallard", "created_at": "2024-12-10T12:32:45Z", "body_clean": "Thanks for your precious feedback @Jakolo121, I guess I'll wait for some feedback from the LangChain folks cc @ccurme @efriis @eyurtsev"}, {"author": "efriis", "created_at": "2024-12-12T01:38:49Z", "body_clean": "simplest repro here. This is something weird going on in pydantic, not langchain [code] if you switch the order of the type, it works. I don't know why some of these pydantic things are a mystery. Probably something to do with some type inference on the first type that gets passed in. [code]"}, {"author": "jacopo-chevallard", "created_at": "2024-12-12T09:01:21Z", "body_clean": "Thanks a lot @efriis, I would have never thought about switching the order! ; )"}]}, {"ollama_summary": "The LangChain CLI failed to download the Grit CLI, despite attempts to troubleshoot through documentation, search, and updates. The issue appears to be a bug within LangChain itself, not a coding error in the user's project. The user is encountering a \"not found\" error when attempting to run the CLI tool, likely due to an issue with the Grit CLI integration.", "final_category": "bug", "comments": [{"author": "codekie", "created_at": "2024-12-05T13:58:29Z", "body_clean": "Duplicate of 27822 ."}]}, {"ollama_summary": "The issue is a `ModuleError: 'openai' has no attribute 'error'` occurring when attempting to embed documents with LocalAI and pgvector. This seems to be a regression issue in the LangChain library, potentially related to an outdated integration package. The user has successfully tested the code directly with the same configuration, suggesting the problem is specific to the integration rather than the core LangChain code.", "final_category": "bug", "comments": [{"author": "yichenTv", "created_at": "2024-12-06T01:53:01Z", "body_clean": "same"}, {"author": "dosubot[bot]", "created_at": "2025-03-07T16:00:59Z", "body_clean": "Hi, @wnhrt. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an [code] related to the 'openai' module missing an 'error' attribute. The error occurs when adding documents to a PGVector store. The issue persists even after updating to the latest version of LangChain. Another user, [code] , has confirmed experiencing the same issue. Next Steps: Please let us know if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "yescine", "created_at": "2025-03-09T13:14:42Z", "body_clean": "same error, with those pkg verions [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-09T13:16:53Z", "body_clean": "@eyurtsev, the user @yescine is still encountering the same [code] with the specified package versions. Could you please assist them with this issue?"}]}], "business_insights": ["Library integration issues are a common source of bugs, highlighting the importance of robust dependency management.", "Regression issues are frequently linked to updates, requiring careful testing and rollback strategies.", "Documentation errors can severely impact usability, necessitating thorough review and updates.", "Dependency conflicts can manifest as unexpected errors, highlighting the need for careful dependency management.", "Early bug detection is crucial for maintaining stability and preventing widespread issues."], "technical_insights": ["LangChain's integration with external libraries is a significant point of potential failure.", "The AnyOf attribute is a critical component of the RecursiveSet functionality, requiring careful validation.", "The AttributeError: 'HumanMessage' object has no attribute 'get' error suggests a problem with object retrieval logic.", "The ModuleError: 'openai' has no attribute 'error' indicates a problem with the OpenAI integration.", "The LocalAI and pgvector integration is a recent regression, requiring immediate attention."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Library integration issues are a common source of bugs, highlighting the importance of robust dependency management.\n2.  Regression issues are frequently linked to updates, requiring careful testing and rollback strategies.\n3.  Documentation errors can severely impact usability, necessitating thorough review and updates.\n4.  Dependency conflicts can manifest as unexpected errors, highlighting the need for careful dependency management.\n5.  Early bug detection is crucial for maintaining stability and preventing widespread issues.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's integration with external libraries is a significant point of potential failure.\n2.  The `AnyOf` attribute is a critical component of the `RecursiveSet` functionality, requiring careful validation.\n3.  The `AttributeError: 'HumanMessage' object has no attribute 'get'` error suggests a problem with object retrieval logic.\n4.  The `ModuleError: 'openai' has no attribute 'error'` indicates a problem with the OpenAI integration.\n5.  The `LocalAI` and `pgvector` integration is a recent regression, requiring immediate attention.\n", "batch_number": 165, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here's a summary of the code and the analysis of the output:\n\n**Code:**\n\nThe code snippet is a Python script that uses the `langchain` library to interact with a LangChain model (specifically, `langchain.LLM.ChatCompletion`).  It's designed to send a prompt to the model and then display the model's response.\n\n**Output Analysis:**\n\nThe output shows a series of errors and warnings, indicating a problem with the code's structure and the way it's attempting to interact with the LangChain model. Here's a breakdown:\n\n1.  **`ValueError: setting an array element with a sequence.`**: This is the primary error. It indicates that the code is trying to assign a value to an element in a list that is not a sequence (like a list or tuple). This usually happens when the model's response is not in the expected format.\n\n2.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n3.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n4.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n5.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n6.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n7.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n8.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n9.  **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n10. **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n11. **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n12. **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n13. **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n14. **`ValueError: setting an array element with a sequence.`**: This error is repeated.\n\n15. **`ValueError: setting an array element with a sequence.`**: This error is repeated.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-06T16:00:59Z", "body_clean": "Hi, @hanruiyao163. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] when using a reranker with Lancedb's hybrid search in LangChain. The issue persists even after updating to the latest version. Example code and a partial stack trace were provided to illustrate the problem. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "AmirBraham", "created_at": "2025-05-26T19:59:38Z", "body_clean": "Any update on this? Anyone implementing this currently or have a workaround ?"}]}, {"ollama_summary": "The issue stems from a bug in LangChain's `get_relevant_documents()` function, which returns a list of `DocumentWithState` objects instead of the expected `Document` objects. This causes an embedded vector passing problem, hindering the performance of RAG applications due to large vector sizes.  The code involves a specific method that generates these objects, and the bug originates in that process.", "final_category": "bug", "comments": [{"author": "gauravmindzk", "created_at": "2025-01-02T07:20:35Z", "body_clean": "hi @matteo rusconi , were you able to resolve the issue ?"}, {"author": "dosubot[bot]", "created_at": "2025-04-03T16:00:49Z", "body_clean": "Hi, @matteo rusconi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves the [code] method returning [code] objects instead of [code] objects. This discrepancy contradicts the documentation and persists in the latest stable version of LangChain. @gauravmindzk asked if you were able to resolve the issue, but there have been no further updates. Next Steps Please let us know if this issue is still relevant with the latest version of LangChain by commenting here to keep the discussion open. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The provided text is a series of comments and instructions related to code formatting and linting tasks for an OpenAI Batch API implementation. It outlines a process of running code formatters and linting checks to ensure code quality and adherence to project standards.\n\nHere's a breakdown of the key points:\n\n* **Task Overview:** The process involves running code formatters and linting checks to verify code quality.\n* **Specific Actions:**\n    * **Format:** Run `make format` to apply formatting changes.\n    * **Lint:** Run `make lint` to check for code quality issues.\n    * **Verify Import Structure:** Run `make check imports` to verify the import structure.\n* **Status:** The task is currently inactive (status: false) and has not been completed.\n* **Context:** The text is part of a larger workflow for maintaining and improving the OpenAI Batch API implementation.\n* **Goal:** The overall goal is to ensure the code is clean, well-formatted, and meets project standards.\n\nEssentially, it's a checklist of steps to keep the code in a good state.  The \"activeTaskIndex\" indicates that this task is currently in the process of being completed.", "final_category": "question", "comments": [{"author": "jerryqhyu", "created_at": "2025-02-02T16:58:05Z", "body_clean": "Any update on this? Seems bad that langchain wouldn't support something that literally saves 50% of the cost."}, {"author": "smartinezbragado", "created_at": "2025-02-07T12:21:07Z", "body_clean": "We are waiting for this feature too"}, {"author": "EliezerIsrael", "created_at": "2025-02-26T12:01:56Z", "body_clean": "Also interested. And willing to put some development into it."}, {"author": "Grigorij-Dudnik", "created_at": "2025-03-04T08:35:29Z", "body_clean": "Same here."}, {"author": "chiar11", "created_at": "2025-03-10T10:08:54Z", "body_clean": "we are waiting this feature too!"}, {"author": "danb27", "created_at": "2025-03-20T17:57:19Z", "body_clean": "same"}, {"author": "ccurme", "created_at": "2025-04-01T20:32:10Z", "body_clean": "LangChain hasn't prioritized a polling API yet, which would be needed to fully support this feature. One of the maintainers has written a library [batch bridge]( [link] which allows you to work with batch APIs as though they were standard completions APIs in LangGraph. More info here: [link] I'd recommend this option if it works for you."}, {"author": "Manouchehri", "created_at": "2025-04-01T20:37:41Z", "body_clean": "Ah, I also wrote a SaaS product called batchbridge a few weeks ago. 😅"}, {"author": "dosubot[bot]", "created_at": "2025-07-01T16:01:35Z", "body_clean": "Hi, @chriss1245. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised a concern about the [code] method not using OpenAI's batch API for cost effective predictions. Several users, including EliezerIsrael, have shown interest in this feature, with EliezerIsrael offering to contribute. ccurme noted the lack of a prioritized polling API but suggested using the [code] library as an alternative. Manouchehri mentioned developing a similar SaaS product called batchbridge. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "HudsonJimenez1", "created_at": "2025-07-07T15:15:42Z", "body_clean": "Don't get rid of this issue, it really is something that would be invaluable for a myriad of use cases"}, {"author": "watanka", "created_at": "2025-08-11T01:26:03Z", "body_clean": "Hi, The advantage of batch api is clear and many people want the feature in langchain, so I'd love to contribute on this issue: batch api support in ChatModels/Runnables. Before I start, I’d like to confirm: Would you be open to a PR that adds batch API support with a polling mechanism? If you are open to this PR, Do you prefer integrating it directly into [code] or creating a separate method/class for asynchronous batch jobs? If a polling mechanism implementation would conflict with LangChain’s design principles(e.g not able to use batch api result without polling in runnable chaining), please let me know so I can adjust the approach accordingly. I can draft an initial design doc before coding so we can align on the approach. Thanks!"}]}, {"ollama_summary": "The issue is a \"NotImplementedError\" occurring during model deployment with LangChain, specifically when attempting to copy out of the meta tensor. This seems to be a bug in LangChain that causes the error when deploying models, and the code is failing to resolve itself by updating to the latest stable version.", "final_category": "bug", "comments": [{"author": "hawkiyc", "created_at": "2024-12-04T04:12:56Z", "body_clean": "Hi, developers I did some more tests with the original Llama from Meta; the error message popped out, too. Here is my code [code] And here is the error message [code] However, these two errors look like results from different sources; the first is loading LoRA adaptor, and the second is initiating [code] . It is very confusing and hard to tell the reason for this issue. I have also reported this issue to the Huggingface team. I will let you know if there are any thoughts from the Huggingface team."}, {"author": "dosubot[bot]", "created_at": "2025-03-05T16:01:17Z", "body_clean": "Hi, @hawkiyc. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are encountering a \"NotImplementedError\" related to meta tensors while deploying a model using LangChain. The issue persists despite updating to the latest version of LangChain. The setup involves multiple libraries, including HuggingFace and FAISS, and you have shared your code for context. Additional tests with the original Llama model from Meta have been conducted. The issue has been reported to the HuggingFace team, as it seems to stem from multiple sources. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a problem where the Codespace build fails because the `dev.Dockerfile` is missing, preventing the creation of a devcontainer.  After investigating through documentation, GitHub search, and code analysis, the developer believes this is a bug in LangChain and isn't easily resolved by updates.  The error occurs when the removed code is required for the devcontainer build process.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-05T16:01:08Z", "body_clean": "Hi, @blacksmithop. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The removal of [code] has caused failures in codespace builds. The file was removed due to an outdated version of poetry. You suggested updating the file to the current version of poetry to resolve the issue. No further comments or developments have been made. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "hesreallyhim", "created_at": "2025-03-09T13:41:21Z", "body_clean": "Please keep this issue open, I would like to know a solution."}, {"author": "dosubot[bot]", "created_at": "2025-03-09T13:43:31Z", "body_clean": "@eyurtsev, the user has indicated that this issue regarding the removal of [code] and its impact on codespace builds is still relevant and they are seeking a solution. Could you please assist them with this?"}, {"author": "harrisonfloam", "created_at": "2025-04-01T00:00:05Z", "body_clean": "Bumping this for visibility. I just sat down to work on a PR and having a working dev container would have sped this up a lot. If there isn't a planned fix for this, there's a lot of documentation that should change. I'm new ish to contributing here so wouldn't trust myself setting up a the environment correctly, hopefully someone can assist."}, {"author": "eyurtsev", "created_at": "2025-04-01T15:52:25Z", "body_clean": "None of the core maintainers use dev containers. they seem to be always in a broken state, so we may just end up removing them"}, {"author": "dosubot[bot]", "created_at": "2025-07-01T16:01:30Z", "body_clean": "Hi, @blacksmithop. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a failure in building a codespace due to the removal of the [code] . The file was removed because it contained an outdated version of poetry; you suggested updating it. @hesreallyhim requested the issue remain open for a solution. @harrisonfloam emphasized the importance of a working dev container for contributors. @eyurtsev noted that core maintainers do not use dev containers and suggested they might be removed entirely. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "mdrxy", "created_at": "2025-07-28T03:55:14Z", "body_clean": "This is now fixed give it a try and lmk if you run into any issues"}]}], "business_insights": ["LangChain's get_relevant_documents() function's bug is a significant bottleneck, potentially impacting RAG application performance.", "The bug's root cause likely involves a misconfiguration or incorrect method within the function, necessitating thorough code review.", "Addressing this bug will improve the overall usability and efficiency of LangChain's RAG capabilities.", "Investigate the specific implementation details of the get_relevant_documents() method to pinpoint the root cause.", "Prioritize fixing this bug as it directly affects user experience and application value."], "technical_insights": ["The ValueError: setting an array element with a sequence. error suggests a potential issue with how the model's response is being formatted or interpreted.", "The ValueError: setting an array element with a sequence. error repeats, indicating a cyclical problem.", "The bug originates in the get_relevant_documents() function, suggesting a deeper issue within LangChain's document retrieval logic.", "The embedded vector passing problem highlights a potential performance concern, demanding optimization of the retrieval process.", "The code involves a specific method that generates these objects, requiring detailed examination to identify the source of the error."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain's `get_relevant_documents()` function's bug is a significant bottleneck, potentially impacting RAG application performance.\n2.  The bug's root cause likely involves a misconfiguration or incorrect method within the function, necessitating thorough code review.\n3.  Addressing this bug will improve the overall usability and efficiency of LangChain's RAG capabilities.\n4.  Investigate the specific implementation details of the `get_relevant_documents()` method to pinpoint the root cause.\n5.  Prioritize fixing this bug as it directly affects user experience and application value.\n\nTECHNICAL INSIGHTS:\n1.  The `ValueError: setting an array element with a sequence.` error suggests a potential issue with how the model's response is being formatted or interpreted.\n2.  The `ValueError: setting an array element with a sequence.` error repeats, indicating a cyclical problem.\n3.  The bug originates in the `get_relevant_documents()` function, suggesting a deeper issue within LangChain's document retrieval logic.\n4.  The embedded vector passing problem highlights a potential performance concern, demanding optimization of the retrieval process.\n5.  The code involves a specific method that generates these objects, requiring detailed examination to identify the source of the error.\n\n", "batch_number": 166, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in LangChain's `PDFPlumberParser` that causes errors when processing PDFs containing 1-bit images, specifically when attempting to convert the image data to a NumPy array. The code fails to correctly reshape the data, leading to a `ValueError` and preventing the extraction of images.  The solution involves using PIL to convert the image data to a 8-bit format, which resolves the issue.", "final_category": "bug", "comments": [{"author": "c-xlenz", "created_at": "2024-12-04T08:49:21Z", "body_clean": "@keenborder786 Thanks for fast tackling this. I checked your implementation and saw that you are applying it to all images, which is from my point of view not correct. It is only required for 1 bit images: if img[\"stream\"][\"BitsPerComponent\"] == 1: ..... Otherwise it will fail on other images and produce incorrect images. The PIL image gets this information with the \"1\" and then converts this to grayscale (\"L\") Thanks!"}, {"author": "c-xlenz", "created_at": "2024-12-04T09:11:06Z", "body_clean": "Here are some more examples that might help: Black/White 1 bit image: <PDFStream(321): raw=66079, { 'BitsPerComponent': 1 , 'ColorSpace': /'DeviceGray', 'DecodeParms': {'Columns': 2552, 'K': 1, 'Rows': 3300}, 'Filter': /'CCITTFaxDecode', 'Height': 3300, 'Subtype': /'Image', 'Type': /'XObject', 'Width': 2552, 'Length': 66079} Conversion: [code] only in this case we need an additional conversion to grayscale... otherwise it causes problems downstream as it is interpreted as array of boolean... Grayscale image: <PDFStream(321): raw=66079, { 'BitsPerComponent': 8 , 'ColorSpace': /'DeviceGray', 'DecodeParms': {'Columns': 2552, 'K': 1, 'Rows': 3300}, 'Filter': /'CCITTFaxDecode', 'Height': 3300, 'Subtype': /'Image', 'Type': /'XObject', 'Width': 2552, 'Length': 66079} Conversion: [code] RGB Image in PDF <PDFStream(5175): raw=236560, { 'BitsPerComponent': 8 , 'ColorSpace': /'DeviceRGB', 'Filter': /'DCTDecode', 'Height': 1758, 'Subtype': /'Image', 'Type': /'XObject', 'Width': 1235, 'Length': 236560} Conversion: [code] CMYK Image in PDF <PDFStream(5175): raw=236560, { 'BitsPerComponent': 8 , 'ColorSpace': /'DeviceCMYK', 'Filter': /'DCTDecode', 'Height': 1758, 'Subtype': /'Image', 'Type': /'XObject', 'Width': 1235, 'Length': 236560} Conversion: [code] More information about modes can be found here: [link]"}, {"author": "keenborder786", "created_at": "2024-12-10T07:28:04Z", "body_clean": "@c xlenz please check now"}, {"author": "c-xlenz", "created_at": "2024-12-10T07:50:55Z", "body_clean": "@keenborder786 It is true, that your fix now checks for the BitsPerComponent Flag... but you are combining it with the other check. [code] Now you are ONLY allowing this combination 1bit and without loss... which would of course fail on all other images in the pdf that are without loss... So inside the if block, we need to do the distinction [code] I also thought about another way without pillow (just an idea, untested): a 1 bit image can be represented as a boolean np.array the bool np array can then be casted into a uint8 np array Maybe worth checking Thanks"}, {"author": "dosubot[bot]", "created_at": "2025-03-11T16:01:07Z", "body_clean": "Hi, @c xlenz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in LangChain's PDFPlumberLoader related to 1 bit image extraction from PDFs. The current implementation incorrectly assumes an 8 bit format, causing a ValueError. You suggested using PIL for proper conversion, and @keenborder786 attempted a fix. You noted that the fix was too broad, affecting other image types, and provided detailed examples. You proposed a more nuanced approach, including using numpy arrays for 1 bit images. Next Steps Please let us know if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a LangChain client failing to correctly format requests for Azure ML's inference endpoint due to a bug in the integration package. The client consistently returns a 400 Bad Request error when attempting to use the endpoint, and the developer has successfully tested it with the Azure ML lib, suggesting a problem with the client's configuration or payload.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-04T16:00:58Z", "body_clean": "Hi, @Allaye. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Encountering a 400 Bad Request error with [code] . Issue persists despite updating to the latest LangChain version. Example code provided; no further comments or developments. Next Steps: Please confirm if this issue is still relevant with the latest LangChain version by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue stems from a bug in LangChain’s “mmr” vector store similarity search method that fails when embedding parameters are used.  The bug is triggered by an update to the Cosmos DB query, resulting in items lacking the required embedding metadata.  Currently, the issue isn’t resolved by updating LangChain, suggesting a potential bug within the integration package itself.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-04T16:01:08Z", "body_clean": "Hi, @wassim mechergui shift. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug was reported in the \"max marginal relevance\" (MMR) similarity search method. The issue occurs when using the Azure Cosmos DB NoSQL vector store. Example code and a partial error message were provided, indicating a problem with the [code] function. The issue persists even after updating to the latest version of LangChain. No further comments or activity have been noted on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves attempting to replace the OllamaFunctions library with LlamaCpp for LLM transformer conversion, resulting in a failure to generate informative graph documents.  The current code works, but the replacement isn’t producing the desired output, suggesting a potential bug in LangChain or its integration with LlamaCpp.  The user is attempting to leverage LangChain to perform GraphRAG-like tasks, and the current approach isn’t producing the expected results.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-06T16:01:05Z", "body_clean": "Hi, @chocwaffles. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You are experiencing issues transitioning from OllamaFunctions to LlamaCpp in your document conversion script. The script runs without errors but fails to produce meaningful nodes and relationships. You are seeking assistance to run the process locally with LlamaCpp and LlamaCppembeddings. No comments or developments have been made on this issue yet. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a bug in LangChain Chroma Similarity Search where it incorrectly expects a single operator in the query, resulting in a `ValueError`.  The bug persists even after updating to the latest stable version of LangChain.  The solution requires a fix to the query parsing logic within the Chroma Search integration.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-03-04T16:00:58Z", "body_clean": "Hi, @wangyaoyong wyy. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in the LangChain Chroma library. The [code] function throws a ValueError with two metadata fields. The issue persists with the latest versions of LangChain and LangChain Chroma. No further comments or developments have been made. Next Steps Please confirm if this issue is still relevant with the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "hesreallyhim", "created_at": "2025-03-26T16:10:33Z", "body_clean": "@wyy holding i think you have to use logical operators, like [code] if you want to combine metadata filters."}]}], "business_insights": ["Bug handling impacts core LangChain functionality, requiring immediate attention.", "Integration package stability is crucial; consistent errors hinder development.", "Vector store similarity search issues highlight potential package instability.", "Chroma Similarity Search query parsing bugs need resolution.", "LangChain’s integration with LlamaCpp is a significant area of concern."], "technical_insights": ["PDFPlumberParser bug affects image data processing across multiple PDFs.", "Client integration package bug causes Azure ML inference errors.", "LangChain vector store similarity search failure triggers item metadata issues.", "Chroma Similarity Search query parsing bug requires a fix.", "LangChain version updates are causing potential integration package problems."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Bug handling impacts core LangChain functionality, requiring immediate attention.\n2.  Integration package stability is crucial; consistent errors hinder development.\n3.  Vector store similarity search issues highlight potential package instability.\n4.  Chroma Similarity Search query parsing bugs need resolution.\n5.  LangChain’s integration with LlamaCpp is a significant area of concern.\n\nTECHNICAL INSIGHTS:\n1.  PDFPlumberParser bug affects image data processing across multiple PDFs.\n2.  Client integration package bug causes Azure ML inference errors.\n3.  LangChain vector store similarity search failure triggers item metadata issues.\n4.  Chroma Similarity Search query parsing bug requires a fix.\n5.  LangChain version updates are causing potential integration package problems.\n\n", "batch_number": 167, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a 400 Bad Request error when attempting to use the LangChain OpenAI library, specifically when providing a prompt.  The error message indicates a required field (\"prompt\") is missing.  Attempts to resolve the issue by updating LangChain have failed, suggesting a bug within the library itself.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-12-03T16:42:25Z", "body_clean": "Instead of specifying [code] , you should just pass the string as a positional arg to [code] . See documentation [here]( [link] Let me know if this does not solve your problem. Note also the warning at the top of that page regarding the use of legacy text completion models ( [code] ) vs. modern chat models ( [code] ). In most cases you want to use [code] ."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on a bug where the model incorrectly retains context from a conversation thread when trimming the history. Specifically, the model is treating the same code snippet as belonging to two separate conversations, leading to incorrect responses.  The proposed solution is to ensure the same code snippet is used for both queries to maintain context retention within a single thread.", "final_category": "other", "comments": [{"author": "asdkfjsd", "created_at": "2024-12-03T08:09:00Z", "body_clean": "Hello, I am interested in taking on this task. However, I have a couple of questions to ensure I understand the scope and requirements correctly. Is it sufficient to only modify this particular text and unify the thread id ( \"abc567\" and \"abc678\" ) across the context? Do I need to check all similar pages across the documentation to address this issue, or is the change limited to a specific page or section? I am eager to assist with this task and would appreciate any guidance you can provide, thank you very much."}, {"author": "efriis", "created_at": "2024-12-03T23:29:39Z", "body_clean": "hey! just ran the existing code, and it's working as expected. if we use the same thread id, then it'll duplicate some of the messages, so the intention is actually to create a new thread (with the same conversation history in [code] )"}]}, {"ollama_summary": "This GitHub issue reports a bug in LangChain that causes the indexer to incorrectly delete records when source IDs are identical.  The issue stems from a potential interaction with the vector database and record manager, leading to a broken indexing process.  Currently, the bug isn’t addressed by updating the LangChain version, and the issue is suspected to be a fundamental flaw in the integration.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2024-12-13T20:08:30Z", "body_clean": "Confirmed"}, {"author": "eyurtsev", "created_at": "2024-12-13T20:08:44Z", "body_clean": "@KeiichiHirobe thank you for the simple example!"}, {"author": "dosubot[bot]", "created_at": "2025-03-14T16:01:08Z", "body_clean": "Hi, @KeiichiHirobe. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary A bug was introduced by PR 25754 affecting the LangChain project. The indexer fails to delete records due to missing [code] in [code] . @eyurtsev confirmed the issue and appreciated your example illustrating the problem. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "KeiichiHirobe", "created_at": "2025-03-15T04:28:02Z", "body_clean": "This has been fixed, so I've just closed this"}, {"author": "dosubot[bot]", "created_at": "2025-03-15T04:28:08Z", "body_clean": "Thank you for closing the issue, KeiichiHirobe! We appreciate your contribution to LangChain."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\nThe HuggingFaceEmbeddings library currently uses the FP16 data type within a nested loop, leading to a specific error.  The issue requests a revised documentation explaining this issue and providing a solution to avoid the error.", "final_category": "other", "comments": [{"author": "MoosaTae", "created_at": "2024-12-01T09:43:28Z", "body_clean": "[code] it work right now, [code] it need to parse to be [code] , should it fix document or code?"}, {"author": "keenborder786", "created_at": "2024-12-01T20:35:59Z", "body_clean": "@MoosaTae I have created a PR which resolves this issue."}]}, {"ollama_summary": "The issue is a critical bug in LangChain that causes an ImportError when importing the `GoogleSearchAPIWrapper` in a newly created Python 3.12 environment. This is a widespread problem affecting various functionalities and requires a fix before continued use.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-30T17:56:59Z", "body_clean": "I tried and it worked for me. Can you make sure you have upgraded to latest versions."}, {"author": "hjenryin", "created_at": "2024-11-30T18:14:41Z", "body_clean": "That's strange. Could you post your system requirements as well? (By running [code] ) Thanks!"}, {"author": "dosubot[bot]", "created_at": "2025-03-01T16:00:46Z", "body_clean": "Hi, @hjenryin. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You encountered a circular import error with [code] from [code] in Python 3.12. Another user, keenborder786, mentioned the package worked for them and suggested checking for updated versions. You requested keenborder786 to share their system requirements for further diagnosis. Next Steps Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["LangChain OpenAI library integration is failing with a missing prompt field, requiring a bug within the library itself.", "Updating LangChain may be the root cause of the issue, suggesting a fundamental library bug.", "The issue highlights a critical bug that needs immediate attention to maintain functionality.", "Addressing the bug will likely affect multiple features and functionalities.", "Focus on the prompt field to understand the root cause of the error."], "technical_insights": ["LangChain library bug: Missing prompt field causing errors with OpenAI.", "Potential bug in the LangChain library itself: Affecting the prompt field.", "Integration issue: Corrupting context retention between conversations.", "Vector database and record manager interaction: The core problem is a broken indexing process.", "Indexer deletion: Potential issue with the indexer deleting records due to code issues."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain OpenAI library integration is failing with a missing `prompt` field, requiring a bug within the library itself.\n2. Updating LangChain may be the root cause of the issue, suggesting a fundamental library bug.\n3. The issue highlights a critical bug that needs immediate attention to maintain functionality.\n4. Addressing the bug will likely affect multiple features and functionalities.\n5. Focus on the `prompt` field to understand the root cause of the error.\n\nTECHNICAL INSIGHTS:\n1. LangChain library bug: Missing `prompt` field causing errors with OpenAI.\n2. Potential bug in the LangChain library itself: Affecting the `prompt` field.\n3. Integration issue: Corrupting context retention between conversations.\n4. Vector database and record manager interaction: The core problem is a broken indexing process.\n5. Indexer deletion: Potential issue with the indexer deleting records due to code issues.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 168, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue reports a bug in the Milvus library where the `upsert` function fails to retain the original ID/PK when updating metadata. The code attempts to replace metadata but generates a new ID, requiring a new argument to specify the original ID.  The issue is currently resolved by a recent LangChain update, but the bug persists across multiple versions.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-28T16:01:26Z", "body_clean": "Hi, @joshuajoseph stu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Bug reported in LangChain's integration with Milvus. 'Upsert' operation fails to retain previous ID or primary key of documents. Verified issue persists in the latest version with example code provided. No further comments or developments on the issue. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a bug in LangChain's `similarity_search` function, which incorrectly returns empty results when documents are similar but don’t contain the specified domain. The code currently fetches and filters documents before performing similarity search, leading to the problem.  The proposed solution is to refactor the code to filter documents *before* similarity search, ensuring that only relevant documents are processed.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-28T16:01:25Z", "body_clean": "Hi, @DhavalParmar61. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with the [code] function in LangChain. The current process retrieves documents based on similarity scores before applying a domain filter. This order can result in empty responses if no documents match the domain after retrieval. You suggested reversing the order to filter by domain first for more relevant results. There have been no comments or further activity on this issue yet. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If it is, feel free to comment to keep the discussion open; otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is failing with a `ValidationError` when attempting to parse a `PlayerList` pydantic model with Llama3.1, specifically due to a mismatch in the expected data structure. The error message indicates a problem with the input data format, likely related to the model's expected structure.  The issue appears to be a bug in the LangChain integration, and the provided code snippet highlights the core problem.", "final_category": "bug", "comments": [{"author": "jooray", "created_at": "2024-11-29T10:01:52Z", "body_clean": "Try using outputfixingparser for added robustness."}, {"author": "keenborder786", "created_at": "2024-11-30T18:22:31Z", "body_clean": "@XiaomoWu Make sure you are running [code] on machine which have enough RAM. Do you have a machine which have more than 8GB of Ram? Can you please post your Machine Specification."}, {"author": "XiaomoWu", "created_at": "2024-12-03T03:37:48Z", "body_clean": "@XiaomoWu Make sure you are running [code] on machine which have enough RAM. Do you have a machine which have more than 8GB of Ram? Can you please post your Machine Specification. This is my machine specs: OS: Ubuntu 24.04 GPU: Nvidia RTX 6000 Ada 48 GB CUDA: 12.1 RAM: 256 GB I believe my machine should have more than enough RAM and VRAM to run llama3.1. Any machine that can run Ollama+llama3.1 should be able to reproduce the my minimal example. The issue seems to be related to the nested output format [code] which is defined as [code] . LangSmith shows that the LLM generated a string: [code] which fails to be parsed as [code] ."}, {"author": "XiaomoWu", "created_at": "2024-12-03T03:42:34Z", "body_clean": "Try using outputfixingparser for added robustness. Thank you for the advice. I checked the documentation of [code] but it's too dense to follow. It isn't mentioned in the tutorial or concepts guide either. Could you point me to some examples using this function?"}, {"author": "michael-hoon", "created_at": "2024-12-05T06:58:08Z", "body_clean": "you can check out [ 28225]( [link]"}, {"author": "XiaomoWu", "created_at": "2024-12-05T15:56:06Z", "body_clean": "you can check out [link] Thank you! I checked out [link] and found that it has been merged to master last week. I installed [code] and verified that [code] can successfully parse nested Pydantic model now. Close the issue as it's resolved."}, {"author": "sawsc", "created_at": "2025-01-28T14:31:25Z", "body_clean": "This does not work for me using the latest langchain, langgraph and langchain ollama: [code] Looking at the Ollama log (reformatted): [code] \"Player\" is not expanded. Any advice? [code]"}, {"author": "Mhdi-kr", "created_at": "2025-03-19T02:49:33Z", "body_clean": "updating to 0.2.1 resolved it for me [code]"}]}, {"ollama_summary": "The issue stems from a bug in LangChain's `trim_first_node()` and `trim_last_node()` functions, which incorrectly trims nodes that shouldn’t be removed, causing inconsistencies with the documented behavior.  The bug was identified through investigation of a related issue and hasn’t been addressed by recent updates to the LangChain library.", "final_category": "bug", "comments": [{"author": "Tasif1", "created_at": "2024-11-29T04:02:30Z", "body_clean": "This is a potential fix for the functions: [code]"}]}, {"ollama_summary": "The issue stems from a bug in LangChain version 0.3.9 that prevents importing the `System Info` component, causing an import error. This problem is likely related to a change in the integration package or a bug within LangChain itself, and attempts to update to the latest stable version haven’t resolved it.", "final_category": "bug", "comments": [{"author": "PNMZR", "created_at": "2025-02-26T12:44:28Z", "body_clean": "You can try pip install langchain community."}, {"author": "dosubot[bot]", "created_at": "2025-05-29T23:43:58Z", "body_clean": "Hi, @kazuyaseki. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in LangChain version 0.3.9 related to importing the 'hub' module, resulting in a traceback error. The issue persists even after updating to the latest stable version. PNMZR suggested installing the package using [code] as a potential solution. There have been no further comments or reactions to this suggestion. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "conscious-code-dev", "created_at": "2025-08-06T07:20:37Z", "body_clean": "I didn’t hit this exact hub import issue, but when researching LangChain v0.3 upgrade pitfalls, I ran into a bunch of similar problems caused by Pydantic v2 — especially with how BaseModel and validators behave. I made a video that breaks down common upgrade errors, including .invoke(), structured outputs, memory, and where Pydantic starts breaking things silently: 🎥 LangChain v0.3 Upgrade Fixes (YouTube): [link] 💻 GitHub: [link] Might help future folks debugging weird Pydantic stack traces like this."}]}], "business_insights": ["LangChain’s upsert bug impacts metadata retention across multiple versions, suggesting a potential design flaw requiring a broader fix.", "The bug’s persistence indicates a deeper issue with LangChain’s core data handling logic, necessitating investigation beyond a single fix.", "The bug’s impact across multiple versions highlights a critical issue with the library’s state management, potentially affecting stability.", "The bug’s impact on metadata retention suggests a need for stricter validation of data structures within the LangChain library.", "Addressing this bug could improve the reliability of LangChain’s data management capabilities."], "technical_insights": ["LangChain’s upsert bug demonstrates a lack of comprehensive error handling and validation for data updates, requiring a more robust approach.", "The bug’s persistence across versions points to a potential design flaw in LangChain’s data processing pipeline.", "The bug’s impact on metadata retention highlights a critical vulnerability related to data integrity and consistency.", "The bug’s impact on the similarity_search function signifies a problem with the retrieval and filtering of relevant documents.", "The bug’s root cause necessitates a thorough review of LangChain’s data structure and integration processes."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s `upsert` bug impacts metadata retention across multiple versions, suggesting a potential design flaw requiring a broader fix.\n2. The bug’s persistence indicates a deeper issue with LangChain’s core data handling logic, necessitating investigation beyond a single fix.\n3. The bug’s impact across multiple versions highlights a critical issue with the library’s state management, potentially affecting stability.\n4. The bug’s impact on metadata retention suggests a need for stricter validation of data structures within the LangChain library.\n5. Addressing this bug could improve the reliability of LangChain’s data management capabilities.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s `upsert` bug demonstrates a lack of comprehensive error handling and validation for data updates, requiring a more robust approach.\n2. The bug’s persistence across versions points to a potential design flaw in LangChain’s data processing pipeline.\n3. The bug’s impact on metadata retention highlights a critical vulnerability related to data integrity and consistency.\n4. The bug’s impact on the `similarity_search` function signifies a problem with the retrieval and filtering of relevant documents.\n5. The bug’s root cause necessitates a thorough review of LangChain’s data structure and integration processes.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 169, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a bug in LangChain where the recursive character splitter (`\\bCHAPTER\\b`) is not working correctly, causing errors when the separator is encountered in Markdown text.  Users are encountering a specific case where the separator is not properly split, resulting in unexpected output.  The issue suggests the problem might be a fundamental bug in LangChain’s regex implementation and isn’t easily resolved by updating the library.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-28T16:01:22Z", "body_clean": "Hi, @jexp. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves a discrepancy in the LangChain documentation regarding [code] and [code] . The documentation suggests that strings are treated as regex when [code] is True, but this only applies if the separator is a raw string. You suggested updating the documentation to clarify this requirement. There have been no further comments or developments on this issue. Next Steps Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "jexp", "created_at": "2025-02-28T16:32:06Z", "body_clean": "Still think it should be fixed in the docs"}, {"author": "dosubot[bot]", "created_at": "2025-02-28T16:35:58Z", "body_clean": "@eyurtsev, the user has indicated that the issue regarding the documentation for [code] and [code] is still relevant and needs to be addressed. Could you please assist them with this?"}]}, {"ollama_summary": "This issue reports a bug in LangChain version 0.3.21 that causes new class instances to throw an exception when using the deprecated arguments `[code]` and `[code]`.  The issue appears to be a regression in the LangChain library, and attempts to fix it by temporarily overriding the deprecated arguments in project dependencies, but the bug persists with newer versions.", "final_category": "bug", "comments": [{"author": "hibana2077", "created_at": "2024-11-29T05:59:49Z", "body_clean": "I also encounter same problem. And I found this code section on path : libs/partners/groq/langchain groq/chat models.py ![image]( [link] It's clear that langchain groq doesn't pass any arugment call proxies. Therefore, I take a look into groq python library : base client.py ![image]( [link] In this section it passed proxies parameter to [link] ![image]( [link] But since 28th November, 2024 new release of [link] package (0.28.0) that \"proxies\" has been removed. So If you change to previous version of [link] this bug should be resolved."}, {"author": "ccurme", "created_at": "2024-11-29T13:57:43Z", "body_clean": "@riccardogabellone would you mind sharing a full stack trace to help identify the problem? From what I can tell [code] specifies [code] (not [code] ) when creating the [link] client: [link]"}, {"author": "artpods56", "created_at": "2024-11-29T17:52:18Z", "body_clean": "downgrading to [link] fixed the problem for me"}, {"author": "riccardogabellone", "created_at": "2024-11-30T14:49:39Z", "body_clean": "@riccardogabellone would you mind sharing a full stack trace to help identify the problem? From what I can tell [code] specifies [code] (not [code] ) when creating the [link] client: [link] After depth investigating stack trace I found out issue was indeed the OpenAI lib, but a [new recent version]( [link] fixed that, so, no need for manual downgrade anything. All last versions work normally, at least, for my use case."}]}, {"ollama_summary": "This issue stems from a conflict between the LangChain community version (0.3.8) and SQLAlchemy (2.0.36) libraries, which are both required for the project to function correctly. The project attempts to install a specific version of LangChain, but the required version of SQLAlchemy is incompatible, causing a dependency resolution failure.  The proposed solution is to downgrade LangChain to a previous version that works with SQLAlchemy, which is currently being addressed by the developers.", "final_category": "bug", "comments": [{"author": "ccurme", "created_at": "2024-11-27T17:33:00Z", "body_clean": "I believe this will be resolved on next release of community following [link]"}, {"author": "dosubot[bot]", "created_at": "2025-02-26T16:00:58Z", "body_clean": "Hi, @Danielskry. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a dependency conflict with [code] and [code] version [code] . Downgrading [code] to version [code] resolves the issue temporarily. @ccurme mentioned that the issue is expected to be resolved in the next release. You reacted positively to the update about the upcoming resolution. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe LangChain Indexing API is not significantly reducing the ingestion time for Weaviate and PGVector data, despite using the same code and input file.  The issue stems from a potential bug within the LangChain integration, as the initial ingestion time is still approximately 700 seconds, even with incremental cleanup.  The developer is investigating this to determine if it’s a bug in the library itself rather than the user’s code.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-26T16:00:57Z", "body_clean": "Hi, @arjunsohanlal. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported that the LangChain Indexing API does not significantly reduce ingestion time with OpenSearch. Initial ingestion takes around 700 seconds, and re ingestion takes about 590 seconds. This behavior contrasts with Weaviate and PGVector, where re ingestion is much faster. You are seeking insights into why this discrepancy occurs with OpenSearch. There have been no comments or developments on this issue yet. Next Steps Could you confirm if this issue is still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that causes the `MATCH` clause in the GraphCypherQAChain code to incorrectly handle node names containing spaces. This results in an error message and stack trace, indicating a syntax error within the Cypher query generation. The code is currently using a cypher query with spaces in the generated query, which is causing the error.", "final_category": "bug", "comments": [{"author": "chkaty", "created_at": "2024-11-29T02:48:24Z", "body_clean": "Hi @Jeri jose, as a group of students from the University of Toronto, we would like to address this issue. Our proposed solution is to modify the [code] function using regular expressions to wrap node names containing spaces in backticks"}, {"author": "dosubot[bot]", "created_at": "2025-02-28T16:01:22Z", "body_clean": "Hi, @Jeri jose. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary A bug was reported in the GraphCypherQAChain where Cypher queries fail due to node names with spaces not being enclosed in single quotes. Despite using the latest version, the issue persists. User chkaty proposed a solution to modify the [code] function to use regular expressions to wrap node names with spaces in backticks. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Bug fixes in the recursive character splitter (\\bCHAPTER\\b) are a recurring issue across multiple issues, suggesting a fundamental bug in LangChain’s regex implementation.", "The regression in LangChain version 0.3.21 highlights a potential stability issue requiring immediate attention.", "The dependency resolution failure in the SQLAlchemy integration points to potential version conflicts and requires a focused fix.", "The conflict between LangChain and SQLAlchemy versions impacts the project's functionality, demanding a resolution.", "The bug affecting the indexing API time suggests a possible performance bottleneck requiring investigation."], "technical_insights": ["LangChain’s regex implementation is the primary focus, potentially requiring a comprehensive update.", "The regression in version 0.3.21 indicates a critical bug affecting core functionality.", "The SQLAlchemy dependency conflict highlights a potential system integration issue.", "The LangChain-SQLAlchemy conflict needs to be addressed to ensure compatibility.", "The indexing API bug points to a potential issue with LangChain’s integration with Weaviate and PGVector."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Bug fixes in the recursive character splitter (`\\bCHAPTER\\b`) are a recurring issue across multiple issues, suggesting a fundamental bug in LangChain’s regex implementation.\n2.  The regression in LangChain version 0.3.21 highlights a potential stability issue requiring immediate attention.\n3.  The dependency resolution failure in the SQLAlchemy integration points to potential version conflicts and requires a focused fix.\n4.  The conflict between LangChain and SQLAlchemy versions impacts the project's functionality, demanding a resolution.\n5.  The bug affecting the indexing API time suggests a possible performance bottleneck requiring investigation.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s regex implementation is the primary focus, potentially requiring a comprehensive update.\n2.  The regression in version 0.3.21 indicates a critical bug affecting core functionality.\n3.  The SQLAlchemy dependency conflict highlights a potential system integration issue.\n4.  The LangChain-SQLAlchemy conflict needs to be addressed to ensure compatibility.\n5.  The indexing API bug points to a potential issue with LangChain’s integration with Weaviate and PGVector.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 170, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a summary of the provided code snippet, broken down into key observations and potential issues:\n\n**Code Snippet:**\n\nThe code snippet is a Python script that initializes a ChromaDB database using the `chroma` library. It includes:\n\n1.  **Initialization:**  It calls `chroma.from documents()` to create a new ChromaDB database.\n2.  **Documents:** The `documents` argument is specified as a list of documents.\n3.  **Embedding:** The `embedding` object is defined and passed to `chroma.from`.\n4.  **Database Configuration:** The `db` and `settings` are configured.\n5.  **Error Handling:**  The code includes a `try...except` block to catch potential errors during the database initialization process.\n\n**Observations & Potential Issues:**\n\n*   **`chroma.from` Error:** The most critical issue is the `Error Message and Stack Trace (if applicable)` and `Traceback`.  The traceback indicates a problem with the `embedding` object's configuration. Specifically, it seems the `embedding` object is not correctly configured to handle the documents.  The `embedding` object is not correctly configured to handle the documents. This is likely the root cause of the error.\n*   **Missing `embedding` Configuration:** The `embedding` object is not properly configured. The `embedding` object is not properly configured.\n*   **`documents` Argument:** The `documents` argument is being passed to `chroma.from` without any configuration.\n*   **Missing `db` and `settings`:** The `db` and `settings` are not being set.\n\n**Recommendations:**\n\n1.  **Examine the `embedding` Object:**  Carefully inspect the `embedding` object to understand how it's being configured.  It's likely that the `embed documents` method is not being called correctly.\n2.  **Verify `documents`:** Ensure the `documents` argument is correctly formatted.\n3.  **Check `db` and `settings`:** Verify that the `db` and `settings` are being set correctly.\n4.  **Debugging:** Add more detailed logging or debugging statements to trace the execution flow and identify the exact point where the error occurs.\n\n**In short, the code is attempting to create a ChromaDB database,", "final_category": "bug", "comments": [{"author": "moore269", "created_at": "2024-11-26T23:26:25Z", "body_clean": "I just tried this on windows. It works on windows platform, but not on linux. I'm not too sure why, but maybe it has something to do with differing sqlite installs?"}, {"author": "dosubot[bot]", "created_at": "2025-02-25T16:00:56Z", "body_clean": "Hi, @moore269. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Encountering [code] : \"database disk image is malformed\" with [code] . Issue persists despite updating to the latest LangChain version. Error occurs on Linux but not on Windows, indicating potential SQLite installation differences. Next Steps Is this issue still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain issue highlights a bug where the `response_format` parameter in the `langchain.agents.openai_assistant.base` method doesn't allow for JSON schemas. The issue was identified through searching, testing, and comparing to similar questions, and the bug is not related to the user’s code.  The solution is to update the code to accept the `response_format` parameter as a valid input, allowing it to function correctly with the OpenAI client library.", "final_category": "bug", "comments": [{"author": "EricBLivingston", "created_at": "2024-11-26T18:28:46Z", "body_clean": "It's also worth mentioning that the create and run in openai threads.py you are calling in the code above does not accept \"run metadata\" as an option; I'd recommend removing that from the list of acceptable keywords. Per their code: python def create and run( self, , assistant id: str, instructions: Optional[str] | NotGiven = NOT GIVEN, max completion tokens: Optional[int] | NotGiven = NOT GIVEN, max prompt tokens: Optional[int] | NotGiven = NOT GIVEN, metadata: Optional[object] | NotGiven = NOT GIVEN, model: Union[str, ChatModel, None] | NotGiven = NOT GIVEN, parallel tool calls: bool | NotGiven = NOT GIVEN, response format: Optional[AssistantResponseFormatOptionParam] | NotGiven = NOT GIVEN, stream: Optional[Literal[False]] | NotGiven = NOT GIVEN, temperature: Optional[float] | NotGiven = NOT GIVEN, thread: thread create and run params.Thread | NotGiven = NOT GIVEN, tool choice: Optional[AssistantToolChoiceOptionParam] | NotGiven = NOT GIVEN, tool resources: Optional[thread create and run params.ToolResources] | NotGiven = NOT GIVEN, tools: Optional[Iterable[thread create and run params.Tool]] | NotGiven = NOT GIVEN, top p: Optional[float] | NotGiven = NOT GIVEN, truncation strategy: Optional[thread create and run params.TruncationStrategy] | NotGiven = NOT GIVEN, Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs. The extra values given here take precedence over values defined on the client or passed to this method. extra headers: Headers | None = None, extra query: Query | None = None, extra body: Body | None = None, timeout: float | [link] | None | NotGiven = NOT GIVEN, ) Run:"}, {"author": "EricBLivingston", "created_at": "2024-11-26T20:25:46Z", "body_clean": "I think I've narrowed down how this should work that is, how to create and use OpenAI assistants with a schema response format. The following code works using the OpenAI client from openai (once I edit create thread and run to accept response format), but if I try to swap the client instantiation by uncommenting out the ChatOpenAI version (that has .with structured output) then it fails the ChatOpenAI client doesn't have the beta.assistants component. However, OpenAIAssistantRunnable also has no way of using with structured output (and, seemingly, no way to delete an assistant once created, which is why I have to pass in an OpenAI client, to keep track of it and use its deletion ability later). So, I think we need to incorporate with structured output into the creation of Assistants, and we also need the ability to delete them later. python from openai import OpenAI from langchain openai import ChatOpenAI from pydantic import BaseModel from langchain.agents.openai assistant.base import OpenAIAssistantRunnable api key = 'My API Key' class Step(BaseModel): explanation: str output: str class Response(BaseModel): steps: list[Step] final answer: str client = ChatOpenAI(openai api key=api key).with structured output(Response) client = OpenAI(api key=api key) assistant = OpenAIAssistantRunnable.create assistant( client=client, name=\"Math Tutor\", instructions=\"You are a helpful math tutor.\", tools=[], No tools required model=\"gpt 4o mini\" ) input query = { \"content\": \"Solve 8x + 31 = 2.\", 'response format': { 'type': 'json schema', 'json schema': { 'name': 'math response', 'schema': Response.model json schema() } } } try: response = assistant.invoke(input query) print(response) except Exception as e: print(f\"An error occurred: {e}\") finally: try: response = client.beta.assistants.delete(assistant.assistant id) if response.deleted: print(f\"Assistant {assistant.assistant id} has been successfully deleted.\") else: print(f\"Failed to delete assistant {assistant.assistant id}.\") except Exception as e: print(f\"An error occurred while deleting the assistant: {e}\")"}, {"author": "winsento", "created_at": "2025-01-12T18:26:23Z", "body_clean": "A similar problem is described in issue 17574 only with additional instructions."}, {"author": "dosubot[bot]", "created_at": "2025-04-13T16:00:55Z", "body_clean": "Hi, @EricBLivingston. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] methods lack support for the [code] parameter, which is now available in OpenAI clients. You suggested updating the code to include this parameter and noted that manual edits resolve the issue. The [code] method in [code] incorrectly lists [code] as an acceptable keyword. You highlighted the need for [code] in assistant creation and the ability to delete assistants. User winsento mentioned a related issue, 17574, about [code] . Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe API reference link for Google Vertex AI Embeddings in LangChain’s documentation is broken, resulting in a “Page Not Found” error. This issue hinders users from accessing detailed documentation and configuration options.  The proposed solution is to update the link to point to the correct API reference page or provide an explanation if the page is unavailable.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-25T16:00:58Z", "body_clean": "Hi, @rahulsamant37. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a broken link in the LangChain documentation related to Google Vertex AI Embeddings. The link currently leads to a \"Page Not Found\" error. You requested an update to the correct API reference page or an explanation if unavailable. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain application is failing to retrieve documents with Bedrock KnowledgeBase/Amazon KnowledgeBasesRetriever metadata due to a mismatch between the prompt template and the metadata structure. The current hack attempts to bypass the metadata check by allowing the dictionary path, which is causing the issue.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-25T16:00:59Z", "body_clean": "Hi, @bdavj. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug in LangChain's [code] affects handling multi layer metadata. The issue is particularly relevant for sources like BedrockKnowledgeBase. Current implementation struggles with accessing nested metadata fields, impacting document retrieval chains. A temporary workaround exists, but a robust solution is suggested to specify dictionary paths for nested metadata. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a critical problem with LangChain's SQLDatabaseLoader, specifically when attempting to query the database using the `SQLDatabaseLoader` component. The code encounters a `pyodbc.Error: (HY010)` exception, indicating a function sequence error within the SQL Server driver. This error consistently occurs when the `SELECT` query is executed, triggering a `SQLFetch` error. The traceback points to a potential issue with the SQL Server driver configuration or a problem with the query itself, but the issue isn't resolved by updating the LangChain version.  The code attempts to load data from a database using the `SQLDatabaseLoader` and the `load()` method, which is failing.  The code is currently using a specific `SQLDatabaseLoader` configuration that is causing the error.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-25T16:00:53Z", "body_clean": "Hi, @JuanSaavedra. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You are encountering an error with the [code] in LangChain. The error occurs during the initialization and query execution process. You have followed the documentation and are using the latest version. There have been no further comments or developments on this issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment and keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "thisnotebooksuser", "created_at": "2025-08-27T20:01:34Z", "body_clean": "I'm getting the same error. I created a specific file for testing this and, even with minimal implementation, I still get the issue. PS: sorry for a billion edits, I'm new to the website and can't format my stuff correctly. from langchain community.utilities.sql database import SQLDatabase from langchain community.document loaders.sql database import SQLDatabaseLoader from sqlalchemy import create engine, text from langchain core.documents import Document db user = 'lanchain issue' db password = 'pwd langchain issue' db host = 'localhost' db name = 'langchain issue' sql server uri = f\"mssql+pyodbc://{db user}:{db password}@{db host}/{db name}?driver=ODBC+Driver+17+for+SQL+Server\" query = 'SELECT CONTENT FROM docs test' def load documents from sql(): engine = create engine(sql server uri) documents = [] with engine.connect() as connection: result = connection.execute(text(query)) for row in result: doc = Document(page content=str(row.CONTENT)) documents.append(doc) return documents documents = load documents from sql() print(documents) print(\"OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\") this is only here so it's easier to tell apart the outputs of the different parts of the code; without this, looking at the console was giving me headaches and yes, I realize I could have been smarter about this print(\"OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\") print(\"OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\") sql db = SQLDatabase.from uri(sql server uri) sql loader = SQLDatabaseLoader(query=query, db = sql db) sql loaded = sql loader.load() print(sql loaded) Here's what I get in the console: \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Scripts\\python.exe\" \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\run.py\" [Document(metadata={}, page content='im not an error!')] OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO Traceback (most recent call last): File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\cursor.py\", line 1106, in fetchone row = dbapi cursor.fetchone() pyodbc.Error: ('HY010', '[HY010] [Microsoft][ODBC Driver 17 for SQL Server]Function sequence error (0) (SQLFetch)') The above exception was the direct cause of the following exception: Traceback (most recent call last): File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\run.py\", line 37, in <module sql loaded = sql loader.load() File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\langchain core\\document loaders\\base.py\", line 32, in load return list(self.lazy load()) File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\langchain community\\document loaders\\sql database.py\", line 90, in lazy load for i, row in enumerate(result.mappings()): ~~~~~~~~~^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\result.py\", line 527, in iterrows for raw row in self. fetchiter impl(): ~~~~~~~~~~~~~~~~~~~~^^ File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\cursor.py\", line 2126, in fetchiter impl row = fetchone(self, self.cursor) File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\cursor.py\", line 1111, in fetchone self.handle exception(result, dbapi cursor, e) ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\cursor.py\", line 1082, in handle exception result.connection. handle dbapi exception( ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^ err, None, None, dbapi cursor, result.context ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ) ^ File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\base.py\", line 2355, in handle dbapi exception raise sqlalchemy exception.with traceback(exc info[2]) from e File \"C:\\Users\\User\\PycharmProjects\\langchain moretests\\.venv\\Lib\\site packages\\sqlalchemy\\engine\\cursor.py\", line 1106, in fetchone row = dbapi cursor.fetchone() sqlalchemy.exc.DBAPIError: (pyodbc.Error) ('HY010', '[HY010] [Microsoft][ODBC Driver 17 for SQL Server]Function sequence error (0) (SQLFetch)') (Background on this error at: [link] I have: langchain==0.3.27 langchain cohere==0.4.5 langchain community==0.3.29 langchain core==0.3.75 langchain text splitters==0.3.9 langgraph==0.6.6 langgraph checkpoint==2.1.1 langgraph prebuilt==0.6.4 langgraph sdk==0.2.3 langsmith==0.4.19 Running on python 3.13.3 on Windows 10.0.26100. No langserve, just like OP. Full pip freeze: aiohappyeyeballs==2.6.1 aio [link] aiosignal==1.4.0 annotated types==0.7.0 anyio==4.10.0 attrs==25.3.0 beautifulsoup4==4.13.5 bs4==0.0.2 certifi==2025.8.3 charset normalizer==3.4.3 cohere==5.17.0 colorama==0.4.6 dataclasses json==0.6.7 fastavro==1.12.0 filelock==3.19.1 frozenlist==1.7.0 fsspec==2025.7.0 greenlet==3.2.4 h11==0.16.0 [link] [link] [link] huggingface hub==0.34.4 idna==3.10 jsonpatch==1.33 jsonpointer==3.0.0 langchain==0.3.27 langchain cohere==0.4.5 langchain community==0.3.29 langchain core==0.3.75 langchain text splitters==0.3.9 langgraph==0.6.6 langgraph checkpoint==2.1.1 langgraph prebuilt==0.6.4 langgraph sdk==0.2.3 langsmith==0.4.19 marshmallow==3.26.1 multidict==6.6.4 mypy extensions==1.1.0 numpy==2.3.2 orjson==3.11.3 ormsgpack==1.10.0 packaging==25.0 propcache==0.3.2 pydantic==2.11.7 pydantic settings==2.10.1 pydantic core==2.33.2 pyodbc==5.2.0 python dotenv==1.1.1 PyYAML==6.0.2 requests==2.32.5 requests toolbelt==1.0.0 sniffio==1.3.1 soupsieve==2.8 SQLAlchemy==2.0.43 tenacity==9.1.2 tokenizers==0.21.4 tqdm==4.67.1 types PyYAML==6.0.12.20250822 types requests==2.32.4.20250809 typing inspect==0.9.0 typing inspection==0.4.1 typing extensions==4.15.0 urllib3==2.5.0 xxhash==3.5.0 yarl==1.20.1 zstandard==0.24.0"}]}], "business_insights": ["**Metadata Consistency:**  The embedding object’s configuration is a primary source of errors, highlighting a need for stricter validation and consistent schema usage.", "**Driver Conflicts:** The pyodbc.Error indicates a potential driver conflict, suggesting a need for driver updates or configuration adjustments.", "**SQL Server Driver:** The root cause of the SQLFetch error points to the SQL Server driver configuration, requiring investigation and potential optimization.", "**Prompt Template vs. Metadata:** The mismatch between the prompt template and metadata is a critical issue; the code must ensure proper metadata mapping.", "**Data Retrieval:** The issue with SQLDatabaseLoader and load() suggests a complex data retrieval process that needs careful examination."], "technical_insights": ["**embedding Object:** The embedding object is the core of the issue, and its configuration is the key to the problem.", "**documents Argument:** The documents argument is not being properly used with the embedding process.", "**db and settings:** The missing db and settings are not being set, which is a significant source of the error.", "**pyodbc.Error:** The pyodbc.Error is a critical error indicating a driver problem.", "**SQL Server Driver:** The SQL Server driver configuration is the root cause of the SQLFetch error."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  **Metadata Consistency:**  The `embedding` object’s configuration is a primary source of errors, highlighting a need for stricter validation and consistent schema usage.\n2.  **Driver Conflicts:** The `pyodbc.Error` indicates a potential driver conflict, suggesting a need for driver updates or configuration adjustments.\n3.  **SQL Server Driver:** The root cause of the `SQLFetch` error points to the SQL Server driver configuration, requiring investigation and potential optimization.\n4.  **Prompt Template vs. Metadata:** The mismatch between the prompt template and metadata is a critical issue; the code must ensure proper metadata mapping.\n5.  **Data Retrieval:** The issue with `SQLDatabaseLoader` and `load()` suggests a complex data retrieval process that needs careful examination.\n\nTECHNICAL INSIGHTS:\n1.  **`embedding` Object:** The `embedding` object is the core of the issue, and its configuration is the key to the problem.\n2.  **`documents` Argument:** The `documents` argument is not being properly used with the embedding process.\n3.  **`db` and `settings`:** The missing `db` and `settings` are not being set, which is a significant source of the error.\n4.  **`pyodbc.Error`:** The `pyodbc.Error` is a critical error indicating a driver problem.\n5.  **SQL Server Driver:** The SQL Server driver configuration is the root cause of the `SQLFetch` error.\n", "batch_number": 171, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue involves a persistent problem where LangChain's `pgvector` database sessions remain idle in the pgAdmin interface, causing errors and impacting concurrency. This is likely due to a bug in the LangChain PostgreSQL integration, potentially related to session timeouts or database connection handling. The solution involves updating to the latest stable version of LangChain and ensuring the PostgreSQL connection parameters are correctly configured.", "final_category": "bug", "comments": [{"author": "Archimonde666", "created_at": "2024-12-12T17:27:51Z", "body_clean": "Same issue here with connection object managed by PGVector : [code] ![image]( [link]"}, {"author": "EricBLivingston", "created_at": "2024-12-30T21:34:43Z", "body_clean": "I'm having the same problem; sessions are not being closed and are being used up completely."}, {"author": "dosubot[bot]", "created_at": "2025-03-31T16:01:00Z", "body_clean": "Hi, @nitual1. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves the LangChain PGVector library not closing database sessions automatically. This leads to reaching the maximum number of concurrent sessions in pgAdmin. Attempts to use PostgreSQL timeout parameters have not resolved the issue. Other users, including @Archimonde666 and @EricBLivingston, have confirmed experiencing the same problem. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "nitual1", "created_at": "2025-04-01T05:58:36Z", "body_clean": "This issue is not relevant anymore. I didn't see it reproducing anymore. Thank you!"}, {"author": "dosubot[bot]", "created_at": "2025-04-01T06:02:50Z", "body_clean": "Thank you for your response, @nitual1! We're glad to hear that the issue is no longer relevant. We'll go ahead and close this issue now."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe `aload` function in LangChain is not designed for concurrent execution, preventing it from working with other asynchronous operations.  After investigating through documentation, search, and code, the issue is a fundamental bug within the function’s design.  Attempts to update to the latest version of LangChain haven’t resolved the problem.", "final_category": "bug", "comments": [{"author": "yeounhak", "created_at": "2024-11-29T07:34:38Z", "body_clean": "In the document loaders folder, there are 9 files that implement aload or alazy load, but only web base.py is not defined as an async def. This causes inconvenience for users, who need to check the code to determine whether to use await aload() or aload() . A bigger problem is that users cannot use web base.py's aload concurrently with other async functions. The root cause is that web base.py overrides the aload function from [langchain core's base.py]( [link] as [a synchronous function in here]( [link] Therefore, I submitted a pull request to fix this issue in 28337. The 9 files that use the aload function, which I found in the document loaders folder, are: 1. async html.py 2. astradb.py 3. cassandra.py 4. chromium.py 5. merge.py 6. mongodb.py 7. surrealdb.py 8. url playwright.py 9. web base.py @baskaryan @efriis @eyurtsev @ccurme @vbarda @hwchase17"}, {"author": "dosubot[bot]", "created_at": "2025-02-28T16:01:24Z", "body_clean": "Hi, @yeounhak. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where the [code] function in [code] is not asynchronous. This inconsistency affects concurrent execution with other async functions. You submitted a pull request ( 28337) to resolve this issue. Several maintainers were tagged for review, but the issue remains unresolved. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The `Marqo.add_texts()` function throws an exception when using Marqo versions 2.0 and above in LangChain.  The issue stems from a bug in LangChain's integration of Marqo, specifically when it doesn’t populate vector stores after removing the Marqo integration.  Attempts to update LangChain to the latest stable version haven’t resolved the problem.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-25T23:44:50Z", "body_clean": "@tad1 [code] was still accounting for v1.5.x API but in the above PR accounted for later 2.x versions"}]}, {"ollama_summary": "This issue stems from a bug in LangChain's Ollama integration that causes an `TypeError: 'NoneType' object is not iterable` error when attempting to iterate through the chat stream. The code is attempting to use the `generate` method with a `messages` list, but the `messages` list is unexpectedly empty, leading to this error.  The suggested solution is to ensure the `messages` list is populated with some data before calling the `invoke` method.", "final_category": "bug", "comments": [{"author": "Fernando7181", "created_at": "2024-11-23T13:15:23Z", "body_clean": "we had another issue that was similar to this one, maybe try [code] and see if that works"}, {"author": "bauerem", "created_at": "2024-11-23T14:43:42Z", "body_clean": "Yes, that is how I would also fix the bug in the langchain implementation"}, {"author": "Fernando7181", "created_at": "2024-11-23T14:45:31Z", "body_clean": "Yes, that is how I would also fix the bug in the langchain implementation did it work?"}, {"author": "keenborder786", "created_at": "2024-11-23T23:19:13Z", "body_clean": "@bauerem please upgrade to latest version of [code] . It should fix the issue."}, {"author": "espositodaniele", "created_at": "2024-11-24T17:20:02Z", "body_clean": "Same error here: Package Information ollama 0.4.1 langchain 0.3.8 langchain community 0.3.8 langchain core 0.3.21 langchain ollama 0.2.0 Code example [code] Error TypeError Traceback (most recent call last) Cell In[34], [line 4](vscode notebook cell:?execution count=34&line=4) [1](vscode notebook cell:?execution count=34&line=1) from langchain ollama import ChatOllama [3](vscode notebook cell:?execution count=34&line=3) model = ChatOllama(model=\"llama3.2\", temperature=0) [4](vscode notebook cell:?execution count=34&line=4) model.invoke(\"Chi è il presidente degli Stati Uniti?\") File ~/aidev/pdf rag/.venv/lib/python3.13/site packages/langchain core/language models/chat models.py:286, in BaseChatModel.invoke(self, input, config, stop, kwargs) [275]( [link] def invoke( [276]( [link] self, [277]( [link] input: LanguageModelInput, (...) [281]( [link] kwargs: Any, [282]( [link] ) BaseMessage: [283]( [link] config = ensure config(config) [284]( [link] return cast( [285]( [link] ChatGeneration, [286]( [link] self.generate prompt( [287]( [link] [self. convert input(input)], [288]( [link] stop=stop, [289]( [link] callbacks=config.get(\"callbacks\"), [290]( [link] tags=config.get(\"tags\"), [291]( [link] metadata=config.get(\"metadata\"), [292]( [link] run name=config.get(\"run name\"), [293]( [link] run id=config.pop(\"run id\", None), ... [76]( [link] ) [77]( [link] ) [78]( [link] return tool calls TypeError: 'NoneType' object is not iterable"}, {"author": "nourishnew", "created_at": "2024-11-25T16:16:31Z", "body_clean": "@keenborder786 Latest version doesn't seem to have the None check."}, {"author": "keenborder786", "created_at": "2024-11-25T21:22:30Z", "body_clean": "@nourishnew yeap you are correct I have fixed it it in the PR. Hopefully in the next release it will be fixed."}, {"author": "dosubot[bot]", "created_at": "2025-02-24T16:00:58Z", "body_clean": "Hi, @bauerem. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a bug in LangChain's ChatOllama model causing a 'NoneType' object is not iterable error. @Fernando7181 suggested a fix by checking if [code] is not None, which you agreed with. @keenborder786 mentioned a fix has been made in a pull request and will be included in the next release. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain’s `SQLDatabaseToolkit` that’s preventing the user from successfully building the tool. The code was working fine before, and the problem is now occurring after an update to LangChain. The user needs to define `BaseCache` and then call `SQLDatabaseToolkit.model_rebuild()` to resolve the issue.", "final_category": "bug", "comments": [{"author": "ksteimel", "created_at": "2024-11-22T16:54:22Z", "body_clean": "I had a similar issue and downgrading pydantic to 2.9.2 resolved it for me."}, {"author": "ahmed33033", "created_at": "2024-11-22T17:04:16Z", "body_clean": "28257 mentions a very similar issue!"}, {"author": "eyurtsev", "created_at": "2024-11-22T20:04:32Z", "body_clean": "Breaking due to new pydantic release: [link] investigating"}, {"author": "yadav-shivani", "created_at": "2024-11-23T12:51:52Z", "body_clean": "I had a similar issue and downgrading pydantic to 2.9.2 resolved it for me. Thanks a lot!. It is working for me now."}, {"author": "Viicos", "created_at": "2024-11-24T11:36:35Z", "body_clean": "As discussed on Slack: [link] fixed the issue, however there might be a more robust way to fix it. The [ [code] ]( [link] is a Pydantic model with a [code] field annotated as [code] . This class, also a Pydantic model, has a [code] field defined: [link] Because [code] is imported in an [ [code] ]( [link] block, meaning Pydantic can't know about it (same for [code] , used in another field): [link] For every Pydantic model using [code] , the current fix from [link] added a [code] call and imported the missing symbols. While this works, this is quite confusing as is. The reason it works is [code] will use the module namespace where is it called to resolve annotations that previously failed to resolve. Hence the added [code] and [code] imports in the aforementioned PR. Here are options I would consider instead: For every [code] call, provide the missing annotations using the [code] argument, e.g. [code] . This is more explicit, as we at least know why the two imports were added and not used explicitly in the module (I believe that's why you had to use the [code] form — initially used by typing stub files — to avoid having the import marked as unused). Fix the root issue: instead of rebuilding every model making use of [code] , I would strongly recommend having [code] defined properly in the first place. It seems like moving [code] and [code] outside of the [code] block does not cause any circular import issues. Additionally, it seems like [code] (which [code] inherits from) is defined as a Pydantic model. [code] has only one field that Pydantic can validate ( [code] , itself a Pydantic model), meaning you had to use [code] . Is validation necessary for these kind of classes? Pydantic's primarily usage is to validate data, having most of the fields using arbitrary types (meaning no validation is performed) defeats the initial purpose of the library [^1]. [^1]: Note that I'm not familiar with this library, there might be a valid reason for [code] / [code] to be Pydantic models."}, {"author": "Manideep-Kanna", "created_at": "2025-04-20T07:37:24Z", "body_clean": "I have faced the same issue while trying to install only langchain core and langchain opeanai. But additionally I have installed langchain package which resolved my issue"}]}], "business_insights": ["LangChain’s PostgreSQL integration is a critical point of failure, potentially impacting concurrency.", "Session timeouts in the pgvector database could be a root cause, requiring a fix.", "Updating LangChain must address potential design flaws within the aload function.", "Marqo version compatibility issues require a focused update strategy.", "Ollama integration bug causes an TypeError when iterating through chat streams."], "technical_insights": ["LangChain’s PostgreSQL integration requires careful session management.", "The aload function’s design needs revisiting for concurrency.", "Marqo’s integration has a bug that affects vector store population.", "Ollama integration’s TypeError is a fundamental bug impacting data handling.", "LangChain’s SQLDatabaseToolkit requires BaseCache configuration."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain’s PostgreSQL integration is a critical point of failure, potentially impacting concurrency.\n2.  Session timeouts in the `pgvector` database could be a root cause, requiring a fix.\n3.  Updating LangChain must address potential design flaws within the `aload` function.\n4.  Marqo version compatibility issues require a focused update strategy.\n5.  Ollama integration bug causes an `TypeError` when iterating through chat streams.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s PostgreSQL integration requires careful session management.\n2.  The `aload` function’s design needs revisiting for concurrency.\n3.  Marqo’s integration has a bug that affects vector store population.\n4.  Ollama integration’s `TypeError` is a fundamental bug impacting data handling.\n5.  LangChain’s `SQLDatabaseToolkit` requires `BaseCache` configuration.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]\n\nTECHNICAL INSIGHTS:\n1.  [insight here]\n2.  [insight here]\n3.  [insight here]\n4.  [insight here]\n5.  [insight here]", "batch_number": 172, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue is preventing the installation of LangChain due to a circular dependency between LangChain, deepsearch glm, docling, and langchain.  Specifically, deepsearch glm requires numpy version 1.26.0, which in turn requires langchain version 0.3.7, and docling version 2.7.0, creating a conflict that the system cannot resolve. The user wants to install both concurrently and the current solution is failing.", "final_category": "bug", "comments": [{"author": "vagenas", "created_at": "2024-11-22T20:50:06Z", "body_clean": "@ryotaro ikeda0 for a workaround check out this comment: [link]"}, {"author": "ryotaro-ikeda0", "created_at": "2024-11-25T06:28:56Z", "body_clean": "@vagenas Thank you so much!! resolved!"}]}, {"ollama_summary": "This issue is concerning a bug in the LangChain `SteamWebAPIWrapper` library that causes errors when importing functions from the `Steam` package. The code attempts to access functions from a package that isn’t properly initialized, leading to system-level errors and a lack of response from the library.  The issue appears to be a fundamental bug within LangChain itself, and attempts to update to the latest version haven't resolved it.", "final_category": "bug", "comments": []}, {"ollama_summary": "This issue report indicates a critical problem with the Langchain Ollama chatbot. The chatbot is currently unresponsive and failing to provide text output, and the issue is being reported as a bug stemming from a recent update to the Ollama integration package.  The report details a series of dependency issues and suggests a potential regression in the chatbot’s functionality, requiring investigation and potential rollback to a previous stable version of LangChain.", "final_category": "bug", "comments": [{"author": "rtuin", "created_at": "2024-11-22T10:05:43Z", "body_clean": "I'm also getting this error using [code] model. Perhaps it helps to share the stack trace: [code] Edit: mention that i use a different model"}, {"author": "Ruslando", "created_at": "2024-11-22T11:08:06Z", "body_clean": "Same thing happening with Llama3.1"}, {"author": "Ruslando", "created_at": "2024-11-22T11:08:06Z", "body_clean": "Same thing happening with Llama3.1"}, {"author": "Fernando7181", "created_at": "2024-11-22T16:20:28Z", "body_clean": "I was having this problem using llama3 but once switched to llma3.1 everything is working fine and using base model"}, {"author": "AlbertoFormaggio1", "created_at": "2024-11-22T17:05:36Z", "body_clean": "@Fernando7181 can it be the case that llama3.1 was already downloaded in your system, while llama3 was freshly downloaded after the update? I am having this problem with every model I am using (all of them pulled today from ollama)"}, {"author": "pythongirl325", "created_at": "2024-11-22T18:29:04Z", "body_clean": "I believe the Ollama 0.4.0 update changed how the tool call API works, it now returns [code] instead of having no [code] key on the response message ( [link] [link] Here the condition should be [code] instead of [code]"}, {"author": "miguelg719", "created_at": "2024-11-22T18:44:13Z", "body_clean": "@pythongirl325 great lead, attaching log to support this issue. Nonetheless, it's interesting that in my case it's able to select a tool but not generate a text output response, even when taking out tools and only using a simple ChatOllama call | ERROR:backend.main:Error testing Ollama: 'NoneType' object is not iterable | Traceback (most recent call last): | File \"/app/backend/main.py\", line 58, in test ollama | response = await ollama chat completion( | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | File \"/app/backend/agent/services.py\", line 29, in ollama chat completion | response = await llm.ainvoke(messages) | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ | File \"/usr/local/lib/python3.11/site packages/langchain core/language models/chat models.py\", line 307, in ainvoke | llm result = await self.agenerate prompt( | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | File \"/usr/local/lib/python3.11/site packages/langchain core/language models/chat models.py\", line 796, in agenerate prompt | return await self.agenerate( | ^^^^^^^^^^^^^^^^^^^^^ | File \"/usr/local/lib/python3.11/site packages/langchain core/language models/chat models.py\", line 756, in agenerate | raise exceptions[0] | File \"/usr/local/lib/python3.11/site packages/langchain core/language models/chat models.py\", line 924, in agenerate with cache | result = await self. agenerate( | ^^^^^^^^^^^^^^^^^^^^^^ | File \"/usr/local/lib/python3.11/site packages/langchain ollama/chat models.py\", line 731, in agenerate | final chunk = await self. achat stream with aggregation( | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | File \"/usr/local/lib/python3.11/site packages/langchain ollama/chat models.py\", line 601, in achat stream with aggregation | tool calls= get tool calls from response(stream resp), | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | File \"/usr/local/lib/python3.11/site packages/langchain ollama/chat models.py\", line 70, in get tool calls from response | for tc in response[\"message\"][\"tool calls\"]: | TypeError: 'NoneType' object is not iterable"}, {"author": "Fernando7181", "created_at": "2024-11-22T18:51:25Z", "body_clean": "@Fernando7181 can it be the case that llama3.1 was already downloaded in your system, while llama3 was freshly downloaded after the update? I am having this problem with every model I am using (all of them pulled today from ollama) I don't think so because I downloaded not that long ago, and I'm using it for my vector database and RAG system and seems to be working just fine. I know that when I was using llama3 wasn't working"}, {"author": "rrajakaec", "created_at": "2024-11-22T18:53:07Z", "body_clean": "How to resolve this issue? Do we need to re download the llama3.2 model or we need to switch to ChatOpenAI. Do we need to wait till the issue is resolved by the support team. From llm = ChatOllama(model='llama3.2', temperature=0) To llm = ChatOpenAI(model=\"llama3.2\", api key=\"ollama\", base url=\" [link] temperature=0)"}, {"author": "pythongirl325", "created_at": "2024-11-22T18:57:14Z", "body_clean": "@pythongirl325 great lead, attaching log to support this issue. Nonetheless, it's interesting that in my case it's able to select a tool but not generate a text output response, even when taking out tools and only using a simple ChatOllama call I experienced this without any tools as well. I wanted to try and switch from using the ollama api directly to using the langchain library. Here's the code I ran to get the issue: [code] My stack trace looks pretty much like yours. I have not used langchain before, so I might be doing something wrong here."}, {"author": "rtuin", "created_at": "2024-11-22T19:05:17Z", "body_clean": "@edmcman made a fix for this here: [link]"}, {"author": "edmcman", "created_at": "2024-11-22T19:11:58Z", "body_clean": "As a work around, you can [code]"}, {"author": "rrajakaec", "created_at": "2024-11-22T19:23:49Z", "body_clean": "As a work around, you can [code] After downgrading the ollama 0.4.0 to ollama 0.3.3, the issue got resolved."}, {"author": "lsukharn", "created_at": "2024-11-22T20:43:26Z", "body_clean": "pip install 'ollama<0.4.0' works for me. Thanks @edmcman"}, {"author": "Fernando7181", "created_at": "2024-11-22T20:53:13Z", "body_clean": "@pythongirl325 great lead, attaching log to support this issue. Nonetheless, it's interesting that in my case it's able to select a tool but not generate a text output response, even when taking out tools and only using a simple ChatOllama call I experienced this without any tools as well. I wanted to try and switch from using the ollama api directly to using the langchain library. Here's the code I ran to get the issue: [code] My stack trace looks pretty much like yours. I have not used langchain before, so I might be doing something wrong here. This is how im doing mine [code]"}, {"author": "hgudella", "created_at": "2024-11-23T03:07:54Z", "body_clean": "I believe the Ollama 0.4.0 update changed how the tool call API works, it now returns [code] instead of having no [code] key on the response message ( [link] [link] Here the condition should be [code] instead of [code] This is the actual fix. Can we please create new version and publish with fix? Thank You!"}, {"author": "Fernando7181", "created_at": "2024-11-23T13:13:44Z", "body_clean": "I agree, i think [code] Should be the right fix and we could close this issue"}, {"author": "edmcman", "created_at": "2024-11-23T16:00:03Z", "body_clean": "That is the fix here: [link]"}, {"author": "jmorganca", "created_at": "2024-11-24T02:35:39Z", "body_clean": "Hi all, this is also fixed in the [code] package from version 0.4.1 onwards – so sorry about that: [link] [code]"}, {"author": "espositodaniele", "created_at": "2024-11-24T17:33:36Z", "body_clean": "Still having issue here: Package Information ollama 0.4.1 langchain 0.3.8 langchain community 0.3.8 langchain core 0.3.21 langchain ollama 0.2.0 Code example [code] Error TypeError Traceback (most recent call last) Cell In[34], [line 4](vscode notebook cell:?execution count=34&line=4) [1](vscode notebook cell:?execution count=34&line=1) from langchain ollama import ChatOllama [3](vscode notebook cell:?execution count=34&line=3) model = ChatOllama(model=\"llama3.2\", temperature=0) [4](vscode notebook cell:?execution count=34&line=4) model.invoke(\"Chi è il presidente degli Stati Uniti?\") File ~/aidev/pdf rag/.venv/lib/python3.13/site packages/langchain core/language models/chat models.py:286, in BaseChatModel.invoke(self, input, config, stop, kwargs) [275]( [link] def invoke( [276]( [link] self, [277]( [link] input: LanguageModelInput, (...) [281]( [link] kwargs: Any, [282]( [link] ) BaseMessage: [283]( [link] config = ensure config(config) [284]( [link] return cast( [285]( [link] ChatGeneration, [286]( [link] self.generate prompt( [287]( [link] [self. convert input(input)], [288]( [link] stop=stop, [289]( [link] callbacks=config.get(\"callbacks\"), [290]( [link] tags=config.get(\"tags\"), [291]( [link] metadata=config.get(\"metadata\"), [292]( [link] run name=config.get(\"run name\"), [293]( [link] run id=config.pop(\"run id\", None), ... [76]( [link] ) [77]( [link] ) [78]( [link] return tool calls TypeError: 'NoneType' object is not iterable"}, {"author": "edmcman", "created_at": "2024-11-24T18:12:44Z", "body_clean": "@espositodaniele Are you sure that is the entire traceback?"}, {"author": "espositodaniele", "created_at": "2024-11-24T18:52:54Z", "body_clean": "here the full error: [code]"}, {"author": "edmcman", "created_at": "2024-11-24T19:41:13Z", "body_clean": "It does seem like the same problem. Did you restart your notebook kernel to ensure that it has the new ollama code?"}, {"author": "espositodaniele", "created_at": "2024-11-24T20:04:06Z", "body_clean": "Thank you, I have restarted everything, and it seems to be working with the updates."}, {"author": "Fernando7181", "created_at": "2024-11-25T13:08:28Z", "body_clean": "glad that the issue was solved, so do we close this issue now?"}, {"author": "miguelg719", "created_at": "2024-11-25T21:23:53Z", "body_clean": "Confirmed working on 0.4.1, closing the issue thanks everyone!"}, {"author": "wujb13", "created_at": "2024-11-26T08:30:00Z", "body_clean": "try langchain==0.3.1, langchain ollama==0.2.0"}]}, {"ollama_summary": "The issue stems from a bug in LangChain's `get_by_ids` method for Chroma, which is not yet fully supported. This causes a `NotImplementedError` when attempting to retrieve documents by their IDs, requiring a specific version of LangChain (v0.2.11) to be used.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-22T23:44:59Z", "body_clean": "It's currently not supported despite what the documentation said."}, {"author": "Fernando7181", "created_at": "2024-11-23T13:17:18Z", "body_clean": "im using a vector database with chroma and seems to be working just fine, maybe we could help each other but im ingesting the documents first to the db and then pulling the entire db to get the information"}, {"author": "punsoca", "created_at": "2024-11-25T03:47:08Z", "body_clean": "Hi thank you for sharing. I received another email response saying the get by ids isn’t currently available right under langchain chroma. On Sat, Nov 23, 2024 at 5:17 AM Fernando Rodrigues @ . wrote: im using a vector database with chroma and seems to be working just fine, maybe we could help each other but im ingesting the documents first to the db and then pulling the entire db to get the information — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ ."}, {"author": "Fernando7181", "created_at": "2024-11-25T13:11:50Z", "body_clean": "that's interesting. im not polling from ids and most the intire vector data base maybe could be that?"}, {"author": "dosubot[bot]", "created_at": "2025-02-24T16:00:57Z", "body_clean": "Hi, @punsoca. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] method in [code] raises a [code] . Documentation incorrectly suggests that [code] is supported. You acknowledged that the method is not available in the current package version. Alternative data retrieval methods, like document ingestion, are suggested. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that causes the `SafetySetting` annotation to be undefined when using the `ChatVertexAI` integration. This problem is not resolved by updating the LangChain version, and the error occurs when the exact example code from the documentation is used.  The code involves several dependencies and potential issues with the `pydantic` library.", "final_category": "bug", "comments": [{"author": "OlaPietka", "created_at": "2024-11-22T09:46:49Z", "body_clean": "I have the same issue. No resolution whatsoever."}, {"author": "twiedijk", "created_at": "2024-11-22T09:59:05Z", "body_clean": "It can be resolved by downgrading to pydantic==2.9.0"}, {"author": "Luc2357", "created_at": "2024-11-22T11:01:15Z", "body_clean": "See [link]"}, {"author": "andrewginns", "created_at": "2024-11-22T11:01:46Z", "body_clean": "I am also having this problem, no changes in pinned dependencies but suddenly my container is failing. I can replicate this consistenly on both [code] and [code] , I've not tested other versions. This minimal Dockerfile demonstrates the issue: [code]"}, {"author": "k3ybladewielder", "created_at": "2024-11-22T13:05:44Z", "body_clean": "I encountered the same issue and resolved it by downgrading to pydantic==2.9.0 See [langchain ai/langchain google 610]( [link] Thanks for the answer @twiedijk @Luc2357. I tried and works well. I'll wait for the bug fix in the meantime"}, {"author": "Viicos", "created_at": "2024-11-22T14:04:18Z", "body_clean": "See [link] for more details. TL;DR: Upgrade back to 2.9 to avoid the issue. But do note that the 2.10 release revealed what could be a genuine bug in the [code] library, as the field annotations are not properly resolved to the correct type."}, {"author": "daniel-deychakiwsky", "created_at": "2024-11-22T16:06:05Z", "body_clean": "@k3ybladewielder @Viicos we experienced the same issue. Would you happen to the have the bug link open within the langchain google? I notcied [link] is closed."}, {"author": "Viicos", "created_at": "2024-11-22T16:07:49Z", "body_clean": "The original author closed it but it was mentioned that it should be kept open. I do not maintain the library so we'll have to wait for them to reopen it again. In the meanwhile you can probably subscribe to the closed issue. I'm currently working on a fix."}, {"author": "DanielAvdar", "created_at": "2024-11-24T09:48:32Z", "body_clean": "same"}, {"author": "ProtikKumarBiswas", "created_at": "2024-12-15T13:34:35Z", "body_clean": "It can be resolved by downgrading to pydantic==2.9.0 This resolved the issue. Thanks."}, {"author": "dosubot[bot]", "created_at": "2025-03-16T16:01:01Z", "body_clean": "Hi, @k3ybladewielder. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a [code] due to an undefined annotation 'SafetySetting' in the [code] model. Several users, including @OlaPietka and @andrewginns, have confirmed the same problem. A temporary solution is to downgrade to [code] , which has been effective. The issue is linked to a potential bug in the [code] library and is tracked in a related issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "ezhilvendhan", "created_at": "2025-03-18T08:36:55Z", "body_clean": "The issue still persists with v2.0.15"}, {"author": "dosubot[bot]", "created_at": "2025-03-18T08:39:18Z", "body_clean": "@eyurtsev, the user @ezhilvendhan has confirmed that the [code] issue with the [code] model still persists in version 2.0.15. Could you please assist them with this?"}, {"author": "Viicos", "created_at": "2025-03-18T09:42:56Z", "body_clean": "The issue still persists with v2.0.15 I can't reproduce, make sure to upgrade all the related dependencies as well."}, {"author": "gmyrianthous", "created_at": "2025-04-17T08:47:25Z", "body_clean": "Issue still persists for myself, with the following package versions: [code] Due to version conflicts in my service, I'm unable to upgrade to the latest [code] but I feel that shouldn't be an issue in the first place. The only workaround is to pin [code] to [code] which is not ideal either."}, {"author": "sydney-runkle", "created_at": "2025-04-17T20:24:20Z", "body_clean": "Hmm, I'm not able to reproduce this with: [code] Closing as resolved for now. Happy to revisit if someone is able to reproduce with those latest deps."}]}], "business_insights": ["Circular dependency is a persistent issue, requiring careful dependency management across multiple libraries.", "Dependency conflicts are a recurring theme, potentially indicating poor versioning practices.", "Addressing circular dependencies is a significant challenge requiring a systematic approach.", "Version conflicts are impacting multiple libraries, demanding careful version control.", "Dependency resolution is crucial for maintaining system stability, necessitating robust tools."], "technical_insights": ["Deepsearch glm's numpy version requirement highlights a potential incompatibility layer.", "LangChain SteamWebAPIWrapper bug suggests a fundamental flaw in the library's integration process.", "Ollama chatbot instability requires investigation into the integration package update.", "LangChain get_by_ids bug for Chroma necessitates a specific version of LangChain.", "SafetySetting annotation undefined error requires a specific version of LangChain."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Circular dependency is a persistent issue, requiring careful dependency management across multiple libraries.\n2. Dependency conflicts are a recurring theme, potentially indicating poor versioning practices.\n3. Addressing circular dependencies is a significant challenge requiring a systematic approach.\n4. Version conflicts are impacting multiple libraries, demanding careful version control.\n5. Dependency resolution is crucial for maintaining system stability, necessitating robust tools.\n\nTECHNICAL INSIGHTS:\n1. Deepsearch glm's numpy version requirement highlights a potential incompatibility layer.\n2. LangChain `SteamWebAPIWrapper` bug suggests a fundamental flaw in the library's integration process.\n3. Ollama chatbot instability requires investigation into the integration package update.\n4. LangChain `get_by_ids` bug for Chroma necessitates a specific version of LangChain.\n5. SafetySetting annotation undefined error requires a specific version of LangChain.\n", "batch_number": 173, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue reports a problem where the ChatCoze system message isn’t functioning correctly, causing an error message and stack trace. This issue appears to be related to a deprecated method within the LangChain library, specifically the `systemMessage` integration.  The suggested solution is to update to the latest stable version of LangChain or the specific integration package.", "final_category": "bug", "comments": [{"author": "lymanzhao", "created_at": "2024-11-21T15:28:46Z", "body_clean": "ref: [link]"}, {"author": "keenborder786", "created_at": "2024-11-22T23:48:36Z", "body_clean": "Please do this: [code]"}, {"author": "lymanzhao", "created_at": "2024-11-28T09:46:29Z", "body_clean": "The issue has been translated but remains unresolved; contacting Coze is recommended, as it appears to be their problem."}]}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where the `ConversationSummaryBufferMemory` object isn't fully defined, requiring the user to define it using `BaseCache` and then call `ConversationSummaryBufferMemory.model_rebuild()`.  The issue was initially reported as a potential bug in the latest version of LangChain, and attempts to resolve it by updating the package haven’t worked.", "final_category": "bug", "comments": [{"author": "miguelrgonzalez", "created_at": "2024-11-21T12:47:14Z", "body_clean": "I had the same issue, but in my case the error was raised when instantiating a custom Retriever. The underlying issue is with the pydantic settings version 2.6.1. Downgrading fixed the problem for me. \"pydantic core==2.23.4\", \"pydantic settings==2.6.0\","}, {"author": "LeadsiftAI", "created_at": "2024-11-21T14:18:06Z", "body_clean": "I had the same issue, but in my case the error was raised when instantiating a custom Retriever. The underlying issue is with the pydantic settings version 2.6.1. Downgrading fixed the problem for me. [code] @miguelrgonzalez thanks, i've downgrade my project's [code] version to [code] and fixed"}, {"author": "coolbeevip", "created_at": "2024-11-22T06:39:19Z", "body_clean": "same issue [code]"}, {"author": "ahmed33033", "created_at": "2024-11-22T15:45:17Z", "body_clean": "I got a similar issue as well, but with SQLDatabaseToolkit. If you're using poetry, I simply changed my pydantic dependency to: [code] , and I ran the following command: [code]"}, {"author": "kuangdai", "created_at": "2024-11-22T21:43:53Z", "body_clean": "Same here. pydantic 2.10.0 pydantic core 2.27.0 pydantic settings 2.6.1"}, {"author": "thecodemancer", "created_at": "2024-11-23T04:50:43Z", "body_clean": "Same here: [code]"}, {"author": "ahmed33033", "created_at": "2024-11-24T15:46:55Z", "body_clean": "28284 mentions a fix to SQLDatabaseToolKit, which suffered the same type of error as ConversationSummaryBufferMemory. The fix was added to the latest langchain core release, so updating your packages should hopefully make your applications work fine again!"}, {"author": "dosubot[bot]", "created_at": "2025-02-23T16:00:59Z", "body_clean": "Hi, @LeadsiftAI. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] with [code] in LangChain. The issue was linked to [code] version 2.6.1. Users resolved it by downgrading [code] and [code] . A fix has been incorporated into the latest [code] release. Next Steps: Please check if the issue persists with the latest version of LangChain. If the issue is resolved, no action is needed; otherwise, comment to keep the discussion open. The issue will be automatically closed in 7 days if there are no updates. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for the FAISS `get_by_id` function isn’t currently implemented, requiring a solution. The issue highlights a gap in the documentation that needs to be addressed, with a suggestion to either implement the functionality or remove it.", "final_category": "other", "comments": [{"author": "ZhangShenao", "created_at": "2024-11-27T12:25:17Z", "body_clean": "The function [code] is implemented by base class [code] ."}, {"author": "sbguthery", "created_at": "2024-11-27T13:28:07Z", "body_clean": "Thanks, Zhang but the source code seems to be: def get by ids(self, ids: Sequence[str], /) list[Document]: \"\"\"Get documents by their IDs. The returned documents are expected to have the ID field set to the ID of the document in the vector store. Fewer documents may be returned than requested if some IDs are not found or if there are duplicated IDs. Users should not assume that the order of the returned documents matches the order of the input IDs. Instead, users should rely on the ID field of the returned documents. This method should NOT raise exceptions if no documents are found for some IDs. Args: ids: List of ids to retrieve. Returns: List of Documents. .. versionadded:: 0.2.11 \"\"\" msg = f\"{self. class . name } does not yet support get by ids.\" raise NotImplementedError(msg) Implementations should override this method to provide an async native version. On Wed, Nov 27, 2024 at 7:25 AM ZhangShenao @ . wrote: The function get by id is implemented by base class VectorStore. — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you authored the thread.Message ID: @ ."}, {"author": "XinZhang0423", "created_at": "2024-12-25T10:23:02Z", "body_clean": "I had the same issue: i installed the langchain community package and used the get by id method. It didn't work. it seems that langchain community has implemented this method but not in langchain core. Using the get by id method in langchain community somehow calls the method in langchain core which has not been overided in langchain community? I solved this issue by updating the langchain community: pip install upgrade langchain community"}, {"author": "dosubot[bot]", "created_at": "2025-03-26T16:00:59Z", "body_clean": "Hi, @sbguthery. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that the [code] function mentioned in the FAISS documentation is not implemented, causing confusion. @ZhangShenao mentioned that the function is in the base class [code] , but you provided evidence of a [code] . @XinZhang0423 experienced a similar issue and resolved it by upgrading the [code] package. Next Steps: Could you confirm if this issue is still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a compatibility problem with Pydantic v2, preventing the import of the `__modify_schema__` method.  After investigating through various resources and documentation, the problem appears to be a bug within LangChain itself, not directly coded in the user's project.  The code provided fails to import the required function due to the outdated Pydantic version.", "final_category": "bug", "comments": [{"author": "suifengfengye", "created_at": "2024-11-22T02:24:41Z", "body_clean": "I can run your code normally. Please use conda to create a new environment and try again."}, {"author": "EgorKraevTransferwise", "created_at": "2024-11-22T08:35:55Z", "body_clean": "My apologies, the problem was indeed in my setup. I had indeed ran the code in a fresh environment, but had overlooked langchain source code that the IDE was loading instead of the installed packages. With that deleted, all was resolved. Thanks a lot for taking a look!"}, {"author": "dosubot[bot]", "created_at": "2025-02-21T16:01:07Z", "body_clean": "Hi, @ZmeiGorynych. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an import error with [code] from the [code] package due to a Pydantic v2 deprecation warning. EgorKraevTransferwise identified the problem as the IDE loading outdated LangChain source code. suifengfengye suggested creating a new environment with conda, which helped resolve the setup issue. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nUsers are encountering issues with the SemanticChunker.split_documents() function, specifically requesting a maximum chunk size limit of more than 8k tokens. This limitation is hindering the ability to send large documents for embedding due to Azure embedding model compatibility. The issue highlights a need for clearer documentation regarding this maximum chunk size to address this challenge.", "final_category": "question", "comments": [{"author": "keenborder786", "created_at": "2024-11-28T23:26:33Z", "body_clean": "@abhipandey09, I don't think so there is any upper limit as such. But it depends of number of chunks. If [code] is high then each chunk size will be lower and vice versa so you can adjust that parameter."}, {"author": "dosubot[bot]", "created_at": "2025-02-27T16:00:58Z", "body_clean": "Hi, @abhipandey09. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are seeking clarification on the maximum chunk size that [code] can return. Concerned about compatibility with your Azure embedding model if chunks exceed 8,000 tokens. Suggested that this limitation should be documented. @keenborder786 responded that there isn't a specific upper limit, but chunk size is influenced by the [code] parameter. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Update LangChain to latest stable version to address the deprecated method issue.", "Correct the ConversationSummaryBufferMemory definition to use BaseCache for consistent integration.", "Address the pydantic settings ve issue to ensure correct data representation.", "Implement the FAISS get_by_id function to enhance document retrieval.", "Standardize the LangChain code to avoid compatibility issues with Pydantic v2."], "technical_insights": ["LangChain’s deprecated method integration is a critical bug.", "The ConversationSummaryBufferMemory object definition requires careful handling.", "The pydantic settings ve issue points to a bug in the LangChain source.", "The FAISS get_by_id function requires implementation or removal.", "The LangChain code is incompatible with Pydantic v2."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Update LangChain to latest stable version to address the deprecated method issue.\n2. Correct the `ConversationSummaryBufferMemory` definition to use `BaseCache` for consistent integration.\n3. Address the pydantic settings ve issue to ensure correct data representation.\n4. Implement the FAISS `get_by_id` function to enhance document retrieval.\n5. Standardize the LangChain code to avoid compatibility issues with Pydantic v2.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s deprecated method integration is a critical bug.\n2. The `ConversationSummaryBufferMemory` object definition requires careful handling.\n3. The pydantic settings ve issue points to a bug in the LangChain source.\n4. The FAISS `get_by_id` function requires implementation or removal.\n5. The LangChain code is incompatible with Pydantic v2.\n", "batch_number": 174, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\n**The issue focuses on a potential problem with the way Mistral models are being used within LangChain. Specifically, there’s a reported issue where the tool message is not being correctly interpreted, leading to unexpected behavior.**  This is a critical issue impacting the functionality of LangChain’s tools and requires investigation to ensure stability and prevent future errors.  Currently, the issue is being addressed by the maintainer to determine the root cause and implement a fix.", "final_category": "other", "comments": [{"author": "eyurtsev", "created_at": "2024-11-20T21:54:46Z", "body_clean": "[link]"}, {"author": "eyurtsev", "created_at": "2024-11-20T22:09:22Z", "body_clean": "Will be released in langchain mistral 0.2.2"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue involves a discrepancy between the documentation for the Hugging Face embeddings model and the actual code snippet used. The code currently uses a different parameter value than the recommended one, requiring a change to the code.  The issue is currently unresolved, with no response to the documentation.", "final_category": "bug", "comments": []}, {"ollama_summary": "The `max_tokens` parameter for the ChatPerplexity model is not functioning correctly, causing errors and impacting the model’s output. This issue stems from a bug within LangChain, potentially related to a specific integration package, and is not being addressed through recent updates. The code involves several dependencies and potential issues with the model itself.", "final_category": "bug", "comments": [{"author": "fanericcw", "created_at": "2024-11-26T01:12:46Z", "body_clean": "Hello, we are a group of students from the University of Toronto Scarborough. We are interested in working on this issue, and we hope to have a working PR soon."}, {"author": "arnavp103", "created_at": "2024-11-28T04:34:26Z", "body_clean": "Hi, I'm part of the team investigating this. I was able to successfully reproduce this error and found that not only is [code] not respected, neither is [code] and I presume the other kwargs as well. Your suggested fix unfortunately didn't work, but we're investigating another fix and should have have it by tomorrow."}, {"author": "trisolarion", "created_at": "2024-12-02T18:43:28Z", "body_clean": "Thanks for the fix. I needed this for work"}]}, {"ollama_summary": "The issue is that the `init_chat_model` function in LangChain fails to work with Hugging Face models, despite attempts to troubleshoot and verify it’s not a coding error. The code attempts to instantiate a model using the `[code]` function, but it encounters an error message and stack trace indicating a problem with the integration process.  The solution currently involves updating to the latest stable version of LangChain, but the bug persists.", "final_category": "bug", "comments": [{"author": "dkincaid", "created_at": "2024-12-09T21:51:09Z", "body_clean": "I'm getting the same error here. Is there any workaround?"}, {"author": "SauravMaheshkar", "created_at": "2024-12-24T11:26:28Z", "body_clean": "I'm getting the same error here. Is there any workaround? I just migrated to [code] 🤷🏼‍♂️"}, {"author": "Ramana-vummenthala", "created_at": "2025-03-18T14:16:38Z", "body_clean": "You can replace init chat model with HuggingFaceEndpoint: [code] This should work as a direct alternative."}, {"author": "bhavan-kaya", "created_at": "2025-04-09T05:27:41Z", "body_clean": "Facing the same issue. Any possible solutions using init chat model?"}, {"author": "SauravMaheshkar", "created_at": "2025-05-18T15:55:29Z", "body_clean": "Tested for this again with version [code] and it still fails with the same error."}, {"author": "zizaola", "created_at": "2025-07-23T15:23:49Z", "body_clean": "Similar error while using [code] . [code] version 2.35. [code]"}, {"author": "eyurtsev", "created_at": "2025-07-25T16:55:46Z", "body_clean": "@zizaola you leaked a secret: [code] please revoke the key immediately and assume it's been compromised"}, {"author": "eyurtsev", "created_at": "2025-07-25T16:57:22Z", "body_clean": "@SauravMaheshkar It looks like it should be working based on the existing code. what is the output of [code]"}, {"author": "zizaola", "created_at": "2025-07-28T06:16:16Z", "body_clean": "@eyurtsev Thanks for the note in the API KEY. Here is the output python m langchain core.sys info System Information OS: Windows OS Version: 10.0.19045 Python Version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:16:22) [MSC v.1916 64 bit (AMD64)] Package Information langchain core: 0.3.68 langchain: 0.3.25 langchain community: 0.3.25 langsmith: 0.3.45 langchain anthropic: 0.3.17 langchain chroma: 0.2.4 langchain google vertexai: 2.0.27 langchain huggingface: 0.3.0 langchain openai: 0.3.22 langchain text splitters: 0.3.8 Optional packages not installed langserve Other Dependencies aio [link] Installed. No version info available. anthropic<1, =0.57.0: Installed. No version info available. anthropic[vertexai]: Installed. No version info available. async timeout<5.0.0, =4.0.0;: Installed. No version info available. bottleneck: 1.5.0 chromadb =1.0.9: Installed. No version info available. dataclasses json<0.7, =0.5.7: Installed. No version info available. google cloud aiplatform: 1.101.0 google cloud storage: 2.19.0 [link] 0.28.1 [link] 0.4.0 [link] Installed. No version info available. huggingface hub =0.30.2: Installed. No version info available. jsonpatch<2.0, =1.33: Installed. No version info available. langchain anthropic;: Installed. No version info available. langchain aws;: Installed. No version info available. langchain azure ai;: Installed. No version info available. langchain cohere;: Installed. No version info available. langchain community;: Installed. No version info available. langchain core<1.0.0, =0.3.51: Installed. No version info available. langchain core<1.0.0, =0.3.58: Installed. No version info available. langchain core<1.0.0, =0.3.64: Installed. No version info available. langchain core<1.0.0, =0.3.65: Installed. No version info available. langchain core<1.0.0, =0.3.68: Installed. No version info available. langchain core =0.3.60: Installed. No version info available. langchain deepseek;: Installed. No version info available. langchain fireworks;: Installed. No version info available. langchain google genai;: Installed. No version info available. langchain google vertexai;: Installed. No version info available. langchain groq;: Installed. No version info available. langchain huggingface;: Installed. No version info available. langchain mistralai: Installed. No version info available. langchain mistralai;: Installed. No version info available. langchain ollama;: Installed. No version info available. langchain openai;: Installed. No version info available. langchain perplexity;: Installed. No version info available. langchain text splitters<1.0.0, =0.3.8: Installed. No version info available. langchain together;: Installed. No version info available. langchain xai;: Installed. No version info available. langchain<1.0.0, =0.3.25: Installed. No version info available. langsmith pyo3: Installed. No version info available. langsmith<0.4, =0.1.125: Installed. No version info available. langsmith<0.4, =0.1.17: Installed. No version info available. langsmith =0.3.45: Installed. No version info available. numexpr: 2.11.0 numpy =1.26.0;: Installed. No version info available. numpy =1.26.2;: Installed. No version info available. numpy =2.1.0;: Installed. No version info available. openai agents: Installed. No version info available. openai<2.0.0, =1.68.2: Installed. No version info available. opentelemetry api: 1.34.1 opentelemetry exporter otlp proto [link] Installed. No version info available. opentelemetry sdk: 1.34.1 orjson: 3.10.18 packaging: 24.2 packaging<25, =23.2: Installed. No version info available. pyarrow: 19.0.1 pydantic: 2.11.5 pydantic settings<3.0.0, =2.4.0: Installed. No version info available. pydantic<3.0.0, =2.7.4: Installed. No version info available. pydantic =2.7.4: Installed. No version info available. pytest: 8.4.0 PyYAML =5.3: Installed. No version info available. requests: 2.32.4 requests toolbelt: 1.0.0 requests<3, =2: Installed. No version info available. rich: 14.0.0 sentence transformers =2.6.0;: Installed. No version info available. SQLAlchemy<3, =1.4: Installed. No version info available. tenacity!=8.4.0,<10, =8.1.0: Installed. No version info available. tenacity!=8.4.0,<10.0.0, =8.1.0: Installed. No version info available. tiktoken<1, =0.7: Installed. No version info available. tokenizers =0.19.1: Installed. No version info available. transformers =4.39.0;: Installed. No version info available. typing extensions =4.7: Installed. No version info available. validators: 0.35.0 zstandard: 0.23.0"}, {"author": "aaron-seq", "created_at": "2025-09-12T20:01:40Z", "body_clean": "I'd like to work on this, @mrdrxy"}, {"author": "aaron-seq", "created_at": "2025-09-14T15:30:21Z", "body_clean": "Hey, I have a solution, let me know if anyone is still working on this @mdrxy"}, {"author": "aaron-seq", "created_at": "2025-09-14T15:35:01Z", "body_clean": "From my initial investigation, it seems like the init chat model helper function in langchain/chat models/base.py is incorrectly instantiating ChatHuggingFace. It's passing a model id string directly, but the ChatHuggingFace class expects a fully initialized llm object (like a HuggingFacePipeline instance) in its constructor. My plan is to: Modify the helper function to first create a HuggingFacePipeline instance. Pass this llm instance to the ChatHuggingFace wrapper. Add a unit test to verify that init chat model works correctly with model provider=\"huggingface\". I'll submit a PR with the fix and the new test. Let me know if that sounds right!"}, {"author": "AkibDa", "created_at": "2025-09-26T04:24:12Z", "body_clean": "You need to update your code to initialize the model in two steps: first create the Hugging Face pipeline, then wrap it with LangChain's [code] . Here is the corrected code: [code]"}, {"author": "KunjShah95", "created_at": "2025-09-30T02:26:26Z", "body_clean": "is anybody working on this or can i work on it"}, {"author": "Accidental-MVP", "created_at": "2025-10-01T23:16:09Z", "body_clean": "Hi all, I noticed that while 33167 is fixing the core issue, there isn’t full test or docs coverage yet for init chat model(model provider=\"huggingface\"). I’d be happy to open a separate PR that: • Adds offline/mocked regression tests (basic HF init, max tokens vs max new tokens tolerance, and timeout/max retries). • Adds a small docs snippet showing correct usage + troubleshooting. This would complement the fix PR and help prevent regressions in the future. If this isn’t needed or should be folded into 33167 instead, happy to adjust. Thanks!"}, {"author": "KushagraaWadhwa", "created_at": "2025-10-06T06:07:01Z", "body_clean": "Hi, I'd like to work on this issue. I see there are already some PRs in progress, but I'd be happy to help review them or contribute additional test coverage and documentation if needed."}, {"author": "ccurme", "created_at": "2025-10-21T18:21:55Z", "body_clean": "Hi all, thanks for reporting the issue here. I've merged [link] into [code] , it will go out in the next release. However, I think some more thought is required around this: How do we support instantiation for both [HuggingFaceEndpoint and HuggingFacePipeline]( [link] How do we control what kwargs are passed to the LLM and what are passed to the chat model HuggingFace definitely breaks the mold and we'd welcome thoughts here. We'll also need to port to [code] (v1.0) once the design is set."}]}, {"ollama_summary": "The `bind_tools` function in LangChain fails to work with the AzureMLChatOnlineEndpoint, resulting in a `NotImplementedError`. This issue is likely a bug in the integration package, as attempts to update to the latest version haven’t resolved it. The error occurs within the `BaseChatModel.bind` function, specifically when the tool isn’t properly supported.", "final_category": "bug", "comments": [{"author": "informatica92", "created_at": "2024-11-19T13:45:10Z", "body_clean": "I reported the same issue here: [link]"}, {"author": "dosubot[bot]", "created_at": "2025-02-18T16:01:20Z", "body_clean": "Hi, @azraimahadan. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] with the [code] function and [code] . The issue persists even after updating to the latest version of LangChain. Another user, informatica92, has encountered the same issue, indicating it might be affecting multiple users. Next Steps: Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Mistral model integration is a critical point of failure, impacting LangChain’s core functionality.", "The root cause likely involves misinterpretation of the Mistral model’s message, requiring investigation.", "The maintainer’s response highlights a significant stability risk, emphasizing immediate attention.", "The bug’s impact is widespread, affecting multiple tools, necessitating a comprehensive fix.", "The bug’s scope may be limited to a specific integration package, requiring focused troubleshooting.", "Mistral model integration is a critical point of failure, impacting LangChain’s core functionality.", "The root cause likely involves misinterpretation of the Mistral model’s message, requiring investigation.", "The maintainer’s response highlights a significant stability risk, emphasizing immediate attention.", "The bug’s impact is widespread, affecting multiple tools, necessitating a comprehensive fix.", "The bug’s scope may be limited to a specific integration package, requiring focused troubleshooting."], "technical_insights": ["Incorrectly interpreted Mistral model messages are a primary driver of the issue.", "The code’s reliance on a specific parameter value in the Hugging Face embeddings model is problematic.", "The bug within LangChain’s ChatPerplexity model suggests a potential issue with the model itself.", "The max_tokens parameter issue impacts the model’s output, requiring code updates.", "The integration package bug is a known issue, potentially impacting multiple dependencies.", "Incorrectly interpreted Mistral model messages are a primary driver of the issue.", "The code’s reliance on a specific parameter value in the Hugging Face embeddings model is problematic.", "The bug within LangChain’s ChatPerplexity model suggests a potential issue with the model itself.", "The max_tokens parameter issue impacts the model’s output, requiring code updates.", "The integration package bug is a known issue, potentially impacting multiple dependencies."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Mistral model integration is a critical point of failure, impacting LangChain’s core functionality.\n2.  The root cause likely involves misinterpretation of the Mistral model’s message, requiring investigation.\n3.  The maintainer’s response highlights a significant stability risk, emphasizing immediate attention.\n4.  The bug’s impact is widespread, affecting multiple tools, necessitating a comprehensive fix.\n5.  The bug’s scope may be limited to a specific integration package, requiring focused troubleshooting.\n\nTECHNICAL INSIGHTS:\n1.  Incorrectly interpreted Mistral model messages are a primary driver of the issue.\n2.  The code’s reliance on a specific parameter value in the Hugging Face embeddings model is problematic.\n3.  The bug within LangChain’s `ChatPerplexity` model suggests a potential issue with the model itself.\n4.  The `max_tokens` parameter issue impacts the model’s output, requiring code updates.\n5.  The integration package bug is a known issue, potentially impacting multiple dependencies.\n\nRULES:\nBUSINESS INSIGHTS:\n1.  Mistral model integration is a critical point of failure, impacting LangChain’s core functionality.\n2.  The root cause likely involves misinterpretation of the Mistral model’s message, requiring investigation.\n3.  The maintainer’s response highlights a significant stability risk, emphasizing immediate attention.\n4.  The bug’s impact is widespread, affecting multiple tools, necessitating a comprehensive fix.\n5.  The bug’s scope may be limited to a specific integration package, requiring focused troubleshooting.\n\nTECHNICAL INSIGHTS:\n1.  Incorrectly interpreted Mistral model messages are a primary driver of the issue.\n2.  The code’s reliance on a specific parameter value in the Hugging Face embeddings model is problematic.\n3.  The bug within LangChain’s `ChatPerplexity` model suggests a potential issue with the model itself.\n4.  The `max_tokens` parameter issue impacts the model’s output, requiring code updates.\n5.  The integration package bug is a known issue, potentially impacting multiple dependencies.\n", "batch_number": 175, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a discrepancy in cost calculations between LangChain’s integration with both ChatOpenAI and AzureChatOpenAI, where the reported cost for the “[code]” integration is approximately double compared to the expected value.  The discrepancy seems to be linked to differences in how costs are handled for Azure models, requiring investigation and potential adjustments to the integration logic.  Currently, the issue is not resolved by updating the LangChain version, suggesting a bug within the integration itself.", "final_category": "bug", "comments": []}, {"ollama_summary": "The GitHub issue describes a bug in LangChain where the local large model glm 4 9b chat generates empty nodes and relationships during graph creation. This issue is being addressed by updating the model and the integration package, but the problem persists.", "final_category": "bug", "comments": [{"author": "KOBEBRYANTand", "created_at": "2024-11-18T13:44:58Z", "body_clean": "Is isuue with the llm？"}, {"author": "vikasnr", "created_at": "2024-12-30T09:06:37Z", "body_clean": "I had a similar issue while using pixtal model. Started seeing better results after setting [ignore tool usage=True]( [link] \"If set to True, the transformer will not use the language model’s native function calling capabilities to handle structured output.\" You could also debug by printing the final prompt that goes out to llm and use it to explicitly request your model."}, {"author": "dosubot[bot]", "created_at": "2025-03-31T16:00:53Z", "body_clean": "Hi, @KOBEBRYANTand. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with LangChain where using the local large model glm 4 9b chat results in empty nodes and relationships in a knowledge graph. You confirmed this is a bug in LangChain and not an issue with your code. Vikasnr suggested setting [code] and debugging by printing the final prompt to potentially resolve the issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue proposes adding a way to override the default OpenAI client for tutorials, as the current documentation lacks a dedicated section on customizing the user agent.  The core request is to create a simple, easily-implemented custom user agent header that would provide visibility into langchain usage for analytics purposes.", "final_category": "other", "comments": [{"author": "Aijeyomah", "created_at": "2024-11-27T18:55:08Z", "body_clean": "@remyleone I am interested in working on this issue. Can you assign to me?"}, {"author": "remyleone", "created_at": "2024-11-27T19:13:22Z", "body_clean": "I don't have any particular permissions on this repository. I guess it is ok for you to work on it"}, {"author": "dosubot[bot]", "created_at": "2025-02-26T16:00:58Z", "body_clean": "Hi, @remyleone. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights the lack of documentation on overriding the default OpenAI client to include custom user agent information. This feature is important for tracking usage analytics. @Aijeyomah showed interest in addressing the issue and was encouraged by you to proceed, despite not having assignment permissions. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If it is, feel free to comment to keep the discussion open. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "remyleone", "created_at": "2025-02-26T17:07:00Z", "body_clean": "Yes it is still relevant"}, {"author": "dosubot[bot]", "created_at": "2025-02-26T17:09:12Z", "body_clean": "@eyurtsev, the user @remyleone has confirmed that this issue regarding the documentation for overriding the default OpenAI client is still relevant. Could you please assist them with this?"}]}, {"ollama_summary": "The issue reports a problem with the `with_structured_output` functionality when using the ChatLiteLLM model with OpenAI models, specifically causing an error. The code attempts to utilize the model, but it throws an exception, and attempts to resolve it by updating LangChain, but the issue persists. The user has ruled out a bug in LangChain itself and has tested with Anthropic models, suggesting it’s likely a problem with the integration.", "final_category": "bug", "comments": [{"author": "ShawnLJW", "created_at": "2024-11-19T07:04:42Z", "body_clean": "Similar problem with ChatDeepInfra. It doesn't error but tools will not get called. @keenborder786 i see that you opened a PR for this, could u also look at ChatDeepInfra once ChatLiteLLM is approved? should be the same fix"}, {"author": "keenborder786", "created_at": "2024-11-28T01:25:08Z", "body_clean": "@ShawnLJW Sure"}, {"author": "danielbichuetti", "created_at": "2025-01-04T20:53:24Z", "body_clean": "There is a related issue when using Vertex AI and ChatLiteLLMRouter too: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-04-05T16:02:56Z", "body_clean": "Hi, @chenzimin. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] method failing with the [code] model, causing a [code] . \"ShawnLJW\" noted a similar issue with the ChatDeepInfra model, suggesting a fix after resolving the ChatLiteLLM problem. \"keenborder786\" agreed to investigate the issue. \"danielbichuetti\" mentioned a related problem with Vertex AI and ChatLiteLLMRouter, receiving support from other users. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "sayoojbkumar", "created_at": "2025-06-18T09:23:48Z", "body_clean": "Was this issue investigated, fixed, or resolved? I’m facing the same issue. What is the workaround for this? @ShawnLJW"}, {"author": "AndreasVolkmann", "created_at": "2025-06-18T15:49:08Z", "body_clean": "As a work around, I was able to override the [code] method to change the [code] : (This is for [code] ) [code]"}, {"author": "priyanshujain", "created_at": "2025-06-20T20:29:23Z", "body_clean": "I did a hacky workaround. By adding comprehensive method overrides that all use the fix tool choice helper function, we ensure that any tool choice='any' gets converted to tool choice='auto' before being passed to the underlying LiteLLM implementation. [code]"}]}, {"ollama_summary": "This issue reports a bug in LangChain that prevents the `cohere` model from being used on bedrock. The code attempts to utilize the `cohere` model, but it fails due to an incompatibility with the specific bedrock integration, requiring a recent update to the LangChain library.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-17T01:36:18Z", "body_clean": "Hi, @Anirudh31415926535. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a [code] when using the Cohere model for chat functionality. The issue occurs with the [code] class in LangChain. The error persists even after updating to the latest version, suggesting a bug in LangChain. No further comments or developments have been made on this issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment and keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Cost discrepancies between integration methods are a recurring bug, requiring investigation and potential adjustments.", "Azure model costs are a significant factor impacting the integration, necessitating a detailed cost analysis.", "Integration logic errors are impacting the core functionality of LangChain.", "Integration package updates are not resolving the bug, suggesting a fundamental flaw.", "Cost discrepancies are impacting the integration of both models, requiring investigation."], "technical_insights": ["Cost discrepancies are linked to Azure model differences, demanding detailed cost analysis.", "Integration package updates are failing to resolve the bug, indicating a potential issue within the package.", "Integration logic errors are causing discrepancies in cost calculations.", "The bug’s persistence suggests a bug in the LangChain integration itself.", "Azure model cost discrepancies are impacting the integration process."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Cost discrepancies between integration methods are a recurring bug, requiring investigation and potential adjustments.\n2. Azure model costs are a significant factor impacting the integration, necessitating a detailed cost analysis.\n3. Integration logic errors are impacting the core functionality of LangChain.\n4. Integration package updates are not resolving the bug, suggesting a fundamental flaw.\n5. Cost discrepancies are impacting the integration of both models, requiring investigation.\n\nTECHNICAL INSIGHTS:\n1. Cost discrepancies are linked to Azure model differences, demanding detailed cost analysis.\n2. Integration package updates are failing to resolve the bug, indicating a potential issue within the package.\n3. Integration logic errors are causing discrepancies in cost calculations.\n4. The bug’s persistence suggests a bug in the LangChain integration itself.\n5. Azure model cost discrepancies are impacting the integration process.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 176, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue involves a bug where the outputs from the `AgentExecutor` and `langgraph` tools are not being passed back to the model, preventing the expected functionality.  Users are experiencing this problem with both legacy and LangGraph agents, specifically when attempting to use them with HuggingFace tools and the default API.  The problem appears to be a bug within LangChain itself, and attempts to update the library haven't resolved it.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-23T00:22:29Z", "body_clean": "Hello I tried the following code and it worked: [code] I feel using the [code] is causing it to stuck in a loop where you keep on looping between nodes. Can you please do the turn on debugging for [code] by setting [code] to True. That way I will be able to help you better."}, {"author": "dosubot[bot]", "created_at": "2025-02-22T16:00:55Z", "body_clean": "Hi, @JeromeLo. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where outputs from the ChatHuggingFace model are not returned when using AgentExecutor or create react agent tools. Despite updating to the latest version, the issue persists. User keenborder786 suggested a potential solution with a working code example and recommended enabling debugging to investigate further. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a \"ConnectionError\" when attempting to connect to the LangChain API on port 80, specifically when running the code on Windows WSL2.  The error indicates a connection refused response, suggesting a potential issue with the LangChain integration.  The suggested solution involves updating to the latest stable version of LangChain, which hasn’t resolved the problem.", "final_category": "bug", "comments": [{"author": "farhan0167", "created_at": "2024-11-23T14:56:35Z", "body_clean": "have you tried doing [code] instead of just [code] as the base url because Ollama listens on port 11434 and not the default port 80 when you set just [code]"}, {"author": "dosubot[bot]", "created_at": "2025-02-22T16:00:57Z", "body_clean": "Hi, @zhoufy20. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You encountered a [code] when connecting to [code] using LangChain on WSL2 in Windows. Despite successful ping tests, the connection failed, indicating a potential local server setup issue. User farhan0167 suggested using [code] as Ollama listens on port 11434. The issue was resolved by changing the connection URL to [code] . Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue highlights a bug in LangGraph that causes a ValueError when using two system messages in agents, leading to unexpected output. This issue specifically targets a problem within the LangGraph documentation and doesn't relate to the code itself.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2024-11-17T16:14:52Z", "body_clean": "@andressilvac having multiple system messages is not necessary to implement the supervisor architecture we'll be updating the tutorials to simplify this! are there any other reasons why you need 2 system messages besides the tutorial?"}, {"author": "andressilvac", "created_at": "2024-11-17T20:48:27Z", "body_clean": "Thanks. So far, not really, I guess I can work without multiple system messages. Thanks."}, {"author": "keenborder786", "created_at": "2024-11-22T23:51:03Z", "body_clean": "@andressilvac You can also use langraph if you want to use multiple agents."}, {"author": "dosubot[bot]", "created_at": "2025-02-21T16:01:05Z", "body_clean": "Hi, @andressilvac. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a [code] when using two system messages in a chat prompt template with [code] . @vbarda suggested that multiple system messages are unnecessary for the supervisor architecture and mentioned upcoming tutorial updates. You acknowledged that you can proceed without multiple system messages. @keenborder786 suggested using Langraph for scenarios with multiple agents. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a critical bug in the AzureMLChatOnlineEndpoint that causes a “NotImplementedError” when attempting to use the `BaseModel` bind tool with a LangChain-based create React Agent setup. This stems from a change in LangChain’s architecture, requiring a different approach to agent creation.  The solution involves updating LangChain to a compatible version to ensure compatibility with the existing code and the specific integration.", "final_category": "bug", "comments": [{"author": "Allaye", "created_at": "2024-12-05T12:03:03Z", "body_clean": "@informatica92 have you found any solution for this problem? i did implement my own bind tools but it is clearly not working"}, {"author": "informatica92", "created_at": "2024-12-05T14:19:48Z", "body_clean": "unfortunately no, I also tried the solution to use the OpenAI compatible interface using something like: [code] but the interaction with the tools end at the first stage. The only solution I adopt at the moment is to deploy a MistralAI model instead of a Llama3.X, always on Azure AI Studio , and use the MistralAI langchain library (langchain mistralai) . Please note that, at least with the versions I am using there is a weird issue about a pass through parameter (as the additional pass through that I passed above into ChatOpenAI). So my solution to work with Azure deployed models requires few precautions: use a MistralAI (not Llama3.x) install langchain mistralai create a custom MistralAI Chat class to f orce the pass through header as discussed below: [code]"}, {"author": "hschmied", "created_at": "2024-12-05T14:28:59Z", "body_clean": "I also just started experimenting with AzureMLChatOnlineEndpoint and noticed that binding tools is an issue as well as multimodal messaging (e.g. images). Since AzureMLChat isn't one of the featured providers, I guess it's to be expected that certain features might not be available/work right away. [link] It's probably also more difficult with all the potential different implementations of tool calls a model hosted on azure can have e.g. llama, mistral,... I know for mistral there's some work in progress to get the mistral provider to work with models hosted on azure, but it's not ready/approved yet: [link] Anyway... looking forward to what comes next."}, {"author": "informatica92", "created_at": "2024-12-05T14:51:12Z", "body_clean": "I AM using MistralAI models deployed on Azure and it's already working as expected (apart from the pass through parameter)"}, {"author": "Allaye", "created_at": "2024-12-05T15:04:21Z", "body_clean": "I AM using MistralAI models deployed on Azure and it's already working as expected (apart from the pass through parameter) i see, i wanted to use the [link] so i created a working solution, but now, i needed the models, llama, mistra and co to use tools, that is where i am struggling with now, my idea is to integrate with langchain and maybe contribute the solution."}, {"author": "hschmied", "created_at": "2024-12-05T18:38:11Z", "body_clean": "I've now spent some time with it and as you said, directly with the modified ChatMistralAI it's working; the other task has to do w/ making it available via the 'init chat model' method and be able to use configure to switch between them. but this workaround and at least mistral working is helpful. thx!"}, {"author": "dosubot[bot]", "created_at": "2025-03-06T16:01:07Z", "body_clean": "Hi, @informatica92. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Compatibility issue between [code] and [code] function. Results in a [code] for the [code] method. Attempts to resolve using an OpenAI compatible interface were unsuccessful. Workaround found by deploying MistralAI models on Azure with a custom class. Other users, like @Allaye and @hschmied, are experiencing similar issues and working on solutions. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nUsers are encountering a broken link to the Azure OpenAI text embeddings page, leading to a dead page. The issue stems from a potential misconfiguration or outdated documentation, as the link directs to a non-existent page after clicking.  The issue is currently being investigated and is likely a simple documentation error requiring a fix.", "final_category": "other", "comments": [{"author": "keenborder786", "created_at": "2024-11-22T23:50:15Z", "body_clean": "It's working fine now, can you double check now."}, {"author": "dosubot[bot]", "created_at": "2025-02-21T16:01:03Z", "body_clean": "Hi, @rileyhawk1417. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a broken link on the AzureOpenAI text embeddings page in the LangChain documentation. User keenborder786 commented that the link seems to be working fine now. The issue appears to be resolved, pending your verification. Next Steps: Could you please confirm if the issue is still relevant with the latest version of the LangChain documentation? If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["LangChain updates frequently; consistent updates are crucial for stability.", "The bug in LangChain’s agent creation is a recurring issue, requiring thorough testing.", "Updating LangChain is a significant risk; careful testing and rollback strategies are needed.", "The AzureMLChatOnlineEndpoint bug indicates a potential architectural shift.", "Documentation errors are often the root cause of bugs; clear and updated documentation is vital."], "technical_insights": ["LangChain’s agent creation process is complex; a unified approach is needed.", "The ConnectionError on Windows WSL2 suggests a specific environment configuration.", "The ValueError in LangGraph indicates a specific library version conflict.", "The AzureMLChatOnlineEndpoint bug highlights a potential API change.", "Updating LangChain requires a rollback strategy to mitigate risks."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain updates frequently; consistent updates are crucial for stability.\n2.  The bug in LangChain’s agent creation is a recurring issue, requiring thorough testing.\n3.  Updating LangChain is a significant risk; careful testing and rollback strategies are needed.\n4.  The AzureMLChatOnlineEndpoint bug indicates a potential architectural shift.\n5.  Documentation errors are often the root cause of bugs; clear and updated documentation is vital.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s agent creation process is complex; a unified approach is needed.\n2.  The `ConnectionError` on Windows WSL2 suggests a specific environment configuration.\n3.  The `ValueError` in LangGraph indicates a specific library version conflict.\n4.  The AzureMLChatOnlineEndpoint bug highlights a potential API change.\n5.  Updating LangChain requires a rollback strategy to mitigate risks.\n", "batch_number": 177, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `BaseTool.run` function is failing to pass keyword arguments to the actual function call, causing unexpected behavior in a LangChain tool. The issue is not related to code changes and has been identified through searching and investigation, suggesting a bug within the LangChain integration.  The code attempts to use kwargs, but the function doesn't support them, and the error message points to a potential issue with the LangChain library.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-16T01:30:45Z", "body_clean": "I guess the Docstring for [code] need a little bit clarification but you can achieve your behaviour using the following code: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-02-15T16:00:55Z", "body_clean": "Hi, @kapicic. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where [code] does not pass [code] as expected. Example code was provided showing [code] resulting in an empty dictionary. \"keenborder786\" suggested using [code] as a workaround. Documentation for [code] might need clarification. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a missing \"prompts\" folder in LangChain version 0.3.3, which is causing a vulnerability. After upgrading to version 0.3.3, the code attempts to access the `PromptTemplate` object, resulting in a \"Package subpath is not defined\" error. The solution is to update the path to the `prompts` folder to the correct version.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-13T16:00:54Z", "body_clean": "Hi, @preethy 1. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You upgraded LangChain to version 0.3.3 to address a vulnerability. Encountered an issue with the 'prompts' folder missing in the new version. Need guidance on updating the path to access [code] as your existing code is causing an error. No further comments or developments have been made on this issue. Next Steps Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment here to keep the discussion open. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem with accessing Perplexity AI citations when using the LangChain API. Users are experiencing missing citations when using the raw requests, despite attempts to debug the response and documentation. The solution appears to be a bug within the LangChain integration, requiring an update to the latest stable version.", "final_category": "question", "comments": [{"author": "sam-bercovici", "created_at": "2024-11-15T11:12:27Z", "body_clean": "location of the issue : looks like [link] does not pass the response.model extra to AIMessage Proposed Fix : The line should be updated to something like: [code] Explanation: The response variable contains the \"citations\" in the model extra dict. Passing it to AIMessage will set it in its own model extra dict Getting the citations after the fix : [code] Note : Similar should be done for streaming response."}, {"author": "dickreuter", "created_at": "2025-01-30T10:48:58Z", "body_clean": "Is this issue fixed already? I don't see a way to extract citations at this point. Any suggestions are greatly appreciated."}, {"author": "sydney-runkle", "created_at": "2025-04-15T19:17:18Z", "body_clean": "Hi! Yep, this is fixed with [code] v0.1.1. New results: [code] Closing as resolved."}, {"author": "amanlai", "created_at": "2025-04-26T17:25:56Z", "body_clean": "@sydney runkle if I use structured output the citations go missing. A minimal example: [code] [code] looks like [code] with no citations. How do we also get the citations in this case? I understand that because [code] must be an [code] instance in this case, not an [code] instance so the citations are missing but how do we \"force\" the citations to also be included in the [code] object?"}, {"author": "dickreuter", "created_at": "2025-08-04T10:53:04Z", "body_clean": "yes agree, this is not fixed."}]}, {"ollama_summary": "The issue stems from LangChain incorrectly applying strict schema validation for Pydantic models with union types, causing OpenAI API errors.  Specifically, the bug manifests when the `additionalProperties` flag is set to `False` in the schema for the `[code]` and `[code]` classes.  The solution involves ensuring the schema is correctly constructed to avoid this issue, potentially by adjusting the Pydantic model's configuration.", "final_category": "bug", "comments": [{"author": "alan-santandrea-blip-ai", "created_at": "2024-12-09T18:57:52Z", "body_clean": "Hello @dominik jelinek geneea, I've encountered the same error. The issue is that Langchain has a bug where it doesn't recursively look into the 'OneOf' properties created when using Union and doesn't add the additionalProperties. However, you can work around this by creating a Config class in the BaseModel with extra = Extra.forbid. Here's an example in Python: [code] or for Pydantic v2: [link] [code]"}, {"author": "dosubot[bot]", "created_at": "2025-03-10T16:01:17Z", "body_clean": "Hi, @dominik jelinek geneea. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary LangChain was incorrectly handling schema generation from a Pydantic model with a union. This resulted in OpenAI validation errors due to missing 'additionalProperties' settings. @alan santandrea blip ai suggested using a Config class in the BaseModel with [code] as a workaround. You appreciated this workaround, indicating it resolved the issue. Next Steps Could you confirm if this issue is still relevant to the latest version of LangChain? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a bug in Ollama where the function returns only the agent’s response without triggering any tool calls, despite proper installation and dependencies.  The developer has identified this as a potential issue with LangGraph/LangChain and believes it’s a bug rather than a design choice.  They are providing a code example and stack trace for further investigation and potential resolution.", "final_category": "bug", "comments": [{"author": "BennisonDevadoss", "created_at": "2024-11-14T05:49:46Z", "body_clean": "I am also facing the same issue, Any update on it?"}, {"author": "f000x0", "created_at": "2024-11-25T14:55:46Z", "body_clean": "I have the same issue, is there a solution now?"}, {"author": "dosubot[bot]", "created_at": "2025-03-22T16:02:40Z", "body_clean": "Hi, @Billian D. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug in the LangGraph/LangChain system where the Ollama Function fails to make tool calls, only providing responses. The issue is confirmed not to be related to your code. Other users, BennisonDevadoss and f000x0, have reported experiencing the same problem. The issue has received a thumbs up from marcusmotill, indicating interest or agreement. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["LangChain integration’s keyword argument handling requires a significant refactoring of the run function, potentially simplifying the code and reducing potential errors.", "Consistent data flow between LangChain and the underlying libraries is crucial for stability; the current implementation introduces a potential point of failure.", "The Docstring for [code] needs clarification to enhance code understanding and reduce ambiguity.", "The [code] and [code] classes’ schema validation needs careful consideration to avoid unexpected errors.", "The [link] location to the issue is stale and should be updated to the latest version."], "technical_insights": ["LangChain’s run function’s keyword argument support is a critical integration point; existing code needs review.", "The Prompts folder vulnerability highlights a dependency issue; a direct update to the version is required.", "The [code] and [code] class schema validation bug necessitates a specific code adjustment.", "The [link] location to the issue is stale and should be updated to the latest version.", "The [code] and [code] classes’ schema validation needs careful consideration to avoid unexpected errors."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain integration’s keyword argument handling requires a significant refactoring of the `run` function, potentially simplifying the code and reducing potential errors.\n2. Consistent data flow between LangChain and the underlying libraries is crucial for stability; the current implementation introduces a potential point of failure.\n3. The `Docstring` for `[code]` needs clarification to enhance code understanding and reduce ambiguity.\n4. The `[code]` and `[code]` classes’ schema validation needs careful consideration to avoid unexpected errors.\n5.  The `[link]` location to the issue is stale and should be updated to the latest version.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s `run` function’s keyword argument support is a critical integration point; existing code needs review.\n2.  The `Prompts` folder vulnerability highlights a dependency issue; a direct update to the version is required.\n3.  The `[code]` and `[code]` class schema validation bug necessitates a specific code adjustment.\n4.  The `[link]` location to the issue is stale and should be updated to the latest version.\n5.  The `[code]` and `[code]` classes’ schema validation needs careful consideration to avoid unexpected errors.\n", "batch_number": 178, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a discrepancy between the API documentation and the langchain official documentation, specifically concerning the support for different agent types (nine in total).  The SQL agent, utilizing the provided class and function, is failing to generate correct values due to limitations in the supported agent types.  The core request is to update the documentation to clarify the supported agent types and address the confusion caused by this limitation.", "final_category": "other", "comments": [{"author": "AHB102", "created_at": "2024-11-14T14:57:13Z", "body_clean": "@ENUMERA8OR Can I take this issue ?"}, {"author": "ENUMERA8OR", "created_at": "2024-11-14T15:02:57Z", "body_clean": "I am not a maintainer. Please ask a maintainer of the repo... & Read the contribution guide."}, {"author": "dosubot[bot]", "created_at": "2025-02-13T16:00:52Z", "body_clean": "Hi, @ENUMERA8OR. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights a discrepancy in the LangChain documentation about the number of supported agent types in the [code] class. Documentation claims nine agent types are supported, but only four are actually available. @AHB102 showed interest in fixing the issue, but you advised them to consult a maintainer and review the contribution guide. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "ENUMERA8OR", "created_at": "2025-02-13T16:04:24Z", "body_clean": "Yes relevant, if lnot already solved..."}, {"author": "dosubot[bot]", "created_at": "2025-02-13T16:06:35Z", "body_clean": "@eyurtsev, the user @ENUMERA8OR has confirmed that this issue regarding the discrepancy in the LangChain documentation is still relevant. Could you please assist them with this?"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\nThe `chat ollama` component in LangChain fails to produce structured output due to a union type issue, specifically related to the expected data format. This issue was reported by a LangChain maintainer and requires investigation to ensure compatibility with existing functionality.  Currently, the code doesn’t handle the expected data structure for the output, leading to errors during the generation process.", "final_category": "bug", "comments": [{"author": "eyurtsev", "created_at": "2024-11-13T16:40:22Z", "body_clean": "stack trace: [code]"}, {"author": "eyurtsev", "created_at": "2024-11-13T17:40:49Z", "body_clean": "This is likely not an issue with the implementation, but the model failing to actually output appropriate structured output so performance issue w/ the underlying model. The TODO item is to figure out how to improve error messages so such issues are easier for the user to understand"}, {"author": "ENUMERA8OR", "created_at": "2024-11-13T17:58:16Z", "body_clean": "@eyurtsev Would like to contribute to this issue. Please tell me what to do."}, {"author": "jooray", "created_at": "2024-11-13T22:33:53Z", "body_clean": "What branch are you running? I get NotImplementedError, which seems correct, because: [link] does not implement with structured output, so the parent class raises this error."}, {"author": "Linnore", "created_at": "2025-01-10T03:55:58Z", "body_clean": "Hi @jooray @eyurtsev , I encounter a similar problem with Union[type1, type2] when using [code] . When langchain infers the tool schema, the Union type is disappeared! Say I have a tool: [code] I expect the args schema to be: [code] [code] At this point, the schema of indicating the Union type is correct. However, when I check what is really passed to the LLM, the Union type is disappeared for the argument [code] . Example codes: Let's first turn on the Ollama's debug mode: [code] I will use a [code] to showcase. The problem of interring the tool's args schema can be reproduced by using any model, so you can change it to your own local model. [code] Run the codes: [code] Now we can see the ollama debug messages in the terminal for what the llm received: [code] NOTE: we can see the schema for \"a\" is [code] with empty [code] , while the schema of \"b\" is [code] It is clear that when [code] , the args schema is not inferred correctly for a Union type."}, {"author": "dosubot[bot]", "created_at": "2025-04-11T16:01:17Z", "body_clean": "Hi, @eyurtsev. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue involves a validation error in the [code] function when handling structured output with a union type. The error occurs when invoking a response that can be either a [code] or a [code] . You suggested the issue might be due to model performance rather than implementation and highlighted the need for better error messages. @jooray and @Linnore discussed related issues, with @Linnore providing a detailed example. @ENUMERA8OR expressed interest in contributing to the resolution. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "jboreiko", "created_at": "2025-08-18T16:02:40Z", "body_clean": "I believe I am seeing a similar issue where tool input arguments appear to be dropping the union type information provided by the input pydantic typings. I'm using the built in create react agent and various models through openrouter."}]}, {"ollama_summary": "The GitHub issue addresses a bug where the ChatLiteLLMRouter's routing fails to correctly select the first model from the model list, leading to incorrect model usage. The issue was triggered by a LangChain integration package update, and the solution involves updating the router configuration to explicitly specify the desired model.", "final_category": "bug", "comments": [{"author": "kjoth", "created_at": "2024-11-13T11:32:12Z", "body_clean": "@bburgin @baskaryan @mackong Please have a look at the issue."}, {"author": "doncat99", "created_at": "2024-11-14T07:15:49Z", "body_clean": "Yes, i met the same problem, i have a demo code block at another project. [agent service toolkit: issue 89]( [link] Wait for bug fix."}, {"author": "dosubot[bot]", "created_at": "2025-02-13T16:00:52Z", "body_clean": "Hi, @kjoth. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with the ChatLiteLLMRouter incorrectly routing requests to a \"small\" model instead of a \"large\" model. User \"doncat99\" confirmed experiencing the same issue and referenced a related problem in another project. Both you and \"doncat99\" are awaiting a resolution from the maintainers. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "kjoth", "created_at": "2025-02-21T06:02:59Z", "body_clean": "Hi @dosu, The model routing issue has been fixed in the latest release and routing functionality is working now."}, {"author": "dosubot[bot]", "created_at": "2025-02-21T06:03:23Z", "body_clean": "<! Answer Hey @kjoth! I'm thrilled to hear that the issue with the router functionality has been fixed in the latest release. 🎉 However, if you have any more technical questions or need help with bugs, feel free to ask! If you think I should have addressed something else, you can always reach out to the [Dosu Team](mailto:customersuccess@dosu.dev). 😊 <! Dosu Comment Footer To continue talking to [Dosu]( [link] mention @dosu. <sup Help Dosu learn! Give it feedback: [Great Response]( [link] | [Irrelevant Answer]( [link] | [Incorrect Sources]( [link] | [Too Verbose]( [link] | [Hallucination]( [link] | [Bug Report]( [link] | [Other]( [link]"}]}, {"ollama_summary": "The GitHub issue addresses a bug in the LangChain library that causes double escaping of strings when loading Hugging Face datasets, specifically due to the `json.dumps()` function. The code attempts to convert all instances of strings to strings, leading to unintended escaped characters. A fix is proposed to implement a check for strings before conversion, resolving the issue and preventing the double escaping.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-19T16:01:22Z", "body_clean": "Hi, @skaltenp. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves [code] using [code] , leading to double escaped characters. The proposed solution is to check if the content is already a string to avoid unnecessary conversion. The issue arises because strings are treated as objects, causing unintended escaping. No further comments or activities have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports a problem where the LangChain `tokentextsplitter` library is failing to load the Hugging Face tokenizer, despite using the GPT2 tokenizer.  It’s attempting to use the GPT2 tokenizer instead of the intended Hugging Face Tokenizer, and attempts to update LangChain hasn’t resolved the issue.", "final_category": "bug", "comments": [{"author": "suifengfengye", "created_at": "2024-11-13T02:42:41Z", "body_clean": "please show how to create your tokenizer?"}, {"author": "bhavnicksm", "created_at": "2024-11-14T11:16:58Z", "body_clean": "Normally, like it expects me to. [code]"}, {"author": "suifengfengye", "created_at": "2024-11-16T11:48:36Z", "body_clean": "@bhavnicksm Now encoding name needs to be passed in the TokenTextSplitter.from huggingface tokenizer(), otherwise the default value is \"gpt2\". But TokenTextSplitter use \"tiktoken\", it don't support \"llama\". Maybe you can use custom tokenizer length. Hope this helps. [code]"}, {"author": "bhavnicksm", "created_at": "2024-11-16T11:53:21Z", "body_clean": "@bhavnicksm Now encoding name needs to be passed in the TokenTextSplitter.from huggingface tokenizer(), otherwise the default value is \"gpt2\". But TokenTextSplitter use \"tiktoken\", it don't support \"llama\". Maybe you can use custom tokenizer length. Hope this helps. [code] Thanks for the custom tokenizer length approach! I still think having the [code] should mean that it doesn't use tiktoken but uses [code] tokenizer. It doesn't make sense otherwise."}, {"author": "dosubot[bot]", "created_at": "2025-02-15T16:00:54Z", "body_clean": "Hi, @bhavnicksm. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with the [code] class defaulting to the GPT2 tokenizer. Despite updating, the issue persisted with the [code] method. @suifengfengye suggested a workaround by passing an [code] and using a custom tokenizer length function. You appreciated the workaround but noted the method should use the specified Huggingface tokenizer by default. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Clear documentation is crucial for seamless integration, addressing the API discrepancy proactively.", "Addressing the API discrepancy will improve developer experience and reduce confusion.", "Maintaining accurate documentation is essential for long-term maintainability.", "Prioritize documentation updates to avoid future issues and maintain code clarity.", "Collaboration between API developers and maintainers is vital for effective documentation."], "technical_insights": ["API documentation and langchain official documentation conflict necessitates clarification.", "SQL agent failing to generate correct values highlights a specific data type issue.", "LangChain maintainer investigation is required to identify and resolve the union type error.", "Router configuration update addresses the model selection issue, ensuring correct model usage.", "Double escaping issues in Hugging Face dataset loading are a bug requiring a fix."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Clear documentation is crucial for seamless integration, addressing the API discrepancy proactively.\n2. Addressing the API discrepancy will improve developer experience and reduce confusion.\n3. Maintaining accurate documentation is essential for long-term maintainability.\n4. Prioritize documentation updates to avoid future issues and maintain code clarity.\n5. Collaboration between API developers and maintainers is vital for effective documentation.\n\nTECHNICAL INSIGHTS:\n1. API documentation and langchain official documentation conflict necessitates clarification.\n2. SQL agent failing to generate correct values highlights a specific data type issue.\n3. LangChain maintainer investigation is required to identify and resolve the union type error.\n4. Router configuration update addresses the model selection issue, ensuring correct model usage.\n5. Double escaping issues in Hugging Face dataset loading are a bug requiring a fix.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 179, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe developers are requesting a detailed dependency table to be added to the v0.2 LangChain documentation to improve compatibility with the existing v0.2 codebase. Currently, the documentation lacks a structured dependency table, hindering developers’ ability to manage dependencies effectively. The proposed solution is to include a table outlining recommended version constraints for each package within the v0.2 ecosystem.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-11T16:00:50Z", "body_clean": "Hi, @TanmayDoesAI. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported that the v0.2 LangChain documentation lacks a structured dependency table. The v0.3 version of the documentation includes this table. You suggested adding the table to the v0.2 documentation to help developers manage dependencies. There have been no further comments or activity on this issue. Next Steps Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on correcting a typo in documentation for streaming modes, specifically addressing the incorrect spelling of “written” in the original statement. The documentation currently mentions a specific method for streaming output using a LangGraph StreamWriter, and the documentation needs to be updated to reflect this.", "final_category": "other", "comments": []}, {"ollama_summary": "The AzureMLChatOnlineEndpoint currently doesn’t support the HumanMessage class with a list of dictionaries as input, causing an error.  The developer has attempted a workaround by removing references to the problematic class, but the issue persists.  A potential fix is to introduce a custom formatter to handle the data format correctly.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-11T16:00:50Z", "body_clean": "Hi, @informatica92. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with [code] in LangChain failing to handle [code] objects with a list of dictionary content. The error occurs specifically with Azure's LLM, but not with the Groq LLM, indicating a potential bug or limitation in AzureML integration. There have been no comments or further activity on this issue since it was reported. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "informatica92", "created_at": "2025-02-17T07:25:35Z", "body_clean": "Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution! Yeah, it is still present in the latest version of langchain. Here the versions of the langchain components I am using: [code]"}, {"author": "dosubot[bot]", "created_at": "2025-02-17T07:27:50Z", "body_clean": "@eyurtsev, the user @informatica92 has confirmed that the issue with [code] is still present in the latest version of LangChain (0.3.18). Could you please assist them with this issue?"}]}, {"ollama_summary": "The issue lies in the Neo4jVector.from_existing_index() function, which silently returns a random index when an invalid index name is provided. This prevents the application from detecting the problem and potentially causing unexpected behavior. The proposed solution is to add a check to ensure the index name exists before attempting to create a vector, improving error handling and preventing silent failures.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-11T16:00:51Z", "body_clean": "Hi, @trjw. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with [code] not raising an error for an invalid [code] . The function currently returns a random existing index, leading to potential unexpected behavior. You suggested modifying [code] to return an empty list if the [code] is not found for better error handling. There have been no further comments or activity on this issue. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a 404 error when attempting to list LangChain template packages. The code fails to retrieve the expected output, despite checking other resources and the GitHub search, and suggests a potential bug within LangChain itself rather than the user’s code.  The suggested solution is to update to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "zoneria", "created_at": "2024-11-13T15:35:37Z", "body_clean": "Did you find a solution?"}, {"author": "pierluigimarchioro-Moku", "created_at": "2024-12-10T10:46:41Z", "body_clean": "Probably related, I am getting this error whenever I try to add any template via langchain cli [code] [code] It seems the tool expects to find a [code] directory in the langchain repo, but it is just not there as of today"}, {"author": "tpcgold", "created_at": "2025-01-15T08:27:23Z", "body_clean": "it is... or rather was a thing in v0.1 and v0.2 [link] [link] idk. why langchain removed them 🤷‍♂"}, {"author": "datoslabs", "created_at": "2025-02-03T20:52:02Z", "body_clean": "It appears that most of the templates are not compatible with V3, see [ [link] I cloned [code] branch for my own future reference/use. Also, as a result, [ [link] is completely not usable due to this change..."}, {"author": "dosubot[bot]", "created_at": "2025-05-05T16:00:51Z", "body_clean": "Hi, @markalosey. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] command results in a 404 error due to JSON parsing issues in the [code] function. The CLI expects a [code] directory, which is missing in the current repository version. Earlier versions (v0.1 and v0.2) included this directory, but it has been removed in later versions. Most templates are incompatible with version 3, and the templates website is currently unusable. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is crucial for complex projects like LangChain, improving code maintainability and reducing integration issues.", "Consistent documentation is essential for developer adoption and usability of the LangChain ecosystem.", "Addressing bugs promptly prevents wider issues and maintains developer confidence.", "Correcting typos in documentation minimizes confusion and errors for users.", "Streamlining dependencies improves overall code organization and reduces technical debt."], "technical_insights": ["LangChain's dependency management system requires improved clarity in documentation.", "The streaming output documentation lacks a structured dependency table.", "The AzureMLChatOnlineEndpoint's error handling for human message input is incomplete.", "The Neo4jVector.from_existing_index() function needs improved error handling.", "The LangChain template listing bug involves a 404 error, suggesting a potential issue within the framework."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency management is crucial for complex projects like LangChain, improving code maintainability and reducing integration issues.\n2. Consistent documentation is essential for developer adoption and usability of the LangChain ecosystem.\n3. Addressing bugs promptly prevents wider issues and maintains developer confidence.\n4. Correcting typos in documentation minimizes confusion and errors for users.\n5. Streamlining dependencies improves overall code organization and reduces technical debt.\n\nTECHNICAL INSIGHTS:\n1.  LangChain's dependency management system requires improved clarity in documentation.\n2.  The streaming output documentation lacks a structured dependency table.\n3.  The AzureMLChatOnlineEndpoint's error handling for human message input is incomplete.\n4.  The Neo4jVector.from_existing_index() function needs improved error handling.\n5.  The LangChain template listing bug involves a 404 error, suggesting a potential issue within the framework.", "batch_number": 180, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports that LangChain’s `results_to_docs_and_scores` method is returning metadata as a Fragment object instead of a dictionary, causing validation errors. This likely stems from an issue with how the database results are being deserialized into the metadata, potentially requiring explicit conversion to a dictionary. The solution involves wrapping the `result.EmbeddingStore.cmetadata` object with `dict()` to ensure proper metadata conversion.", "final_category": "bug", "comments": [{"author": "simadimonyan", "created_at": "2024-11-18T12:55:51Z", "body_clean": "Fixed in: [link]"}]}, {"ollama_summary": "The issue is a `AttributeError` occurring when attempting to use the `vectorstore.similarity search()` function with a string query. This is happening because the function expects a string as input, but it's receiving a string instead. The code uses the `vectorstore` library, specifically the `similarity` function, which is failing due to the incorrect input type.", "final_category": "bug", "comments": [{"author": "naveen-vsamy", "created_at": "2024-11-11T17:06:12Z", "body_clean": "When defining \"vectorstore\" I passed \"index\" as arg instead of index name. I changed the code and it worked fine"}, {"author": "naveen-vsamy", "created_at": "2024-11-11T17:11:14Z", "body_clean": "But still the error was misleading"}, {"author": "myke11j", "created_at": "2024-11-17T09:51:16Z", "body_clean": "In your initial code, when you passed a string in index parameter which should actually be pinecone.Index [code] When you invoke any search function, it calls index.query which is a function from pinecone, but becauuse you passed a String, it tried to call \"index\" function on a string which is not part of string object. That's why you get the error [code] , which is not an error from lang chain but it's a Python error. Here's the source code for reference [link]"}, {"author": "naveen-vsamy", "created_at": "2024-12-14T02:13:01Z", "body_clean": "Got it, Thanks for the explanation"}]}, {"ollama_summary": "This issue stems from a pydantic error within the LangChain RAG library (version 0.2.45) when running the `langgraph` example code. The code attempts to use a specific title for the RAG pipeline, which causes the pydantic validation to fail.  The issue appears to be a bug in LangChain itself, and the suggested solution is to update to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "DangerousPotential", "created_at": "2024-11-17T06:34:26Z", "body_clean": "刚刚试了一下代码，除了LCEL的网站更换到了 [link] 其余代码还能运行。但只测试到了用OpenAI的阶段"}, {"author": "dosubot[bot]", "created_at": "2025-02-17T01:36:18Z", "body_clean": "Hi, @The uyu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered a Pydantic error when running example code from the LangChain documentation for RAG in the langgraph library. You provided a link to the example code and details about your environment setup. Another user, DangerousPotential, mentioned that the code runs except for the LCEL website, which they replaced, and tested up to the OpenAI stage. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports that the SQL Ollama documentation link ([link]) is leading to a removed page, suggesting a potential update or issue with the documentation itself. The user is requesting information about the updated documentation and is suggesting a review of the link’s status.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-10T16:00:51Z", "body_clean": "Hi, @100pearlcent. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a broken link to the SQL Ollama documentation on the LangChain website. The link currently leads to a removed page. You are seeking clarification on the availability of an updated version of the documentation. There have been no further comments or updates on this issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to keep the discussion open by commenting here. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that prevents setting the `max_token_limit` for the `ContextualCompressionRetriever`. This causes an indexing error when processing documents, specifically when the model's sequence length exceeds the specified limit. The solution involves updating to the latest stable version of LangChain or the integration package, which resolves the problem.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-11T16:00:53Z", "body_clean": "Hi, @railsstudent. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with the [code] function where [code] cannot be set. The issue occurs when using [code] for document compression. You confirmed the issue persists in the latest stable version of LangChain. No additional comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Update dependencies is crucial to avoid compatibility issues with recent library versions.", "Addressing bugs early in the development lifecycle reduces downstream rework.", "Maintaining consistent code across different components improves stability.", "Testing is essential to catch issues before they impact users.", "Version control is vital for tracking changes and reverting to previous states."], "technical_insights": ["Deserialization issues are a recurring theme, requiring explicit data conversion.", "vectorstore.similarity search() failing due to incorrect input type.", "LangChain version 0.2.45 pydantic validation errors.", "results_to_docs_and_scores method metadata conversion is complex.", "Integration package update addresses LangChain itself."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Update dependencies is crucial to avoid compatibility issues with recent library versions.\n2.  Addressing bugs early in the development lifecycle reduces downstream rework.\n3.  Maintaining consistent code across different components improves stability.\n4.  Testing is essential to catch issues before they impact users.\n5.  Version control is vital for tracking changes and reverting to previous states.\n\nTECHNICAL INSIGHTS:\n1.  Deserialization issues are a recurring theme, requiring explicit data conversion.\n2.  `vectorstore.similarity search()` failing due to incorrect input type.\n3.  LangChain version 0.2.45 pydantic validation errors.\n4.  `results_to_docs_and_scores` method metadata conversion is complex.\n5.  Integration package update addresses LangChain itself.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 181, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem with the DSPy integration with LangChain – it’s no longer supported by the DSPy side.  The documentation confirms this change, and the issue asks for clarification on whether the integration remains supported.  Currently, the issue lacks a response to the question about the integration’s continued viability.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-10T16:00:47Z", "body_clean": "Hi, @hasalams. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You raised a question about the integration status between DSPy and LangChain. DSPy documentation indicates that the integration is no longer maintained. You are seeking clarification on whether LangChain still supports this integration. No comments or updates have been made on this issue yet. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "mindful-time", "created_at": "2025-08-30T10:48:03Z", "body_clean": "Is there any plan for this to be integrated properly in langchain new update ?"}]}, {"ollama_summary": "The issue involves a bug in LangChain that prevents accurate token counting and usage tracking while using the AzureChatOpenAI model. The code attempts to use a custom tool to measure the length of a word, but the tool fails to provide the expected results, leading to inaccurate cost calculations. The solution requires updating to the latest stable version of LangChain or the integration package, and the bug is not resolved by simply updating the version.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-09T16:00:48Z", "body_clean": "Hi, @RajarshiBhadra. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug related to token counting and usage tracking with AgentExecutor and AzureChatOpenAI. The issue persists despite following the documentation and updating to the latest version. A code snippet was provided to illustrate your setup. No further activity or comments have been made on the issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Qdrant Vector Store’s filtering functionality is not working correctly due to an incorrect import statement within the code. The issue stems from a change in the import used in the documentation, which is causing the metadata filtering to function as expected.  The core problem is a mismatch between the code and the documentation’s recommended import, requiring an update to the code to ensure proper functionality.", "final_category": "bug", "comments": [{"author": "ZhangShenao", "created_at": "2024-11-22T11:12:39Z", "body_clean": "Try to fix it in 28286"}, {"author": "dosubot[bot]", "created_at": "2025-02-21T16:01:05Z", "body_clean": "Hi, @andresnatanael. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue highlights an incorrect import statement in the Qdrant Vector Store documentation. The import should be updated from [code] to [code] . @ZhangShenao has submitted pull request 28286 to address this issue. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a critical problem with LangChain: the `poppler` library is not being found and is essential for the application to function correctly. The code attempts to retrieve the page count but fails, requiring the user to ensure `poppler` is installed and in their system's PATH environment variable.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-09T23:35:02Z", "body_clean": "Just install the following: [code]"}, {"author": "keenborder786", "created_at": "2024-11-09T23:42:16Z", "body_clean": "Since the [code] is None and langchain by default uses [code] to load your pdf which might be requiring the above dependency!!!"}, {"author": "ejstembler", "created_at": "2024-11-11T16:46:10Z", "body_clean": "On macOS, I had several iterations to get it all working. Poppler took awhile to get it to completely install. Basically something like this: Make sure Xcode CommandLineTools are installed with header files in the right locations. [code] Wait for Xcode dialog window to appear and click the install button. Takes 10 15 minutes. [code] [code]"}, {"author": "cat-sun", "created_at": "2025-09-11T07:13:45Z", "body_clean": "brew install poppler"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nYouTube is currently preventing users from viewing video details due to a bug in LangChain that requires login. The issue stems from a flawed integration that forces the user to authenticate with YouTube before accessing the video information.  Attempts to update LangChain haven’t resolved the problem, suggesting a bug within the YouTube loader library itself.", "final_category": "bug", "comments": [{"author": "Harsimran-19", "created_at": "2024-11-08T15:45:08Z", "body_clean": "Can I work on this issue?"}, {"author": "sonalshreya", "created_at": "2024-11-09T00:44:44Z", "body_clean": "I want to work on this issue"}, {"author": "Patotricks15", "created_at": "2024-11-15T12:15:52Z", "body_clean": "The same problem here trying to develop a langchain project using YoutubeLoader"}, {"author": "ashvini8", "created_at": "2024-11-29T22:38:49Z", "body_clean": "Hi! My teammates (@khushiDesai, @anushak18, and @ssumaiyaahmed) and I made a PR with a proposed fix that we hope to solve this error!"}, {"author": "dosubot[bot]", "created_at": "2025-02-28T16:01:22Z", "body_clean": "Hi, @ymcki. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a crash with [code] due to videos requiring login. Suggested fix: modify code to include [code] and [code] . Several users showed interest in resolving the issue. A pull request with a proposed fix has been submitted by a team led by ashvini8. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Integration stability is a key concern, requiring immediate attention.", "YouTube integration remains a significant obstacle.", "The lack of a response to the integration question impacts workflow.", "Support for the DSPy integration is crucial for LangChain.", "Addressing the YouTube issue will positively impact user experience."], "technical_insights": ["DSPy integration stability is critical; ensure continued support.", "YouTube integration requires a specific solution – update the package.", "The core bug relates to the import statement; update the code.", "The integration package needs a fix, not just a version update.", "Addressing the YouTube issue enhances user experience."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Integration stability is a key concern, requiring immediate attention.\n2. YouTube integration remains a significant obstacle.\n3. The lack of a response to the integration question impacts workflow.\n4. Support for the DSPy integration is crucial for LangChain.\n5. Addressing the YouTube issue will positively impact user experience.\n\nTECHNICAL INSIGHTS:\n1. DSPy integration stability is critical; ensure continued support.\n2. YouTube integration requires a specific solution – update the package.\n3. The core bug relates to the import statement; update the code.\n4. The integration package needs a fix, not just a version update.\n5. Addressing the YouTube issue enhances user experience.\n", "batch_number": 182, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue reports a problem where the `RunnableLambda` dependencies are not being correctly extracted from the LangChain codebase.  The code attempts to retrieve the source code to extract dependencies, but this process occasionally returns empty results, leading to an empty `deps` list.  The core problem is a bug in LangChain that prevents the correct extraction of dependencies, potentially impacting functionality.", "final_category": "bug", "comments": [{"author": "Harsimran-19", "created_at": "2024-11-08T15:45:24Z", "body_clean": "Can I work on this issue?"}, {"author": "dosubot[bot]", "created_at": "2025-02-07T16:00:59Z", "body_clean": "Hi, @aravind segu. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug was reported regarding incorrect extraction of dependencies for [code] . The issue persists even after updating to the latest version of LangChain. Example code was provided to demonstrate the problem within a workflow setup. Harsimran 19 has shown interest in working on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code is failing because the LangChain `dict[str, pydantic_model]` annotation is not being correctly processed by the `MultipleJokes` Pydantic model.  The issue stems from a bug in the LangChain integration, requiring a recent update to the library to resolve the validation error.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-06T16:00:51Z", "body_clean": "Hi, @Tesla2000. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug with [code] annotation not working as intended. The issue occurs when creating a dictionary of name joke pairs using the [code] class. The error persists even after updating to the latest version of LangChain. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a lack of clarity regarding whether AzureAISearchRetriever employs hybrid search (textual, vector, or a combination) – a crucial aspect of its functionality.  The developer has added a checklist to address this, but the documentation doesn’t explicitly define the search strategy.  Currently, there’s a request for more detailed documentation on this hybrid search implementation.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-05T16:01:02Z", "body_clean": "Hi, @krlmt8. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Lack of clarity in documentation regarding the search method used by [code] . Uncertainty about whether it uses hybrid, textual, or vector search. You provided a link to the documentation but did not suggest specific changes. No further comments or activity have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "cmt-ermit", "created_at": "2025-02-10T13:22:16Z", "body_clean": "still relevant"}, {"author": "dosubot[bot]", "created_at": "2025-02-10T13:24:25Z", "body_clean": "@eyurtsev, the user has indicated that this issue regarding the clarity in documentation for the [code] is still relevant. Could you please assist them with this?"}]}, {"ollama_summary": "The AIMessage tool call model is incompatible with OpenAI, preventing the creation of AIMessage objects with the correct tool call formatting.  The issue stems from the `tool call` function expecting a specific set of variables, not allowing for extra keyword variables.  The developers are investigating this bug and seeking alternative methods for creating AIMessage objects with tool calls.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-06T21:53:02Z", "body_clean": "@yildirimgoks, this is intentional. [code] is an internal way for representation of AI Tool Call Message. At the end Tool Calling API for OpenAI is invoked with the compatible schema. But if you want to achieve the desire result: [code]"}, {"author": "yildirimgoks", "created_at": "2024-11-08T11:46:36Z", "body_clean": "When I initially did it like your suggestion I had received a BadRequest error from OpenAI complaining the tool call format was wrong which was what actually prompted me to look into the data model LangChain was enforcing and all that. Today we had the opportunity to migrate the project to Langchain 0.3 and I can confirm your suggestion now works. I had looked into relevant parts of the codebase beforehand to check if 0.3 would make a difference and thought it wouldn't, must have overlooked something. Thanks for the guidance & I'll close the issue."}]}, {"ollama_summary": "The GitHub issue reports a bug in LangChain where the `in` operator for filtering similarity searches within the Superbase vector store is not working as expected. The current implementation returns no results when filtering by a list of file IDs, despite the documentation stating it should. The issue appears to be a problem with the integration package itself, and the suggested solution of updating to the latest version doesn't resolve it.", "final_category": "bug", "comments": [{"author": "kc-hsh-value", "created_at": "2024-12-14T11:11:38Z", "body_clean": "hey have you resolved the issue?"}]}], "business_insights": ["Dependency extraction bug impacts core functionality.", "Integration package update is needed.", "Focus on extraction errors – critical."], "technical_insights": ["LangChain dependency retrieval bug.", "Pydantic model validation error.", "Recent library update required."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Dependency extraction bug impacts core functionality.\n2. Integration package update is needed.\n3. Focus on extraction errors – critical.\n\nTECHNICAL INSIGHTS:\n1. LangChain dependency retrieval bug.\n2. Pydantic model validation error.\n3. Recent library update required.\n\nRULES:\n- Each insight must be ≤20 words\n- Start each line with the number (1-5)\n- Be specific and actionable\n- Focus on patterns across issues, not individual issues\n- NO extra text, explanations, or formatting\n\n", "batch_number": 183, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue involves a bug in the LangChain library that causes the model to return incorrect output when the input text is processed. The code attempts to extract a category from the email, but the LLM chain isn't correctly interpreting the input and producing the expected output. The bug is present in the latest stable version of LangChain, and attempts to resolve it by updating the library have not been successful.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-05T23:48:46Z", "body_clean": "@pn12 LLMChain is the old way of constructing the Chain. Please try the following Langchain Expression Language to construct chains: [code]"}]}, {"ollama_summary": "The GitHub issue highlights a bug in LangChain where the `UserWarning` generator produces multiple `pydantic` UserWarnings due to a default protected namespace conflict.  The issue has been investigated and confirmed to be a bug within the LangChain library, and attempts to fix it by updating the library have not resolved the problem.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-04T16:01:16Z", "body_clean": "Hi, @rectalogic. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves the [code] model generating multiple UserWarnings. Warnings are due to conflicts with Pydantic's protected namespace \"model \". Fields like \"model uri\", \"model name\", and \"model version\" in [code] are causing the warnings. You suggested setting [code] to resolve the warnings. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "rectalogic", "created_at": "2025-02-04T16:18:05Z", "body_clean": "Seems like this was probably fixed by [link]"}, {"author": "dosubot[bot]", "created_at": "2025-02-04T16:18:15Z", "body_clean": "Thank you for closing the issue, @rectalogic! We appreciate your help in keeping the repository organized."}]}, {"ollama_summary": "The issue reports a bug in LangChain's React Graph component where the model's direct response is streamed, but the React agent's response is not streamed. This is a problem because the agent’s output is not token-by-token streamed, hindering the intended functionality of streaming the response.  The proposed solution is to address the bug within LangChain itself, as it’s likely a fundamental issue rather than a specific code change.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2024-11-05T21:52:32Z", "body_clean": "@edmcman looks like this is an issue with [code] when it's used with tools, the output is not streamed correctly, i.e. these two code snippets behave differently. this is not an issue with langgraph, will transfer to LangChain [code] [code]"}, {"author": "edmcman", "created_at": "2024-11-06T13:03:50Z", "body_clean": "@vbarda Thanks, didn't think to try that."}, {"author": "siddhawan", "created_at": "2024-11-07T11:41:17Z", "body_clean": "were you able to solve the issue?"}, {"author": "edmcman", "created_at": "2024-11-07T12:48:52Z", "body_clean": "Looks like an ollama limitation actually: [link] So closing because it's not a langchain issue either."}, {"author": "edmcman", "created_at": "2024-11-07T13:00:32Z", "body_clean": "Also: [link]"}]}, {"ollama_summary": "The code returns inconsistent results when invoking the `chain.invoke()` method, consistently returning 100 documents instead of the expected 5. This issue stems from a potential bug in LangChain's integration, specifically related to the retriever's source retrieval. The problem isn't directly related to the code itself but hinders the ability to utilize asynchronous calls within the application.", "final_category": "bug", "comments": [{"author": "dokato", "created_at": "2024-11-06T13:46:35Z", "body_clean": "Ok, I figured that my custom implementation of retriever was lacking: [code] Just wonder why this is not a default behaviour 🤔 ."}]}, {"ollama_summary": "Okay, here's a summary of the code snippets provided, broken down by category:\n\n**1. Python Libraries:**\n\n*   **`requests`:**  Used for making HTTP requests (likely for fetching data from APIs).\n*   **`pytz`:**  For timezone-related operations.\n*   **`pyarrow`:**  A columnar data format library.\n*   **`tensorboard`:**  A visualization toolkit for training and evaluating machine learning models.\n*   **`tensorflow`:**  A deep learning framework.\n*   **`torch`:**  Another deep learning framework (PyTorch).\n*   **`torchsummary`:**  For generating summaries of PyTorch tensors.\n*   **`tornado`:**  A web framework for asynchronous programming.\n*   **`wandb`:**  A platform for experiment tracking and visualization.\n*   **`matplotlib`:**  A plotting library.\n*   **`seaborn`:**  A data visualization library based on matplotlib.\n*   **`scikit-image`:** Image processing library.\n*   **`scikit-learn`:** Machine learning library.\n*   **`pandas`:** Data manipulation and analysis library.\n*   **`numpy`:** Numerical computing library.\n*   **`tqdm`:** Progress bar library.\n*   **`traitlets`:**  A library for creating and managing custom traits.\n*   **`pyparsing`:**  A parser library.\n*   **`wordcloud`:**  A word cloud generator.\n*   **`setuptools`:**  A package and build system.\n*   **`pyyaml`:**  For working with YAML files.\n*   **`toml`:**  For working with TOML files.\n*   **`mlflow`:**  A platform for machine learning experiment tracking and management.\n*   **`pyenv`:** Python version management.\n*   **`pyenv-virtualenv`:**  Virtual environment management.\n*   **`venv`:**  Python virtual environment management.\n*   **`time`:**  For time-related operations.\n*   **`urllib3`:**  For making HTTP requests.\n*   **`pytz`:**  For timezone handling.\n*   **`pyarrow`:** For data", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-04T16:01:17Z", "body_clean": "Hi, @Ishan Kumar2. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where a local language model does not stop generating text at the specified stop token \"Question:\". Despite updating to the latest version of LangChain, the issue persists, with the model continuing to generate the word \"Question\". You suspect this is a bug within the LangChain library. There have been no comments or further activity on this issue. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Library updates frequently introduce breaking changes, requiring careful testing and regression analysis.", "The LangChain library’s reliance on specific versions can lead to compatibility issues across different environments.", "Maintaining a comprehensive test suite is crucial for identifying and resolving bugs early in the development lifecycle.", "Automated testing (unit, integration, end-to-end) is essential for ensuring code quality and stability.", "Collaboration between developers, testers, and operations teams is vital for identifying and addressing issues efficiently."], "technical_insights": [], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Library updates frequently introduce breaking changes, requiring careful testing and regression analysis.\n2.  The `LangChain` library’s reliance on specific versions can lead to compatibility issues across different environments.\n3.  Maintaining a comprehensive test suite is crucial for identifying and resolving bugs early in the development lifecycle.\n4.  Automated testing (unit, integration, end-to-end) is essential for ensuring code quality and stability.\n5.  Collaboration between developers, testers, and operations teams is vital for identifying and addressing issues efficiently.\n", "batch_number": 184, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue stems from a bug in the `tracers/wandb.py` library, specifically related to the `NoneType` object not having an `items` attribute. This causes a `NameError` when attempting to use the wandb library within the LangChain code. The issue is not related to the LangChain library itself but rather a bug within the `wandb` package.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-04T16:01:15Z", "body_clean": "Hi, @holiholiholiholi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug is reported in [code] . The error occurs when a [code] object is accessed with [code] in the [code] function. The issue is confirmed to be within LangChain, not user code. No further comments or developments have been made. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\n**Problem:** The Azure CosmosDB vector store filter is not functioning as expected, returning all documents instead of the intended results.\n\n**Key Details:** The issue stems from a missing or incorrect filter configuration within the search parameters, specifically related to the `kwargs` argument.\n\n**Proposed Solution:**  The developer needs to verify the filter configuration is correctly implemented and tested to ensure it's filtering documents effectively.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-04T16:01:13Z", "body_clean": "Hi, @yyueda. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a problem with the AzureCosmosDB vector store. The [code] filter does not retrieve documents with a specific username as intended. Instead, the search returns all documents. There have been no comments or developments on this issue yet. Next Steps Could you please confirm if this issue is still relevant to the latest version of the LangChain repository? If so, feel free to comment and keep the discussion open. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue involves a Pydantic validation error when invoking a tool call using LangChain, specifically when the input argument to the function is a string representation of a list. This issue stems from an issue with the Llama 3.1 405B model and its integration with the tool call, causing the validation to fail due to the list being represented as a string.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-04T16:01:21Z", "body_clean": "Hi, @psambit9791. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a validation error from Pydantic during a tool call in LangChain. The issue persists despite updating to the latest version of LangChain. Example code provided involves a function for multiplying numbers and AWS credentials. The error occurs specifically during the tool call invocation. No further comments or developments have been made on this issue. Next Steps: Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "benm5678", "created_at": "2025-05-13T16:44:06Z", "body_clean": "Can we reopen this? Or does someone have some solution to make langchain agent retry and show LLM the error?"}]}, {"ollama_summary": "The `create_retrieval_chain` function is failing to produce verbose results, despite the issue being reported as a bug within LangChain. The problem appears to be a restriction within the code that prevents the inclusion of verbose output during the retrieval chain creation process.  The code attempts to use `async timeout` and `dataclasses` which are causing the issue.  The suggested solution is to update to the latest stable version of LangChain or specific integration packages.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-04T16:01:14Z", "body_clean": "Hi, @elhamod. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where [code] lacks support for the [code] parameter. You confirmed the issue persists in the latest version of LangChain. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code produces a `ValueError: 1 validation error for Generation text Input should be a valid string` when attempting to sum the 'Survived' column in a DataFrame. This likely stems from a problem with the `generate` function within the LangChain integration, potentially related to the data format or expected input structure.", "final_category": "bug", "comments": [{"author": "twobitunicorn", "created_at": "2024-11-04T22:45:19Z", "body_clean": "This code does work. [code]"}, {"author": "eyurtsev", "created_at": "2024-11-13T16:24:38Z", "body_clean": "Hi @twobitunicorn where did you find the example? 1. We generally do not recommend using code from langchain experimental without proper sandboxing. 2. If you want to implement a pandas dataframe agent, I'd suggest creating something custom using langgraph."}, {"author": "dosubot[bot]", "created_at": "2025-02-12T16:01:17Z", "body_clean": "Hi, @twobitunicorn. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with LangChain when querying a DataFrame for Titanic survivors. The code calculates correctly but fails during chain invocation, even after updating to the latest version. eyurtsev suggested using [code] for a custom solution instead of [code] . The issue seems resolved with the suggested custom solution approach. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Bug fixes frequently impact core functionality; address them promptly.", "Testing is crucial; rigorous testing mitigates future issues.", "Dependency management impacts stability; ensure consistent versions.", "Code review streamlines quality; identify errors early.", "Documentation updates reflect changes; maintain clarity."], "technical_insights": ["NoneType issue necessitates robust error handling.", "Filter configuration validation is critical.", "Llama 3.1 405B model integration requires attention.", "Data type consistency across LangChain components.", "Verbose output restrictions require careful coding."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Bug fixes frequently impact core functionality; address them promptly.\n2.  Testing is crucial; rigorous testing mitigates future issues.\n3.  Dependency management impacts stability; ensure consistent versions.\n4.  Code review streamlines quality; identify errors early.\n5.  Documentation updates reflect changes; maintain clarity.\n\nTECHNICAL INSIGHTS:\n1.  `NoneType` issue necessitates robust error handling.\n2.  Filter configuration validation is critical.\n3.  Llama 3.1 405B model integration requires attention.\n4.  Data type consistency across LangChain components.\n5.  Verbose output restrictions require careful coding.\n", "batch_number": 185, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The GitHub issue highlights a `KeyError` occurring when using the Mistral AI model through Vertex AI’s Model Garden integration with LangChain. The bug stems from the model’s final usage statistics chunk not containing the expected \"choices\" key, leading to a crash when processing the stream. The proposed solution is to safely access the \"choices\" key using a default empty list, ensuring the code remains robust and prevents errors during streaming responses.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-03T16:01:05Z", "body_clean": "Hi, @mortexsa. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a [code] when using Vertex AI Model Garden Mistral with LangChain in streaming mode. The error occurs during model invocation and persists even after updating to the latest LangChain version. The issue seems related to handling streaming responses in the LangChain Mistral AI integration. No further comments or developments have been made on this issue. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there are no updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The RedisVectorStore implementation uses the incorrect identifier 'keys' instead of 'ids' in its code, causing a bug that affects the function's behavior. This issue stems from a discrepancy between the code and the expected behavior of other vector stores, requiring a fix to ensure consistent functionality.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-04T23:58:20Z", "body_clean": "I have patched the fix in the following PR: [link]"}, {"author": "dosubot[bot]", "created_at": "2025-02-03T16:01:04Z", "body_clean": "Hi, @krjoha. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary Inconsistency reported in RedisVectorStore: parameter 'keys' used instead of 'ids'. Issue required users to inspect code for custom identifiers. User keenborder786 submitted a patch to resolve this. You provided positive feedback on the submitted patch. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a remote connection failing to establish a bind_tools connection, impacting both local and remote Ollama operations. Specifically, the Ollama running remotely cannot see the tools being used, potentially due to a communication problem. The problem appears to be widespread, affecting various API functions and LLMs, requiring further investigation into the data retrieval process.", "final_category": "bug", "comments": [{"author": "zhouhh2017", "created_at": "2024-11-08T08:36:32Z", "body_clean": "Sorry，the reason is the version of ollama on Linux. Linux do not install the latest version of ollama, 0.1.34 was installed. After update it to 0.4.0, all runs well."}]}, {"ollama_summary": "This issue reports a problem with the Cohere command R+ integration in LangChain, specifically when attempting to invoke the model. The error message indicates a malformed input request, likely related to the prompt format. The code snippet demonstrates the error, and the user is seeking a fix, potentially involving a bug in LangChain or a specific integration package.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-03T16:01:03Z", "body_clean": "Hi, @mutazmq1. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are experiencing a \"ValidationException\" error with the [code] class from the [code] package. The error indicates a malformed input request due to an unpermitted key [prompt]. The issue persists even after updating to the latest version of LangChain, suggesting a potential bug or compatibility issue. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangGraph tool is failing to integrate with Azure OpenAI and Azure Search, causing issues with Agentic RAG responses. The issue stems from a bug within LangGraph itself, potentially affecting the entire workflow, and the code provides a detailed error message and stack trace to aid in debugging.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-03T16:01:13Z", "body_clean": "Hi, @kishorekkota. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a failure in tool calling with Azure Search for Agentic RAG within the LangGraph/LangChain framework. Provided example code and detailed steps for tool creation, binding, and workflow setup. Suggested that the problem is likely a bug in the framework. Confirmed reviewing other resources and documentation before reporting. No comments or further activity on the issue yet. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Manan1602", "created_at": "2025-03-26T07:32:23Z", "body_clean": "Hi @kishorekkota I am facing the exact same issue. Did you find a fix for it? Can you share what you changed?"}, {"author": "kishorekkota", "created_at": "2025-03-26T13:41:42Z", "body_clean": "It has been sometime and I do not remember exact details. I was trying different option, finally ended up building custom retriever and building chain with [code] ."}]}], "business_insights": ["Model integration stability is critical for LangChain’s core functionality; consistent model usage is paramount.", "Connectivity issues across multiple services (Mistral, Vertex AI, RedisVectorStore, Ollama) necessitate robust error handling and monitoring.", "The “choices” key failure in the Mistral AI model’s final usage statistics chunk is a fundamental bug impacting downstream processing.", "A standardized approach to data retrieval, particularly with vector stores and Ollama, will improve reliability.", "Stream processing requires careful management of model state and data consistency, minimizing errors."], "technical_insights": ["Mistral AI’s final usage statistics chunk handling requires a robust mechanism to ensure all model states are accessible.", "RedisVectorStore’s identifier ‘keys’ vs. ‘ids’ discrepancy is a critical data integrity issue impacting vector store operations.", "Ollama’s remote connection failure is a systemic problem, requiring investigation into data retrieval processes.", "The LangChain Cohere command R+ integration is experiencing widespread issues, suggesting a bug in LangChain or its dependencies.", "LangGraph’s integration with Azure OpenAI and Azure Search is failing, likely linked to an error within the LangGraph library."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Model integration stability is critical for LangChain’s core functionality; consistent model usage is paramount.\n2. Connectivity issues across multiple services (Mistral, Vertex AI, RedisVectorStore, Ollama) necessitate robust error handling and monitoring.\n3. The “choices” key failure in the Mistral AI model’s final usage statistics chunk is a fundamental bug impacting downstream processing.\n4. A standardized approach to data retrieval, particularly with vector stores and Ollama, will improve reliability.\n5. Stream processing requires careful management of model state and data consistency, minimizing errors.\n\nTECHNICAL INSIGHTS:\n1. Mistral AI’s final usage statistics chunk handling requires a robust mechanism to ensure all model states are accessible.\n2. RedisVectorStore’s identifier ‘keys’ vs. ‘ids’ discrepancy is a critical data integrity issue impacting vector store operations.\n3. Ollama’s remote connection failure is a systemic problem, requiring investigation into data retrieval processes.\n4. The LangChain `Cohere` command R+ integration is experiencing widespread issues, suggesting a bug in LangChain or its dependencies.\n5. LangGraph’s integration with Azure OpenAI and Azure Search is failing, likely linked to an error within the LangGraph library.\n", "batch_number": 186, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The `PipelinePromptTemplate` issue is failing to correctly handle partial input within a pipeline, resulting in an error message related to overlapping variables.  The problem stems from the way the template reinstantiates the input variables during model validation, effectively overwriting the new input.  Currently, the issue appears to be a bug within LangChain’s template system.", "final_category": "bug", "comments": [{"author": "Aarya2004", "created_at": "2024-11-07T16:58:28Z", "body_clean": "Hello @dmenini! My group and I investigated this error and we found the cause of this is due to the partial method not being overridden in the PipleinePromptTemplate class. We've come up with a potential fix but if this issue can be assigned to us, we can open a PR asap!"}, {"author": "efriis", "created_at": "2024-12-10T03:45:51Z", "body_clean": "Hey there! Agreed this is not handled well by the PipelinePromptTemplate, and it's largely because PipelinePromptTemplate doesn't adhere to the PromptTemplate interface in many ways. I would recommend doing something like the following instead [code]"}, {"author": "efriis", "created_at": "2024-12-10T03:51:24Z", "body_clean": "better one not using LCEL: [code]"}]}, {"ollama_summary": "The GitHub issue addresses a “NotImplementedError” within the `MarkdownifyTransformer` class, specifically when using the `atransform_documents()` method. A suggested solution involves implementing the method, which is crucial for a specific application requiring asynchronous document loading and search.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue highlights a critical bug in LangChain where the API token is not being used to access the Replicate LLM service.  The code incorrectly passes the token directly to the constructor, causing the default client to retrieve it from the environment variable instead of the intended API key. This results in the model using the default client, hindering full access to the Replicate service.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-02-01T16:00:55Z", "body_clean": "Hi, @fayvor. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an issue with the Replicate LLM model client in LangChain. The client ignores the API token provided in the constructor. It defaults to using the token from the environment variable, causing authentication errors. You requested that the client should use the explicitly passed API token for all interactions. There have been no comments or developments on this issue yet. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "nov05", "created_at": "2025-06-03T05:45:23Z", "body_clean": "✅ 2025 06 04 update: Issue solved. I didn’t do anything, but the issue disappeared on the second day. I guess my account was new, and it just took some time for the API key to take effect? I am using Google Colab. Here is [the notebook]( [link] I have checked [the official documentation]( [link] [code] [code] ⚠️ I can print [code] and it does return something like [code] , but all my API calls still fail with a 401 error. I’d really appreciate any advice anyone can offer. 🙏 [code] [code] Error details [code]"}]}, {"ollama_summary": "The GitHub issue reports a bug in the `fireworks` library where Llama 8B consistently fails to use a tool, despite having the same tool name or \"any\" selected. This issue impacts the functionality of the fireworks.ai client and appears to be a problem within LangChain itself, rather than a coding error in the user's code.", "final_category": "bug", "comments": [{"author": "aldrinjenson", "created_at": "2025-01-06T08:03:22Z", "body_clean": "Yeah. I've found llama from fireworks to be pretty hesistat to use tool calling as well. a good fix would be appreciated!"}, {"author": "dosubot[bot]", "created_at": "2025-04-07T16:00:55Z", "body_clean": "Hi, @CVxTz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug is reported in the fireworks.ai client where the Llama 8B model fails to use a specified tool despite setting the [code] parameter. The issue persists even after updating to the latest version of LangChain. User aldrinjenson also reports similar issues with tool calling in the Llama model. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code throws an \"invalid input type\" error when using the Ollama embeddings model.  A recent update to the Ollama library caused a change in the embedding class used, leading to a mismatch between the expected input and the actual data received.  The issue is resolved by reverting to the older version of the Ollama library.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-11-01T21:16:16Z", "body_clean": "I guess you are passing a dict as your input. Please see the code below, that might help (I tested it and it works): [code]"}, {"author": "simingy", "created_at": "2024-11-04T18:43:40Z", "body_clean": "thank you for the help it seems like the dict as input used to work. Strange."}]}], "business_insights": ["Template reconstruction errors can significantly impact pipeline reliability, requiring thorough template validation.", "The PipelinePromptTemplate bug highlights a critical oversight in template management – re-instantiation during validation can lead to unexpected errors.", "The MarkdownifyTransformer issue suggests a need for better error handling and potentially a more robust approach to asynchronous document processing.", "The LangChain token issue underscores the importance of securely managing API keys and considering alternative client methods.", "Template inconsistencies across issues indicate a need for standardized template design and testing."], "technical_insights": ["Template reconstruction errors are a major concern, impacting pipeline stability.", "The PipelinePromptTemplate bug necessitates a detailed analysis of template instantiation during validation.", "The MarkdownifyTransformer issue points to a potential flaw in the asynchronous document loading mechanism.", "The LangChain token issue highlights a security vulnerability related to API key management.", "The Fireworks library bug requires a fix to the tool call handling."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Template reconstruction errors can significantly impact pipeline reliability, requiring thorough template validation.\n2. The `PipelinePromptTemplate` bug highlights a critical oversight in template management – re-instantiation during validation can lead to unexpected errors.\n3. The `MarkdownifyTransformer` issue suggests a need for better error handling and potentially a more robust approach to asynchronous document processing.\n4. The `LangChain` token issue underscores the importance of securely managing API keys and considering alternative client methods.\n5. Template inconsistencies across issues indicate a need for standardized template design and testing.\n\nTECHNICAL INSIGHTS:\n1. Template reconstruction errors are a major concern, impacting pipeline stability.\n2. The `PipelinePromptTemplate` bug necessitates a detailed analysis of template instantiation during validation.\n3. The `MarkdownifyTransformer` issue points to a potential flaw in the asynchronous document loading mechanism.\n4. The `LangChain` token issue highlights a security vulnerability related to API key management.\n5. The `Fireworks` library bug requires a fix to the tool call handling.\n", "batch_number": 187, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The Azure AI Search Retriever currently returns up to 50 results, despite the default 50 being set by Azure. This issue stems from a bug where the retrieval doesn’t paginate results correctly, leading to an inconsistent number of returned documents.  The code doesn’t implement pagination, resulting in the retriever returning all documents in a single result set.  The issue is not resolved by updating the LangChain version, and the lack of pagination is a significant flaw impacting the user experience.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-31T16:01:08Z", "body_clean": "Hi, @sjjpo2002. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The Azure AI Search Retriever is limited to returning a maximum of 50 documents. Setting [code] to None does not return all results as expected. The limitation is due to Azure's default settings. You suggested implementing pagination to retrieve all documents. No further comments or developments have been made on this issue. Next Steps: Please confirm if this issue is still relevant with the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The GitHub issue reports a problem where the Anthropic API key is not being used for ChatLiteLLM, causing an error. The user is attempting to call the model without the key, resulting in an error message. The issue suggests a bug within LangChain itself rather than the user’s code, and the fix involves updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "jamesev15", "created_at": "2024-11-01T23:50:30Z", "body_clean": "@ccurme, @DangerousPotential the error is happening because the litellm client needs an api key parameter to work properly. It just needs to be set with any of the available provider API keys to get things running smoothly!"}, {"author": "dosubot[bot]", "created_at": "2025-02-01T16:00:57Z", "body_clean": "Hi, @chenzimin. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] parameter was not being used when initializing the [code] model, causing an [code] . The issue was due to the API key only being recognized if set as an environment variable. User jamesev15 suggested setting the [code] parameter in the [code] client with any available provider API keys to resolve the issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a LangChain integration failing to properly utilize a custom API URL for document parsing, causing an `ImportError` and preventing the application from executing the specified code. The problem is related to the `unstructured` library and its dependency installation, specifically requiring the `md` package.", "final_category": "bug", "comments": [{"author": "gauravprasadgp", "created_at": "2024-11-08T21:04:23Z", "body_clean": "unstructured requires multiple dependent modules to be installed. please follow this documentation about installation: [link]"}, {"author": "camlspotter", "created_at": "2025-01-01T12:24:22Z", "body_clean": "I have the same issue. The workaround is to add [code] to the call of [code] : [code] I think it should be set automatically when [code] is given."}, {"author": "dosubot[bot]", "created_at": "2025-04-02T16:01:04Z", "body_clean": "Hi, @Tibiritabara. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with [code] not using custom API URLs. Gauravprasadgp suggested checking module installations per the official guide. Camlspotter provided a workaround by setting [code] . The issue is resolved by adding [code] to the [code] call. Next Steps Please confirm if this issue is still relevant to the latest version of LangChain. If not updated, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a problem where the Grit Cli library fails to download correctly, resulting in an error message.  After investigating through documentation, GitHub search, and community forums, the problem appears to be a bug within the LangChain library itself, not a user-defined code issue.  The proposed solution is to upgrade to the latest stable version of LangChain (version 0.2.0) to resolve the issue.", "final_category": "bug", "comments": [{"author": "MicAnt64", "created_at": "2024-11-05T12:08:38Z", "body_clean": "I also came across this issue. I notice on [link] that there is no file at [link] to pull from. I went to the installer file in my environment <MY CONDA ENV PATH /lib/python3.11/site packages/gritql/installer.py, and changed: [code] and [code]"}]}, {"ollama_summary": "This GitHub issue highlights a bug in LangGraph where function responses don’t immediately follow a function call. After searching and reviewing documentation, the issue points to a potential issue within the LangGraph library itself, suggesting it’s a bug rather than a coding issue. The problem manifests as two-time interactions between the agent and Gemini, causing inconsistent behavior and impacting a simple agent test.", "final_category": "bug", "comments": [{"author": "vbarda", "created_at": "2024-11-19T16:37:20Z", "body_clean": "This should resolved in langchain google genai == 2.0.5 please let me know if you run into this issue again!"}]}], "business_insights": ["LangChain updates frequently, causing regression and requiring constant re-evaluation of code.", "The bug fix in Issue 4 suggests a widespread dependency issue, potentially impacting numerous projects.", "The integration failure in Issue 3 indicates a need for improved error handling and dependency management within the LangChain ecosystem.", "The Grit Cli issue highlights a potential vulnerability in a critical library component, demanding immediate attention.", "The bug in Issue 5 underscores the importance of thorough testing and documentation in LangChain development."], "technical_insights": ["LangChain’s dependency management is complex and prone to regression.", "The Grit Cli issue suggests a critical bug in the LangChain library itself.", "The integration failure in Issue 3 requires a focused review of LangChain’s structured API handling.", "The 2-3 sentence summary of Issue 5 suggests a bug in the agent response generation.", "The LangGraph issue highlights a potential bug in the agent’s response generation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  LangChain updates frequently, causing regression and requiring constant re-evaluation of code.\n2.  The bug fix in Issue 4 suggests a widespread dependency issue, potentially impacting numerous projects.\n3.  The integration failure in Issue 3 indicates a need for improved error handling and dependency management within the LangChain ecosystem.\n4.  The Grit Cli issue highlights a potential vulnerability in a critical library component, demanding immediate attention.\n5.  The bug in Issue 5 underscores the importance of thorough testing and documentation in LangChain development.\n\nTECHNICAL INSIGHTS:\n1.  LangChain’s dependency management is complex and prone to regression.\n2.  The Grit Cli issue suggests a critical bug in the LangChain library itself.\n3.  The integration failure in Issue 3 requires a focused review of LangChain’s structured API handling.\n4.  The 2-3 sentence summary of Issue 5 suggests a bug in the agent response generation.\n5.  The LangGraph issue highlights a potential bug in the agent’s response generation.\n", "batch_number": 188, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue involves a bug in LangChain that prevents the creation of MistralAI embeddings from PDFs or URLs. The code throws an error message indicating a problem with the integration of the LangChain ChromaDB component.  Currently, there aren’t readily available flags or parameters to avoid this issue, and the bug appears to be a fundamental issue within the LangChain library itself.", "final_category": "bug", "comments": [{"author": "jamesev15", "created_at": "2024-11-01T01:51:24Z", "body_clean": "The KeyError: 'data' in the issue occurs due to a 429 Too Many Requests response, which prevents some documents from being processed and results in payloads that lack the data key. To reveal the actual error and improve clarity, I propose adding a check with raise for status() to handle cases where the status code is not 200. This will ensure that the code only attempts to access the data key when the response is successful."}, {"author": "keenborder786", "created_at": "2024-11-01T02:29:55Z", "body_clean": "@jamesev15 please see my PR. I have implemented a simple retrying mechanism to account for this, rather than just raising the error which works."}, {"author": "jamesev15", "created_at": "2024-11-01T13:24:55Z", "body_clean": "Sure! I like your approach"}, {"author": "dosubot[bot]", "created_at": "2025-01-31T16:01:10Z", "body_clean": "Hi, @PabloVD. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with creating MistralAI embeddings from PDFs or URLs using LangChain, encountering a 'data' error. Jamesev15 identified the error as a 429 Too Many Requests response, suggesting a check with [code] . Keenborder786 proposed a retry mechanism to address the issue, which was supported by jamesev15. The issue has been resolved by implementing the retry mechanism. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "smita-09", "created_at": "2025-02-15T08:43:55Z", "body_clean": "Hello there, I am getting the same error as you @PabloVD. Can you please mention the solution you used to resolve the error? :) PS: In my case, finding the right batch size of the documents that i was sending to the documents helped but I am keen to hear what solved your problem, thanks. :)"}, {"author": "PabloVD", "created_at": "2025-02-18T09:59:30Z", "body_clean": "Hi @smita 09 I was unable to use Mistral embeddings so I just used other embeddings (HuggingFaceInstructEmbeddings, which can be imported as [code] ). Hope it helps!"}]}, {"ollama_summary": "The issue involves the LangChain `sentence-transformers` library failing to run on Windows 11, despite having all necessary packages installed. Users are encountering an error message similar to the one shown but consistently works on Linux.  The problem appears to be a bug within the LangChain integration, not a code issue, and the solution requires updating to the latest stable version of LangChain.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-30T16:01:03Z", "body_clean": "Hi, @codenamics. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Encountering an issue with [code] on Windows 11. Problem occurs when using [code] with [code] . Shared example code and partial error message related to module importation. Updated to the latest LangChain version, but the issue persists. No further comments or developments have been made. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "anujsahanids3", "created_at": "2025-07-01T09:31:04Z", "body_clean": "I am facing the same issue !!"}]}, {"ollama_summary": "The issue stems from inconsistent results when using `NLTKTextSplitter`’s `add_start_index=True` feature in LangChain.  After searching and investigating, the problem appears to be a bug within the LangChain integration, specifically related to the text splitter’s behavior.  Attempts to update to the latest version of LangChain haven’t resolved the inconsistency.", "final_category": "bug", "comments": []}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe ChatAnthropicVertex component in LangChain is failing to correctly utilize the `api_endpoint` and `base_url` parameters, causing issues with its functionality.  Despite searching documentation and using GitHub search, the problem persists despite updating to the latest stable version of LangChain.  The issue currently manifests as errors related to HTTP requests and logs indicate a failure to interpret the specified parameters.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-30T16:01:01Z", "body_clean": "Hi, @jokester. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Bug reported in [code] class. [code] or [code] parameters not respected, causing \"400 Bad Request\" error. Issue persists in the latest version of LangChain. Confirmed as a bug within LangChain, not user code. No further comments or developments. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe user is experiencing an error when loading PDFs with PyPDFLoader, specifically when using the `download` method.  They’ve already investigated potential causes by searching the LangChain documentation, GitHub search, and other resources, and confirmed it’s not a code issue.  The error persists regardless of the PDF file type and suggests a bug within the PyPDFLoader integration.", "final_category": "bug", "comments": [{"author": "PabloVD", "created_at": "2024-10-31T01:33:37Z", "body_clean": "Seems to be a problem related to the last pypdf release 5.1.0. Uninstalling and installing version 5.0.1 fixed the issue."}, {"author": "stefan6419846", "created_at": "2025-02-06T13:56:14Z", "body_clean": "pypdf maintainer here (although I usually do not look in the issues of the langchain repository): We still have an open PR ( [link] to fix this, but although this issue here is the third report I am reading, nobody has been able to provide me a file which would show this behavior to keep this from happening in the future. I appreciate anyone who is able to provide a reproducing file (either publicly or by private e mail). The above link does not raise for me with the latest pypdf code, but apparently it has been changed after the initial report on 2024 11 29."}, {"author": "PabloVD", "created_at": "2025-02-07T10:01:38Z", "body_clean": "Hi @stefan6419846 thanks for looking into this! [This pdf]( [link] which is used in the example above raises the error for me if I move to pypdf==5.1.0, either from url or locally loaded."}, {"author": "stefan6419846", "created_at": "2025-02-07T10:18:42Z", "body_clean": "Thanks for the hint. I only tried with [code] which worked, but reverting back to [code] does indeed show this issue. Apparently, we already solved this in [link] and I just forgot about the duplicate there when [link] showed up. Thus this bug should not appear anymore with the latest pypdf release."}, {"author": "PabloVD", "created_at": "2025-02-07T10:30:58Z", "body_clean": "I tried with 5.2.0 and it worked fine, yes! Great that the problem was already solved! :D Many thanks!"}, {"author": "sorooshsorkhani", "created_at": "2025-02-12T20:57:59Z", "body_clean": "I had the same issue with [code] . Changing it to [code] solved it. The attached file is the file that caused this error for me. [2022 Microbial Community Level Physiological Profiles and Genetic Prokaryotic Structure of Burned Soils Under Mediterranean Sclerophyll Forests in Central Chile.pdf]( [link]"}, {"author": "stefan6419846", "created_at": "2025-02-13T08:25:27Z", "body_clean": "5.3.0 should not have broken this again and running this locally did not yield any issues. Please provide some more details if you are indeed still experiencing exceptions with the latest release."}, {"author": "sorooshsorkhani", "created_at": "2025-02-13T16:46:37Z", "body_clean": "I apologize, it's fixed now. Previously, to fix the issue, I just upgraded my package to [code] but the problem didn't get fixed. I uninstalled and installed [code] , then it was fixed. Now, to test it again, I uninstalled [code] and installed [code] and it's fixed."}]}], "business_insights": ["LangChain’s ChromaDB integration is a core component; a fundamental bug within the library is causing widespread issues.", "The ‘data’ key error highlights a critical issue with the ChromaDB component’s integration; it’s a widespread problem impacting multiple users.", "The retrying mechanism is a good solution; addressing the root cause of the error is crucial for stability.", "Updating LangChain is necessary; the bug suggests a regression in the library's core functionality.", "ChromaDB integration is a significant bottleneck; addressing this will improve overall performance."], "technical_insights": ["LangChain’s ChromaDB integration is a core component; a fundamental bug is causing widespread issues.", "The ‘data’ key error indicates a critical issue with the ChromaDB component’s integration; it’s a widespread problem impacting multiple users.", "The retrying mechanism is a good solution; addressing the root cause of the error is crucial for stability.", "Updating LangChain is necessary; the bug suggests a regression in the library’s core functionality.", "ChromaDB integration is a significant bottleneck; addressing this will improve overall performance."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s ChromaDB integration is a core component; a fundamental bug within the library is causing widespread issues.\n2. The ‘data’ key error highlights a critical issue with the ChromaDB component’s integration; it’s a widespread problem impacting multiple users.\n3. The retrying mechanism is a good solution; addressing the root cause of the error is crucial for stability.\n4. Updating LangChain is necessary; the bug suggests a regression in the library's core functionality.\n5. ChromaDB integration is a significant bottleneck; addressing this will improve overall performance.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s ChromaDB integration is a core component; a fundamental bug is causing widespread issues.\n2. The ‘data’ key error indicates a critical issue with the ChromaDB component’s integration; it’s a widespread problem impacting multiple users.\n3. The retrying mechanism is a good solution; addressing the root cause of the error is crucial for stability.\n4. Updating LangChain is necessary; the bug suggests a regression in the library’s core functionality.\n5. ChromaDB integration is a significant bottleneck; addressing this will improve overall performance.\n", "batch_number": 189, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The code is experiencing an `ImportError: Dependencies for InstructorEmbedding not found` issue, likely due to a missing dependency for a specific LangChain component – InstructorEmbedding. The issue appears to be a bug within the LangChain library itself, and attempts to update to the latest version of LangChain haven’t resolved the problem, suggesting a potential issue with the integration package.", "final_category": "bug", "comments": [{"author": "siddarthreddygsr", "created_at": "2024-11-04T20:01:28Z", "body_clean": "[link]"}, {"author": "dosubot[bot]", "created_at": "2025-02-03T16:01:06Z", "body_clean": "Hi, @PabloVD. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You experienced an [code] with [code] due to missing dependencies for [code] . You updated to the latest version of LangChain, but the issue persisted. siddarthreddygsr suggested installing the [code] package from PyPI, which resolved the issue. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe AgentExecutor is consistently submitting tool outputs twice, causing a repeating behavior.  The issue stems from a fundamental issue with LangChain’s integration, specifically related to the model’s restart causing the output to be re-generated.  Attempts to update LangChain haven’t resolved the problem, and the bug persists with a structured output format.", "final_category": "bug", "comments": [{"author": "burakcbdn", "created_at": "2024-11-12T13:03:31Z", "body_clean": "issue still persists"}, {"author": "dosubot[bot]", "created_at": "2025-02-11T16:00:51Z", "body_clean": "Hi, @burakcbdn. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] in LangChain submits tool outputs twice. This behavior causes the model to restart output production unexpectedly. The issue disrupts the structured output format. The problem does not occur in the OpenAI playground, suggesting a LangChain specific bug. You have confirmed that the issue still persists. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This GitHub issue highlights a problem where the documentation for splitting text into tokens is incorrectly pointing users to the wrong page within the `TokenTextSplitter` library. The current documentation uses outdated links and redirects to a non-existent page, hindering users’ ability to effectively utilize the tool. The issue requests a redirect to the correct, updated documentation page.", "final_category": "other", "comments": [{"author": "DangerousPotential", "created_at": "2024-11-01T14:21:32Z", "body_clean": "Proposed changes in 27824"}, {"author": "inclinedadarsh", "created_at": "2024-11-16T18:45:31Z", "body_clean": "This issue has been fixed and merged in 27824."}]}, {"ollama_summary": "The LangChain `agent_executor` tool cannot run due to a bug in `chat_models.py` that causes the `event.delta.partial_json` and `event.delta.stop_reason` arguments to fail when interacting with the Anthropic models. The issue stems from a problem with the model's internal data processing within the `chat_models.py` file, specifically related to the `partial_json` and `stop_reason` parameters.  The code example demonstrates this failure with specific error messages.", "final_category": "bug", "comments": [{"author": "LaiosOvO", "created_at": "2024-10-30T16:05:20Z", "body_clean": "if it is possible please renew a version of langchain anthropic but use langchain =0.2.0"}, {"author": "dosubot[bot]", "created_at": "2025-01-30T16:01:01Z", "body_clean": "Hi, @LaiosOvO. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: A bug was reported in the [code] tool, specifically in [code] . The issue involves \"args\": [code] and \"stop reason\": [code] . You confirmed the bug persists in the latest stable version of LangChain. A request was made for a new version of [code] compatible with [code] . Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue reports a bug in LangChain's `chat models.py` that causes the agent executor to fail when providing the input \"What time is it?\". The bug stems from an issue with the `partial json` and `stop reason` parameters within the `event.delta` data, leading to an AttributeError when `event.delta` is `None`. The code attempts to use `event.delta.partial json` which is not being correctly handled, resulting in the `AttributeError`.  The fix involves ensuring the `event.delta` data is properly processed and that the `partial json` parameter is not being called.", "final_category": "bug", "comments": []}], "business_insights": ["Incorrect dependency handling is a recurring issue, impacting LangChain’s core functionality.", "Model restart issues are frequently linked to integration package problems, requiring careful package management.", "Documentation inconsistencies can significantly hinder user experience, necessitating updated resources.", "Model data processing errors within chat_models.py are causing critical failures.", "Dependency updates haven’t completely resolved the reported bug, suggesting deeper integration challenges."], "technical_insights": ["LangChain's integration package is critical, and its stability directly affects the entire system.", "Model restart causes re-generation, demanding careful management of model lifecycle.", "Documentation errors impede user understanding, requiring updated resources.", "chat_models.py bug is causing attribute errors when event.delta is None, indicating data processing problems.", "Dependency management issues impact model performance and stability, requiring remediation."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Incorrect dependency handling is a recurring issue, impacting LangChain’s core functionality.\n2. Model restart issues are frequently linked to integration package problems, requiring careful package management.\n3. Documentation inconsistencies can significantly hinder user experience, necessitating updated resources.\n4. Model data processing errors within `chat_models.py` are causing critical failures.\n5. Dependency updates haven’t completely resolved the reported bug, suggesting deeper integration challenges.\n\nTECHNICAL INSIGHTS:\n1. LangChain's integration package is critical, and its stability directly affects the entire system.\n2. Model restart causes re-generation, demanding careful management of model lifecycle.\n3. Documentation errors impede user understanding, requiring updated resources.\n4. `chat_models.py` bug is causing attribute errors when `event.delta` is `None`, indicating data processing problems.\n5. Dependency management issues impact model performance and stability, requiring remediation.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 190, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe DuckDuckGo community tool documentation lacks a `output_format` option for a specific version, which is currently only available on the latest version.  The documentation indicates this option is present in the previous version, causing a discrepancy between the published documentation and the actual code.  The issue suggests a potential synchronization problem between the documentation and the code, requiring a fix to ensure accurate information is provided.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-29T16:01:07Z", "body_clean": "Hi, @ramyma. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights a mismatch between the DuckDuckGo community tool documentation and the code for version 0.3.3. Specifically, the [code] option is documented but not implemented in the code. You suggested updating the documentation and releasing a new version to resolve this. Recommended enhancing deployment synchronization to prevent future discrepancies. No further comments or activity have been made on this issue. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code exhibits a bug where the `set_llm_cache` function doesn't correctly cache LLM responses, leading to inconsistent results. This issue is impacting the AgentExecutor chain, causing errors and potentially hindering the functionality of the LangChain application.  The code uses a `tool call` to invoke a function, and the bug seems to be in the function's logic, causing it to not properly store or retrieve the cached response.", "final_category": "bug", "comments": [{"author": "hippopond", "created_at": "2024-11-15T00:27:35Z", "body_clean": "I tried: agent executor = AgentExecutor(agent=agent, tools=tools, verbose=True, stream runnable=False) Adding the \"stream runnable=False\" seems to have made it use the Cache. Because in this file: [link] The Streaming does not use the Cache, the non Streaming : uses the code path that uses the Cache. if self.stream runnable: Use streaming to make sure that the underlying LLM is invoked in a streaming fashion to make it possible to get access to the individual LLM tokens when using stream log with the Agent Executor. Because the response from the plan is not a generator, we need to accumulate the output into final output and return that. for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}): if final output is None: final output = chunk else: final output += chunk else: final output = self.runnable.invoke(inputs, config={\"callbacks\": callbacks})"}, {"author": "hippopond", "created_at": "2024-11-15T00:28:49Z", "body_clean": "There may be a reason why in the code path for Streaming it does not use the Cache. Not sure myself. At least for now a workaround is adding stream runnable=False"}, {"author": "dosubot[bot]", "created_at": "2025-02-14T16:00:58Z", "body_clean": "Hi, @kakiii. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The [code] function was not working as expected with [code] . User \"hippopond\" suggested setting [code] to enable caching. The streaming code path does not utilize the cache, possibly by design. Using the non streaming path allows the cache to be used, providing a workaround. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "sivagao", "created_at": "2025-02-19T10:44:33Z", "body_clean": "still not work. can you give example for how to use cache in agent executor @hippopond"}, {"author": "dosubot[bot]", "created_at": "2025-02-19T10:46:49Z", "body_clean": "@eyurtsev, the user @sivagao has indicated that the issue with the [code] function still persists and is requesting an example of how to use the cache in the agent executor. Could you please assist them with this?"}]}, {"ollama_summary": "The code is failing to correctly embed a query (\"this is a test\") and is receiving an unexpected output. The issue stems from a bug in LangChain that causes the embedding model to change its output format unexpectedly, resulting in the incorrect embedding vector.  The code attempts to generate a fake embedding, but the model is now producing a different vector, and the issue is not resolved by updating the LangChain version.", "final_category": "bug", "comments": [{"author": "gabrielpondc", "created_at": "2024-10-31T06:31:54Z", "body_clean": "find the reason that langchain unsing cl100k base encoder encoding the text"}]}, {"ollama_summary": "This GitHub issue proposes adding voice input support to Ollama models in LangChain, aiming to enable voice-controlled applications. The core solution involves a speech-to-text conversion component, integrating with existing LangChain chains and agents, and ultimately providing a way for the LLM to receive spoken language input.  The project will involve developing new classes and components, testing thoroughly, and documenting the solution for future enhancements and maintainability.", "final_category": "feature", "comments": [{"author": "efriis", "created_at": "2024-10-29T17:49:42Z", "body_clean": "assigning to @kodychik"}, {"author": "dosubot[bot]", "created_at": "2025-01-28T16:02:40Z", "body_clean": "Hi, @efriis. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Proposal to add voice input support to LangChain's Ollama models. Suggested integration of a Speech to Text component for processing voice inputs. Task assigned to @kodychik for further development. Currently unresolved. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting on the issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue is a critical bug in the PydanticUserError library that causes a significant import statement error when using the `invoke()` method with OpenAI models. The bug prevents the correct import of `PromptTemplate` from `langchain.prompts`, severely hindering the development workflow and requiring a downgrade of the Pydantic version.", "final_category": "bug", "comments": [{"author": "bansky-cl", "created_at": "2024-11-25T02:29:32Z", "body_clean": "I have the same problem as you, how did you solve it?"}, {"author": "dosubot[bot]", "created_at": "2025-02-24T16:01:00Z", "body_clean": "Hi, @Bala Friedkin. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered a [code] when using the [code] method with OpenAI LLMs in LangChain. The error message suggests replacing [code] with [code] . You expressed frustration with frequent import changes and inadequate documentation. Another user, bansky cl, also reported experiencing the same issue and asked for a solution. The issue remains unresolved. Next Steps: Could you confirm if this issue is still relevant with the latest version of LangChain? If so, please comment to keep the discussion open. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Consistent documentation discrepancies across different versions highlight a potential issue in the workflow between the documentation and code.", "The synchronization problem suggests a need for improved version control and testing for the documentation and code.", "Addressing this could streamline the development process and reduce errors.", "Clear documentation is crucial for developers, impacting overall project success.", "Maintaining consistent documentation improves code maintainability."], "technical_insights": ["The set_llm_cache function's logic is the core of the bug, requiring thorough debugging.", "The tool call integration needs careful examination to ensure the caching mechanism is functioning correctly.", "The bug is impacting the AgentExecutor chain, emphasizing the need for robust error handling and logging.", "The stream runnable=False setting is likely a workaround, requiring investigation of its impact.", "The bug's root cause could be related to the model's caching behavior."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Consistent documentation discrepancies across different versions highlight a potential issue in the workflow between the documentation and code.\n2. The synchronization problem suggests a need for improved version control and testing for the documentation and code.\n3. Addressing this could streamline the development process and reduce errors.\n4. Clear documentation is crucial for developers, impacting overall project success.\n5. Maintaining consistent documentation improves code maintainability.\n\nTECHNICAL INSIGHTS:\n1. The `set_llm_cache` function's logic is the core of the bug, requiring thorough debugging.\n2. The `tool call` integration needs careful examination to ensure the caching mechanism is functioning correctly.\n3. The bug is impacting the AgentExecutor chain, emphasizing the need for robust error handling and logging.\n4. The `stream runnable=False` setting is likely a workaround, requiring investigation of its impact.\n5. The bug's root cause could be related to the model's caching behavior.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 191, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue reports a bug where the `DirectoryLoader` and `UnstructuredLoader` timeout when loading files from a folder containing only one file, failing to complete the `loader.load()` operation.  The problem isn’t observed with the `TextLoader`, suggesting a potential issue with the `UnstructuredLoader`’s handling of public URLs or its internal logic.  Currently, the issue appears to be a bug within LangChain itself and isn’t resolved by updating the library version.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-10-29T22:50:08Z", "body_clean": "Hey, It's not hitting any Public URL. [code] just loads the files as Documents using [code] . Unlike [code] , it does not hit any public URL. What I would recommend is to use [code] and [code] to show and speed up the loading process respectively: [code] Note that [code] loads one file as a single document while [code] loads all the files as individual documents which match the [code] . So if your case is loading a single file then you should use [code] . If you have many files in the [code] Most likely [code] might be taking too much time to load and match all of the files which you can see if you enable [code] ."}, {"author": "garyfanhku", "created_at": "2024-11-13T09:29:48Z", "body_clean": "TL;DR, Langchain should be mindful of telemetry as discussed in [link] [code] package could be hitting [code] and you would need to set env variables as in [link] to turn the it off. In offline environment, [code] call seems to be blocking."}, {"author": "dosubot[bot]", "created_at": "2025-02-12T16:01:03Z", "body_clean": "Hi, @GanPeixin. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a timeout issue with [code] or [code] when loading a text file offline. User keenborder786 clarified that [code] does not access public URLs and suggested using [code] and [code] . User garyfanhku identified that the [code] package might be trying to connect to an external server and recommended setting environment variables to disable telemetry. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a bug in the LangChain agent that limits the generated text length to 20 characters. This results in unexpected behavior when initializing the agent and can cause issues with the agent’s output. The proposed solution is to increase the maximum length setting or, ideally, adjust the agent’s configuration to allow for longer text generation.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-10-29T22:18:14Z", "body_clean": "Please set up [code] as follow: [code]"}, {"author": "my36z", "created_at": "2024-10-31T03:45:44Z", "body_clean": "[code] [code] both error. I think create react agent or agent executor.invoke reset the max length."}, {"author": "nai-kon", "created_at": "2024-11-25T07:41:31Z", "body_clean": "@my36z @keenborder786 I have the same problem. When I debugged [code] of [code] , [code] argument was [code] . And this causes max length = 20 (default value when generation config is None) [code] generation config is None and this causes max length=20 (default value). On the other hand, when calling without create react agent(), the correct generation config value (max new tokens=512) was passed. [code] It seems that the generation setting is not passed when using create react agent()."}, {"author": "dosubot[bot]", "created_at": "2025-02-24T16:01:04Z", "body_clean": "Hi, @my36z. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug in the [code] function where [code] resets to 20, causing a [code] . Despite setting [code] to 512, the issue persists. [code] suggested setting [code] in [code] , but this did not resolve the issue. [code] confirmed the issue, noting that [code] is [code] with [code] , leading to the default [code] of 20. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code snippet contains a significant issue: it relies on a deprecated `modify schema` method in Pydantic, which is causing compatibility problems with Langchain. Specifically, the `get pydantic json schema` method is being used instead, which is not supported in newer versions of Pydantic. This is a critical bug that needs to be addressed.\n\nHere’s a breakdown of the problem and potential solutions:\n\n**Problem:**\n\n* **Deprecated Method:** The `modify schema` method is deprecated in Pydantic v2.  Using it will lead to errors and potentially break functionality.\n* **Langchain Dependency:** Langchain relies on Pydantic for data serialization and deserialization. The outdated `modify schema` method is causing this dependency to fail.\n\n**Solution:**\n\nThe most straightforward solution is to **replace the deprecated `modify schema` method with the new `get pydantic json schema` method.** This ensures compatibility with the latest Pydantic version.\n\n**Code Change (Illustrative - Adapt to your specific code):**\n\n```python\nfrom pydantic import BaseModel, validator\n\nclass MyModel(BaseModel):\n    x: int\n    y: str\n```\n\n**Important Considerations:**\n\n* **Testing:** Thoroughly test the code after implementing the change to ensure that it works correctly with Langchain and other dependencies.\n* **Documentation:** Update any documentation that references the deprecated `modify schema` method to reflect the new method.\n* **Upgrade Pydantic:**  Consider upgrading to the latest stable version of Pydantic to benefit from the latest bug fixes and improvements.\n\n**In summary, the code snippet is vulnerable to a critical compatibility issue due to the use of a deprecated method. Replacing it with the correct `get pydantic json schema` method is the recommended solution.**", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-10-28T22:41:30Z", "body_clean": "Hello, Can you try the following and see if it helps, basically initalizes using [code] [code]"}, {"author": "igor-elbert", "created_at": "2024-12-13T19:41:36Z", "body_clean": "Encountered the same error trying to get [Sarm.world example]( [link] to run"}, {"author": "Myoungs", "created_at": "2025-02-15T08:51:07Z", "body_clean": "try this: [code]"}, {"author": "ckxxm", "created_at": "2025-03-13T07:49:07Z", "body_clean": "try this: [code] using upgrade always fails, after completely uninstalling and reinstalling, this error is gone, the reason is that the version of langchain openai is too low."}, {"author": "dosubot[bot]", "created_at": "2025-06-12T16:03:03Z", "body_clean": "Hi, @DavidNavarroSaiz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: Original issue with LangChain's compatibility with Pydantic v2 due to unsupported [code] method. Affected similarity searches using MongoDBAtlasVectorSearch and OpenAIEmbeddings. Suggested workaround by keenborder786 using [code] . Resolution confirmed by ckxxm after upgrading langchain openai and reinstalling the package. Next Steps: Please confirm if the issue is still relevant to the latest version of the LangChain repository by commenting here. If no updates are provided, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a summary of the GitHub issue:\n\nThe issue involves a bug in the LangChain `MongoDBAtlasVectorSearch` library, specifically related to the `create vector search index` method.  The code attempts to create a vector store index using the `create` method, but it encounters an error indicating that this method is not available.  The developers are investigating this issue and are working on a fix, but the current state of the library is misleading to users following the documentation.  The issue highlights a potential problem with the library's internal implementation and suggests a manual index creation process as a workaround.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-27T16:01:09Z", "body_clean": "Hi, @DavidNavarroSaiz. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a mismatch between the LangChain documentation and the [code] class. The documentation mentions a [code] method that is missing, causing an [code] . You proposed a workaround by manually creating the index in MongoDB and suggested updating the documentation or implementing the method. Next Steps: Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe documentation for a specific function uses the `.dict()` method instead of the correct method to convert a Python dictionary to JSON, resulting in incorrect output.  The issue highlights a discrepancy between the documentation's instructions and the code's implementation.  The proposed solution is to update the code to use `res.json()` instead of `.dict()` to ensure proper JSON formatting.", "final_category": "other", "comments": [{"author": "DangerousPotential", "created_at": "2024-10-28T08:17:50Z", "body_clean": "In 27675 , I changed the word JSON to dictionary, but the team can choose whether to replace the [code] to [code] if the intended use case is for JSON"}, {"author": "DangerousPotential", "created_at": "2024-10-29T15:03:39Z", "body_clean": "Fixed with 27675."}]}], "business_insights": ["**Dependency Management:** The issue highlights a critical dependency issue – the UnstructuredLoader’s handling of public URLs is causing a bug, suggesting a potential broader problem with Langchain’s handling of external data sources.", "**Documentation Consistency:** The discrepancy between documentation and code contradicts the intended functionality, indicating a need for improved documentation and code alignment.", "**Versioning Conflicts:** The modify schema deprecation highlights a potential versioning conflict, requiring careful consideration of library updates and compatibility.", "**Data Serialization Errors:** The modify schema issue suggests a problem with data serialization, potentially impacting other Langchain components.", "**Testing is Crucial:** Thorough testing is essential to validate the fix and prevent future compatibility issues."], "technical_insights": ["**Deprecated Method Handling:** The modify schema method is deprecated, necessitating a replacement with the new get pydantic json schema method.", "**Pydantic Dependency:** The dependency on Pydantic for JSON schema serialization is a key point of concern, requiring a solution to maintain compatibility.", "**Vector Search Library:** The bug in the MongoDBAtlasVectorSearch library is a significant issue, impacting the functionality of Langchain's vector search capabilities.", "**JSON Formatting:** The discrepancy between documentation and code indicates a potential problem with the code's JSON formatting, requiring a fix to ensure consistent output.", "**Version Control:** The modify schema deprecation signals a potential version control issue, requiring a strategy to handle library upgrades."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  **Dependency Management:** The issue highlights a critical dependency issue – the `UnstructuredLoader`’s handling of public URLs is causing a bug, suggesting a potential broader problem with Langchain’s handling of external data sources.\n2.  **Documentation Consistency:** The discrepancy between documentation and code contradicts the intended functionality, indicating a need for improved documentation and code alignment.\n3.  **Versioning Conflicts:** The `modify schema` deprecation highlights a potential versioning conflict, requiring careful consideration of library updates and compatibility.\n4.  **Data Serialization Errors:** The `modify schema` issue suggests a problem with data serialization, potentially impacting other Langchain components.\n5.  **Testing is Crucial:** Thorough testing is essential to validate the fix and prevent future compatibility issues.\n\nTECHNICAL INSIGHTS:\n1.  **Deprecated Method Handling:** The `modify schema` method is deprecated, necessitating a replacement with the new `get pydantic json schema` method.\n2.  **Pydantic Dependency:** The dependency on Pydantic for JSON schema serialization is a key point of concern, requiring a solution to maintain compatibility.\n3.  **Vector Search Library:** The bug in the `MongoDBAtlasVectorSearch` library is a significant issue, impacting the functionality of Langchain's vector search capabilities.\n4.  **JSON Formatting:** The discrepancy between documentation and code indicates a potential problem with the code's JSON formatting, requiring a fix to ensure consistent output.\n5.  **Version Control:** The `modify schema` deprecation signals a potential version control issue, requiring a strategy to handle library upgrades.\n\n", "batch_number": 192, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe Action Input component in LangChain is losing the last symbols after using the AgentExecutor, despite attempts to resolve it with documentation, search, and updates. The issue appears to be a bug within the LangChain integration, not a coding error in the user's code.  Currently, the Action Input consistently outputs \" and \" without the expected final characters.", "final_category": "bug", "comments": [{"author": "avyrodov", "created_at": "2024-10-29T12:19:23Z", "body_clean": "A similar problem."}, {"author": "format37", "created_at": "2024-11-03T20:36:54Z", "body_clean": "Since it is not fixed yet, the issue can be avoided by using another tool and agent initialization approach: [code] You can also try adding \"Input should end with 2 new lines\" in the tool description."}, {"author": "qingwli", "created_at": "2024-11-04T08:52:01Z", "body_clean": "Thanks @avyrodov @format37 @hippopond Here is my update [code] It's better. But sometimes (\" \") will be added before action input. I don't know why. [code]"}, {"author": "hippopond", "created_at": "2024-11-04T16:01:29Z", "body_clean": "Thanks @format37 @qingwli 1) Agreed that modifying the prompt is not ideal. Sometimes I have also seen it add \" 2 \" after the line which is not wanted. 2) I'm going to withdraw my PR since it's not ideal and does not address the root cause. 3) Currently in my investigation: When I use ChatOllama directly, it works fine. When I use AgentExecutor on top of ChatOllama that's when it drops the last character if it is not alphanumeric. 4) I am trying to disable streaming: llm = ChatOllama( model=\"llama3.1\", base url=\" [link] timeout=300, temperature=0, disable streaming=True ) But it still streams. I have also changed \"disable streaming=True\" to \"streaming=False\" it still streams. I suspect the streaming is missing the last chunk. Any suggestion on how to turn off streaming will help me. Thanks everyone !"}, {"author": "hippopond", "created_at": "2024-11-05T03:10:35Z", "body_clean": "Here is my investigation so far: Simple ChatOllama: (the last character comes back no problem) from langchain ollama import ChatOllama llm x = ChatOllama( model=\"llama3.1\", base url=\" [link] timeout=300, temperature=0, ) user input = \"echo back with [code] \" response = llm x.invoke(user input) print(response.content) output: [code] Simple AgentExecutor on top of ChatOllama: (we miss the last character) llm y = ChatOllama( model=\"llama3.1\", base url=\" [link] timeout=300, temperature=0, ) from langchain.tools import Tool def echo(text): \"\"\"Echoes the input text.\"\"\" return text echo tool = Tool( name=\"Echo\", func=echo, description=\"Repeats the input text.\" ) simple agent = initialize agent( tools=[echo tool], agent=AgentType.ZERO SHOT REACT DESCRIPTION, llm=llm y, handle parsing errors=True, verbose=True, ) user input = \"echo back with [code] \" response = simple agent.invoke(user input) output Entering new AgentExecutor chain... Question: echo back with [code] Thought: I need to use the Echo tool to repeat the text \"(customers)\" Action: Echo Action Input: (customers Observation: (customers Thought:Here are the steps: .........."}, {"author": "hippopond", "created_at": "2024-11-05T03:14:44Z", "body_clean": "The results from ChatOllama is fine. The results from the SimpleExecutor on top of ChatOllama loses the last character if the last character is non alphnumeric. See the line for Action Input Both code paths wind up in : Line 544 langchain/libs/partners/ollama/langchain ollama/chat models.py Where the chunk for the last non alpha numeric character is missed."}, {"author": "qingwli", "created_at": "2024-11-05T03:22:05Z", "body_clean": "Hi @hippopond It looks like we can 100% reproduce this issue and try to fix it in the source code. I'm new to Python. Are you referring this line? [link] [link]"}, {"author": "hippopond", "created_at": "2024-11-05T04:47:53Z", "body_clean": "Yes. There are 2 Paths to reach that line 544. Here's the output of pdb \"where\" command The path where it is ChatOllama only: response = llm x.invoke(user input) /langchain/libs/core/langchain core/language models/chat models.py(286)invoke() self.generate prompt( /langchain/libs/core/langchain core/language models/chat models.py(786)generate prompt() return self.generate(prompt messages, stop=stop, callbacks=callbacks, kwargs) /langchain/libs/core/langchain core/language models/chat models.py(633)generate() self. generate with cache( /langchain/libs/core/langchain core/language models/chat models.py(851) generate with cache() result = self. generate( /langchain/libs/partners/ollama/langchain ollama/chat models.py(644) generate() final chunk = self. chat stream with aggregation( /langchain/libs/partners/ollama/langchain ollama/chat models.py(544) chat stream with aggregation() final chunk = None The Path where it is the AgentExecutor on top of ChatOllama response = simple agent.invoke(user input) /langchain/libs/langchain/langchain/chains/base.py(160)invoke() self. call(inputs, run manager=run manager) /langchain/libs/langchain/langchain/agents/agent.py(1629) call() next step output = self. take next step( /langchain/libs/langchain/langchain/agents/agent.py(1335) take next step() [ /langchain/libs/langchain/langchain/agents/agent.py(1335)<listcomp () [ /langchain/libs/langchain/langchain/agents/agent.py(1363) iter next step() output = self. action agent.plan( /langchain/libs/langchain/langchain/agents/agent.py(809)plan() full output = self.llm chain.predict(callbacks=callbacks, full inputs) /langchain/libs/langchain/langchain/chains/llm.py(318)predict() return self(kwargs, callbacks=callbacks)[self.output key] /langchain/libs/core/langchain core/ api/deprecation.py(182)warning emitting wrapper() return wrapped( args, kwargs) /langchain/libs/langchain/langchain/chains/base.py(389) call () return self.invoke( /langchain/libs/langchain/langchain/chains/base.py(160)invoke() self. call(inputs, run manager=run manager) /langchain/libs/langchain/langchain/chains/llm.py(126) call() response = self.generate([inputs], run manager=run manager) /langchain/libs/langchain/langchain/chains/llm.py(138)generate() return self.llm.generate prompt( /langchain/libs/core/langchain core/language models/chat models.py(786)generate prompt() return self.generate(prompt messages, stop=stop, callbacks=callbacks, kwargs) /langchain/libs/core/langchain core/language models/chat models.py(633)generate() self. generate with cache( /langchain/libs/core/langchain core/language models/chat models.py(851) generate with cache() result = self. generate( /langchain/libs/partners/ollama/langchain ollama/chat models.py(644) generate() final chunk = self. chat stream with aggregation( /langchain/libs/partners/ollama/langchain ollama/chat models.py(544) chat stream with aggregation() final chunk = None"}, {"author": "hippopond", "created_at": "2024-11-05T04:50:07Z", "body_clean": "BOTH Paths lead to the same code. So the thinking is: the extra steps taken by the AgentExecutor BEFORE reaching ChatOllama caused ChatOllama not to get the last chunk. But I'm not sure how to find the bug that caused it."}, {"author": "avyrodov", "created_at": "2024-11-05T10:54:48Z", "body_clean": "@hippopond, Hi, I did some tests, they showed that the problem is probably not in the langchain implementation of ollama, if you try to listen to the response from ollama to a query ( [code] ), you can see that the response already contains clipped information."}, {"author": "hippopond", "created_at": "2024-11-05T16:11:32Z", "body_clean": "Thank you @avyrodov That's a good debugging step. (now I can use tcpflow in my toolkit in the future Thanks ! ). Your investigation aligns with what I see. The data, even the last chunk of \" \" has arrived at LangChain. Here's a small screenshot of what I see in LangSmith: ONLY ChatOllama The results are good: ![ChatOllama]( [link] LLMChain on top of ChatOllama As confirmed by @avyrodov the last chunk is in, but not going through code ![LLMChain ChatOllama]( [link]"}, {"author": "hippopond", "created_at": "2024-11-05T16:23:21Z", "body_clean": "Cleaning up the Paths: This is the code path ONLY ChatOllama (which gets the last chunk) response = llm x.invoke(user input) /langchain/libs/core/langchain core/language models/chat models.py(286)invoke() /langchain/libs/core/langchain core/language models/chat models.py(786)generate prompt() /langchain/libs/core/langchain core/language models/chat models.py(633)generate() /langchain/libs/core/langchain core/language models/chat models.py(851) generate with cache() /langchain/libs/partners/ollama/langchain ollama/chat models.py(644) generate() /langchain/libs/partners/ollama/langchain ollama/chat models.py(544) chat stream with aggregation() This code path from the Simple Executor to the ChatOllama (which does NOT get the last chunk). response = simple agent.invoke(user input) /langchain/libs/langchain/langchain/chains/base.py(160)invoke() /langchain/libs/langchain/langchain/agents/agent.py(1629) call() /langchain/libs/langchain/langchain/agents/agent.py(1335) take next step() /langchain/libs/langchain/langchain/agents/agent.py(1335)<listcomp () /langchain/libs/langchain/langchain/agents/agent.py(1363) iter next step() /langchain/libs/langchain/langchain/agents/agent.py(809)plan() /langchain/libs/langchain/langchain/chains/llm.py(318)predict() /langchain/libs/core/langchain core/ api/deprecation.py(182)warning emitting wrapper() /langchain/libs/langchain/langchain/chains/base.py(389) call () /langchain/libs/langchain/langchain/chains/base.py(160)invoke() /langchain/libs/langchain/langchain/chains/llm.py(126) call() /langchain/libs/langchain/langchain/chains/llm.py(138)generate() /langchain/libs/core/langchain core/language models/chat models.py(786)generate prompt() /langchain/libs/core/langchain core/language models/chat models.py(633)generate() /langchain/libs/core/langchain core/language models/chat models.py(851) generate with cache() /langchain/libs/partners/ollama/langchain ollama/chat models.py(644) generate() /langchain/libs/partners/ollama/langchain ollama/chat models.py(544) chat stream with aggregation()"}, {"author": "hippopond", "created_at": "2024-11-05T16:24:12Z", "body_clean": "They both meet at: /langchain/libs/core/langchain core/language models/chat models.py(786)generate prompt() My next investigation step is to put a breakpoint at that point and see the difference between all the variables....."}, {"author": "hippopond", "created_at": "2024-11-07T03:25:22Z", "body_clean": "What I found so far. 1) There was no difference except the prompt at the breakpoint. 2) However, when I ran tcpflow: The last chunk \"'\" was returned by ollama server when the client was a simple ChatOllama object. The last chunk was NOT returned by the ollama server when the client was a AgentExecutor on top of ChatOllama object. 3) I think the ollama server was initialized differently when the AgentExecutor got initialized"}, {"author": "hippopond", "created_at": "2024-11-07T05:00:41Z", "body_clean": "When i try to change the LLM model: (NOTE: llama3.4 does not exist) llm x = ChatOllama( model=\"llama3.4\", base url=\" [link] timeout=300, temperature=0, ) user input = \"echo back with [code] \" response = llm x.invoke(user input) I get the error: ResponseError: model \"llama3.4\" not found, try pulling it first This is NOT captured by: tcpflow i any c 'not port 11434' Which other port could ollama be listening in ?"}, {"author": "qingwli", "created_at": "2024-11-07T07:01:13Z", "body_clean": "I have a question, Ollama is running on 11434, why we need to run [code] It means see all tcp logs expect 11434, But we want to Ollama logs right? Why dont we use [code]"}, {"author": "qingwli", "created_at": "2024-11-07T07:41:18Z", "body_clean": "[code] Here is my test code. Almost the same as above. I add a [code] after cus.tomers. I dont know why agent think () is not the word. So I add a [code] at the end.] Here is the output: [code] And here is the tcp log. [code] We can see the response: [code] There is no last [code] Now we can see the api request information. I will just use this message to chat with Ollama. [code] Looks like it is last [code] . So let's see two api request is any different. From python agent [code] From iTerm Ollama [code] Looks like the messages is all the same. The only difference is [code] . From python agent [code] From iTerm Ollama [code] I will use postman send two request and see what's happend."}, {"author": "qingwli", "created_at": "2024-11-07T07:45:21Z", "body_clean": "![image]( [link] ![image]( [link] Very clear, Looks like call chat API, some options will affect this [code] I will test these options, which option is the key [code]"}, {"author": "qingwli", "created_at": "2024-11-07T07:50:06Z", "body_clean": "Very simple: just delete every single item in the options and test, Now I know which key affects the last [code] ![image]( [link] ![image]( [link]"}, {"author": "qingwli", "created_at": "2024-11-07T07:51:20Z", "body_clean": "![image]( [link]"}, {"author": "hippopond", "created_at": "2024-11-07T07:53:34Z", "body_clean": "Interesting. FYI: When I run tcpflow i any c 'not port 11434' I only get the lines related to port 11434"}, {"author": "hippopond", "created_at": "2024-11-07T07:54:36Z", "body_clean": "Currently all the options are not controlled by the application developer. it's handled by a lower level. I don't know if we have a way to fine control it......"}, {"author": "qingwli", "created_at": "2024-11-07T07:57:15Z", "body_clean": "<img width=\"1016\" alt=\"image\" src=\" [link] <img width=\"1010\" alt=\"image\" src=\" [link]"}, {"author": "hippopond", "created_at": "2024-11-07T08:01:56Z", "body_clean": "[link]"}, {"author": "hippopond", "created_at": "2024-11-07T08:03:51Z", "body_clean": "When we instantiate the ChatOllama class: (We don't use stop) llm y = ChatOllama( model=\"llama3.1\", base url=\" [link] timeout=300, temperature=0, ) But, I think when we add on AgentExecutor it adds in the \"stop\". Because of the complex prompt simple agent = initialize agent( tools=[echo tool], agent=AgentType.ZERO SHOT REACT DESCRIPTION, llm=llm y, handle parsing errors=True, verbose=True, )"}, {"author": "qingwli", "created_at": "2024-11-07T08:17:33Z", "body_clean": "Yeah, you can change to use [code] or [code] . Then add stop=[\"Observation:\"]. [code] It will work fine. But I don't know why adding [code] in Observation will lose last chunk, LOL"}, {"author": "hippopond", "created_at": "2024-11-07T08:22:17Z", "body_clean": "LOL. These LLM very unpredictable.... I like your workaround: put in the \"stop=[\"Observation:\"]\""}, {"author": "qingwli", "created_at": "2024-11-07T08:27:29Z", "body_clean": "Looks like add \"stop=[\"Observation:\"]\" is the only way we can do It's better than changing the prompt like let the agent add 2 spaces. It's more unstable, sometime like you said will add '2' at the end. It does not fix this issue totally but can avoid this issue , LOL. FYI @format37 @avyrodov"}, {"author": "hippopond", "created_at": "2024-11-07T08:30:06Z", "body_clean": "Just an FYI: When I run a session, and do a: netstat ant | grep i 127 I get a pair of: tcp4 0 0 127.0.0.1.11434 127.0.0.1.62591 ESTABLISHED tcp4 0 0 127.0.0.1.62591 127.0.0.1.11434 ESTABLISHED I have to do TWO different terminals: tcpflow i any c 'not port 11434' tcpflow i any c 'not port 62591' The 2 different tcpflow captures: 1) 1 captures the prompt and response 2) the other captures the Model setup and loading."}, {"author": "qingwli", "created_at": "2024-11-07T08:33:47Z", "body_clean": "Interesting, I run tcpflow i any c 'port 11434' in mac, I can see everything"}]}, {"ollama_summary": "The issue reports a bug in LangChain where the model incorrectly answers questions when it shouldn’t, despite thorough searching and checking resources. The model seems to be exhibiting a problem with its internal knowledge and response generation, not the code itself.  The proposed solution is to add a specific prompt instruction to guide the model to only utilize available information, improving the accuracy of the answers.", "final_category": "bug", "comments": [{"author": "Googlogogo", "created_at": "2024-10-28T23:22:37Z", "body_clean": "Hi, we are a group of 4 students from University of Toronto, could we take a look at this issue? Thanks!"}, {"author": "nadgeri14", "created_at": "2024-10-29T09:14:44Z", "body_clean": "Hi, thanks for the help, I already have a solution. I am waiting for the bug to be assigned to me so that i can create a pull request."}, {"author": "Googlogogo", "created_at": "2024-10-29T14:50:29Z", "body_clean": "Hi Abhishek, Thank you for telling me that! In this case, good luck moving forward! Best, Gogo On Tue, Oct 29, 2024 at 5:15 AM Abhishek Nadgeri @ . wrote: Hi, thanks for the help, I already have a solution. I am waiting for the bug to be assigned to me so that i can create a pull request. — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you commented.Message ID: @ ."}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe LangChain documentation lacks comprehensive details about tool integrations, particularly regarding subscription details, regional availability, and model support, hindering developer adoption.  The issue proposes enhancing the documentation with filterable tables to improve usability and simplify integration for developers, supported by a prepared notebook with examples.", "final_category": "other", "comments": [{"author": "efriis", "created_at": "2024-12-05T23:03:18Z", "body_clean": "super thorough and appreciate the notebook! Going to convert this to a discussion and write some thoughts / solicit ideas on improvement. Fully agreed there's some low hanging fruit to fix now, and would also love to come up with concrete issues that can be improved either by the OSS community or by the maintainers when we have more capacity"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe documentation currently focuses on “AWS” and needs to be updated to reflect the broader “Bedrock” platform, which encompasses SageMaker.  The issue highlights a need to restructure the documentation to better categorize it under the Bedrock tab, aligning with a previous design.  Currently, there’s a request to move the documentation to the left side of the page.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-25T16:00:57Z", "body_clean": "Hi, @rsgrewal aws. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The issue is about the categorization of Bedrock documentation. Currently, it's under the \"AWS\" tab, but you suggest moving it back to the \"Bedrock\" tab. The reason is that the \"AWS\" category is too broad and includes other services like SageMaker. There have been no further comments or developments on this issue. Next Steps Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue reports difficulty using HuggingFaceEmbeddings and HuggingFaceBgeEmbeddings within LangChain. Initial troubleshooting efforts – searching documentation, using GitHub search, and checking other resources – haven't identified a solution. The problem appears to be a bug within LangChain itself, as updating the latest version doesn’t resolve it.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-25T16:00:56Z", "body_clean": "Hi, @suvraadeep. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an [code] when using [code] with the \"sentence transformers/all mpnet base v2\" model. You attempted to resolve the issue by updating to the latest version of LangChain. You believe the problem lies within the library itself. No further activity or comments have been made on the issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["LangChain’s integration issues with the AgentExecutor could be a systemic bug, impacting multiple components, requiring a comprehensive fix.", "Documentation gaps are a common issue, hindering developer adoption and requiring a focused improvement effort.", "The lack of detailed tool integration information impacts developer experience and could be addressed with a more structured approach.", "The bug is likely within LangChain itself, necessitating a fix rather than a tool-specific issue.", "Addressing this bug will improve developer experience and adoption."], "technical_insights": ["LangChain’s AgentExecutor integration needs thorough testing and debugging, potentially involving updated integration logic.", "The documentation regarding tool integrations needs a prioritized revamp, focusing on key features and supported platforms.", "The bug's root cause might be a subtle coding error within LangChain’s core agent execution, requiring deep investigation.", "The bug may be related to a specific version of LangChain, requiring a rollback to a stable version.", "Enhanced documentation with visual aids and clear examples will improve developer usability."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. LangChain’s integration issues with the AgentExecutor could be a systemic bug, impacting multiple components, requiring a comprehensive fix.\n2. Documentation gaps are a common issue, hindering developer adoption and requiring a focused improvement effort.\n3. The lack of detailed tool integration information impacts developer experience and could be addressed with a more structured approach.\n4. The bug is likely within LangChain itself, necessitating a fix rather than a tool-specific issue.\n5. Addressing this bug will improve developer experience and adoption.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s AgentExecutor integration needs thorough testing and debugging, potentially involving updated integration logic.\n2. The documentation regarding tool integrations needs a prioritized revamp, focusing on key features and supported platforms.\n3. The bug's root cause might be a subtle coding error within LangChain’s core agent execution, requiring deep investigation.\n4. The bug may be related to a specific version of LangChain, requiring a rollback to a stable version.\n5. Enhanced documentation with visual aids and clear examples will improve developer usability.\n\n", "batch_number": 193, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "This issue addresses a problem where the multi-agent supervisor example fails to work with ChatOllama when using two system prompts. The bug stems from the LangChain integration, specifically when the system prompt includes two separate instructions, causing the supervisor to misinterpret the task and produce incorrect results.", "final_category": "bug", "comments": [{"author": "EmPajak21", "created_at": "2024-10-29T20:50:20Z", "body_clean": "I also have the same issue and error message"}, {"author": "aguilarcarboni", "created_at": "2024-12-01T03:54:29Z", "body_clean": "Has to do with Ollama's API and how it handle's system prompts, not langchain."}]}, {"ollama_summary": "The AzureSearch integration in LangChain is causing an error, specifically when attempting to del the AzureSearch object. This issue is reproducible and not resolved by updating the LangChain version. The error occurs when the system is shutting down, likely due to a problem with the AzureSearch integration itself.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-10-27T22:02:39Z", "body_clean": "It has nothing to do with Langchain, their is something wrong with your python environment. Or how you are starting the asyncio event loop. Can you share code so I can help you better"}, {"author": "paprocki-r", "created_at": "2024-11-07T14:11:48Z", "body_clean": "related [link]"}, {"author": "dosubot[bot]", "created_at": "2025-02-06T16:00:52Z", "body_clean": "Hi, @codenamics. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You are experiencing an [code] with the AzureSearch integration during Python's shutdown process. You are using the latest version of LangChain and following the documentation. \"keenborder786\" suggested the issue might be related to your Python environment or the asyncio event loop. \"paprocki r\" referenced a potentially related issue, linking to GitHub issue langchain ai/langchain community 188 for additional context. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "thecaptain2000", "created_at": "2025-02-10T18:02:41Z", "body_clean": "The issue is still relevant, I have created the environment today in two different systems using conda and these ar the packages I install: azure storage azure storage blob azure identity azure search documents langchain openai langchain community langchain text splitters python dotenv streamlit streamlit chat unstructured model = \"gpt 4o mini\" vector store address: str = f\" [link] vector store address: str = f\" [link] os.environ[\"OPENAI API KEY\"]=os.getenv(\"MYOPENAI API KEY\") embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=model, chunk size=1) embeddings = OpenAIEmbeddings( deployment=model, chunk size=1000, openai api key=os.environ[\"OPENAI API KEY\"] ) index name: str = \"langchain vector demo\" def sync embed query(text): return asyncio.run(embeddings.aembed query(text)) vector store = AzureSearch( azure search endpoint=vector store address, azure search key=os.environ.get(\"AZURE COGNITIVE SEARCH API KEY\"), index name=index name, embedding function=embeddings.embed query, embedding function=embeddings.embed query, ) loader = AzureBlobStorageContainerLoader( conn str=os.environ.get(\"AZURE CONN STRING\"), container=os.environ.get(\"CONTAINER NAME\"), ) documents = loader.load() text splitter = CharacterTextSplitter(chunk size=150, chunk overlap=20) docs = text splitter.split documents(documents) returns an error: Exception ignored in: <function AzureSearch. del at 0x77dff6bee4c0 Traceback (most recent call last): File \"/home/renato/miniconda3/envs/azure/lib/python3.9/site packages/langchain community/vectorstores/azuresearch.py\", line 422, in del File \"/home/renato/miniconda3/envs/azure/lib/python3.9/asyncio/events.py\", line 725, in get event loop policy File \"/home/renato/miniconda3/envs/azure/lib/python3.9/asyncio/events.py\", line 718, in init event loop policy ImportError: sys.meta path is None, Python is likely shutting down the result is the metadata is loaded into the index WITHOUT the embeddigs."}, {"author": "dosubot[bot]", "created_at": "2025-02-10T18:05:08Z", "body_clean": "@eyurtsev, the user @thecaptain2000 has confirmed that the issue with the [code] during Python's shutdown process is still relevant and has provided additional context about their environment setup. Could you please assist them with this issue?"}, {"author": "ivanvaccarics", "created_at": "2025-04-02T15:01:40Z", "body_clean": "The only workaround i found is to encapsulate the code inside an async function, any news on this topic?"}, {"author": "thecaptain2000", "created_at": "2025-04-02T15:05:05Z", "body_clean": "no and the workaround does not work as I do not see the embedding vector value in the vector DB Il giorno mer 2 apr 2025 alle ore 17:02 Ivan Vaccari < @ . ha scritto: The only workaround i found is to encapsulate the code inside an async function, any news on this topic? — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you were mentioned.Message ID: @ . [image: ivanvaccarics] ivanvaccarics left a comment (langchain ai/langchain 27643) < [link] The only workaround i found is to encapsulate the code inside an async function, any news on this topic? — Reply to this email directly, view it on GitHub < [link] or unsubscribe < [link] . You are receiving this because you were mentioned.Message ID: @ ."}, {"author": "dosubot[bot]", "created_at": "2025-07-02T16:01:39Z", "body_clean": "Hi, @codenamics. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported an [code] during Python's shutdown with AzureSearch in LangChain, possibly due to [code] being [code] . User \"keenborder786\" suggested the issue might be related to the Python environment or asyncio event loop. User \"thecaptain2000\" confirmed the issue persists across different systems and provided detailed code and package information. User \"ivanvaccarics\" proposed a workaround with an async function, but it didn't resolve the embedding vector issue. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue describes a problem where the LangChain integration for vLLM serve doesn't work correctly, causing errors when attempting to execute a specific command.  Initial research and searches yielded no similar issues, suggesting a potential bug within the LangChain integration. The user is attempting to use a specific command and encountering errors, and the issue is not being addressed by updating the LangChain version.", "final_category": "question", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-24T16:01:03Z", "body_clean": "Hi, @Jimmy L99. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You are trying to integrate LangChain with the [code] tool. The goal is to facilitate function calls using a specific model configuration. Example code and configuration details have been shared. You are facing challenges with the integration process and have requested assistance. There have been no comments or developments on this issue yet. Next Steps Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "wangsiyu666", "created_at": "2025-07-30T09:26:08Z", "body_clean": "vllm start parameters add auto tool choice"}]}, {"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\nThe issue focuses on the lack of robust error handling for data parsing within the codebase, specifically when attempts to fix errors fail.  The core request is to improve the documentation by explicitly detailing how to handle parsing errors in all scenarios, particularly when the LLM-based fix attempts fail.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-24T16:01:05Z", "body_clean": "Hi, @han xiao upright. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You highlighted the need for improved documentation on managing data parsing errors. Current methods like prompting LLMs or retrying are not always reliable. Proposed enhancing the output parser class for better error handling in worst case scenarios. No further comments or developments have been made on this issue. Next Steps: Is this issue still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The code exhibits a bug where the `tool calls` returned by LangChain are not always structured as a valid dictionary, leading to inconsistencies and errors. Specifically, the `tool calls` returned in the second AIMessage are incorrectly formatted as a nested, escaped string, causing issues with parsing and potentially impacting the LLM's behavior.  The code attempts to resolve this by adding a `print` statement for debugging, but the root cause remains a structural mismatch in the returned data.", "final_category": "bug", "comments": [{"author": "ccq1", "created_at": "2024-10-25T03:40:43Z", "body_clean": "![image]( [link] This is a potential solution to the issue."}, {"author": "keenborder786", "created_at": "2024-10-26T11:05:52Z", "body_clean": "@ccq1, their were couple of issues with your code which I have corrected, please have a look at below update code [code]"}, {"author": "dosubot[bot]", "created_at": "2025-01-25T16:00:57Z", "body_clean": "Hi, @ccq1. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where [code] was not consistently returned as a valid dictionary. Despite updating to the latest version, the issue persisted. You provided a potential solution, and @keenborder786 responded with a corrected version of the code. The updated code ensures proper handling of [code] and tool integration within LangChain. Next Steps: Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Error handling for LangChain integration is a critical area for improvement.", "Data parsing errors are a recurring challenge, requiring more robust documentation.", "Structured data output from LangChain calls needs clarification.", "Integration testing is insufficient, leading to unexpected bugs.", "LangChain’s data handling needs better validation."], "technical_insights": ["LangChain’s system prompt handling is the root cause of the supervisor’s failure.", "AzureSearch integration’s API issue likely impacts the entire system.", "LangChain’s vLLM serve integration has a bug causing shutdown errors.", "Data parsing errors within LangChain calls are a persistent problem.", "The debugging print statement is a workaround, not the solution."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Error handling for LangChain integration is a critical area for improvement.\n2. Data parsing errors are a recurring challenge, requiring more robust documentation.\n3. Structured data output from LangChain calls needs clarification.\n4. Integration testing is insufficient, leading to unexpected bugs.\n5. LangChain’s data handling needs better validation.\n\nTECHNICAL INSIGHTS:\n1. LangChain’s system prompt handling is the root cause of the supervisor’s failure.\n2. AzureSearch integration’s API issue likely impacts the entire system.\n3. LangChain’s vLLM serve integration has a bug causing shutdown errors.\n4. Data parsing errors within LangChain calls are a persistent problem.\n5. The debugging print statement is a workaround, not the solution.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n", "batch_number": 194, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here's a 2-3 sentence summary of the GitHub issue:\n\n**Problem:** A LangChain community member is experiencing failing unit tests when running with SQLAlchemy 2.0.36.\n\n**Key Details:** The issue stems from a requirement to ensure the latest SQLAlchemy version is installed, which is causing the unit tests to fail.\n\n**Proposed Solution:** The issue requests a LangChain community-driven solution to install and verify the latest SQLAlchemy version.", "final_category": "bug", "comments": [{"author": "Aarya2004", "created_at": "2024-10-24T23:44:37Z", "body_clean": "Hello @baskaryan! I'm investigating this error now. I'll add a comment when I have some clarity on some possible causes. Do you have any idea why this error may be thrown? (Just to know if you have an idea how to approach the fix)"}, {"author": "Aarya2004", "created_at": "2024-10-25T02:29:54Z", "body_clean": "It appears that [this bug]( [link] [and the commit to fix it ]( [link] caused this code to error out (since it seems to be working fine with sqlalchemy v2.0.35). It seems that the REGCLASS typecasting done is not a type supported by duckdb and causes this error. I will be looking for workaround for this but if you have any suggestions on how to fix the issue, do let me know! Edit: There was an issue brought up in the sqlalchemy repo: [link]"}, {"author": "Aarya2004", "created_at": "2024-11-02T18:55:41Z", "body_clean": "Update: Got a PR going with the fixes to this issue. Once it's been approved and merged, this issue should be resolved. The PR Mause/duckdb engine 1147"}, {"author": "Aarya2004", "created_at": "2024-11-07T16:54:54Z", "body_clean": "Hello! We were able to merge our PR in the duckdb engine repo ( [link] Once our updates are released, this issue should be fixed!"}, {"author": "Aarya2004", "created_at": "2024-12-10T03:49:48Z", "body_clean": "@efriis Sorry while you are closing issues, I think this could be closed as well? The fix has been released, the package just needs to be updated and the test should be fixed."}]}, {"ollama_summary": "The issue reports a critical problem – SSL certificate verification failure when connecting to MongoDB Atlas using the provided connection string. This prevents the LangChain integration from establishing a secure connection, causing errors. The problem is suspected to be a configuration issue within LangChain itself, rather than a bug in the code, and the solution involves ensuring TLS is properly configured.", "final_category": "bug", "comments": [{"author": "codenamics", "created_at": "2024-10-24T23:01:46Z", "body_clean": "install certificates on mac application/python install certs"}]}, {"ollama_summary": "This issue stems from a serialization problem when saving a FAISS vector store using the LangChain library. The `__pydantic_private__` attribute within the `[code]` method is causing an error during the saving process, leading to a specific error message. The code attempts to save a FAISS vector store, but the issue is related to the serialization process and the `__pydantic_private__` attribute.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-23T16:00:56Z", "body_clean": "Hi, @sidsanc. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a serialization error with the [code] method in the [code] library. The error is related to the [code] attribute, preventing the FAISS vector store from being saved. Example code and reproduction steps were provided. No further comments or developments have been made on this issue. Next Steps: Could you confirm if this issue is still relevant with the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there is no response, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in LangChain that prevents the import of the `HuggingFaceBgeEmbeddings` and `huggingfaceembeddings` modules, despite the system being configured correctly.  The problem isn’t directly related to the latest version of LangChain, and attempts to update haven’t resolved it.  The code demonstrates the import failure with an error message and stack trace.", "final_category": "bug", "comments": [{"author": "giuliaguglielmi123", "created_at": "2024-10-27T20:08:44Z", "body_clean": "I've been trying to replicate your error without success, I can indeed correctly extract the vector embedding without error. However I noticed that you have python 3.10 whereas mine is 3.12.3 version. Besides, why it tries to import transformers ? When I tried to replicate the issue it instead used sentence transformers, did you install it ?"}, {"author": "dosubot[bot]", "created_at": "2025-01-26T16:03:18Z", "body_clean": "Hi, @suvraadeep. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You encountered an [code] related to 'openssl' when importing [code] from LangChain. You confirmed this as a bug in LangChain, despite updating to the latest version. Another user, @giuliaguglielmi123, could not replicate the issue and noted a difference in Python versions (3.10 vs. 3.12.3). There was a question about the import of [code] instead of [code] . Next Steps: Could you please check if this issue is still relevant with the latest version of the LangChain repository? If it is, feel free to comment here to keep the discussion open. If there are no further updates, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue stems from a bug in LangChain that causes warnings related to protected namespaces, specifically concerning the `model_name` field in JinaEmbeddings. The bug persists despite updates to the latest stable version of LangChain and doesn’t appear to be a problem with the code itself, suggesting it’s a fundamental issue within the library’s design.", "final_category": "bug", "comments": [{"author": "gawbul", "created_at": "2024-10-24T10:20:48Z", "body_clean": "I'm working on a PR for this now 👍"}, {"author": "gawbul", "created_at": "2024-10-25T14:43:10Z", "body_clean": "The PR has been merged. Just waiting for a new release version."}, {"author": "dosubot[bot]", "created_at": "2025-01-24T16:01:07Z", "body_clean": "Hi, @gawbul. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported warnings related to Pydantic's protected namespaces in LangChain. Despite updating, the issue persisted, and you suggested a fix. You submitted a pull request to address the issue, which has been merged. The resolution is pending the release of a new version. Next Steps: Please confirm if this issue is still relevant to the latest version of LangChain. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Dependency management is critical; failing dependencies can severely impact project stability.", "Testing needs to be prioritized; failing tests early in the development cycle is costly.", "Code quality impacts reliability; addressing bugs early prevents future issues.", "Version control is vital; ensuring consistent code across different releases.", "Communication between community members is key; collaborative problem-solving is essential."], "technical_insights": ["SQLAlchemy 2.0.36 issue is a core dependency; failing tests indicates a fundamental problem.", "SSL certificate verification failure in MongoDB Atlas; suggests configuration issues.", "LangChain serialization problem; __pydantic_private__ attribute error requires investigation.", "Import errors for HuggingFaceBgeEmbeddings and huggingfaceembeddings modules; not related to LangChain version.", "Protected namespace warnings; potential design flaw within LangChain library."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Dependency management is critical; failing dependencies can severely impact project stability.\n2.  Testing needs to be prioritized; failing tests early in the development cycle is costly.\n3.  Code quality impacts reliability; addressing bugs early prevents future issues.\n4.  Version control is vital; ensuring consistent code across different releases.\n5.  Communication between community members is key; collaborative problem-solving is essential.\n\nTECHNICAL INSIGHTS:\n1.  SQLAlchemy 2.0.36 issue is a core dependency; failing tests indicates a fundamental problem.\n2.  SSL certificate verification failure in MongoDB Atlas; suggests configuration issues.\n3.  LangChain serialization problem; `__pydantic_private__` attribute error requires investigation.\n4.  Import errors for `HuggingFaceBgeEmbeddings` and `huggingfaceembeddings` modules; not related to LangChain version.\n5.  Protected namespace warnings; potential design flaw within LangChain library.\n", "batch_number": 195, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a bug in LangChain's `deepinfra.chat` model that fails to parse a JSON input with an empty tool call argument, leading to a JSONDecodeError. This problem is currently unresolved with the latest stable version of LangChain, and the solution involves adding a parser to handle empty arguments.", "final_category": "bug", "comments": []}, {"ollama_summary": "The issue stems from a bug in the `DallEAPIWrapper` library that doesn’t correctly support the base URL setting required by the OpenAI SDK. This causes the code to fail to utilize the intended functionality, resulting in an error message and stack trace. The code is currently stable and doesn’t require a fix, suggesting it’s a bug within the LangChain integration package itself.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-23T16:00:56Z", "body_clean": "Hi, @overheat. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that the [code] in LangChain lacks support for the [code] setting. This feature is available in the OpenAI SDK but missing in LangChain. You confirmed this is a bug within LangChain and not related to your own code. The issue persists even after updating to the latest version. No further comments or developments have been made on this issue. Next Steps: Please let us know if this issue is still relevant to the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a \"ConfigError\" related to the `PowerBIDataSet` credential, specifically a \"ForwardRef\" type field that hasn't been fully prepared. This prevents the LLM from correctly accessing the PowerBI data, requiring a local workaround.", "final_category": "bug", "comments": [{"author": "zhaoJoseph", "created_at": "2024-10-23T16:24:29Z", "body_clean": "This seems like a straightforward issue, me and a group of students from the University of Toronto are eager to help with LangChain, could my team look into this issue?"}, {"author": "eyurtsev", "created_at": "2024-10-24T14:32:57Z", "body_clean": "This looks like a bug in user code + bad errors from pydantic. Likely nothing that needs to be done in langchain side. [code] is this pydantic v1? This \"ConfigError: field \"credential\" not yet prepared so type is still a ForwardRef, you might need to call PowerBIDataset.update forward refs().\" and this path [code] Suggest that user code is using pydantic.v1."}, {"author": "eyurtsev", "created_at": "2024-10-24T14:35:15Z", "body_clean": "@jerschi could you check whether [code] is a pydantic.v1 or a pydantic object?"}, {"author": "jerschi", "created_at": "2024-10-24T16:53:12Z", "body_clean": "Sorry @eyurtsev , I don't understand that question. My pydantic version is 2.8.2. The code is from the langchain documentation ( [link]"}, {"author": "jerschi", "created_at": "2024-10-24T17:13:51Z", "body_clean": "Out of curiosity i created a new environment with just the packages needed to execute the code and it still doesn't work; [code]"}, {"author": "zhaoJoseph", "created_at": "2024-10-25T04:56:19Z", "body_clean": "Can confirm @jerschi, I ran the same code and got the same error. when I remove type checking here [link] [code] to [code] as suggested by [link] it works completely fine and also needed to define output token limit in PowerBIToolkit."}, {"author": "dosubot[bot]", "created_at": "2025-01-24T16:01:14Z", "body_clean": "Hi, @jerschi. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves a bug in the LangChain library with the [code] field in [code] causing a [code] error. @eyurtsev suggested the problem might be related to user code and pydantic versioning. You confirmed using pydantic version 2.8.2 and encountered the same error in a new environment. @zhaoJoseph confirmed the issue and suggested a workaround by modifying the import statement for [code] . The issue was resolved by modifying the import statement, aligning with a previous pull request suggestion. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting on the issue. Otherwise, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue stems from a bug in the `ChatBedrockConverse` library that causes it to fail to correctly generate content and max tokens, specifically when using LangChain. The code attempts to use the `chat model` function, but it encounters an error when the content is generated as a list.  The problem is likely related to the library's internal handling of the `max_tokens` setting and the way it interacts with the `chat model` function.", "final_category": "bug", "comments": [{"author": "idotr7", "created_at": "2024-10-23T11:21:19Z", "body_clean": "also i was unable to use the: meta.llama3 2 3b instruct v1:0 model id claiming it is not on demand throughput, although it is. botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the ConverseStream operation: Invocation of model ID meta.llama3 2 3b instruct v1:0 with on demand throughput isn’t supported. Retry your request with the ID or ARN of an inference profile that contains this model. with other model id it works well."}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe Langchain documentation lacks sufficient detail regarding the filter syntax and how to use the various object types (like `[code]` objects) effectively, hindering users’ ability to effectively utilize the filtering capabilities. The documentation is fragmented between the main Langchain doc and specific vector store documentation, making it difficult to understand the distinctions between the different types of filter expressions.  The issue requests improved documentation clarity, particularly regarding nested filter conditions and the proper usage of the `[code]` object.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-22T16:01:05Z", "body_clean": "Hi, @Voileexperiments. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue highlights insufficient documentation on filter syntax in LangChain. Specific concerns include unclear usage of [code] objects and [code] . Documentation is scattered between LangChain's main and vector store documentation. A request for examples of complex filter queries, including nested conditions, was made. Next Steps: Please let us know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no further input, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "Voileexperiments", "created_at": "2025-01-22T17:02:57Z", "body_clean": "bump"}, {"author": "dosubot[bot]", "created_at": "2025-01-22T17:05:08Z", "body_clean": "@eyurtsev, the user @Voileexperiments has indicated that this issue regarding insufficient documentation on filter syntax in LangChain is still relevant. Could you please assist them with this?"}]}], "business_insights": ["Comprehensive documentation is crucial for users to effectively leverage LangChain’s filtering capabilities.", "Fragmented documentation creates confusion and hinders user adoption.", "Improved clarity across both the main Langchain doc and vector store documentation would benefit many users.", "Addressing the filter syntax and [code] object usage directly impacts user experience.", "Streamlining the documentation will increase user satisfaction and productivity."], "technical_insights": ["LangChain's deepinfra.chat model has a bug causing JSONDecodeError with empty input arguments.", "DallEAPIWrapper fails to correctly utilize the base URL for OpenAI SDK, leading to an error.", "ConfigError related to the PowerBIDataSet credential prevents LLM access.", "ChatBedrockConverse library generates incorrect content due to max_tokens and chat model function interaction.", "Filter syntax and [code] object usage documentation is fragmented and unclear."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Comprehensive documentation is crucial for users to effectively leverage LangChain’s filtering capabilities.\n2. Fragmented documentation creates confusion and hinders user adoption.\n3. Improved clarity across both the main Langchain doc and vector store documentation would benefit many users.\n4. Addressing the filter syntax and `[code]` object usage directly impacts user experience.\n5. Streamlining the documentation will increase user satisfaction and productivity.\n\nTECHNICAL INSIGHTS:\n1. LangChain's `deepinfra.chat` model has a bug causing JSONDecodeError with empty input arguments.\n2. `DallEAPIWrapper` fails to correctly utilize the base URL for OpenAI SDK, leading to an error.\n3. `ConfigError` related to the `PowerBIDataSet` credential prevents LLM access.\n4. `ChatBedrockConverse` library generates incorrect content due to max_tokens and `chat model` function interaction.\n5. Filter syntax and `[code]` object usage documentation is fragmented and unclear.\n\nRULES:\nBUSINESS INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]\n\nTECHNICAL INSIGHTS:\n1. [insight here]\n2. [insight here]\n3. [insight here]\n4. [insight here]\n5. [insight here]", "batch_number": 196, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue concerns a discrepancy between the documentation for Bedrock Embeddings and Langchain’s integration with AWS Embedding Models. The current documentation incorrectly references a specific code module, prompting a preference for a similar integration strategy as used for chat/LLM models.  The core request is to align the documentation with best practices and potentially adopt a more consistent approach for these models.", "final_category": "other", "comments": [{"author": "athewsey", "created_at": "2024-10-24T05:46:50Z", "body_clean": "Ah just realised this is an outdated doc for v0.1x... v0.3 seems to have clarified things already but it wasn't ranking for our queries on Google so we were looking at the old doc."}]}, {"ollama_summary": "The issue reports a bug in LangChain where the `loadEvaluator` function fails to correctly calculate the Euclidean distance between embeddings when the `option` field is missing for the `llm` parameter.  The code attempts to use the `llm` option, but the error occurs when the required `llm` parameter isn't present, suggesting a potential issue with the integration of the `llm` option within the `loadEvaluator` function.", "final_category": "bug", "comments": [{"author": "trend-ouki-wang", "created_at": "2024-10-23T06:44:28Z", "body_clean": "sorry, wrong repo"}]}, {"ollama_summary": "This issue is related to a critical bug in the LangChain library, specifically when initializing the `GoogleScholarAPIWrapper` component. The code attempts to use a `SERP API KEY` which is not properly validated, leading to a `ValidationError` and preventing the integration with the Google Scholar engine.  The issue is currently unresolved and requires a fix, potentially involving a change to the LangChain library itself.", "final_category": "bug", "comments": []}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\nThe “docs/ignore-step.sh” script is failing to correctly handle accumulation of sub-PRs on feature branches, resulting in inconsistent behavior. This is a priority issue for the LangChain maintainer, as it impacts the script’s functionality and potentially other related tools.  The current solution is to investigate and potentially adjust the script’s logic to accommodate this scenario.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-21T16:02:12Z", "body_clean": "Hi, @efriis. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The [code] script fails for PRs with multiple sub PRs on a feature branch. The issue is demonstrated by the first 16 commits in a specific PR. It is considered low priority as the script works well in other scenarios. No further comments or developments have been made. Next Steps Please confirm if this issue is still relevant to the latest version of the LangChain repository. If so, you can keep the discussion open by commenting here. Otherwise, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "This issue involves a bug in the LangChain Chatollama component that fails to utilize the custom tools generated by the integrated search. The code attempts to leverage the `rag` and `general` tools, but the `custom agent` function isn't correctly invoking them, resulting in an incorrect answer.  The issue appears to be a fundamental bug within the tool integration process.", "final_category": "bug", "comments": [{"author": "xnnxnyx", "created_at": "2024-10-22T15:11:34Z", "body_clean": "Hello! We're a group of students from the University of Toronto Scarborough, and we're excited to contribute to LangChain. We'd love the opportunity to investigate this bug further."}, {"author": "dosubot[bot]", "created_at": "2025-01-21T16:02:10Z", "body_clean": "Hi, @26Kenn07. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported a bug where Chatollama is not utilizing custom tools like [code] and [code] . The issue persists despite updating to the latest version of LangChain. A group of students from the University of Toronto Scarborough, represented by @xnnxnyx, has shown interest in investigating this further. Next Steps: Please confirm if this issue is still relevant with the latest version of LangChain. If it is, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Documentation discrepancies are a recurring source of confusion for users, requiring focused attention.", "Consistent documentation is crucial for developer experience and maintainability.", "Aligning documentation with best practices improves usability and reduces support requests.", "Clear documentation minimizes ambiguity and reduces the need for troubleshooting.", "Updated documentation is vital for maintaining software quality and stability."], "technical_insights": ["Incorrect documentation referencing an outdated code module is a significant issue.", "The loadEvaluator bug impacts the llm integration, potentially affecting the GoogleScholarAPIWrapper.", "The LangChain library’s GoogleScholarAPIWrapper initialization is vulnerable to validation errors.", "The serp api key validation within the loadEvaluator function needs careful attention.", "The docs/ignore-step.sh script’s accumulation of sub-PRs is causing inconsistency."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. Documentation discrepancies are a recurring source of confusion for users, requiring focused attention.\n2. Consistent documentation is crucial for developer experience and maintainability.\n3. Aligning documentation with best practices improves usability and reduces support requests.\n4. Clear documentation minimizes ambiguity and reduces the need for troubleshooting.\n5. Updated documentation is vital for maintaining software quality and stability.\n\nTECHNICAL INSIGHTS:\n1.  Incorrect documentation referencing an outdated code module is a significant issue.\n2.  The `loadEvaluator` bug impacts the `llm` integration, potentially affecting the `GoogleScholarAPIWrapper`.\n3.  The `LangChain` library’s `GoogleScholarAPIWrapper` initialization is vulnerable to validation errors.\n4.  The `serp api key` validation within the `loadEvaluator` function needs careful attention.\n5.  The `docs/ignore-step.sh` script’s accumulation of sub-PRs is causing inconsistency.\n\n", "batch_number": 197, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "The issue stems from a bug in the LangChain Ollama Gemma 2 model that limits the maximum sequence length to 6214 tokens, preventing the model from processing longer prompts.  The problem isn’t directly in the code but rather a limitation within the model itself, and attempts to fix it by updating to the latest stable version of LangChain haven’t resolved the issue.  The user is seeking guidance on how to increase this maximum sequence length.", "final_category": "bug", "comments": [{"author": "AntonioFerreras", "created_at": "2024-10-22T19:24:39Z", "body_clean": "Hi Alexander! I'm on a team of 4 from the University of Toronto and we can take a look into this issue."}, {"author": "dosubot[bot]", "created_at": "2025-01-21T16:02:21Z", "body_clean": "Hi, @JohannFaust666. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported an issue with the LangChain Ollama Gemma 2 model, where the input sequence length is limited to 1024 tokens. The model is expected to support up to 8000 tokens, and you are seeking a solution to increase the sequence length without using MapReduce and chunking methods. AntonioFerreras from the University of Toronto has offered to investigate the issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of the LangChain repository? If so, feel free to comment here to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}, {"author": "hajiabadi-finbridge", "created_at": "2025-03-04T15:34:40Z", "body_clean": "I'm using [code] However I've tried [code] for a quite long text and got the response [code] together with a warning [code] So can the model now work with 8192 tokens or not? I'm using langchain ollama==0.2.2"}]}, {"ollama_summary": "The GitHub issue reports a bug in LangChain where the `azure_search_key` parameter is not optional and defaults to `None`. This is causing issues when initializing the LangChain client, specifically when using a ManagedIdentity locally. The proposed solution is to make the parameter optional and default to `None` within the code.", "final_category": "bug", "comments": [{"author": "e-than-c", "created_at": "2024-10-22T16:19:40Z", "body_clean": "Hi @koberghe, we're a group of University of Toronto students. Do you mind if we try to implement this fix and submit a PR for this issue?"}, {"author": "dosubot[bot]", "created_at": "2025-01-21T16:02:22Z", "body_clean": "Hi, @koberghe. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue suggests making the [code] parameter optional in the [code] class. This change would allow the use of [code] when the key is not provided, supporting ManagedIdentity scenarios. @e than c, from the University of Toronto, showed interest in implementing this change, and you responded positively. Next Steps: Could you confirm if this issue is still relevant to the latest version of the LangChain repository? If so, please comment to keep the discussion open. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a problem with outdated documentation for Playwright’s agents, specifically regarding the handling of LLM inference with LangChain. The documentation incorrectly suggests unsupported tools like ChatOpenAI and OpenAI, leading to errors when using these models.  The root cause appears to be a flaw in how the tool handles Pydantic schemas when the model JSON schema is called, impacting the agent’s functionality.", "final_category": "other", "comments": [{"author": "giulio-utf", "created_at": "2024-10-26T15:06:08Z", "body_clean": "that's a problem indeed"}, {"author": "dosubot[bot]", "created_at": "2025-01-25T16:00:57Z", "body_clean": "Hi, @IvannikovG. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary The documentation for integrating Playwright with LangChain is outdated. Issues arise when using agents with language models like ChatOpenAI and OpenAI. An [code] related to the [code] method occurs, likely due to [code] handling. User giulio utf has acknowledged this as a valid concern. Next Steps Could you confirm if this issue is still relevant with the latest version of LangChain? If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The issue involves a bug in LangChain's shell tool that fails to decode specific characters in Windows, specifically when using the `p4.exe` command. This problem is impacting the tool's functionality and requires a solution involving encoding settings.", "final_category": "bug", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-21T16:02:18Z", "body_clean": "Hi, @njnuwjq. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary You reported a [code] in the LangChain shell tool on Windows. The error is due to the 'utf 8' codec failing to decode certain characters. You suggested using 'latin1' encoding as a workaround. There is currently no parameter to set this encoding in the tool. No further activity or comments have been made on this issue. Next Steps Could you please confirm if this issue is still relevant with the latest version of LangChain? If so, feel free to comment to keep the discussion open. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue:\n\nThe issue highlights a missing debugging and tracing guide in the v0.3 documentation, despite the search bar on the top page pointing to the existing documentation.  Users are requesting the guide to be reinstated from the previous version (v0.1) or corrected in the current documentation to ensure comprehensive support for developers.", "final_category": "other", "comments": [{"author": "dosubot[bot]", "created_at": "2025-01-20T16:01:16Z", "body_clean": "Hi, @3coins. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: You reported that the debugging and tracing guide is missing from the v0.3 documentation. The guide appears in search results but is not accessible in the v0.3 documentation. You suggested restoring the guide from v0.1 or fixing the search function. No further comments or developments have been made on this issue. Next Steps: Please let me know if this issue is still relevant to the latest version of the LangChain repository by commenting here. If there is no response, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["Model length limitations necessitate careful sequence length management across all models.", "Updating the latest stable version of LangChain could resolve the sequence length issue.", "Increased sequence length management is crucial for model performance and user experience.", "Understanding the model’s inherent limitations informs development strategy.", "Addressing the sequence length issue will improve model usability."], "technical_insights": ["LangChain Ollama Gemma 2 model has a maximum sequence length of 6214 tokens.", "Updating LangChain ensures compatibility with the latest model version.", "The issue is a model-specific limitation, not a code issue.", "The solution involves adjusting the model’s maximum sequence length.", "Correcting the model’s sequence length limitation is vital for the project."], "raw_llm_response": "BUSINESS INSIGHTS:\n1.  Model length limitations necessitate careful sequence length management across all models.\n2.  Updating the latest stable version of LangChain could resolve the sequence length issue.\n3.  Increased sequence length management is crucial for model performance and user experience.\n4.  Understanding the model’s inherent limitations informs development strategy.\n5.  Addressing the sequence length issue will improve model usability.\n\nTECHNICAL INSIGHTS:\n1.  LangChain Ollama Gemma 2 model has a maximum sequence length of 6214 tokens.\n2.  Updating LangChain ensures compatibility with the latest model version.\n3.  The issue is a model-specific limitation, not a code issue.\n4.  The solution involves adjusting the model’s maximum sequence length.\n5.  Correcting the model’s sequence length limitation is vital for the project.\n\n", "batch_number": 198, "num_issues": 5}
{"batch_issues": [{"ollama_summary": "Okay, here’s a 2-3 sentence summary of the GitHub issue, focusing on the core problem and key details:\n\n**Summary:**  Users are encountering a problem where the schema inspection functionality within LangChain fails when working with special type annotations. This issue is a priority because it impacts the core ability to validate and understand data structures used in LangChain models.  Currently, the issue is being addressed by the maintainer to resolve this issue and ensure consistent schema inspection across the platform.", "final_category": "bug", "comments": [{"author": "chloepan33", "created_at": "2024-10-21T15:27:24Z", "body_clean": "Hey @eyurtsev! We are a group of students from UofT interested in this issue. Is it possible we could know more details of this issue and the desire output?"}, {"author": "eyurtsev", "created_at": "2024-10-21T18:20:19Z", "body_clean": "A tool is an association between: 1. underlying function 2. a schema that describes the function name, description and its inputs There are use cases, where some of the tools inputs should not be controllable by the chat model, but dictated by the application logic. (e.g., [code] should be associated with the user logged into the application and not chosen by the chat model as that would be a (very serious) security vulnerability) We use special type annotations to mark arguments as \"hidden\" from the chat model. This allows us to use the [code] decorator to easily generate a schema that can be presented to a chat model without surfacing other parameters that the chat model should not know about (these parameters will be injected during run time). FYI I haven't triaged this issue yet to determine whether it manifests itself when used with chat models (there might be another code path used) i don't know if this is a high priority issue yet or not, if it's high priority we will likely tackle within a few days time"}, {"author": "chloepan33", "created_at": "2024-10-28T16:04:04Z", "body_clean": "hey @eyurtsev, To confirm our understanding of the issue: The goal is that when we use: [code] The schema generated by [code] should only include the [code] argument, without any reference to [code] , since [code] is meant to be injected at runtime and not controlled by the chat model. Additionally, if we define: [code] The expected output should be: [code] Loop in team members @Chloekyuu @JANERUBBISHTOEAT @XiaoConan"}, {"author": "JANERUBBISHTOEAT", "created_at": "2024-11-12T00:49:44Z", "body_clean": "Our team has determined that modifying the [code] and [code] methods, along with updating the [code] class definition, would address this issue. Does this approach seem appropriate? ccing team: @chloepan33 @Chloekyuu @XiaoConan"}, {"author": "XiaoConan", "created_at": "2024-12-01T03:23:21Z", "body_clean": "Hi @eyurtsev, Our team had identified that the issue arises because the [code] type annotation is not compatible with Pydantic's JSON schema generation. This leads to two primary problems: 1. Schema Generation Failure: When [code] needs to be included as an argument in a tool or model, attempts to generate its JSON schema result in errors (PydanticInvalidForJsonSchema), which makes tools or models with InjectedToolArg arguments uninspectable or imcompatible with workflows requireing schema validation. 2. Argument Filtering Logic: The current [code] function fails to detect runtime injected arguments like [code] , which couldn't be filtering out during the create schema process when we need to exclude such arguments. To address these issues, we propose the following solutions: 1. We create a function [code] to replace the functionality of [code] , which will correctly identify [code] Arguments. This can be helpful in the filtering our runtime injected argument process. 2. We defined [code] that wraps [code] in [code] with a custom schema defined via [code] , which allows [code] to be parsed into a JSON schema format without causing errors, enabling proper inspection and compatibility with [code] . We created a PR here: 28435 Here's a testing file to observe the actual behavior: [code] Loop in team members @Chloekyuu @JANERUBBISHTOEAT @chloepan33"}, {"author": "shruthiR-fauna", "created_at": "2025-01-24T16:11:21Z", "body_clean": "I'm seeing a similar issue when trying to inject runtime args to my custom tool which I've raised here 29412. Please let me know if this PR solves this issue and whether it is worth testing."}, {"author": "dosubot[bot]", "created_at": "2025-04-25T16:01:07Z", "body_clean": "Hi, @eyurtsev. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: The issue involves difficulties with [code] type annotations appearing in the schema accessible to the chat model. A group of students from UofT, including @chloepan33 and @XiaoConan, proposed a solution with modifications to [code] and a custom schema. A pull request ( 28435) has been submitted to implement these changes. @shruthiR fauna reported a similar issue and inquired about the proposed solution's effectiveness. Next Steps: Please confirm if this issue is still relevant to the latest version of the LangChain repository by commenting on this issue. If there is no further activity, the issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}, {"ollama_summary": "The LangChain application is failing to generate expected output when working with custom Azure OpenAI deployments, specifically when attempting a simple \"hello world\" command. Initial troubleshooting revealed the issue isn’t a code bug but a bug within the LangChain integration itself, and attempts to update to the latest version haven’t resolved it. The core problem appears to be a mismatch between the OpenAI library and the LangChain framework.", "final_category": "bug", "comments": [{"author": "keenborder786", "created_at": "2024-10-21T10:39:10Z", "body_clean": "@pratikkejriwal there is something wrong with your Azure Deployment. Try making the temperature to 0. And please double check your azure deployment."}, {"author": "pratikkejriwal", "created_at": "2024-10-21T12:00:10Z", "body_clean": "tried with temperature = 0, same issue: <img width=\"959\" alt=\"image\" src=\" [link] checked the azure deployment could not understand the issue here, cause I am able to get the data properly while using the openai libraries."}, {"author": "dosubot[bot]", "created_at": "2025-01-20T16:01:16Z", "body_clean": "Hi, @pratikkejriwal. I'm [Dosu]( [link] and I'm helping the LangChain team manage their backlog. I'm marking this issue as stale. Issue Summary: LangChain is not working correctly with Azure OpenAI deployments. Despite successful data retrieval using OpenAI libraries, outputs are nonsensical. @keenborder786 suggested checking Azure deployment and setting temperature to 0. You confirmed the issue persists even after these adjustments. You believe the problem lies within LangChain, not your code or configuration. Next Steps: Please let me know if this issue is still relevant to the latest version of LangChain by commenting here. If there is no further activity, this issue will be automatically closed in 7 days. Thank you for your understanding and contribution!"}]}], "business_insights": ["User schema validation is crucial for LangChain models.", "Addressing schema issues impacts model reliability.", "Maintainer’s fix is a priority for core functionality.", "Integration bug impacting custom deployment.", "Collaboration with students enhances issue understanding."], "technical_insights": ["OpenAI library integration is the root cause.", "Schema mismatch causes output errors.", "Update to latest LangChain version is needed.", "Temperature setting needs adjustment.", "Azure deployment configuration must be reviewed."], "raw_llm_response": "BUSINESS INSIGHTS:\n1. User schema validation is crucial for LangChain models.\n2. Addressing schema issues impacts model reliability.\n3. Maintainer’s fix is a priority for core functionality.\n4. Integration bug impacting custom deployment.\n5. Collaboration with students enhances issue understanding.\n\nTECHNICAL INSIGHTS:\n1. OpenAI library integration is the root cause.\n2. Schema mismatch causes output errors.\n3. Update to latest LangChain version is needed.\n4. Temperature setting needs adjustment.\n5. Azure deployment configuration must be reviewed.", "batch_number": 199, "num_issues": 2}
